# 다변량 극단값 이론 {#mevtheory}

이 부분은 [@Dey2015]의 2장을 참고하였다. 많은 경우 marginal GEV distribution과 코퓰라를 혼합해 사용하는데, 이런 경우 extreme-value copula가 아닌 이상 다변량 극단값 분포가 marginal GEV distribution으로 잘 표현되지 않는다. 이 장에서는 다변량 극단값 분포, 극단값 코퓰라, extremal dependence의 측정, 다변량 일반화 파레토 분포, 준모수 조건부 상관성 모형들 그리고 그것들의 통계적 추론에 대해서 다룬다.

## 극한의 정규화(limiting standardization)

$d$-차원 **다변량 극단값 분포(multivariate extreme value distribution, MEVD)**은 d-차원 다변량 분포로부터 무작위로 생성된 값들의 componentwise maxima의 극한 분포로부터 유래한다. $\{\mathbf{X}_{i} = (X_{i,1},\ldots, X_{i,d}):i=1,\ldots, n\}$은 joint distribution $F$, marginal distribution $F_{1}, \ldots, F_{d}$ 그리고 코퓰라 $C_{F}$를 갖는 $d$-차원 무작위벡터로부터 생성된 무작위 표본이라고 하자. 각각의 margin $j=1,\ldots, d$에 대해 적절한 표준화수열(normalizing sequence) $\mathbf{a}_{n}=(a_{n,1},\ldots, a_{n,d})>0$과 $\mathbf{b}_{n}=(b_{n,1},\ldots, b_{n,d})$가 존재해 limiting marginal distribution
$$Z_{n,j} = \frac{M_{n,j}-b_{n,j}}{a_{n,j}}$$
$n\rightarrow\infty$일 때 non-degenerate generalized extreme value distribution을 갖는다고 정의한다. 여기서 우리들의 관심사는 $\mathbf{Z}_{n}=(Z_{n,1},\ldots, Z_{n,d})$의 limiting joint distribution인 $G$ (즉 MEVD)이다. 특별히, $\mathbf{z}\in\mathbb{R}^{d}$에 대해
$$P(\mathbf{Z}_{n}\leq z)=F^{n}(\mathbf{az} +\mathbf{b}) \rightarrow G(\mathbf{z})$$
이다. 여기서 벡터 계산들은 모두 componentwise하다. 이때 분포 $F$는 $G$의 domain of attraction이라고 부르며 $F\in\mathcal{D}(G)$라고 적는다.

MEVD들은 **최대안정성(max-stability)**라는 것으로 특성화되어진다. $d$차원 분포함수 $G$는 모든 정수 $k\geq 1$에서 벡터 $\boldsymbol{\alpha}_{k}>0$와 $\boldsymbol{\beta}_{k}$가 존재해
\begin{equation}
G^{k}(\boldsymbol{\alpha}_{k}\mathbf{z}+\boldsymbol{\beta}_{k}) = G(\mathbf{z}), \qquad{\forall \mathbf{z}\in\mathbb{R}^{d}}
(\#eq:MEVDmaxstable)
\end{equation}
를 만족할 때 최대안정하다라고 말한다. 최대안정 분포 $G$는 그것만의 domain of attraction을 갖는데 그것이 MEVD이다. 또한 역도 성립한다.


## 코퓰라(copula)

이변량 또는 다변량 분포를 만들 수 있는 방법으로 **코퓰라(copula)**라는 것이 있다. 이것은 보험학, 금융, 경제 모델링, 생존분석, 극단값, 환경 모델링, 시계열과 생물통계 등에서 최근에 주목을 받고 있다. 이 부분은 [@Mikosch2006]를 참고하였다.

연속 분포 $F$를 갖고 그것의 support에서 역 $F^{-1}$을 갖는 실변수 확률변수 $X$를 생각해보자. 만약 $U$가 $(0,1)$에서 정의된 균등분포일 때 $X\stackrel{d}{=}F^{-1}(U)$와 $F(X)\stackrel{d}{=}U$임을 쉽게 체크할 수 있다.

이제 respective marginal distribution functions $F_{i}$ (assumed to be continous and have inverse on the support of $X_{i}$)를 갖는 $\mathbb{R}^{d}$차원 무작위벡터 $\mathbf{X}=(X_{1},\ldots, X_{d})$를 생각하보자. 1차원일 때와 같은 방법으로 다음의 결과를 얻을 수 있다.
$$
\begin{align*} 
P(X_{1}\leq F_{1}^{-1}(x_{1}),\ldots, X_{d}\leq F_{d}^{-1}(x_{d})) &=  P(F_{1}(X_{1})\leq x_{1}, \ldots, F_{d}(X_{d})\leq x_{d}) \\ 
 &= C(x_{1},\ldots, x_{d}).
\end{align*}
$$
식의 오른쪽에서 $d$차원 분포함수 $C$는 support $[0,1]^{d}$를 갖고 uniform marginal distribution functions를 갖는다. 이 때 이 분포함수 $C$를 벡터 $\mathbf{X}$의 **코퓰라(copula)**라고 부른다. 한편 $\mathbf{X}$의 copula $C$가 주어졌을 때 우리는 분포함수들 $F_{i}$들을 이용해 $\mathbf{X}$의 distribution function을 재구성할 수 있다.
$$
\begin{align*} 
P(X_{1}\leq y_{1}, \ldots, X_{d}\leq y_{d}) &=  P(F_{1}(X_{1})\leq F_{1}(y_{1}), \ldots, F_{d}(X_{d})\leq F_{d}(y_{d})) \\ 
 &= C(F_{1}(y_{1}),\ldots,F_{d}(y_{d})).
\end{align*}
$$
좀 더 넓은 의미로 $[0,1]^{d}$에서 support를 갖고 uniform marginal을 갖는 분포함수들을 코퓰라라고 부른다.

주변 분포 함수들 $F_{i}$에 대한 가정이 주어졌다면, 코퓰라 $C$와 $\mathbf{X}$의 분포 사이에는 일대일 대응관계가 존재한다. 즉, $X_{1},\ldots, X_{d}$의 상관관계 구조는 코퓰라와 주변분포 $F_{i}$로 재구성될 수 있다는 것이다. 그러나 코퓰라 $C$를 갖는 벡터 $\mathbf{X}=(X_{1},\ldots, X_{d})$와 분포함수 $C$를 갖는 $\mathbf{Y}=(F_{1}(X_{1}), \ldots, F_{d}(X_{d}))$의 dependence structure가 같다고 얘기하는 것은 아니다.

예를 들어, 벡터 $\mathbf{X}$의 상관관계가 정의될 경우, 그것은 보통 $\mathbf{Y}$의 상관관계 구조와 다르다. $X_{1},\ldots, X_{d}$가 zero autocorrelation들을 갖는 seond order stationary process에서 얻은 표본들이라고 하자. 이것에 대응되는 $F_{1}(X_{1}), \ldots, F_{d}(X_{d})$들을 매우 correlated되어 있고 따라서 일반적으로 second order stationary가 아닐 것이다. 마찬가지로 spectral measure도 $\mathbf{X}$ with unbounded support에서 make sense한 $\mathbf{Y}$에서는 그렇지 않다.


```{theorem, name="누적 분포 함수와 코퓰라"}
Sklar (1959)의 정리는 코퓰라 이론의 시작점을 제시하였다. [@Yee2015] $F$가 무작위 벡터 $(Y_{1}, Y_{2})$의 CDF이고 marginal이 $F_{1}$, $F_{2}$일 때, 대응되는 copula $C$가 존재해 다음을 만족한다.
$$F(y_{1}, y_{2})=C(F_{1}(y_{1}), F_{2}(y_{2});\boldsymbol{\alpha})=C(u_{1},u_{2};\boldsymbol{\alpha}).$$
모든 $(y_{1}, y_{2})\in\mathbb{R}^{2}$에 대해 $F_{j}$가 연속이라면 $C$는 unique하다고 할 수 있다.

```

우리는 $C$를 dependency parameter $\boldsymbol{\alpha}$를 통해 $F$의 dependence structure 정보를 담고 있는 것으로 볼 수 있다. 보통 $\boldsymbol{\alpha}$는 1차원 또는 2차원이다.

```{example, name="이변량 가우스 코퓰라"}
$\boldsymbol{\alpha}=\rho$일 때 **이변량 가우스 코퓰라(bivariate Gaussian copula)**는
$$C(u_{1}, u_{2}, \rho)=\Phi_{2}(\Phi^{-1}(u_{1}), \Phi^{-1}(u_{2});\rho), -1<\rho < 1, 0\leq u_{j} \leq 1$$
이다.
  
```

[@Yee2015]는 이변량 코퓰라들의 흥미로운 성질들을 적어놓았다.

1. $C(u_{1}, u_{2})=0$ if $u_{1}=0$ and/or $u_{2}=0$

2. $C(u_{1}, 1) =u_{1}$ and $C(1,u_{2})=u_{2}$

3. For $j=1,2$, $C(u_{1}, u_{2})$ is nondecreasing as $u_{j}$ increases, keeping the other agument fixed.

4. $F$로부터 random variates를 생성하기  위한 방법으로 다음의 방법을 사용한다. 그 전에 $u_{j}$가 증가함에 따라 $C(u_{1}, u_{2})$또한 증가한다는 강한 가정이 필요하다.

- $U_{1}$, $U_{2}$를 standard uniform distribution으로부터 독립적으로 만든다.

- $Z_{2}=C_{U_{2}|U_{1}}^{-1}(u_{2})$ where $C_{U_{2}|U_{1}}(u_{2})=\partial C(u_{1}, u_{2})/\partial u_{1}= P(U_{2}\leq u_{2}|U_{1}=u_{1})$ is the conditional for $U_{2}$ given $U_{1}=u_{1}$.

- Then $(U_{1}, Z_{2})\sim F$.

5. 연속 확률 변수 $(Y_{1}, Y_{2})\in\mathbb{R}^{2}$에 대응되는 unique copula는 $Y_{1}$ and/or $Y_{2}$에 continuous monotonic transform을 적용해도 변하지 않는다.

## 극단값 코퓰라(extreme-value copula)

이 부분은 [@Dey2015]의 2장을 참고하였다. MEVD $G$의 상관 구조는 그것의 **코퓰라(copula)** $C_{G}$에 의해 특성화된다. MEVD $G$의 코퓰라를 특별히 **극단값 코퓰라(extreme-value copula)**라고 부른다. 어떤 코퓰라 $C$는 다음과 같은 코퓰라 $C_{F}$가 존재해 $n\rightarrow\infty$일 때
$$C_{F}^{n}(\mathbf{u}^{1/n})\rightarrow C(u_{1},\ldots, u_{d}), \qquad{(u_{1}, \ldots, u_{d})\in [0,1]^{d}}$$
를 만족하면 그것을 극단값 코퓰라라고 부르는 것이다. 이 경우에 $C_{F}$는 $C$의 domain of attraction에 속한다고 말한다.

극단값 코퓰라는 또한 최대안정성에 의해서도 특성화된다. 어떤 코퓰라 $C$는 모든 양의정수 $k\geq 1$에 대해 다음
$$C(\mathbf{u})=C^{k}(\mathbf{u}^{1/k}),\qquad{\mathbf{u}\in[0,1]^{d}}$$
을 만족할 때 최대안정이라고 부른다. 최대안정 코퓰라는 자기 자신의 domain of attraction 안에 있다. 그리고 또 한가지 중요한 성질로 극단값 코퓰라는 최대안정임과 동치이다 라는 것이 있다. 정의에 의해 극단값 코퓰라 또는 최대안정 코퓰라의 족(family)는 MEVD의 코퓰라의 집합과 일치한다.

극단값 코퓰라 $C$는 **Pickands의 종속함수(Pickands dependence function)**으로 표현할 수 있다. $\Delta_{d-1}$을 $\mathbb{R}^{d}$에서의 단위 심플렉스로
$$\Delta_{d-1} = \{ (w_{1},\ldots, w_{d}: w_{i}>0, i=1,\ldots, d, \sum_{i=1}^{d}w_{i}=1) \}$$
와 같다.

그러면 극단값 코퓰라 $C$는 다음과 같이 쓸 수 있다.
$$C(u_{1},\ldots, u_{d}) = \exp{\Big\{ \Big( \sum_{j=1}^{d}\log u_{j} \Big)  A \Big( \frac{\log u_{1}}{\sum_{j=1}^{d}\log u_{j}},\ldots,  \frac{\log u_{d}}{\sum_{j=1}^{d}\log u_{j}} \Big) \Big\}}.$$
이 때 $A$는 $\Delta_{d-1}\rightarrow [\frac{1}{d},1]$에서 정의되었으며 convex이고 $\max(\mathbf{w})\leq A(\mathbf{w}) \leq q, \forall \mathbf{w} \in \Delta_{d-1}$인 함수로 **Pickands의 종속함수(Pickands dependence function)**이다. 

Marginal GEV 분포에 대해 가우스 코퓰라를 쓸 수도 있다. 그러나 가우스 코퓰라의 꼬리부분은 점근적 독립(asymptotically independent)이 되며 따라서 어떠한 극단값 의존성도 존재하지 않게 딘다.

## 단위 프례세 마진을 갖는 최대안정분포(max-stable distribution with unit Frechet margin)

MEVD의 표현들은 종종 분포함수로 $G_{1}(z) = \exp(-1/z), z>0$을 갖는 **단위 프례세 마진(unit Frechet margin)**으로 설명하기도 한다. 다변량 분포 $G$는 $G$가 다음을 만족할 때 단위 프례세 마진을 갖는 MEVD가 되는 필요충분조건임이 알려져 있다.
$$G(\mathbf{z})=\exp(-V(\mathbf{z})), \qquad{\mathbf{z}\in[0,\infty)^{d}\backslash \{\mathbf{0}\}},$$
이 때
$$V(\mathbf{z})=\int_{\Delta_{d-1}}\max_{j=1,\ldots,d}\Big(\frac{w_{j}}{z_{j}}\Big) dS(w_{1},\ldots, w_{d})$$
이며 $S$는 $\Delta_{d-1}$에서 정의된 양의 측도이며 $\int_{\Delta_{d-1}}w_{j}dS(w_{1},\ldots, w_{d})=1, j=1,\ldots, d$이다. 이 때 측도 $S$를 **스펙트럼 측도(spectral measure)**라고 부르며 $G$의 dependence structure를 특성화한다.

MEVD $G$의 최대안정성 식 \@ref(eq:MEVDmaxstable)은 $G^{-1/k}$가 모든 양의 정수 $k$에 대해 분포함수가 됨을 의미한다. 그것은 $G$가 **최대-무한분해가능한(max-infinitely divisible)** 분포임을 의미한다. 그러면 $[0,\infty)^{d}\backslash\{\mathbf{0}\}$에서 측도 $\mu$가 존재해 다음을 만족한다.
$$V(\mathbf{z})=\mu((0,\mathbf{z}]^{c}), \qquad{\mathbf{z}\in [0,\infty)^{d}\backslash \{\mathbf{0}\}.}$$
이 때 측도 $\mu$를 **지수측도(exponent measure)**라고 하며 함수 $V$는 **지수함수(exponent function)**이라고 부른다. Extreme-value copula의 최대안정성을 프례세 마진을 갖는 MEVD로 변환시키면 모든 $r>0$에 대해 $G^{r}(r\mathbf{z})=G(\mathbf{z})$을 얻는다. 동등하게, $V(r\cdot)=r^{-1}V(\cdot)$이고 $\mu(r\cdot)=r^{-1}\mu(\cdot)$이 된다. 즉, $V$와 $\mu$는 모두 homogeneous of order $-1$이다.

또 이들과 깊게 연관되어있는 개념으로 **안정 꼬리 의존 함수(stable tail dependence function)** $l:[0,\infty]^{d} \rightarrow [0,\infty)$가 있으며 다음과 같이 정의된다.
$$l(\mathbf{v}) = V(1/\mathbf{v}), \qquad{v\in[0,\infty]^{d}.}$$
안정 꼬리 의존 함수는 다음의 성질들을 만족함이 알려져 있다. ([@Beirlant2004]의 257쪽)

1. $l(r\cdot) = r l(\cdot)$ for $r>0$ **(homogeneous of order 1)**

2. $l(e_{j} ) = 1$ for $j=1,\ldots, d$ with $e_{j}$ being the $j$th unit vector in $\mathbb{R}^{d}$

3. $\max_{i=1}^{d}v_{i} \leq l(\mathbf{v})\leq \sum_{i=1}^{d}v_{i}$ for $\mathbf{v} \in [0,\infty)^{d}$

4. $l$ is convex

위의 성질들 중 첫번째 성질 때문에, 안정 꼬리 의존 함수 $l$은 Pickands의 종속함수 $A$와 관련이 있게 된다. 그리고 그것은 $l$을 unit simplex 위에서 제한시킬 수 있게 한다.
$$l(\mathbf{x}) = \Big( \sum_{i=1}^{d}x_{i} \Big) A(w_{1},\ldots, w_{d}), \qquad{\mathbf{x}\in\mathbb{R}_{+}^{d}},$$
이 때 $w_{j} = \frac{x_{j}}{\sum_{i=1}^{d}x_{i}}$이다.

MEVD에 대한 다양한 모수족들이 사전연구에서 제시되었다. [@Gudendorf2010]에서는 extreme value copula들에 대해 정리하였다. 일반적으로 많이 쓰이는 예들은 다음과 같다.

- Logistic model (and its variants)

- H\''{u}sler-Reiss model

- t-extreme-value copula

## 극단 의존성의 측도들 (measures of extremal dependence)

MEVD의 의존성 구조는 다음

- Spectral measure $S$

- Stable tail dependence function $l$

- Pickands dependence function $A$

들로 특성화된다. 이들은 자료로부터 쉽게 추론해낼 수 없는 복잡한 구조들을 말해준다.

때로 의존성에 대한 단순한 요약통계량이 유용할 때가 있다. 이변량일 때에는 의존 측도들로 **켄달의 타우(Kendall's tau)** 또는 **스피어맨의 로우(Spearman's rho)** 들을 쓴다. 이들을 $A$로 표현하면 다음과 같다.
$$\tau=\int_{0}^{1}\frac{t(1-t)}{A(t)}dA'(t), \qquad{\rho = 12\int_{0}^{1}\{A(t)+1\}^{-2}dt-3.}$$
이들은 두 마진의 overall dependence를 잰다. 그러나 때대로 우리는 꼬리에서의 extreme observation들의 의존성을 재는 측도에 좀 더 관심이 있을 것이다.
