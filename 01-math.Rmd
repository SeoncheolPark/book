# (PART) Basic Concepts {-}

# 기본적인 수학 개념들 {#math}
이 장에서는 앞으로 다룰 내용을 이해하기 위해 필요한 기본적인 수학 개념을 정리하였다.

## 집합론(set theory)

### 카디널리티(cardinality)

**카디널리티(cardinality)**는 집합의 원소의 갯수를 세기 위해 도입되었다. 유한집합에서는 원소의 갯수를 세는 것이 어렵지 않지만, 무한집합의 경우는 갯수를 세는 것이 문제가 될 수 있다. 집합 $A$가 주어졌을 때, 그것의 카디널리티를 $|A|$로 쓰도록 하자. 자연수 집합의 카디널리티는 특별히 $|\mathbb{N}|=\aleph_{0}$로 쓰며 **알레프-널(aleph-null)**로 부른다.

<div class="definition">

두 집합 $A$, $B$ 사이에 전단사(bijection, 일대일 대응) 관계가 성립할 때, 두 집합의 카디널리티가 같다고 정의하고, $|A|=|B|$로 표기한다.

</div>

## 수열(sequence)과 수열의 극한(limit)

### 상한(supremum)과 하한(infimum)

수열은 극한이 존재하는 경우와 존재하지 않는 경우로 나누어 생각할 수 있다. 극한이 존재하지 않는 수열에서, **상계(upper bound)**와 **하계(lower bound)**의 점근적인 움직임(asymptotic behavior)를 고려해 볼 수 있을 것이다.

$\{x_{n}\}_{n=1}^{\infty}$를 실수로 구성된 수열(sequence)이라고 하자. 우선 상계와 하계를 다음과 같이 정의한다.

<div class="definition">

다음 조건을 만족하는
$$x_{n} \leq u \text{ 모든 } n \in \mathbb{N}$$
$u \in \mathbb{R}$을 수열 $\{x_{n}\}_{n=1}^{\infty}$의 **상계(upper bound)**라고 한다.

</div>

<div class="definition">

다음 조건을 만족하는
$$x_{n} \geq l \text{ 모든 } n \in \mathbb{N}$$
$l \in \mathbb{R}$을 수열 $\{x_{n}\}_{n=1}^{\infty}$의 **하계(lower bound)**라고 한다.

</div>

이들을 이용해 상한과 하한을 정의할 수 있다.

<div class="definition">

다음 조건을 만족하는
$$u_{l} \text{은 } \{x_{n}\}_{n=1}^{\infty} \text{의 상계이고 } \{x_{n}\}_{n=1}^{\infty} \text{의 다른 상계 } u \text{가 존재할 때 } u_{l} \leq u$$
$u_{l} \in \mathbb{R}$을 $\{x_{n}\}_{n=1}^{\infty}$의 **상한(supremum)**이라고 하며, 다음과 같이 표현한다.
$$u_{l}=\sup_{n\in\mathbb{N}}x_{n}$$

</div>

<div class="definition">

다음 조건을 만족하는
$$l_{u} \text{는 } \{x_{n}\}_{n=1}^{\infty} \text{의 하계이고 } \{x_{n}\}_{n=1}^{\infty} \text{의 다른 하계 } l \text{이 존재할 때 } l_{u} \leq l$$
$l_{u} \in \mathbb{R}$을 $\{x_{n}\}_{n=1}^{\infty}$의 **하한(infimum)**이라고 하며, 다음과 같이 표현한다.
$$l_{u}=\inf_{n\in\mathbb{N}}x_{n}$$

</div>

### 상극한(limit superior)과 하극한(limit infimum)

### 실함수의 수열들(sequences of real functions)

확률변수(random variable)의 수열이 함수의 수열처럼 여겨질 수 있다는 사실에서 함수의 수열의 성질을 이해하는 것은 중요하다. 일반적인 수열의 수렴에 관한 성질들과 비교했을 때 함수의 수열들의 수렴에 관한 성질에서는 여러 개의 정의로 다뤄질 수 있다는 점에서 차이가 있다. 가장 널리 알려진 함수의 수렴은 **점별수렴(pointwise convergence)**과 **균등수렴(uniform convergence)**이 있다.

<div class="definition">

$\{ f_{n}(x)\}_{n=1}^{\infty}$를 실함수의 수열이라고 하자. 그러면 모든 $x\in\mathbb{R}$에 대해
$$\lim_{n\rightarrow \infty}f_{n}(x)=f(x)$$
를 만족하는 실함수 $f$가 존재할 때 수열 $\{ f_{n}(x)\}_{n=1}^{\infty}$이 $f$에 **점별수렴(pointwise convergence)**한다고 한다. 여기서는 $n\rightarrow \infty$일 때
$$f_{n} \stackrel{pw}{\rightarrow} f$$
로 표현하기로 한다.

</div>

점별수렴보다 더 강한 조건으로 $x \in \mathbb{R}$에 상관 없이 모든 지점에서 동시에 $n\rightarrow\infty$일 때 $f_{n}(x) \rightarrow f(x)$이길 요구할 수도 있다. 이 때 사용되는 정의가 균등수렴이다.

<div class="definition">

$\{ f_{n}(x)\}_{n=1}^{\infty}$를 실함수의 수열이라고 하자. 그러면 모든 $\epsilon > 0$에 대해
$$|f_{n}(x)-f(x)| <\epsilon \forall n \geq n_{\epsilon} \text{ and } x\in \mathbb{R}$$
을 만족시키는 정수 $n_{\epsilon}$이 존재할 때 수열 $\{ f_{n}(x)\}_{n=1}^{\infty}$이 $f$에 **균등수렴(uniform convergence)**한다고 한다. 여기서는 $n\rightarrow \infty$일 때
$$f_{n} \stackrel{u}{\rightarrow} f$$
로 표현하기로 한다.

</div>

(두 수열의 차이점 설명)

## 연산자들과 노름(operators and norms)

### 직합(direct sum)

<div class="definition">

크기 $m \times n$인 행렬 $\mathbf{A}$와 $p\times q$인 행렬 $\mathbf{B}$가 있을 때 이들의 **직합(direct sum)**은
$$\mathbf{A}\oplus\mathbf{B}=
\begin{bmatrix}
\mathbf{A} & 0\\
0 & \mathbf{B}\\
\end{bmatrix}
=
\begin{bmatrix}
a_{11} & \cdots & a_{1n} & 0 & \cdots & 0 \\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
a_{m1} & \cdots & a_{mn} & 0 & \cdots & 0 \\
0 & \cdots & 0 & b_{11} & \cdots & b_{1q} \\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
0 & \cdots & 0 & b_{p1} & \cdots & b_{pq} \\
\end{bmatrix}
$$

</div>

<div class="example">

$$
\begin{bmatrix}
1 & 3 & 2\\
2 & 3 & 1\\
\end{bmatrix}
\oplus
\begin{bmatrix}
1 & 6\\
0 & 1\\
\end{bmatrix}
=
\begin{bmatrix}
1 & 3 & 2 & 0 & 0\\
2 & 3 & 1 & 0 & 0\\
0 & 0 & 0 & 1 & 6\\
0 & 0 & 0 & 0 & 1\\
\end{bmatrix}
$$

</div>

### 크로네커 곱(Kronecker product)

<div class="definition">

크기 $m \times n$인 행렬 $\mathbf{A}$와 $p\times q$인 행렬 $\mathbf{B}$가 있을 때 이들의 **크로네커 곱(Kronecker product)**은
$$\mathbf{A}\otimes\mathbf{B}
=
\begin{bmatrix}
a_{11}\mathbf{B} & \cdots & a_{1n}\mathbf{B} \\
\vdots & \ddots & \vdots \\
a_{m1}\mathbf{B} & \cdots & a_{mn}\mathbf{B} \\
\end{bmatrix}
$$

</div>

<div class="example">

다음은 크로네커 곱의 한 예이다.

$$
\begin{bmatrix}
1 & 2\\
3 & 4\\
\end{bmatrix}
\otimes
\begin{bmatrix}
0 & 5\\
6 & 7\\
\end{bmatrix}
=
\begin{bmatrix}
1\cdot 0 & 1\cdot 5 & 2\cdot 0 & 2\cdot 5\\
1\cdot 6 & 1\cdot 7 & 2\cdot 6 & 2\cdot 7\\
3\cdot 0 & 3\cdot 5 & 4\cdot 0 & 4\cdot 5\\
3\cdot 6 & 3\cdot 7 & 4\cdot 6 & 4\cdot 7\\
\end{bmatrix}
=
\begin{bmatrix}
0 & 5 & 0 & 10\\
6 & 7 & 12 & 14\\
0 & 5 & 0 & 20\\
18 & 21 & 24 & 28\\
\end{bmatrix}
$$

</div>

### 텐서곱(tensor product)

### 데카르트 곱(Cartesian product)

두 개의 집합 $A$, $B$가 있을 때, 이들의 **데카르트 곱(Cartesian product)** $A\times B$는
$$A\times B = \{ (a,b)| a\in A \text{ and } b \in B\}$$
로 정의된다.

### 노름(norm)

#### 벡터 노름(vector norm)

#### 행렬 노름(matrix norm)

## 공간(space)

### 실수공간(space R)

실수공간 $\mathbb{R}$에서 집합 $E\subseteq \mathbb{R}$이 **열린(open)** 집합이라는 것은 모든 $x\in E$에 대해 $x$에 depend하는 $\epsilon > 0$이 존재해 $(x-\epsilon, x+\epsilon) \subseteq E$를 만족하는 것이다.

실수공간 $\mathbb{R}$에서 집합 $F\subseteq \mathbb{R}$이 **닫힌(closed)** 집합이라는 것은 $F^{C}$가 열린집합일 때이다.

### 벡터공간(vector space)

<div class="definition">

같은 수의 성분을 가지는 벡터들로 이루어진 공집합이 아닌 집합 $V$가 있을 때,

1. $V$에 속하는 임의의 두 벡터 $\mathbf{a}$와 $\mathbf{b}$의 일차결합이 $\alpha \mathbf{a} + \beta \mathbf{b}$ ($\alpha$, $\beta$는 임의의 실수)가 또한 $V$에 속하고

2. 벡터에 대한 **덧셈**과 스칼라곱이 아래 연산법칙을 만족하면

- $\mathbf{a} + \mathbf{b} = \mathbf{b} + \mathbf{a}$: 교환(commutative)법칙
 
- $(\mathbf{a} + \mathbf{b}) + \mathbf{c} = \mathbf{a} + (\mathbf{b} + \mathbf{c})$: 결합(associative)법칙

- $\mathbf{a} + \mathbf{0} = \mathbf{a}$: 다음 식을 만족하는 항등원(identity element)이 벡터공간 내에 존재($\mathbf{0} \in V$)
 
- $\mathbf{a} - \mathbf{a} = \mathbf{0}$: 다음 식을 만족하는 역원(inverse element)이 벡터공간 내에 존재($-\mathbf{a} \in V$)

(스칼라 곱에 대해)
 
- $c(\mathbf{a} + \mathbf{b}) = c\mathbf{a}+c\mathbf{b}$: 분배법칙
 
- $(c+k)\mathbf{a}=c\mathbf{a}+k\mathbf{a}$: 분배법칙
 
- $c(k\mathbf{a})=(ck)\mathbf{a}$

- $1\mathbf{a}=\mathbf{a}$: 곱셈에 대한 항등원($V$안에 있을 필요는 없는 듯)

이 집합 $V$를 **벡터공간(vector space)** 또는 **선형공간(linear space)**이라고 하며, 그 원소를 **벡터(vector)**라고 부른다. 이때 $c$, $k$, $1$은 어떤 체(field)의 원소여야 한다($c,k,1 \in F$). 여기서는 편의상  $F=\mathbb{R}$로 놓도록 한다.

</div>

### L2 공간(L2 space)

$$\| f\|_{p}=(\int_{S}|f|^{p}d\mu)^{1/p}<\infty$$

### Sobolev 공간(Sobolev space)

### Besov 공간(Besov space)

### Reproducing kernel Hilbert space

## 거리(distance)

군집분석 방법에서는 관측값들의 거리를 이용해 군집을 나눌 때 사용된다.

- 유클리드 거리(Euclidean distance): $d(x,y)=(\sum_{i=1}^{p}(x_{i}-y_{i})^{2})^{1/2}$

- 민콥스키 거리(Minkowski distance): $d(x,y)=(\sum_{i=1}^{p}(x_{i}-y_{i})^{m})^{1/m}$

- 맨하탄 거리(Manhattan distance): $d(x,y)=\sum_{i=1}^{p}|x_{i}-y_{i}|$

- 표준화 거리(standardized distance): $d(x,y)=(\sum_{i=1}^{p}(x_{i}-y_{i})^{2}/s_{i}^{2})^{1/2}$, 여기서 $s_{i}$는 $i$번째 변수에 대한 표준편차

- 마할라노비스 거리(Mahalanobis distance): $d(x,y)=(x-y)^{T}\boldsymbol{\Sigma}^{-1}(x-y)$, 여기서 $\Sigma$는 공분산행렬

- 체비셰프 거리(Chebychev distance): $d(x,y)=\max_{i=1,\ldots ,p}|x_{i}-y_{i}|$

