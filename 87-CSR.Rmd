# 완전공간임의성 {#csr}

공간점패턴 자료를 받으면 제일 처음으로 이 자료가 **완전공간임의성(complete spatial randomness, CSR)**을 따르는지 체크하게 되는데, 그 이유는 이것을 따르면 모델링이 단순해지기 때문이다.


```{definition, name="동질적 포아송 점과정"}
완전공간임의성 가정은 다음 두 조건

1. 면적이 $|A|$인 관찰 지역 $A$ 안의 사건의 숫자가 $\text{Poisson}(\lambda |A|), \lambda >0, |A| >0$을 따른다.

2. $n$개의 사건이 주어졌을 때, 각각의 사건들 $x_{i}, i=1,\ldots , n$은 $A$ 위에서 균등분포(uniform distribution)를 따르는 독립인 무작위 표본들이다.

을 만족하는 것이다. 이를 만족하는 점과정을 특별히 **동질적 포아송 점과정(homogeneous Poisson point process)**이라고 부른다. $\lambda$는 강도(intensity)로 단위 면적 당 사건 발생의 기대값을 결정하는 값이다. $\lambda$가 위치에 관계 없는 상수값이라는 것은 사건의 발생횟수가 위치에 따라 변하지 않는다는 의미이다. 또한 CSR 가정은 사건들 사이에 어떤 상호작용도 존재하지 않음을 의미한다.

```

우리는 어떤 자료가 정규분포를 따르는지 알아보기 위해 평균, 분산, 왜도, 첨도 등을 체크하고 Q-Q plot 등을 그리기도 한다. 그렇다면 CSR의 특징은 무엇인가? 이를 알먄 어떤 자료가 CSR을 따르는지 체크 가능할 것이다.

## 완전공간임의성 검정을 위한 일반적인 몬테카를로 방법 (general Monte Carlo methods for CSR test)

$u_{1}$을 통계량 $U$ (아마 확률번수인 듯)를 따르는 관찰값이라고 하자. 그리고 $u_{i}, i =2,\ldots, s$를 어떤 단순한 가정($H_{0}$) 하의 $U$의 분포에서 뽑힌 독립 표본들의 값이라고 하자. $u_{(j)}$를 $u_{i}, i=1,\ldots , s$ 중 $j$번째로 큰 순서통계량이라고 하자. 그러면
$$P(u_{i}=u_{(j)})=\frac{1}{s} \qquad{\text{under } H_{0}},$$
$$P(u_{i}\geq u_{(j)})=\frac{k}{s}=\text{(test의) size} \qquad{\text{(one-sided test)}}$$
가 된다.

이 때 $U$는 동률이 없는 연속인 경우를 일단 생각한다. 만약 $U$가 이산이라면 동률이 생겨 rank 계산에 문제가 생길 것이다. 이 때는 less extreme rank(?)를 하는게 보수적인 판단이라고 한다.

갑자기 몬테카를로 검정을 이야기 한 이유는 어떤 자료가 CSR인지 테스트를 할 때 사용할 수 있기 때문이다.

1. 관찰값들이 있으면 이들의 상호 떨어지 거리(inter-event distance)를 이용하는 것이다. $T$를 지역 $A$ 안에서 독립인 균등분포로 뽑힌 두 사건의 거리들이라고 하자. 관찰 지역이 원이나 정사각형인 경우 $T$의 분포의 명시적 형태가 존재한다. 이 때 명시적 형태는 다음과 같다.

단위 정사각형의 경우, 분포함수 $H(t)$는
$$
H(t)=P(T\leq t) =
\begin{cases}
\pi t^{2}-\frac{8}{3}t^{3}+\frac{1}{2}t^{4} & \text{if $0 \leq t \leq 1$}\\
\frac{1}{3} -2t^{2} + \frac{1}{2}t^{4} + 4(t^{2}-1)^{\frac{1}{2}}(2t^{2}+1)/3\\
+ 2t^{2}\sin^{-1}(2t^{-2}-1) & \text{if $1\leq t \leq \sqrt{2}$}
\end{cases}
$$

이다. 식이 복잡해 보이는데 $a_{1}=(x_{1},y_{1})$, $a_{2}=(x_{2},y_{2})$일 때 $x_{1}, x_{2}, y_{1}, y_{2}$가 모두 독립이고 이 때 $T=\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}$의 CDF를 구한 듯 하다.

단위 원 경우에는 극 좌표계로 변환하여 계산하며
$$H(t)=1+\pi^{-1}\{2(t^{2}-1)\cos^{-1}(\frac{t}{2})-t(1+\frac{t^{2}}{2})\sqrt{1-t^{2}/4}\}, \qquad{0\leq t \leq 2}$$
가 된다.

위 사각형 예제에서, H(t)의 경험적 분포함수(empirical distribution function) $\hat{H}(t)$는
$$\hat{H}(t)=\frac{2}{n(n-1)}\sum_{i,j}^{i\neq j}I_{(t_{ij}\leq t)}$$
이며 이 때 empirical distribution function (EDF) 그림은 q-q plot과 비슷하게 그려진다.

한편, EDF에 봉투(envelope)들(마치 함수의 상한, 하한과 같다) $U(t)$, $L(t)$을 다음과 같이 정의한다.
$$U(t)=\max_{2\leq i \leq s}\{\hat{H}_{i}(t)\} \text{ and } U(t)=\min_{2\leq i \leq s}\{\hat{H}_{i}(t)\}.$$

이 EDF 말고 통계량을 이용해 검정할 수는 없을까? 그러기 위해서는 우선 $\hat{H}(t)$의 분포를 알아야 한다. 그러나 이를 구하는 것은 쉽지 않다. 따라서 공간점과정에서는 몬테칼로 방법(Monte Carlo method)을 많이 사용한다고 한다. 일반적인 절차는

1. CSR 가정 하에 지역 $A$ 안에서 $n$개의 사건을 생성한다.

2. 간단히 하기 위해 먼저 $t$를 고정시킨 다음, $\hat{H}_{1}(t)$ 는 데이터로부터 생성된 경험적 분포함수로, $\hat{H}_{i}(t), i=2,\ldots, s$ ($s$: 몬테칼로 반복 횟수)는 몬테칼로 방법으로 생성된 경험적 분포함수라고 놓는다. 그러면 $t$를 고정했을 때 CSR 하에서 다음이 성립한다.
$$P(\hat{H}_{1}(t)>U(t))=P(\hat{H}_{1}(t)<L(t))=\frac{1}{s}$$

### 경험적 분포함수를 이용한 몬테칼로 검정 방법들(MC tests using EDF)

크게 두 가지 방법이 있다.

1. $t_{0}$를 고른 다음, $u_{1}=\hat{H}_{1}(t_{0})$를 검정통계량으로 쓰는 것이다. 그러면 CSR 가정 하에 $P(U_{(j)}=u_{1})=\frac{1}{s}$가 된다.

2. $t_{0}$가 너무 주관적인 선택이므로 이를 해결하기 위해 $u_{i}=\int (\hat{H}_{i}(t)-H(t) )^{2}dt$를 사용하고 나머지는 앞의 방법과 동일하게 할 수도 있다.

```{corollary}
1. Aggregate pattern이 의심될 경우: 작은 $t_{0}$를 선택하는 것이 좋다.

2. 두 번째 검정은 검정력(power)이 첫 번째 검정에 비해 약하다.

3. 실제 데이터의 분포 지역이 정사각형 또는 원이 아닌 경우 $H(t)$의 명시적 형태를 모른다. 이처럼 $H(t)$를 모르는 경우 $\hat{H}_{i}, i=2,\ldots, s$를 이용해 $H(t)$의 추정량 $\bar{H}(t)$를 만들어 사용하는 것이다.
$$\bar{H}_{i}(t)=\frac{1}{s-1}\sum_{j\neq i}\hat{H}_{j}(t)$$
이며 $\bar{H}_{1}(t)$를 $H(t)$의 추정량으로 주로 쓴다.

```

## 최근접이웃거리 기반 방법들(methods based on nearest neighbor distance)

$Y$를 CSR 가정 하에 $A$ 안에 $n$ ($n$은 고정)개의 사건이 있다고 할 때 **최근접이웃거리(nearest neighbor distance)**라고 하자. 그러면

\begin{eqnarray*}
G(y)=P(Y\leq y)&\approx & 1-(1-\pi y^{2}|A|^{-1})^{n-1}\\
&\approx& 1-e^{-\lambda \pi y^{2}}, \qquad{y \geq 0, \lambda =\frac{n}{|A|}}
\end{eqnarray*}

가 된다. 이제 우리는 $G(y)$와 비교할 empirical한 것을 데이터로부터 찾아야 한다. $y_{i}$를 $i$번째 사건과 그 사건으로부터 가장 가까운 다른 사건 사이의 거리라고 하자. 그러면 $\hat{G}_{1}(y)=\frac{1}{n}\sum I(y_{i} \leq y)$가 되며 이를 이용해 EDF 그림을 그려보거나 몬테칼로 검정을 할 수 있다.

### 최근접이웃거리 기반 몬테칼로 검정 방법들(MC tests based on nearest neighbor distance)

다음의 방법들이 있다.

1. $u_{i}=\int (\hat{G}_{c}(y)-G(y))^{2}dy$를 이용하는 것이다. 이 때 $G$ 대신 $\bar{G}$를 넣어도 된다.

2. [@Clark1954] $\bar{y}=\frac{1}{n}\sum y_{i}$로 놓는다. 이 경우에 $\bar{y}$는 근사적으로 정규분포를 따르며
$$E(\bar{y})=0.5(n^{-1}|A|)^{\frac{1}{2}} + (0.051 + 0.042 n^{-\frac{1}{2}})n^{-1}P$$
$$\text{Var}(\bar{y})=0.070n^{-2}|A| + 0.037(n^{-5}|A|)^{\frac{1}{2}}P$$
이다. 이 때 $P$는 $A$의 둘레의 길이다.

3. (Point-to-nearest event distance) $X$를 $A$ 안에 있는 어떤 점에서 $n$개의 사건들 중 가장 가까운 사건과의 거리라고 하자. 또 $x_{i}, i=1,\ldots ,m$을 $A$의 $i$번째 점에서 $n$개의 사건들 중 가장 가까운 사건과의 거리라고 하자. 그러면
$$F(x)=P(X\leq x) \approx 1 - e^{-\lambda \pi x^{2}}, \qquad{x \geq 0, \lambda = \frac{n}{|A|}}$$
$$\hat{F}_{1}(x)=\frac{1}{m}\sum I(x_{i}\leq x)$$
그 다음에는 앞게 비슷하게 EDF 그림을 그려보거나 $u_{1}=\int (\hat{F}_{1}(x)-\bar{F}_{1}(x))^{2}dx$등으로 검정 가능하다.

4. 정방구역 계산(quadrat count)

```{r, message=F, echo=F}
library(ggplot2)
```

```{r, echo=F, fig.align='center', comment=">", fig.cap = 'Examples of rectangle area.'}
# Setup the data
m <- matrix(c(1,4,7,2,5,8,3,6,9), nrow=3, ncol=3)
df <- expand.grid(x=1:ncol(m),y=1:nrow(m))
df$val <- m[as.matrix(df[c('y','x')])]

ggplot(df, aes(x=x, y=y, label=val)) + 
  geom_tile(fill='transparent', colour = 'black') + 
  geom_text(size = 14) + 
  scale_y_reverse() +
  theme_classic() + 
  theme(axis.text  = element_blank(),
        panel.grid = element_blank(),
        axis.line  = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
```

**정방구역(quadrat)**이란 어떤 관찰구역 $A$를 $m$개의 같은 크기의 소구역으로 나눴을 때 그 구역 하나 하나를 일컫는 말이다. 위 그림에서 셀 하나 하나를 정방구역이라고 부른다. CSR 가정 아래서는 같은 분포를 $m$번 반복하여 관찰하는 것으로 볼 수 있고 $n_{i}$는
$$n_{i} \sim \text{Poisson}(\lambda |B|),\qquad{i=1,\ldots, m}$$
을 따른다. 여기서 $B$는 어떤 지역이다.

이 때의 검정통계량으로는 카이제공통계량을 쓴다. CSR 가정 아래서
$$X^{2}=\sum_{n=1}^{m}\frac{(n_{i}-\bar{n})^{2}}{\bar{n}} \sim \chi_{m-1}^{2}$$
이다. 이 때 $\bar{n}=\frac{n}{m}=\frac{\sum n_{i}}{m}$이다.

## R 예제(R-edf)

```{r, message=F, echo=F}
library(spatstat)
library(ape)
```

```{r, fig.align='center', comment=">", fig.cap = 'EDF plot.'}
# Define points
x <- c(3.4, 7.3, 6.3, 7.7, 5.2, 0.3, 6.8, 7.5, 5.4, 6.1, 5.9, 3.1, 5.2, 1.4, 5.6, 0.3)
y <- c(2.2, 0.4, 0.8, 6.6, 5.6, 2.5, 7.6, 0.3, 3.5, 3.1, 6.1, 6.4, 1.5, 3.9, 3.6, 5.2)
# Store the coordinates as a matrix
coords <- as.matrix(cbind(x, y))
# Store the points as two-dimensional point pattern (ppp) object (ranging from 0 to 8 on both axis)
coords.ppp <- as.ppp(coords, c(0, 8, 0, 8))
#  Number of points
n <- coords.ppp$n
#  We want to generate completely spatially random point patterns to compare against the observed
ex <- expression( runifpoint( n , win = owin(c(0,8),c(0,8))))
#  Reproducible simulation
set.seed(1)
# Compute a simulation envelope using Gest, which estimates the nearest neighbour distance distribution function G(r)
EDF <- envelope( coords.ppp , Gest , nsim = 99, simulate = ex ,verbose = FALSE, savefuns = TRUE )
#  Plot
plot(EDF)
```
