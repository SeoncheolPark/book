# 마르코프 체인 {#markovchain}

## 마르코프 체인(Markov chain)

```{definition, name="마르코프 체인"}
**마르코프 체인(Markov chain)**이란 

$$P(X_{n+1}=X|X_{1}=x_{1}, X_{2}=x_{2}, \ldots , X_{n}=x_{n})=P(X_{n+1}=x|X_{n}=x_{n})$$

을 만족하는 확률변수들의 수열 $X_{1},X_{2},\ldots$를 일컫는다. 여기서$x_{i}$들은 countable set $S$에서 뽑힌 값들이며 $S$를 체인의 state space라고 부른다.

```
