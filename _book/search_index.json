[
["index.html", "통계공부와 관련된 글들 Chapter 1 일러두기", " 통계공부와 관련된 글들 Seoncheol Park 2018-08-10 Chapter 1 일러두기 John W. Tukey는 이렇게 말했다. “통계학은 과학이라는 것이 내 견해다. 통계학은 더이상 수학이나 물리학, 화학 또는 경제학의 한 부류가 아니다.” 각 장은 독립된 구성으로 되어 있으며, 한 권 이상의 책들을 참고문헌으로 하여 그들의 정의 및 표현을 따라가는 방식으로 구성되어 있다. 따라서 각 장마다 표현 및 한국어 용어 번역이 상이할 수 있다. library(wavethresh, splines2, astsa, xts, quantspec, TSA, kza, itsmr, dismo, waveslim, “geoR”, “SpatialEpi”, “spBayes”, fields, RandomFields, SpatialExtremes, spatstat, ggplot2, splancs, evd, plotrix) "],
["2-math.html", "Chapter 2 기본적인 수학 개념들", " Chapter 2 기본적인 수학 개념들 이 장에서는 앞으로 다룰 내용을 이해하기 위해 필요한 기본적인 수학 개념을 정리하였다. "],
["2-1-set-theory.html", "2.1 집합론(set theory)", " 2.1 집합론(set theory) 2.1.1 카디널리티(cardinality) 카디널리티(cardinality)는 집합의 원소의 갯수를 세기 위해 도입되었다. 유한집합에서는 원소의 갯수를 세는 것이 어렵지 않지만, 무한집합의 경우는 갯수를 세는 것이 문제가 될 수 있다. 집합 \\(A\\)가 주어졌을 때, 그것의 카디널리티를 \\(|A|\\)로 쓰도록 하자. 자연수 집합의 카디널리티는 특별히 \\(|\\mathbb{N}|=\\aleph_{0}\\)로 쓰며 알레프-널(aleph-null)로 부른다. Definition 2.1 (카디널리티가 같다) 두 집합 \\(A\\), \\(B\\) 사에 전단사(bijection, 일대일 대응) 관계가 성립할 때, 두 집합의 카디널리티가 같다고 정의하고, \\(|A|=|B|\\)로 표기한다. "],
["2-2-limit.html", "2.2 극한(limit)", " 2.2 극한(limit) 이 부분은 (Polansky 2011)의 1장을 참고하였다. Definition 2.2 (수열의 수렴) \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)를 실수들의 수열이라고 하고 \\(x\\in\\mathbb{R}\\)을 실수라고 하자. 그러면 모든 \\(\\epsilon &gt;0\\)에 대해 \\(n_{\\epsilon}\\in\\mathbb{N}\\)이 존재해 모든 \\(n\\geq n_{\\epsilon}\\)에 대해 \\(|x_{n}-x|&lt;\\epsilon\\)일 때 \\(x_{n}\\)은 \\(n\\rightarrow\\infty\\)함에 따라 \\(x\\)에 수렴(converge)한다고 말하며, 다음과 같이 쓴다. \\[\\lim_{n\\rightarrow\\infty}x_{n}=x.\\] Definition 2.3 (상계와 하계) \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)를 실수들의 수열이라고 하자. 만약 \\(x_{n}\\leq u , \\forall n\\in\\mathbb{N}\\)을 만족하는 실수 \\(u\\in\\mathbb{R}\\)이 존재할 경우 \\(u\\)를 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 상계(upper bound)라고 한다. 마찬가지로 \\(x_{n}\\geq l, \\forall n\\in\\mathbb{N}\\)을 만족하는 실수 \\(l\\in\\mathbb{R}\\)을 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 하계(lower bound)라고 한다. Definition 2.4 (최소상계와 최대하계) \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)를 실수들의 수열이라고 하자. 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 최소상계(supremum) \\(u_{l}\\)은 상계들 중 가장 작은 상계, 즉 모든 다른 상계들 \\(u\\)에 대해 \\(u_{l} \\leq u\\)인 상계이며, \\[u_{l}=\\sup_{n\\in\\mathbb{N}}x_{n}\\] 으로 쓴다. 마찬가지로 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 최대하계(infimum) \\(l_{u}\\)는 하계들 중 가장 큰 하계, 즉 모든 다른 하계들 \\(l\\)에 대해 \\(l_{u}\\geq l\\)인 하계이며, \\[l_{u}=\\inf_{n\\in\\mathbb{N}}x_{n}\\] 으로 쓴다. FIGURE 2.1: 최소상계. 우리는 최소상계와 최대하계의 극한 또한 생각해 볼 수 있다. Definition 2.5 (상극한과 하극한 그리고 극한) \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)를 실수들의 수열이라고 하자. 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 상극한(limit supremum)은 \\[\\lim_{n\\rightarrow\\infty}\\sup x_{n}=\\inf_{n\\in\\mathbb{N}}\\sup_{k\\geq n}x_{k}\\] 이다. 마찬가지로 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 하극한(limit infimum)은 \\[\\lim_{n\\rightarrow\\infty}\\inf x_{n}=\\sup_{n\\in\\mathbb{N}}\\inf_{k\\geq n}x_{k}\\] 로 정의한다. 만약 \\[\\lim_{n\\rightarrow\\infty}\\sup x_{n}=\\lim_{n\\rightarrow\\infty}\\inf x_{n}=c\\in\\mathbb{R}\\] 일 경우 \\(c\\)를 수열 \\(\\{ x_{n}\\}_{n=1}^{\\infty}\\)의 극한(limit)이라고 한다. FIGURE 2.2: 상극한과 하극한. References "],
["2-3-operators-and-norms.html", "2.3 연산자들과 노름(operators and norms)", " 2.3 연산자들과 노름(operators and norms) 2.3.1 직합(direct sum) Definition 2.6 (직합) 크기 \\(m \\times n\\)인 행렬 \\(\\mathbf{A}\\)와 \\(p\\times q\\)인 행렬 \\(\\mathbf{B}\\)가 있을 때 이들의 직합(direct sum)은 \\[\\mathbf{A}\\oplus\\mathbf{B}= \\begin{bmatrix} \\mathbf{A} &amp; 0\\\\ 0 &amp; \\mathbf{B}\\\\ \\end{bmatrix} = \\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1n} &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; \\cdots &amp; a_{mn} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\cdots &amp; 0 &amp; b_{11} &amp; \\cdots &amp; b_{1q} \\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; 0 &amp; b_{p1} &amp; \\cdots &amp; b_{pq} \\\\ \\end{bmatrix} \\] Example 2.1 (직합의 예) \\[ \\begin{bmatrix} 1 &amp; 3 &amp; 2\\\\ 2 &amp; 3 &amp; 1\\\\ \\end{bmatrix} \\oplus \\begin{bmatrix} 1 &amp; 6\\\\ 0 &amp; 1\\\\ \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 3 &amp; 2 &amp; 0 &amp; 0\\\\ 2 &amp; 3 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 6\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\\\ \\end{bmatrix} \\] 2.3.2 크로네커 곱(Kronecker product) Definition 2.7 (크로네커 곱) 크기 \\(m \\times n\\)인 행렬 \\(\\mathbf{A}\\)와 \\(p\\times q\\)인 행렬 \\(\\mathbf{B}\\)가 있을 때 이들의 크로네커 곱(Kronecker product)은 \\[\\mathbf{A}\\otimes\\mathbf{B} = \\begin{bmatrix} a_{11}\\mathbf{B} &amp; \\cdots &amp; a_{1n}\\mathbf{B} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1}\\mathbf{B} &amp; \\cdots &amp; a_{mn}\\mathbf{B} \\\\ \\end{bmatrix} \\] Example 2.2 (크로네커 곱의 예) 다음은 크로네커 곱의 한 예이다. \\[ \\begin{bmatrix} 1 &amp; 2\\\\ 3 &amp; 4\\\\ \\end{bmatrix} \\otimes \\begin{bmatrix} 0 &amp; 5\\\\ 6 &amp; 7\\\\ \\end{bmatrix} = \\begin{bmatrix} 1\\cdot 0 &amp; 1\\cdot 5 &amp; 2\\cdot 0 &amp; 2\\cdot 5\\\\ 1\\cdot 6 &amp; 1\\cdot 7 &amp; 2\\cdot 6 &amp; 2\\cdot 7\\\\ 3\\cdot 0 &amp; 3\\cdot 5 &amp; 4\\cdot 0 &amp; 4\\cdot 5\\\\ 3\\cdot 6 &amp; 3\\cdot 7 &amp; 4\\cdot 6 &amp; 4\\cdot 7\\\\ \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 5 &amp; 0 &amp; 10\\\\ 6 &amp; 7 &amp; 12 &amp; 14\\\\ 0 &amp; 5 &amp; 0 &amp; 20\\\\ 18 &amp; 21 &amp; 24 &amp; 28\\\\ \\end{bmatrix} \\] 2.3.3 크로네커 거듭곱(Kroneckerian power) We call \\(p^{k}\\)-vector \\(\\mathbf{a}^{\\otimes k}\\), the \\(k\\)-th power of the \\(p\\)-vector \\(\\mathbf{a}\\), if \\(\\mathbf{a}^{\\otimes 0}=1\\) and \\[\\mathbf{a}^{\\otimes k} = \\mathbf{a} \\otimes \\cdots \\otimes\\mathbf{a} (\\text{ k times}).\\] In general, for any matrix \\(\\mathbf{A}\\), the Kroneckerian power is given by \\[\\mathbf{A}^{\\otimes k} = \\mathbf{A} \\otimes \\cdots \\otimes\\mathbf{A} (\\text{ k times}).\\] Furthermore, \\(\\mathbf{A}^{\\otimes k}\\mathbf{B}^{\\otimes k}=(\\mathbf{A}\\mathbf{B})^{\\otimes k}\\). In particular, it is noted that \\[\\mathbf{a}^{\\otimes k}\\otimes\\mathbf{a}^{\\otimes j}= \\mathbf{a}^{\\otimes (k+ j)}, \\qquad{k,j\\in\\mathbb{N}.}\\] The following statement makes it possible to identify where in a long vector of the Kroneckerian power a certain element of the product is situated. 2.3.4 텐서곱(tensor product) 이 부분은 (Kokoszka and Reimherr 2017)의 10.5절을 참고하였다. 우리가 covariance operator를 다룰 때 텐서곱과 텐서 공간을 생각하는 것이 편리할 때가 있다고 한다. 특히 무한차원이나 일반적인 힐버트 공간에서는 텐서곱의 활용이 절대적이다. 다음과 같은 행렬 \\(\\mathbf{A}\\in\\mathbb{R}^{N\\times M}\\)을 생각해보자. 이 행렬은 세 가지 방법으로 바라볼 수 있다. 전통적인 행렬 \\(\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}\\)으로 가는 선형 변환: 벡터의 왼쪽이나 오른쪽에 행렬을 곱하는 형태 (유클리드 공간에서의 모든 선형 변환을 떠올려보자) \\(\\mathbb{R}^{N}\\times \\mathbb{R}^{M}\\rightarrow\\mathbb{R}\\)인 겹선형(bilinear) functional: 이차 형식에서 많이 다루는 형태이다. 다음과 같이 두 유클리드 공간 \\(\\mathcal{H}_{1}=\\mathbb{R}^{N},\\mathcal{H}_{2}=\\mathbb{R}^{M}\\)가 있다고 하자. 두 개의 벡터 \\(x_{1}\\in\\mathbb{R}^{N}\\), \\(x_{2}\\in\\mathbb{R}^{M}\\)에 텐서곱(tensor product)를 적용하면 다음과 같은 행렬을 유도한다. \\[x_{1}\\otimes x_{2}:=x_{1}x_{2}^{T}.\\] 또한 공간 \\(\\mathbb{R}^{N}\\otimes \\mathbb{R}^{M}\\)은 위와 같은 원소들의 모든 유한한 선형 결합의 공간으로 정의할 수 있다. 다시 말하면 만약 \\(\\mathbf{A}\\in\\mathbb{R}^{N}\\otimes \\mathbb{R}^{M}\\rightarrow\\mathbb{R}\\)이면 \\(J\\)개의 원소들 \\(x_{1j}\\in\\mathbb{R}^{N}\\), \\(x_{2j}\\in\\mathbb{R}^{M}\\)이 존재해 \\[\\mathbf{A}=\\sum_{j=1}^{J}x_{1j}\\otimes x_{2j}=\\sum_{j=1}^{J}x_{1j}x_{2j}^{T}\\] 를 만족한다. 어떤 \\(N\\times M\\) 행렬도 이런 표현 방법으로 표현할 수 있으므로 \\(\\mathbb{R}^{N}\\otimes \\mathbb{R}^{M}=\\mathbb{R}^{N\\times M}\\)으로 표현할 수 있다. 이제 이 세번째 관점을 다른 공간에 대해서도 특정화해보자. 어떤 \\(N\\times M\\) 행렬 \\(\\mathbf{A}\\)는 다음과 같은 \\[\\mathbf{A}(y_{1},y_{2}):=y_{1}^{T}\\mathbf{A}y_{2}\\] 인 겹선형 mapping을 이끌어낸다. 따라서 공간 \\(\\mathbb{R}^{N}\\otimes \\mathbb{R}^{M}\\)은 모든 겹선형 map \\(\\mathbb{R}^{N}\\times \\mathbb{R}^{M}\\rightarrow \\mathbb{R}\\)들의 집합으로 identified될 수 있다. 오브젝트 \\(x_{1}\\otimes x_{2}\\)는 또한 다음과 같은 겹선형 mapping \\[(x_{1}\\otimes x_{2})(y_{1},y_{2})=y_{1}^{T}x_{1}x_{2}^{T}y_{2}=(y_{1}^{T}x_{1})(y_{2}^{T}x_{2})\\] 로 identified될 수 있다. 이러한 관점에서 텐서를 바라보자. 텐서는 스칼라들의 체가 연관된 공간에서의 cartesian 곱으로부터 오는 다중선형사상(multilinear map)이다. 만약 \\(\\{e_{1j} \\}\\)와 \\(\\{e_{2j} \\}\\)가 \\(\\mathbb{R}^{N}\\)과 \\(\\mathbb{R}^{M}\\)의 정규 기저들이라고 하자. 그러면 \\(\\{e_{1j}\\otimes e_{2j} \\}\\)는 \\(\\mathbb{R}^{N}\\times \\mathbb{R}^{M}\\)의 기저가 된다. 이런 방식으로 우리는 이 기저를 전통적인 행렬에도 적용할 수 있다. \\[\\mathbf{A}(e_{1j}^{T}, e_{2k})=e_{1j}^{Y}\\mathbf{A}e_{2k}=\\mathbf{A}(j,k).\\] Definition 2.8 (힐버트 공간에서의 텝서곱) \\(x_{1}\\in\\mathcal{H}_{1}\\)과 \\(x_{2}\\in\\mathcal{H}_{2}\\)를 두 실 힐버트 공간에서의 원소들이라고 하자. 그러면 텐서곱 \\(x_{1}\\otimes x_{2}: \\mathcal{H}_{1}\\times\\mathcal{H}_{2} \\rightarrow\\mathbb{R}\\)은 겹선형 사상으로 어떤 \\((y_{1},y_{2})\\times \\mathcal{H}_{1}\\times \\mathcal{H}_{2}\\)에 대해 \\[(x_{1}\\otimes x_{2})(y_{1},y_{2})=\\langle x_{1},y_{1}\\rangle_{\\mathcal{H}_{1}}\\langle x_{2},y_{2}\\rangle_{\\mathcal{H}_{2}}\\] 로 정의된다. 2.3.5 데카르트 곱(Cartesian product) 두 개의 집합 \\(A\\), \\(B\\)가 있을 때, 이들의 데카르트 곱(Cartesian product) \\(A\\times B\\)는 \\[A\\times B = \\{ (a,b)| a\\in A \\text{ and } b \\in B\\}\\] 로 정의된다. 2.3.6 노름(norm) 2.3.6.1 벡터 노름(vector norm) Definition 2.9 (노름과 노름공간) 벡터공간 \\(X\\)에서 다음 세 조건들이 만족되면 함수 \\(\\|\\cdot\\|\\)을 노름(norm)이라 하고 또한 벡터공간 \\(X\\)를 노름공간(normed space)라 한다. 임의의 \\(\\mathbf{x}\\in X\\), where \\(\\|\\mathbf{x}\\| \\geq 0\\)이며 \\(\\|\\mathbf{x}\\|=0\\)이기 위한 필요충분조건은 \\(\\mathbf{x}=\\mathbf{0}\\)이다. 임의의 \\(\\mathbf{x}, \\mathbf{y}\\in X\\)에 대해 \\[\\| \\mathbf{x}+\\mathbf{y}\\|\\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|\\] 가 성립한다. 임의의 스칼라 \\(\\alpha\\)와 임의의 \\(\\mathbf{x}\\in X\\)에 대해 \\[\\| \\alpha \\mathbf{x}\\|=|\\alpha| \\|\\mathbf{x}\\|\\] 가 성립한다. 2.3.6.2 행렬 노름(matrix norm) References "],
["2-4-matrix-decomposition.html", "2.4 행렬의 분해(matrix decomposition)", " 2.4 행렬의 분해(matrix decomposition) 2.4.1 고유값 분해(eigenvalue decomposition) 고유값 분해는 행렬 \\(A\\)가 \\(n\\times n\\) 정방행렬일 때만 적용 가능하다. 2.4.2 스펙트럼 분해(spectral decomposition) \\(p\\times p\\) 대칭행렬 \\(A\\)에 대한 스펙트럼 분해(spectral decomposition)는 다음과 같다. \\(p\\times p\\) 대칭행렬 \\(A\\)는 직교행렬 \\(P\\)에 의해 대각화(diagonalization)된다고 한다. \\[A=P\\Lambda P^{T}=\\sum_{i=1}^{p}\\lambda_{i}e_{i}e_{i}^{T}.\\] 이때 \\(PP^{T}=P^{T}P=I\\)를 만족하는 직교행렬 \\(P\\)는 \\(P=[e_{1},\\ldots , e_{p}]\\)로 이루어지며, \\(\\Lambda\\)는 \\(A\\)의 고유값(eigenvalue)들로만 이루어진 대각행렬(diagonal matrix) \\[ \\Lambda= \\begin{bmatrix} \\lambda_{1} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ 0 &amp; \\cdots &amp; \\lambda_{p}\\\\ \\end{bmatrix} \\] 이다. 대각행렬 \\(\\Lambda\\)는 \\(P^{T}AP=\\Lambda\\)이다. 2.4.3 특이값분해(SVD) 특이값분해(singular value decomposition, SVD)는 \\(m\\times n\\) 직사각형 행렬 \\(A\\)에 대해 스펙트럼 분해를 일반화한 것이다. \\(A\\)의 특이값 분해는 다음과 같다. \\[A=U\\Sigma V^{T}.\\] 이 때 \\(U\\): \\(A\\)의 left singular vector로 이루어진 \\(m\\times m\\) 직교행렬(orthogonal matrix) \\(\\Sigma\\): 주 대각성분이 \\(\\sqrt{\\lambda_{i}}\\)로 이루어진 \\(m\\times n\\) 직사각 대각행렬(diagonal matrix) \\(V\\): \\(A\\)의 right singular vector로 이루어진 \\(n\\times n\\) 직교행렬(orthogonal matrix) 행렬 \\(A\\)의 계수(rank)가 \\(k\\)라고 할 때, \\(U=[u_{1},\\ldots , u_{k}, \\ldots u_{m}]\\)는 \\(AA^{T}\\)를 고유값분해(eigenvalue decomposition)로 직교대각화하여 얻은 \\(m\\times m\\) 직교행렬(orthogonal matrix)이며, 특히 \\([u_{1},\\ldots, u_{k}]\\)를 좌특이벡터(left signular vector)라고 한다. \\(V=[v_{1},\\ldots ,v_{k},\\ldots , v_{n}]\\)는 \\(A^{T}A\\)를 고유값분해로 직교대각화하여 얻은 \\(n\\times n\\) 직교행렬이며, 특히 \\([v_{1},v_{2},\\ldots ,v_{k}]\\)를 우특이벡터(right signular vector)라고 한다. \\(\\Sigma\\)는 \\(A^{T}A\\)의 0이 아닌 고유값이 \\(\\lambda_{1},\\lambda_{2},\\ldots , \\lambda_{k}\\)일 때 \\(\\sqrt{\\lambda_{1}},\\ldots, \\sqrt{\\lambda_{k}}\\)를 대각성분으로 가지고 나머지 성분을 0으로 갖는 \\(m\\times n\\) 직사각 대각행렬(diagonal matrix)이다. \\[ \\Sigma= \\begin{bmatrix} \\sqrt{\\lambda_{1}} &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\sqrt{\\lambda_{2}} &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; 0\\\\ 0 &amp; 0 &amp; \\cdots &amp; \\sqrt{\\lambda_{k}} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ \\end{bmatrix}. \\] 즉 \\(A\\)를 다시 쓰면 \\[ A= \\begin{bmatrix} u_{1} &amp; \\cdots &amp; u_{k} &amp; \\cdots &amp; u_{m}\\\\ \\end{bmatrix} \\begin{bmatrix} \\sqrt{\\lambda_{1}} &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\sqrt{\\lambda_{2}} &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; 0\\\\ 0 &amp; 0 &amp; \\cdots &amp; \\sqrt{\\lambda_{k}} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\\\ \\end{bmatrix} \\begin{bmatrix} V_{1}^{T}\\\\ \\vdots \\\\ V_{k}^{T}\\\\ \\vdots\\\\ V_{n}^{T}\\\\ \\end{bmatrix} \\] 이다. 위 식에서 특이값(singular value)는 \\(\\sigma_{i}^{2}=\\lambda_{i}\\)로부터 \\(\\sigma_{i}=\\sqrt{\\lambda_{i}}\\)가 된다. 참고로 \\(U, V\\)가 직교행렬이면 \\(UU^{T}=I\\), \\(VV^{T}=I\\)가 성립한다. 2.4.4 특이값분해와 고유값분해의 관계(the relationship between spectral decomposition and eigenvalue decomposition) \\(m\\times n\\) 행렬 \\(A\\)의 특이값분해의 \\(U\\)는 \\(AA^{T}\\)의 고유벡터이고, \\(V\\)는 \\(A^{T}A\\)의 고유벡터이며, \\(A\\)의 0이 아닌 특이값들의 제곱 \\(\\Sigma\\Sigma^{T}, \\Sigma^{T}\\Sigma\\)는 \\(AA^{T}\\), \\(A^{T}A\\)의 고유값과 같음을 알 수 있다. 참고로 \\(\\sigma_{i}=\\sqrt{\\lambda_{i}}\\) 이므로 \\(\\Sigma\\Sigma^{T}\\) 또는 \\(\\Sigma^{T}\\Sigma=\\lambda_{i}\\)이다. \\[\\begin{eqnarray*} U&amp;=&amp;AA^{T}\\\\ &amp;=&amp;(U\\Sigma V^{T})(U\\Sigma V^{T})^{T}\\\\ &amp;=&amp;(U\\Sigma V^{T})(V\\Sigma^{T} U^{T})\\\\ &amp;=&amp;U(\\Sigma\\Sigma^{T})U^{T}\\\\ \\end{eqnarray*}\\] \\[\\begin{eqnarray*} V&amp;=&amp;A^{T}A\\\\ &amp;=&amp;(U\\Sigma V^{T})^{T}(U\\Sigma V^{T})\\\\ &amp;=&amp;(V\\Sigma^{T} U^{T})(U\\Sigma V^{T})\\\\ &amp;=&amp;V(\\Sigma^{T}\\Sigma)V^{T}\\\\ \\end{eqnarray*}\\] 즉 \\(u_{1},\\ldots , u_{k}, \\ldots u_{m}\\)는 range\\((A)\\)의 직교정규벡터, \\(v_{1},\\ldots ,v_{k},\\ldots , v_{n}\\)는 \\(\\mathcal{N}(A)^{\\perp}\\)의 직교정규벡터이다. 2.4.5 특이값 분해에 대한 추가 설명(additional explanation about spectral decomposition) 여기서는 Boyd 교수의 강의노트를 참고하였다. 잠시 편의를 위해 \\(U\\) 는 \\(m\\times n\\) 행렬, \\(\\Sigma\\)는 \\(n \\times n\\) 행렬이라고 하자. 그러면 특이값 분해는 \\[A=U\\Sigma V^{T}=\\sum_{i=1}^{n}\\sigma_{i}u_{i}v_{i}^{T}\\] FIGURE 2.3: SVD 그림. 가 된다. 선형 사상(mapping) \\(y=Ax\\)는 다음과 같이 분해할 수 있다. \\(x\\)를 input direction들 \\(v_{1}, \\ldots , v_{n}\\)을 따라 계수들을 계산한다. \\(\\sigma_{i}\\)는 척도계수 이것들을 다시 output directions \\(u_{1}, \\ldots, u_{n}\\)을 따라 재구성한다. 대칭행렬 \\(A\\)에 대한 고유값 분해와 달라지는 점은 input direction들과 output direction들이 다르다는 것이다. \\(v_{1}\\)는 input direction으로 가장 민감하다.(most sensitive, highest gain) \\(u_{1}\\)은 output direction으로 가장 민감하다. \\(Av_{1}=\\sigma_{1}u_{1}\\)이다. Example 2.3 (SVD의 기하학적 의미 예) \\(A=\\mathbb{R}^{2\\times 2}\\)이며 \\(\\Sigma=\\text{diag}(1,0.5)\\)인 경우를 생각해보자. 이 경우 \\(x\\)를 \\(v_{1}\\), \\(v_{2}\\)를 따라 풀면 \\(v_{1}^{T}x=0.5, v_{2}^{T}x=0.6\\) 즉 \\(x=0.5v_{1} + 0.6v_{2}\\)이며, \\(Ax=(v_{1}^{T}x)\\sigma_{1}u_{1} + (v_{2}^{T}x)\\sigma_{2}u_{2}= (0.5)(1)u_{1} + (0.6)(0.5)u_{2}\\) 이다. FIGURE 2.4: SVD 예제 그림. 2.4.6 특이값 분해의 기하학적 의미(geometrical meaning of spectral decomposition) 위키피디아를 참고하자. "],
["2-5-basis.html", "2.5 기저(basis)", " 2.5 기저(basis) 2.5.1 리츠 기저(Riesz basis) In the Hilbert space \\(L_{2}[0,1]\\), an unconditional basis is called a Riesz basis if it is “almost normalized”. This means that there exist real, positive, non-zero consts \\(m\\) and \\(M\\) so that \\[0 &lt; m \\leq \\| \\phi_{i}\\|\\leq M &lt; \\infty.\\] A Riesz basis is characterized by two Riesz constants \\(A\\) and \\(B\\), so that for all \\(f=\\sum_{i}s_{i}\\phi_{i}\\in L_{2}[0,1]\\), \\[A^{2}\\| f \\|^{2}\\leq \\sum_{i\\in\\mathbb{Z}}s_{i}^{2}\\leq B^{2}\\|f\\|^{2}.\\] (Jensen의 Noise reduction and wavelet thresholding으로부터) There exists \\(\\phi_{0}(x)\\in\\mathcal{V}_{1}\\) such that \\(\\{ \\phi_{0}(x-k) | k\\in\\mathcal{Z} \\}\\) forms a Riesz basis of \\(\\mathcal{V}_{1}\\), i.e, there exists \\(0&lt; A \\leq B &lt;\\infty\\) such that \\[A \\| c_{k}\\|^{2} \\leq \\| \\sum_{k}c_{k}\\phi_{0}(x-k)\\|^{2} \\leq B \\| c_{k} \\|^{2}\\] for all \\(\\{c_{k}\\}\\in l^{2}\\), where \\(A\\) and \\(B\\) do not depend on the \\(c_{k}\\) (동익이형 박사논문 47쪽) 2.5.2 Radial basis function Radial funtion이란 거리에만 의존하는 함수를 의미한다. 어떤 함수에 대한 근사 모델을 radial function의 선형조합으로 표현할 수 있다. Gaussian \\[\\phi(r)=e^{-(\\epsilon r)^{2}}\\] Multiquadric \\[\\phi(r)=\\sqrt{1+(\\epsilon r)^{2}}\\] Inverse quadratic \\[\\phi(r)=\\frac{1}{1+(\\epsilon r)^{2}}\\] Inverse multiquadric \\[\\phi(r)=\\frac{1}{\\sqrt{1+(\\epsilon r)^{2}}}\\] "],
["2-6-space.html", "2.6 공간(space)", " 2.6 공간(space) 이 부분은 전체적으로 (Shima 2016)의 정의와 내용들을 따라간다. 2.6.1 군과 장(groups and fields) 수학에서 군(group)은 연산과 함께 정의되는 원소들의 집합으로 원소들이 closure, associativity, identity and invertability를 만족해야 한다. 대충 말해서 장(field)은 합, 차, 곱, 몫의 개념을 갖고 있는 대수적 구조이다. 2.6.2 벡터 공간(vector spaces) 벡터 공간은 덧셈과 곱셈을 적용할 수 있는 수학적 실재(mathematical entity)들의 집합이다. 예를 들면 숫자 공간 \\(\\mathbb{R}\\), \\(\\mathbb{C}\\) 등은 벡터 공간이 된다. 숫자 뿐만 아니라 함수, 다항식, 선형 연산자, 벡터 등등이 수학적 실재가 될 수 있다. FIGURE 2.5: 벡터 공간은 다양한 종류의 수학적 실재(mathematical entity)로부터 만들어진다. 벡터 공간(vector space) \\(V\\)는 다음 공리들을 만족하는 원소들 \\(\\mathbf{x}\\) (벡터라 부른다)의 collection이다. \\(V\\)는 덧셈 하에서 교환 가능한 가환군(commutative group, 교환 법칩이 성립하는 군)이다. \\(\\mathbf{x}+\\mathbf{y}=\\mathbf{y}+\\mathbf{x}\\in V\\) for any \\(\\mathbf{x},\\mathbf{y}\\in V\\) (closure) \\(\\mathbf{x} + (\\mathbf{y}+\\mathbf{z}) = (\\mathbf{x} + \\mathbf{y}) + \\mathbf{z}\\in V\\) for any \\(\\mathbf{x},\\mathbf{y}, \\mathbf{z}\\in V\\) (associativity) 다음과 같은 \\(\\mathbf{0}\\)벡터(항등원)가 존재해 모든 \\(\\mathbf{x}\\in V\\)에 대해 \\(\\mathbf{x}+\\mathbf{0}=\\mathbf{x}\\)를 만족한다. (identity) 다음과 같은 덧셈에 대한 역원 \\(-\\mathbf{x}\\)이 존재해 \\(\\mathbf{x}+(-\\mathbf{x})=\\mathbf{0}\\)이 된다. (invertibility) \\(V\\)는 어떤 장 \\(\\mathbb{F}\\)에 대해 다음의 공리를 만족하며, 이런 원소들을 스칼라(scalar)라고 부른다. \\(V\\)는 스칼라 곱에 대해 닫혀 있다. \\[\\alpha \\mathbf{x} \\in V \\text{ for arbitrary } \\mathbf{x} \\in V, \\alpha \\in \\mathbb{F}.\\] 스칼라 곱은 \\(V\\)와 \\(\\mathbb{F}\\)의 원소들에 대해 분배가능(distributive)하다. \\[\\alpha(\\mathbf{x}+\\mathbf{y})=\\alpha\\mathbf{x}+ \\alpha\\mathbf{y}\\in V, (\\alpha+\\beta)\\mathbf{x}=\\alpha\\mathbf{x}+\\beta\\mathbf{y}\\in V.\\] 스칼라 곱은 결합법칙이 성립한다. \\(\\alpha(\\beta\\mathbf{x})=\\beta(\\alpha \\mathbf{x}).\\) Zero scalar \\(0\\in\\mathbb{F}\\)에 대한 곱은 항등원 \\(0\\mathbf{x}=\\mathbf{0}\\in V\\)을 생산한다. Unit scalar \\(1 \\in \\mathbb{F}\\)는 \\(1\\mathbf{x}=\\mathbf{x}\\) 성질을 갖는다. 여기서부터는 벡터 공간의 주요 성질들에 대해 다룬다. 2.6.3 내적(inner products) Definition 2.10 (내적) 내적은 \\(\\mathbf{x}\\), \\(\\mathbf{y}\\)의 순서쌍을 스칼라(좀 더 일반적으로는 복소수)에 mapping하는 것이고 \\(\\langle\\mathbf{x},\\mathbf{y}\\rangle\\)로 쓴다. 이 mapping은 다음 규칙들을 만족해야 한다. \\(\\langle\\mathbf{x},\\mathbf{y}\\rangle = \\langle\\mathbf{y},\\mathbf{x}\\rangle^{*}\\). (여기서 별표는 complex conjugate를 의미한다.) \\(\\langle\\alpha\\mathbf{x}+\\beta\\mathbf{y}, \\mathbf{z}\\rangle = \\alpha^{*}\\langle\\mathbf{x},\\mathbf{z}\\rangle+\\beta^{*}\\langle\\mathbf{y},\\mathbf{z}\\rangle\\) (여기서 \\(\\alpha\\), \\(\\beta\\)는 어떤 복소수이다.) 모든 \\(\\mathbf{x}\\)에 대해 \\(\\langle\\mathbf{x},\\mathbf{x}\\rangle \\geq 0\\)이다. \\(\\langle\\mathbf{x},\\mathbf{x}\\rangle = 0\\)은 \\(\\mathbf{x}=\\mathbf{0}\\)과 필요충분조건이다. 특별히 내적을 갖고 있는 벡터 공간을 내적 공간(inner product space)이라고 부른다. 2.6.4 정규직교성(orthogonality) 2.6.4.1 완비 벡터 공간(complete vector spaces) 벡터 공간이 유한차원일 때, 공간의 완비성(completeness)은 같은 공간의 다른 larger orthonormal set에 포한되어 있지 않는 orthonormal set을 찾음으로써 증명할 수 있다. 예를 들면 3차원 공간에서는 linear combination이 그 공간의 모든 벡터를 표현할 수 있는 three orthonormal vector의 set을 찾기만 하면 되는 것이다. 그러나 우리가 무한 차원 공간을 고려할 때, 무한한 숫자의 orthonormal vector를 고려하는 것은 쉽지 않다. 사실 무한한 숫자의 vector의 linear combination은 때대로 같은 공간에 포함된 벡터를 표현하는 데 충분치 않을 수도 있다. 이러한 모호함을 해결하기 위해 무한 차원 공간에서 완비성을 생각하는 것이다. Definition 2.11 (벡터의 Cauchy sequence) 벡터의 수열 \\(\\{ \\mathbf{x}_{1},\\mathbf{x}_{2},\\ldots \\}\\)가 모든 \\(\\epsilon &gt;0\\)에 대해 적단한 근사 숫자 \\(N\\)이 존재해 모든 \\(m,n &gt; N\\)에 대해 \\(\\| \\mathbf{x}_{m} -\\mathbf{x}_{n} \\| &lt; \\epsilon\\)을 만족한다면 이를 벡터의 코시 수열(Cauchy sequence)이라고 한다. 쉽게 얘기하자면 \\(\\mathbf{x}_{m}\\)과 \\(\\mathbf{x}_{n}\\)이 \\(m,n \\rightarrow \\infty\\) 함체 따라 가까어지는 수열을 코시 수열이라 부르는 것이다. Definition 2.12 (코시 수열의 수렴) 벡터의 무한 수열 \\(\\{\\mathbf{x}_{1},\\mathbf{x}_{2}, \\ldots \\}\\)가 있을 때, 만약 \\(\\mathbf{x}\\)가 존재해 \\(\\| \\mathbf{x}_{n} -\\mathbf{x}\\|\\rightarrow 0\\)을 만족한다면 이 수열이 수렴(convergent)한다고 한다. Definition 2.13 (벡터 공간의 완비성) 만약 어떤 벡터 공간의 모든 코시 수열이 수렴한다면, 우리는 그 공간을 완비(complete)라고 부른다. 2.6.5 위상공간(topological space) 2.6.6 분해 가능 공간(separable space) Countable dense subset을 포함하는 위상공간(topological space)을 분해 가능 공간(separable space)이라고 한다. 2.6.7 노름 공간(normed space) Definition 2.14 (노름 공간) 원소들에 일종의 ‘길이’ 또는 ’크기’가 부여된 벡터 공간 \\(V\\)을 노름 공간(normed space)라고 한다. 노름은 벡터 공간 \\(V\\) 위에서의 실수 함수로 \\(\\| \\|\\)로 표시하며 모든 \\(\\lambda\\in\\mathbb{F}\\)와 \\(x\\in V\\)에 대해 \\(\\|\\lambda \\mathbf{x}\\| = |\\lambda|\\|\\mathbf{x}\\|\\) $| +| || +||# \\(\\|\\mathbf{x}\\|=0\\)이라는 것은 \\(\\mathbf{x}=0\\)과 동치다. 노름 공간에 있는 모든 원소들은 항상 유한한 노름을 갖아야 한다. 만약 무한한 노름을 갖는다면 그것은 공간이 될 수 없다. 노름 \\(\\|\\cdot\\|\\)은 항상 계량(metric)을 유도한다. 계량은 \\(\\mathcal{F}\\)에서의 거리 개념이다. 즉 \\(d(f,g)=\\| f-g\\|_{\\mathcal{F}}\\)이다. 이것은 \\(\\mathcal{F}\\)가 어떤 위상 구조를 갖고있다는 뜻도 되며 우리는 \\(\\mathcal{F}\\)의 원소들의 수열들이 정의된 거리에서 수렴하는지, 또는 연속 등에 대해서 생각할 수 있게 한다. 2.6.8 바나흐 공간(Banach space) Definition 2.15 (힐버트 공간) Normed space가 complete일 경우 이를 바나흐 공간(Banach space)라고 부른다. 유한차원에서 노름공간은 항상 완비(complete)이다. 그러나 무한차원에서 노름공간은 완비일 수도 있고, 아닐 수도 있다. Definition 2.16 (원-힐버트 공간) Inner product spaces들 중 완비가 아닌 공간들을 원-힐버트 공간(pre-Hilbert space)라고 부른다. 2.6.9 힐버트 공간(Hilbert space) 모든 힐버트 공간은 함수가 무한차원 공간의 점으로서 간주될 수 있도록 하는 수단을 제공해 준다. 이런 기하학적인 관점의 쓰임새는 우리가 기초 선형대수에서 정의했던 길이, 직교정규, 그리고 원소들의 선형 결합 개념들을 좀 더 추상적인 수학적 공간에 일반화시킬 수 있다는 것이다. 이런 기하학적 관점에 가장 핵심이 되는 개념은 공간의 기저(basis)다. 힐버트 공간과 함께, 무한차원 공간에서 기저의 기초적 성질들을 복습해 보기로 한다. Definition 2.17 (힐버트 공간) A complete normed space endowed with inner product is called a Hilbert space 다음 그림은 (Shima 2016)에 있는 그림으로 각 공간들 간의 사이의 관계를 이해하는 데 도움이 된다. FIGURE 2.6: Metric vector space로부터 힐버트 공간까지의 관계. 벡터 공간(유한이어도 되고 무한이어도 된다)이 주어졌을 때, 벡터의 직교정규 집합은 만약 이것이 완비(complete)일 때에만 기저로서 작동한다. 만약 한 번 기저를 얻는다면, 그 공간의 벡터는 직교정규 벡터들의 선형 결합으로 분해할 수 있다. 그러나 무한히 많은 직교정규 기저로부터의 무한차원 공간에서 기저를 만들고자 할 때 한 가지 주의해야 할 점은 벡터들의 집합이 완비성을 만족하는지 체크해야 한다는 것이다. 이 주의점은 어떤 공간의 벡터들의 무한 합이 수렴하더라도, 그 극한이 같은 벡터 공간 안에 포함되지 않을 수 있다는 사실로부터 야기된다. 즉 이 극한은원래 공간으로부터 빗나가게 할 수 있게 한다. 이런 경우에는 벡터들의 집합이 무한차원 공간의 기저로써 더이상 작동하지 않는 것을 의미한다. 이러한 점을 좀 더 자세히 살펴보기 위해, 힐버트 공간 \\(V\\)에서의 직교정규 벡터들의 무한집합 \\(\\{ e_{i}\\}\\)에 대해 생각해보자. 그 다음에 우리는 한 개의 벡터 \\(\\mathbf{x}\\in V\\)를 골라 \\(e_{i}\\)의 내적을 계산한다. 그러면 \\(\\mathbf{x}\\) 는 다음과 같이 표현된다. \\[c_{i}\\langle e_{i},\\mathbf{x} \\rangle \\in \\mathbb{C}.\\] 무한 수열 \\(\\{c_{i}\\}\\)와 \\(\\{e_{i}\\}\\)의 처음 \\(n\\)항을 사용해 우리는 다음과 같이 유한합 \\[\\sum_{i=1}^{n}c_{i}e_{i} \\equiv \\mathbf{x}_{n}\\] 을 정의할 수 있다. 힐버트 공간의 대표적인 예로, \\(L^{p}\\) 공간이 있다. \\[\\| f\\|_{p}=(\\int_{S}|f|^{p}d\\mu)^{1/p}&lt;\\infty\\] 박창이 교수님 외 책에서, 통계학에서 힐버트 공간을 고려하는 이유를 설명하였는데, 그 이유는 유한차원에서 성립하는 선형대수를 적용할 수 있기 때문이라고 한다. 특히 힐버트 공간은 완비(complete)된 공간으로써 알고리즘의 수렴성을 보장하며, 내적이 존재하므로써 직교성이나 정사영(projection)을 구할 수도 있다. 2.6.10 Holder 공간(Holder space) 이 공간의 정의는 (Wasserman 2006)를 참고하였다. 어떤 정수 \\(m\\)과 \\(\\delta \\in (0,1)\\)에 대해 \\(s=m+\\delta\\)을 정의하자. Holder 공간(Holder space)(정확하게는 H&quot;{o}lder space)은 bounded m차 derivative를 갖는, 즉 모든 \\(u,t\\)에 대해 \\(|f^{m}(u)-f^{m}(t)|\\leq |u-t|^{\\delta}\\)인 bounded function들의 집합니다. 2.6.11 Sobolev 공간(Sobolev space) 해석학에서 소볼레프 공간(Sobolev space)이란 충분히 매끄럽고, 무한대에서 충분히 빨리 0으로 수렴하는 함수들로 구성된 함수공간으로 르베그 공간의 일반화이다. 이 공간의 정의는 (Wasserman 2006)를 참고하였다. 이 책에서 Sobolev 공간의 정의는 smooth function들의 집합이라는 것이다. \\(D^{j}f\\)를 \\(f\\)의 \\(j\\)번째 weak derivative라고 하자. 먼저 weak differentiability에 대해 알아보자. \\(f\\)가 모든 bounded interval에서 적분 가능하다고 하자. 만약 다음꽈 같은 함수 \\(f&#39;\\)가 존재해 모든 bounded interval에서 적분 가능하다면, 즉 모든 \\(x\\leq y\\)에 대해 \\[\\int_{x}^{y}f&#39;(s)ds=f(y)-f(x)\\] 이라면 이를 weakly differentiable이라 부른다. Definition 2.18 (Sobolev 공간) m차 Sobolev space는 다음과 같다. \\[W(m)=\\{ f \\in L^{2}(0,1): D^{m}f \\in L^{2}(0,1)\\}\\] 반지를 \\(c\\)를 갖는 \\(m\\)차 Sobolev space는 다음과 같다. \\[W(m,c)=\\{ f \\in W(m), \\| D^{m}f \\|^{2} \\leq c^{2}\\}\\] 주기를 갖는 Sobolev class (periodic Sobolev class)는 다음과 같다. \\[\\tilde{W}(m,c)=\\{ f \\in W(m,c): D^{j}f(0)=D^{j}f(1), j=0,\\ldots, m-1 \\}.\\] 2.6.12 Besov 공간(Besov space) 이 공간의 정의 또한 (Wasserman 2006)의 9장을 참고하였다. Wavelet threshold estimator는 Besov space에서 good optimality property를 갖는다. 다음과 같이 \\(\\Delta_{h}^{(r)}f(x)\\)를 정의하자. \\[\\Delta_{h}^{(r)}f(x)=\\sum_{k=0}^{r}\\binom{r}{k}(-1)^{k}f(x+kh).\\] 그러면 \\(\\Delta_{h}^{(0)}f(x)=f(x)\\)이고 \\[\\Delta_{h}^{(r)}f(x)=\\Delta_{h}^{(r-1)}f(x+h)-\\Delta_{h}^{(r-1)}f(x).\\] 이다. 이제 \\(w_{r,p}(f;t)\\)를 다음과 같이 정의하자. \\[w_{r,p}(f;t)=\\sup_{|h|\\leq t}\\|\\Delta_{h}^{(r)}f\\|_{p}.\\] 이 때 \\(\\|g\\|_{p}=\\{ \\int |g(x)|^{p}dx \\}^{1/p}\\)이다. \\((p,g,\\zeta)\\)가 주어졌을 때, \\(r\\)이 존재해 \\(r-1\\leq \\zeta \\leq r\\)을 만족한다면, Besov seminorm \\(|f|_{p,q}^{\\zeta}\\)는 \\[|f|_{p,q}^{\\zeta}=[\\int_{0}^{\\infty}(h^{-\\zeta}w_{r,p}(f;h))^{q}\\frac{dh}{h}]^{1/q}\\] 로 정의된다. \\(q=\\infty\\)일 때는 다음과 같이 정의한다. \\[|f|_{p,\\infty}^{\\zeta}=\\sup_{0&lt;h&lt;1}\\frac{w_{r,p}(f;h)}{h^{\\zeta}}\\] Definition 2.19 (Besov 공간) Besov 공간(Besov space) \\(B_{p,q}^{\\xi}(c)\\)는 \\([0,1]\\)에서 \\(\\mathbb{R}\\)로 가는 함수 \\(f\\)들 중 \\(\\int |f|^{p}&lt;\\infty\\)이고 \\(|f|_{p,q}^{\\zeta}\\leq c\\)인 \\(f\\)들의 집합니다. Sobolev space \\(W(m)\\)은 Besov ball \\(B_{2,2}^{m}\\)에 대응된다. Generalized Sobolev space \\(W_{p}(m)\\)은 \\(m\\)차 미분에서 \\(L^{p}\\) 노름을 사용하는 데 이것은 거의 Besov space와 비슷하다. 사실 \\(B_{p,1}^{m} \\subset W_{p}(m) \\subset B_{p,\\infty}^{m}\\)이다. H&quot;{o}lder space는 \\(B_{\\infty,\\infty}^{m+\\delta}\\)와 같다. \\(T\\)를 bounded variation을 갖는 함수들을 포함하는 집합이라고 할 때, \\(B_{1,1}^{1}\\subset T \\subset B_{1,\\infty}^{1}\\)을 만족한다. 즉 Besov space는 넓은 범위희 함수 공간들을 포함한다. 이에 수렴하는 수열(convergent sequence)와 코시 수열(Cauchy sequence)에 대해 생각해 볼 수 있다. 2.6.13 Skorohod 공간(Skorohod space) \\(D[a,b]\\)을 right continuous하고 left limit을 갖는 함수들 \\(z:[a,b]\\rightarrow \\mathbb{R}\\)의 집합을 Skorohod 공간(Skorohod space)이라고 한다. (Vaart 2000) 257쪽에 나와있다. 2.6.14 웨이블릿 expansion의 계수들로 이해하는 Besov 공간(Besov spaces in terms of the coefficients of the wavelet expansion) 2.6.15 재생 커널 힐버트 공간(reproducing kernel Hilbert space) 재생 커널 힐버트 공간(reproducing kernel Hilbert space)이 주어지면 이에 대응되는 유일한 재생 커널이 존재한다. 역으로, 양정치 커널 \\(K\\)가 주어지면 \\(K\\)를 재생 커널로 갖는 유일한 재생 커널 힐버트 공간 \\(\\mathcal{H}\\)가 존재한다. 2.6.16 C 공간과 D 공간(the spaces C and D) (Beran et al. 2013)의 appendix 참고 References "],
["2-7-distance-and-metric.html", "2.7 거리와 계량(distance and metric)", " 2.7 거리와 계량(distance and metric) 2.7.1 거리(distance) Definition 2.20 (거리) 집합 \\(X\\)의 두 원소들 \\(x,y\\)에 대해 값 \\(d(x,y)\\)를 할당하는 함수 \\(d(\\cdot, \\cdot)\\)가 다음 세 조건들을 임의의 \\(x,y\\in X\\)에 대해서 \\(d(x,y)\\geq 0\\)이다. 여기서 \\(d(x,y)=0\\)이기 위한 필요충분조건은 \\(x=y\\)이다. 임의의 \\(x,y\\in X\\)에 대해서 \\(d(x,y)=d(y,x)\\)이다. 임의의 \\(x,y,z\\in X\\)에 대해서 \\(d(x,z)\\leq d(x,y)+d(y,z)\\)가 성립한다. 만약 \\(d(\\mathbf{x},\\mathbf{y})=\\| \\mathbf{x}-\\mathbf{y}\\|\\)라 하면 노름공간이 거리공간이 된다. 그러나 모든 거리공간이 노름공간으로부터 유도되는 것은 이니다. 군집분석 방법에서는 관측값들의 거리를 이용해 군집을 나눌 때 사용된다. 유클리드 거리(Euclidean distance): \\(d(x,y)=(\\sum_{i=1}^{p}(x_{i}-y_{i})^{2})^{1/2}\\) 민콥스키 거리(Minkowski distance): \\(d(x,y)=(\\sum_{i=1}^{p}(x_{i}-y_{i})^{m})^{1/m}\\) 맨하탄 거리(Manhattan distance): \\(d(x,y)=\\sum_{i=1}^{p}|x_{i}-y_{i}|\\) 표준화 거리(standardized distance): \\(d(x,y)=(\\sum_{i=1}^{p}(x_{i}-y_{i})^{2}/s_{i}^{2})^{1/2}\\), 여기서 \\(s_{i}\\)는 \\(i\\)번째 변수에 대한 표준편차 마할라노비스 거리(Mahalanobis distance): \\(d(x,y)=(x-y)^{T}\\boldsymbol{\\Sigma}^{-1}(x-y)\\), 여기서 \\(\\Sigma\\)는 공분산행렬 체비셰프 거리(Chebychev distance): \\(d(x,y)=\\max_{i=1,\\ldots ,p}|x_{i}-y_{i}|\\) 다음 거리들은 유클리드 거리와 더불어 공간통계에서 많이 쓰이는 것들이다. chordal distance (현 거리? 잘 모르겠음) geodesic distance 다른 거리들도 있다. Hamming distance: (Massart 2007) 책에 나오는 것으로 \\(\\mathcal{X}^{n}\\)을 \\(n\\)개의 확률변수들이 값을 취하는 \\(n\\)차원 공간이라고 할 때 다음과 같다. \\[d(y,y&#39;)=\\sum_{i=1}^{n}\\mathbb{I}_{y_{i}\\neq y&#39;_{i}}, \\qquad{\\forall y,y&#39;\\in\\mathcal{X}^{n}}\\] 2.7.2 계량(metric) 계량(metric)은 두 집합 사이의 모든 원소 짝의 거리를 지정해주는 함수이다. References "],
["2-8-sequences-of-real-functions.html", "2.8 실함수의 수열들(sequences of real functions)", " 2.8 실함수의 수열들(sequences of real functions) 이 부분의 내용은 (Polansky 2011)의 내용을 따른다. 확률변수(random variable)의 수열이 함수의 수열처럼 여겨질 수 있다는 사실에서 함수의 수열의 성질을 이해하는 것은 중요하다. 일반적인 수열의 수렴에 관한 성질들과 비교했을 때 함수의 수열들의 수렴에 관한 성질에서는 여러 개의 정의로 다뤄질 수 있다는 점에서 차이가 있다. 가장 널리 알려진 함수의 수렴은 점별수렴(pointwise convergence)과 균등수렴(uniform convergence)이 있다. Definition 2.21 (점별수렴) \\(\\{ f_{n}(x)\\}_{n=1}^{\\infty}\\)를 실함수의 수열이라고 하자. 그러면 모든 \\(x\\in\\mathbb{R}\\)에 대해 \\[\\lim_{n\\rightarrow \\infty}f_{n}(x)=f(x)\\] 를 만족하는 실함수 \\(f\\)가 존재할 때 수열 \\(\\{ f_{n}(x)\\}_{n=1}^{\\infty}\\)이 \\(f\\)에 점별수렴(pointwise convergence)한다고 한다. 여기서는 \\(n\\rightarrow \\infty\\)일 때 \\[f_{n} \\stackrel{pw}{\\rightarrow} f\\] 로 표현하기로 한다. 점별수렴에서 수렴 문제는 \\(x\\)를 고정된 실수로 놓았을 때 실수열 \\(\\{f_{n}(x)\\}_{n=1}^{\\infty}\\)의 수렴 성질을 보는 것으로 줄일 수 있다. 다음은 (Shima 2016)에 나오는 점별수렴하는 함수열의 예제다. Definition 2.22 (점별수렴의 예) 다음과 같은 닫힌 구간 \\([0,1]\\)에서 정의된 함수열 \\(\\{f_{n}\\}\\) \\[f_{n}(x)=x^{n}\\] 이 있다고 하자. 이 수열은 다음 함수로 점별수렴한다. \\[ f(x)=\\lim_{n\\rightarrow\\infty}f_{n}(x)= \\begin{cases} 0 &amp; 0\\leq x &lt; 1\\\\ 1 &amp; x=1. \\end{cases} \\] FIGURE 2.7: 점별수렴하는 함수의 예. 또한 (Shima 2016)에서 언급한 내용 중 중요한 사실은 점별수렴의 경우에는 앞의 예제에서처럼 원래 함수열들이 모두 연속이라 할지라도 그것의 극한 함수는 연속이 아닐 수도 있다는 점이다. 위 예제에서 \\(f(x)\\)는 \\(x=1\\)에서 불연속이다(그림). 이 말은 또한 점별수렴에서는 극한의 순서를 바꾸었을 경우 그 결과가 아래 식처럼 서로 다를 수 있음을 의미한다. \\[\\lim_{x\\rightarrow 1}\\lim_{n\\rightarrow\\infty}f_{n}(x)\\neq \\lim_{n\\rightarrow\\infty}\\lim_{x\\rightarrow 1}f_{n}(x).\\] 이런 현상은 함수열 \\(f_{n}(x)\\)의 미분가능성과 적분가능성에서도 비슷하게 일어난다. 즉, 점별수렴 하에서는 함수열들이 모두 적분가능하거나 미분가넝하더라고 그것의 극한은 그렇지 않을 수도 있음을 의미한다. 이러한 예제들로 다음 예제들이 있다. Definition 2.23 (점별수렴과 적분의 순서) 다음과 같은 함수 \\[f_{n}(x)=nx(1-x^{2})^{n}, \\qquad{x\\in [0,1]}\\] 이 있다고 하자. 여기서는 극한과정 \\(n\\rightarrow\\infty\\)와 적분의 순서를 바꾸면 다른 결과를 줄 것임을 보여줄 것이다. 주어진 함수는 각각의 \\(n\\)에 대해 적분 가능하며 다음과 같다. \\[ \\begin{align*} \\int_{0}^{1}f_{n}(x)dx &amp;= n \\int_{0}^{1}x(1-x^{2})^{n}dx = \\Big[\\frac{-n}{2(n+1)}(1-x^{2})^{n+1}\\Big]_{0}^{1}\\\\ &amp;= \\frac{n}{2(n+1)}\\rightarrow \\frac{1}{2}. \\end{align*} \\] 반대로, 극한은 다음과 같다. \\[f(x)=\\lim_{n\\rightarrow\\infty}f_{n}(x)=0, \\qquad{\\forall x\\in [0,1].}\\] 따라서 당연히 \\(\\int_{0}^{1}f(x)dx=0\\)이다. 그래서 다음과 같은 결론을 내릴 수 있다. \\[\\lim_{n\\rightarrow\\infty}\\int_{0}^{1}f_{n}(x)dx\\neq \\int_{0}^{1}\\lim_{n\\rightarrow\\infty}f_{n}(x)dx.\\] 결론은, 점별수렴 과정에서는 극한 과정과 적분의 순서를 바꾸는 것은 안되다는 것이다. Definition 2.24 (점별수렴과 미분의 순서) 다음과 같은 함수 \\[ f_{n}(x)= \\begin{cases} -1 &amp; x &lt; -\\frac{1}{n},\\\\ \\sin(\\frac{n\\pi x}{2}) &amp; -\\frac{1}{n} &lt; x \\frac{1}{n},\\\\ 1 &amp; x&gt;\\frac{1}{n}. \\end{cases} \\] 우리는 이 함수의 \\(x=0\\)에서의 극한 \\(f(x)=\\lim_{n\\rightarrow\\infty}f_{n}(x)\\)의 연속성을 점검해 볼 것이다. \\(f_{n}(x)\\)는 모든 \\(x\\in \\mathbb{R}\\)에서 미분 가능하므로 당연히 모든 \\(n\\)에서 \\(x=0\\)일 때 연속이다. 그러나 그것의 극한은 \\[ f(x)= \\begin{cases} -1 &amp; x&lt;0,\\\\ 0 &amp; x=0, \\\\ 1 &amp; x &gt;0 \\end{cases} \\] 이며 \\(x=0\\)에서 불연속이다. 따라서 점별수렴 과정에서는 극한 과정과 미분의 순서를 바꾸는 것은 안된다. 점별수렴보다 더 강한 조건으로 \\(x \\in \\mathbb{R}\\)에 상관 없이 모든 지점에서 동시에 \\(n\\rightarrow\\infty\\)일 때 \\(f_{n}(x) \\rightarrow f(x)\\)이길 요구할 수도 있다. 이 때 사용되는 정의가 균등수렴이다. Definition 2.25 (균등수렴) \\(\\{ f_{n}(x)\\}_{n=1}^{\\infty}\\)를 실함수의 수열이라고 하자. 그러면 모든 \\(\\epsilon &gt; 0\\)에 대해 \\[|f_{n}(x)-f(x)| &lt;\\epsilon \\forall n \\geq n_{\\epsilon} \\text{ and } x\\in \\mathbb{R}\\] 을 만족시키는 정수 \\(n_{\\epsilon}\\)이 존재할 때 수열 \\(\\{ f_{n}(x)\\}_{n=1}^{\\infty}\\)이 \\(f\\)에 균등수렴(uniform convergence)한다고 한다. 여기서는 \\(n\\rightarrow \\infty\\)일 때 \\[f_{n} \\stackrel{u}{\\rightarrow} f\\] 로 표현하기로 한다. FIGURE 2.8: 균등수렴하는 함수의 예. 균등수렴에서는 어떤 밴드를 잡았을 때, n을 적당히 조절하여 함수열이 그 밴드 안에 들어가도록 할 수 있다. 균등수렴과 관련된 정리로 어떤 연속함수들의 함수열이 균등수렴이면 그 수열의 극한 또한 반드시 연속이어야 한다는 정리가 있다. 이 정리는 (Polansky 2011)에 나와있다. Theorem 2.1 (함수열의 균등수렴과 함수열의 극한의 연속) \\(\\{f_{n}(x)\\}_{n=1}^{\\infty}\\)가 \\(\\mathbb{R}\\)의 부분집합 \\(R\\)에서 정의된 함수들의 수열이며 함수 \\(f\\)로 균등수렴한다고 하자. 만약 각각의 \\(f_{n}\\)들이 어떤 점 \\(x\\in R\\)에서 연속이면, \\(f\\) 또한 점 \\(x\\)에서 연속이어야 한다. 이 정리의 증명은 Apostol (1974)의 9.4절에서 발견할 수 있다고 한다. 여기서 알아두어야 할 것은 균등수렴은 충분조건이며 필요조건이 아니라는 것이다. 즉 2.8.1 수렴하는 수열(convergent sequence) Definition 2.26 ((함수해석학에서) 수렴하는 수열) 노름 벡터 공간 \\((\\mathcal{F}, \\| \\cdot\\|_{\\mathcal{F}})\\)의 원소들로 이루어진 수열 \\(\\{ f_{n}\\}_{n=1}^{\\infty}\\)가 모든 \\(\\epsilon &gt;0\\)에 대해 \\(N=N(\\epsilon)\\in \\mathbb{N}\\)이 존재해 모든 \\(n \\geq \\mathbb{N}\\)에 대해 \\(\\| f_{n}-f\\|_{\\mathcal{F}} &lt;\\epsilon\\)을 만족할 때, 우리는 수열이 \\(f\\in \\mathcal{F}\\)에 수렴(converge) 한다고 한다. 2.8.2 코시 수열(Cauchy sequence) Definition 2.27 ((함수해석학에서) 수렴하는 수열) 노름 벡터 공간 \\((\\mathcal{F}, \\| \\cdot\\|_{\\mathcal{F}})\\)의 원소들로 이루어진 수열 \\(\\{ f_{n}\\}_{n=1}^{\\infty}\\)가 모든 \\(\\epsilon &gt;0\\)에 대해 \\(N=N(\\epsilon)\\in \\mathbb{N}\\)이 존재해 모든 \\(m,n \\geq \\mathbb{N}\\)에 대해 \\(\\| f_{m}-f_{n}\\|_{\\mathcal{F}} &lt;\\epsilon\\)을 만족할 때, 수열 \\(\\{ f_{n}\\}_{n=1}^{\\infty}\\)를 코시 수열(Cauchy sequence)이라고 한다. Example 2.4 (유리수의 장) 절대값 \\(\\| \\cdot\\|\\)을 노름으로 갖는 유리수 \\(\\mathbb{Q}\\)의 장(field)은 노름 벡터 공간이다. 여기서 수열 \\(1, 1.4, 1.41, \\ldots\\)는 \\(\\mathbb{Q}\\)에서의 코시 수열이나 이것의 극한 \\(\\sqrt{2} \\notin \\mathbb{Q}\\)이므로 수렴하는 수열은 아니다. Example 2.5 (C[0,1]) \\(C[0,1]\\)을 구간 \\([0,1]\\)에서 bounded continuous인 함수들의 집합이라고 하자. 다음과 같은 노름 \\(\\| f\\| =(\\int_{0}^{1}|f(x)|^{2}dx)^{1/2}\\)을 생각할 때 함수들의 수열 \\(\\{ f_{n}\\}\\)은 \\([0, \\frac{1}{2}-\\frac{1}{2n} ]\\)에서 \\(0\\)이고 \\([\\frac{1}{2}+\\frac{1}{2n}, 1]\\)에서 \\(1\\)이기 때문에 코시 수열이나 연속 극한(continuous limit)은 존재하지 않는다. FIGURE 2.9: L2 norm에서 연속 극한을 갖지 않는 연속함수들의 코시 수열의 예. References "],
["2-9-continuity.html", "2.9 연속(continuity)", " 2.9 연속(continuity) 2.9.1 립쉬츠 연속(Lipschitz continous) (Abbott 2015)의 문제 4.4.9를 참고하였다. 어떤 함수 \\(f:A\\rightarrow \\mathbb{R}\\)이 립쉬츠 연속(Lipschitz continous)이라는 것은 모든 \\(x\\neq y\\)에 대해 유계 \\(M &gt;0\\)이 존재해 \\[|\\frac{f(x)-f(y)}{x-y}|\\leq M\\] 을 만족하는 것이다. 기하학적으로 말하면 어떤 함수 \\(f\\)가 립쉬츠라는 것은 \\(f\\)의 임의의 두 점을 잡아 기울기를 계산해도 그것을 cover할 수 있는 uniform bound가 존재한다는 것이다. 만약 \\(f\\)가 미분 가능할 경우 \\(x\\)가 \\(y\\)랑 매우 가까워지게 되면 좌변은 미분의 절대값임을 알 수 있다. 그러나 립쉬츠 연속이 \\(f\\)가 미분가능함을 말하는 것은 아니다. 단지 \\(f\\)가 너무 가파르지 않은 함수라는 것만 알 수 있을 뿐이다. 함수 \\(f:A\\rightarrow \\mathbb{R}\\)가 립쉬츠이면 그 함수는 또한 \\(A\\)에서 uniformly continuous하다. References "],
["3-measure.html", "Chapter 3 측도", " Chapter 3 측도 권순식 교수님의 르베그 적분론 강의노트를 참고하였다. Pivato의 Analysis, Measure, and Probability: A visual introduction 또한 참고하였다. 측도(measure)란 수학에서, 양(quantity)이라 개념을 반영하기 위해 만들어진 장치다. FIGURE 3.1: Cardinality, length, area, volume, frequency and probability. \\(\\mathbf{X}\\)를 집합이라고 하자. 그리고 부분집합들 \\(\\mathbf{U,V}\\subset \\mathbf{X}\\)이 있는데 이들의 ’size’를 비교하고 싶어한다. 이런 ’quantity’의 개념들은 여러가지가 있다. Cardinality: 이산 집합에 해당하는 것으로 어떤 지역의 인구 수나 가방 안의 구슬들의 숫자 등이 해당된다. Length: 줄과 같은 1차원 물체에 적용할 수 있다. Area: 카펫과 같은 2차원 물체에 적용할 수 있다. Volume: 물병의 용량과 같은 3차원 물체에 적용할 수 있다. Mass: 물질의 양을 잴 때 사용한다. Charge: 전자기기에 사용된는 양의 크기 Average Frequency: 종종 어떤 사건이 일어날 때 평균의 양을 정하기 위해 사용한다. 이러한 주기들은 가법성을 갖는다. 예를 들면 1년 중 흐린 날의 숫자를 센다고 했을 때 이들은 흐리면서 비온날 + 흐리면서 비는 안온날 의 합으로 생각할 수 있다. Probability: 어떤 사건이 일어날 것의 승산(odds)을 말하며 이들 또한 가법성을 갖는다. "],
["3-1-limitation-of-riemman-integral.html", "3.1 리만 적분의 한계정(limitation of Riemman integral)", " 3.1 리만 적분의 한계정(limitation of Riemman integral) 전형적인 적분(integral) \\(\\int_{A}f(x)dx\\)는 다음으로 구성되어있다. \\(A\\): the set of integration (or the domain of integration) \\(f(x)\\): the integrand \\(dx\\): the integrator 다시 말해서, 적분이란 것은 연속적으로 변하는 물체들의 합인 것이다. 이는 역사적으로 적분기호 \\(\\int\\)가 합을 뜻하는 sum의 \\(S\\)에서 온 것에서도 확인할 수 있다. 이 적분은 다음 \\[\\sum_{\\alpha\\in I}\\max_{x\\in A_{\\alpha}}f(x)|A_{\\alpha}| \\text{ or } \\sum_{\\alpha\\in I}\\min_{x\\in A_{\\alpha}}f(x)|A_{\\alpha}|\\] 을 근사한다. 이 때 우리는 적분을 하고자 하는 집합 \\(A\\)를 disjoint set으로 나눌 수 있다, 즉 \\(A=\\bigcup_{\\alpha\\in I}A_{\\alpha}\\)로 나눌 수 있다고 가정하고 각 집합 \\(A_{\\alpha}\\) 에서 \\(f\\)는 거의 상수라고 가정한다. 여기서 우리는 \\(|A_{\\alpha}|\\)를 집합 \\(A_{\\alpha}\\)의 size라고 하자. 그리고 \\(\\max_{x\\in A_{\\alpha}}f(x)\\) 또는 \\(\\min_{x\\in A_{\\alpha}}f(x)\\)를 \\(A_{\\alpha}\\)에서의 함수값들을 대표하는 값으로 선택된 것이라 생각해보자. 가장 쉽게 질문할 수 있는 것은 ‘어떻게 set의 size를 정할 것인가?’ 라는 문제가 있다. 리만 적분(Riemman integral)에서는 interval (또는 rectangle, cube 등등)들의 size만 측도(measure)하면 된다. Example 3.1 (정의역과 치역이 1차원인 함수에서의 리만 적분) \\(f\\)를 \\(\\mathbb{R}\\)에서 정의된 함수고 정의역이 \\([a,b]\\)라고 하자. 그러면 우리는 구간 \\([a,b]\\)를 더 잘게, \\([x_{0}=a,x_{1}], [x_{1},x_{2}],\\ldots, [x_{n-1},x_{n}=b]\\)로 나누고 적분을 다음 값으로 근사한다. \\[\\sum_{i=1}^{n}f(x_{i})|x_{i}-x_{i-1}|.\\] 이 합의 극합이 적분값이 되며 우리는 이 적분을 리만 적분이라고 부른다. 여기서는 \\(\\mathbb{R}\\)에서의 집합들의 크기(size)를 측도하기 위해 interval을 사용하였다. FIGURE 3.2: 1차원 공간의 정의역을 자르는 방법. FIGURE 3.3: 2차원 공간의 정의역을 자르는 방법. 이 경우에는 사각형의 면적이 집합의 크기가 된다. 그러나, 불연속 함수의 경우에는 interval (또는 rectangle, cube 등등)의 크기를 재는 것이 적분을 정의하기에 충분치 않을 수도 있다. 따라서 우리는 먼저 집합의 크기를 정의하는 것 부터 다시 정의할 필요가 있다. 이제부터 ’집합의 크기(size)’를 집합의 측도(measure)라고 부를 것이다. 측도함수(measure function) \\(m\\)는 \\[m:\\mathcal{M}\\rightarrow [0,\\infty], \\mathcal{M}\\subseteq\\mathcal{P}(\\mathbb{R}^{n})\\] 이다. 즉 \\(\\mathcal{M}\\)dms \\(\\mathcal{P}(\\mathbb{R}^{n})\\)의 subcollection이다. 이제 여기서의 목표는 적분이론에 잘 맞는 적절한 \\(m,\\mathcal{M}\\)을 찾는 것이다. 그런데 우리가 모든 \\(\\mathcal{P}(\\mathbb{R}^{n})\\)에 대해 \\(m\\)을 정의할 수 있을까? 만약 그렇지 않다면, 적어도 우리는 \\(\\mathcal{M}\\)에서의 측도 \\(m\\)이 interval이나 rectangle, open set, compact set 등 좋은 ’집합’들에서 모두 잘 정의되게끔 구성하고자 한다. 더 나아가, 우리는 이 적분함수 \\(m\\)을 우리 직관에 일치하도록 확장시키고자 한다. 그 직관이란, \\(m(\\emptyset)=0\\) \\(m([a,b])=b-a\\) 또는 \\(m(\\text{Rectangle})=|\\text{vertical side}|\\times |\\text{horizontal side}|\\) 만약 \\(A\\subset B\\)인 경우 \\(m(A)\\leq m(B)\\) 만약 \\(A,B\\)가 disjoint인 경우 \\(m(A\\cup B)=m(A)+m(B)\\) 더 나아가, 우리는 측도가 countable additivity를 갖길 원한다. 즉 \\(A_{i},i=1,2,\\ldots\\)가 disjoint이면 \\(\\sum_{i=1}^{m}=m(\\cup_{i=1}^{\\infty}A_{i}).\\) 정리하면, 만족스러운 적분이론을 얻기 위해 우리는 \\(\\mathbb{R}^{n}\\)에서의 충분히 큰 subset들의 class에 대해 잘 정의되는 측도를 구성하고자 한다. 그러면 여기서 리만 적분으로는 불충분한 점들을 몇 가지 짚고 넘어가고자 한다. 우선, 리만 적분이 가능하려면, ‘대부분의’ 작은 interval에서 \\(\\max f - \\min f\\)가 매우 작아야한다. 즉, 리만 적분 가능성은 함수의 연속성과 관련이 있다. 실제로 함수 \\(f\\)가 리만 적분 가능하려면 \\(f\\)가 거의 모든 지점에서 연속이어야 한다(이는 필요충분조건이다). Example 3.2 (리만 적분이 안되는 함수) 다음과 같이 함수 \\(f_{\\text{Dir}}(x)\\)를 정의하자 \\[ f_{\\text{Dir}}(x) = \\begin{cases} 1 &amp; \\text{if $x\\in\\mathbb{Q}$} \\\\ 0 &amp; \\text{if $x\\in\\mathbb{Q}^{c}$.}\\\\ \\end{cases} \\] 그리면 임의의 구간 \\(I\\subset\\mathbb{R}\\)에 대해 \\[\\max_{x\\in I}f_{\\text{Dir}}(x) =1 \\text{ and } \\min_{x\\in I}f_{\\text{Dir}}(x) =0\\] 이므로 \\(f_{\\text{Dir}}(x)\\)는 리만적분이 가능하지 않다. 참고로 함수 \\(f_{\\text{Dir}}(x)\\)는 어디에서도 연속이 아니다. 두 번째로, 리만 적분 이론에서는 적분의 정의역(domain)을 분해하기 위해 오로지 interval, rectangle 또는 cube 등등만을 고려한다. 그래서 우리는 interval을 어떻게 측도해야할지 알아야 한다. 그러나 어떤 함수드에서는, 다른 형태로 정의역을 분해하는 것이 좀 더 자연스러울 때가 있다. 예를 들면, 우리가 \\(\\mathbb{Q}\\) 또는 \\(\\mathbb{Q}^{c}\\)에서의 측도를 정의하고자 할 때, 가장 자연스럽게 생각할 수 있는 것으로는 다음과 같은 적분이 있다. \\[\\int_{0}^{1}f_{\\text{Dir}}(x)dx:=1\\cdot |\\mathbb{Q}\\cap [0,1]| + 0\\cdot |\\mathbb{Q}^{c}\\cap [0,1]|.\\] 마지막으로, 우리가 다음과 같은 함수들의 수열 \\(\\{f_{n}:[0,1]\\rightarrow\\mathbb{R} \\}\\)을 정의했을 때, \\[ f_{n}(x) := \\begin{cases} 1 &amp; \\text{if $x=p/q$ where $p,q\\in\\mathbb{Z}$ and $q\\leq n$} \\\\ 0 &amp; \\text{otherwise.}\\\\ \\end{cases} \\] \\(f_{n}\\)들은 유한히 많은 점들을 제외하고 모두 연속이므로 리만 적분가능하다. 더불어 \\(n\\rightarrow \\infty\\)일 때 \\(f_{n}\\rightarrow f_{\\text{Dir}}\\)이다. 그러나 앞서 살펴본대로 \\(f_{\\text{Dir}}\\)은 리만 적분 가능하지 않다. 이 예는 모든 함수들의 수열이 리만 적분 가능하더라도, 그것의 극한은 리만 적분 가능하지 않을 수도 있다는 것을 보여준다. 단 \\(\\{f_{n}\\}\\)이 \\(f\\)로 uniform converge 하는 경우에는 \\(f\\)는 항상 리만 적분 가능하다. "],
["3-2-outer-measure.html", "3.2 외측도(outer measure)", " 3.2 외측도(outer measure) 외측도 부분은 Christopher E. Heil의 real analysis 강의를 참고하였다. 보통의 경우에는 우리가 어떻게 측도를 만들 수 있는지 아는 \\(\\mathbb{R}^{d}\\)의 부분집합의 basic class들(rectangular box 또는 cube)로부터 시작한다. 여기서는 그들의 부피로 측도를 정의할 수 있다. 그 다음에는 이 측도의 개념을 \\(\\mathbb{R}^{d}\\)의 모든 부분집합들로 확장할 방법을 찾아야 한다. 모든 부분집합 \\(E \\subset \\mathbb{R}^{d}\\)에서 우리는 음이 아니고 확정된 실수값을 갖는 숫자를 정의할 수 있으며 cube의 개념을 확장한 개념으로 exterior Lebesgue measure \\(\\mu^{*}(E)\\) 또는 \\(|E_{e}|\\)로 정의한다. 여기서 좋은 점은 \\(\\mathbb{R}^{d}\\)의 모든 부분집합은 유일하게 정의된 exterior measure를 갖는다는 것이다. 그러나 문제점도 한 가지 있는데, \\(\\mu^{*}\\)가 측도가 아니란 것이다.(이것은 countably subadditive이지만 not countably additive이다) Definition 3.1 (외측도) \\(X\\)를 공집합이 아닌 집합이라고 하자. \\(X\\)에서의 외측도(outer measure, or exterior measur)는 함수 \\(\\mu^{*}:\\mathcal{P}(X)\\rightarrow [0,\\infty]\\)이며 다음의 조건들을 만족한다. $^{*}() = 0. (monotinicity) 만약 \\(A\\subseteq B\\)이면 \\(\\mu^{*}(A)\\leq \\mu^{*}(B)\\)이다. (countable subadditivity) 만약 \\(E_{1},E_{2},\\ldots \\subseteq X\\)이면 \\(\\mu^{*}(\\bigcup_{k}E_{k})\\leq \\sum_{k}\\mu^{*}(E_{k})\\)이다. 외측도 \\(\\mu^{*}\\)가 주어졌을 때, 우리의 목표는 \\(X\\)에서의 \\(\\sigma\\)-체 \\(\\Sigma\\)를 만들어 \\(\\Sigma\\)에 제한된 \\(\\mu^{*}\\)가 countably additive하게 만드는 것이다. \\(\\Sigma\\)의 원소들은 좋은 집합들이 되어야 하는데, 이 좋은 집합들이란 \\(\\mu^{*}\\)에 대해 가측인 것이다. 그렇다면 우리는 임의의 외측도에서 측도가능성을 어떻게 정의할 수 있을까? \\(X\\)의 위상이 주어지지 않을 가능성도 있어, 측도가능성을 주변을 둘러싼 열린 집합들로 정의할 수 없다. Definition 3.2 (가측집합) \\(\\mu^{*}\\)가 집합 \\(X\\)에서의 외측도라고 하자. 그러면 어떤 집합 \\(E\\subseteq X\\)는 \\[\\forall A\\subseteq X, \\mu^{*}(A)=\\mu^{*}(A\\cap E) + \\mu^{*}(A\\backslash E)\\] 일 때 \\(\\mu^{*}\\)-가측 또는 단순히 가측(measurable)이라고 부른다. "],
["3-3-construction-of-lebesgue-measure.html", "3.3 르베그 측도의 구성(construction of Lebesgue measure)", " 3.3 르베그 측도의 구성(construction of Lebesgue measure) "],
["3-4-properties-of-lebesgue-measure.html", "3.4 르베그 측도의 성질(properties of Lebesgue measure)", " 3.4 르베그 측도의 성질(properties of Lebesgue measure) "],
["3-5-probability-measure.html", "3.5 확률측도(probability measure)", " 3.5 확률측도(probability measure) 확률측도는 측도들 중 \\(P(\\Omega)=1\\)인 측도 \\(P\\)를 일컫는다. Definition 3.3 (르베그 측도) 시그마-장 \\(\\mathcal{L}\\)이 있을 때 \\(C\\)가 어떤 구간(interval)일 경우 \\(\\mu_{L}(C)=\\text{length}C\\)로 정의한 측도 \\(\\mu_{L}\\)을 르베그 측도(Lebesgue measure)라고 부른다. 더불어 \\(\\mathcal{L}\\)을 르베그 집합(Legesgue set)이라고 부른다. 만약 우리가 르베그 집합을 \\([0,1]\\)로 한정할 경우, \\(\\mu_{L}\\)은 확률측도가 된다. "],
["3-6-radon-nykodim-theorem.html", "3.6 라돈-니코딤 정리(Radon-Nykodim theorem)", " 3.6 라돈-니코딤 정리(Radon-Nykodim theorem) "],
["3-7-various-measures.html", "3.7 다양한 측도들(various measures)", " 3.7 다양한 측도들(various measures) 3.7.1 셈 측도(counting measure) 셈 측도(counting measure)는 모든 집합에 그 집합의 cardinality를 준다. \\[\\mu[\\mathbf{S}]:=\\text{card}[\\mathbf{S}].\\] 물론 무한집합의 셈 측도는 단순히 \\(\\infty\\)가 된다. 따라서 셈 측도는 무한집합이 얼마나 작은지 큰지 구분을 할 수 없다. 따라서 셈 측도는 유한 측도 공간에서만 매우 유용하다. 3.7.2 보렐 측도(Borel measure) \\(X\\)가 위상공간(topological space)이라고 가정해보자. 쉽게 생각하자면 \\(X=\\mathbb{R}^{n}\\)이고 standard topolog를 갖는다고 생각하면 편하다. Definition 3.4 (측도가 보렐) \\(X\\) 위의 어떤 측도 \\(\\mu\\)가 모든 열린 공간이 \\(\\mu\\)-가측일 경우 보렐(Borel)이라고 한다. 보렐 \\(\\sigma\\)-체는 열린 공간을 포함하는 가장 작은 \\(\\sigma\\)-체이다. 이 \\(\\sigma\\)-체에 속하는 집합을 보렐 집합(Borel set)이라고 한다. Definition 3.5 (보렐 측도) 모든 보렐 부분집합이 가측일 경우 보렐 측도(Borel measure)를 구성할 수 있다. Definition 3.6 (보렐 정칙) 어떤 측도 \\(\\mu\\)가 보렐이고 모든 \\(A\\subset X\\)에 대해 보렐 \\(B\\subset X\\)가 존재해 \\(A\\subset B\\)이고 \\(\\mu(A)=\\mu(B)\\)이면 이 측도를 보렐 정칙(Borel regular)라고 부른다. 3.7.3 라돈 측도(Radon measure) Definition 3.7 (국소 컴팩트) 어떤 측도 \\(\\mu\\)가 \\(K\\)가 compact일 때 \\(\\mu(K)\\infty\\)일 경우 이 측도를 국소 컴팩트(locally compact)라고 한다. Definition 3.8 (국소 컴팩트) \\(\\mathbb{R}^{n}\\)에서의 라돈 측도는 보렐 정칙이고 국소 컴팩트한 측도를 말한다. "],
["3-8-the-use-of-measure-notation.html", "3.8 적분 기호의 사용(the use of measure notation)", " 3.8 적분 기호의 사용(the use of measure notation) 적분 기호를 사용하는 것은 나에게도 매우 혼란스러운 일이나, 다음의 답변내용 을 번역해 정리해 두기로 한다. \\(\\int f d\\mu\\), \\(\\int f(x)\\mu(dx)\\), \\(\\int f(x) d\\mu(x)\\)는 매우 흔하고 같은 의미를 지닌다고 한다. 만약 \\(\\mu\\)가 확률측도라면 \\(\\mathbb{E}_{\\mu}[f]\\)로도 자주 쓰고, 또는 측도에 혼란이 없을 경우에는 생략하여 \\(\\mathbb{E}[f]\\)로 쓰기도 한다고 한다. \\(\\mu(dx)\\)나 \\(d\\mu(x)\\) 또한 차이가 없지만, 후자가 \\(\\int f d\\mu\\)와 같이 사용할 때는 좀 더 일관성이 있지만, 일반적으로는 전자를 좀 더 많이 사용한다고 한다. 전자를 좀 더 많이 사용하게 될 때에는 특히 다변수인 경우에 그러하다. 예를 들면 커널 \\(\\mu(x,A)\\)는 \\(x\\)에 대해 measurable 함수이고 \\(A\\)는 measure이다. 우리는 \\(\\int f(x,y)\\mu(x,dy)\\)와 같이 쓸 수 있으나, \\(\\int f(x,y)d\\mu(x,y)\\)는 혼란스럽다. 정리하면 다음과 같다. Definition 3.9 (다양한 측도 표현) \\((E,\\mathcal{E})\\)의 측도 \\(m\\)과 \\(f\\in\\mathcal{E}\\)에 대해 \\(m\\)에 대한 적분 \\(f\\)는 다음과 같은 notation들로 쓸 수 있다. \\[\\int f dm, \\int f(x)dm(x), \\int f(x)m(dx), m(f), \\langle m, f \\rangle.\\] 그리고 특별히 \\(E\\)가 유클리드 공간의 부분집합이고 \\(m\\)이 르베그 측도면 \\(\\int f(x)dx\\)로 쓸 수 있다. 표현 \\(\\mu(dx)\\)에서 \\(dx\\)는 실수직선 상에서의 무한히 작은 “chunk”를 나타낸다고 생각할 수 있고, 그 때 \\(\\mu(dx)\\)는 그것의 측도가 된다고 한다. 예를 득어 \\(F\\)는 right-continuous and increasing이고 \\(f\\)는 연속이라고 하자. \\(\\mu\\)는 \\(F\\)와 연관된 Lebesgue-Stiltjes measure라고 하자. 즉 \\(\\mu((a,b])=F(b)-F(a)\\)이다. \\(\\{x_{j} \\}_{j=1}^{n}\\)은 어떤 구간 \\(I\\)를 나눈 부분이고 \\(\\Delta x_{j}=(x_{j-1}, x_{j}]\\)라고 하자. 그러면 \\[\\int_{I}f(x)\\mu(dx)=\\lim_{n\\rightarrow\\infty}\\sum_{j=1}^{n}f(x_{j})\\mu(\\Delta x_{j}).\\] 이는 partition의 mesh가 zero로 가는 경우에 성립한다. 이런 상황에서 \\(\\mu(dx)\\)는 양쪽의 notation consistent를 보장해준다. 즉 \\(\\mu(dx)\\), \\(d\\mu(x)\\)를 쓰던 결과는 같다. "],
["4-basicprob.html", "Chapter 4 기초 확률론", " Chapter 4 기초 확률론 이 장에서는 앞으로 다룰 내용을 이해하기 위해 필요한 기본적인 확률 개념을 정리하였다. 대학원 과정의 확률론을 다룬 유명한 책들로는 (Durrett 2010), (Billingsley 2012) 그리고 (Chung 2001)이 있다. 그 밖에 본인이 추천하는 책들은 다음과 같다. (Gut 2012)는 최근에 나온 대학원 확률론 입문서 교재로써 비교적 내용이 자세하다. (Schilling 2005)는 삽화가 많고 저자가 연습문제의 답을 웹에 올려놓았다. (Shorack 2006)과 (Proschan and Shaw 2016)는 통계학자의 입장에서 필요한 확률론 지식을 비교적 쉽게 서술하였다. 여기서는 앞서 언급한 모든 책들을 참고할 것이다. References "],
["4-1-sample-space-and-events.html", "4.1 표본공간과 사건(sample space and events)", " 4.1 표본공간과 사건(sample space and events) 통계학은 무작위(random) 또는 확률적(stochastic) 실험(experiment), 즉 어떤 결과가 나올지 미리 확실히 예측할 수 없는 실험들에 초점을 맞춘다. Definition 4.1 (표본공간) 어떤 무작위 실험의 표본공간(sample space) \\(\\Omega\\)는 그 실험에서 나올 수 있는 모든 결과들의 집합이다. Example 4.1 (동전 던지기 실험) 동전을 두 번 던지는 실험에서 \\(\\Omega=\\{ HH, HT, TH, TT \\}\\)이다. 이러한 표본공간을 (유한) 이산 표본공간(finite discrete sample space)이라고 한다. Example 4.2 (동전 계속 던지기 실험) 이번에는 동전의 뒷 면이 나올때까지 동전을 계속해서 던지는 실험에 대해 살펴보자. 그러면 \\[\\{ T, HT, HHT, HHHT, \\ldots, \\{ HHH\\ldots\\} \\}\\] 와 같은 결과들의 수얼을 얻을 수 있다. 이를 만약 동전을 던진 횟수로 정리한다면 \\[\\{ 1,2,3,\\ldots, ,\\infty\\}\\] 로 볼 수 있다. 이러한 표본공간을 (무한) 이산 표본공간(infinite discrete sample space)라고 한다. Example 4.3 (지하철 도착 시간) 우리가 지하철을 기다리고 있다고 가정해보자. 지하철은 \\(T\\) 시간마다 한 번씩 도착한다. 그러면 우리가 기다리는 시간에 대한 표본공간은 \\[[0,T]=\\{t:0\\leq y \\leq T\\}\\] 이다. 이러한 표본 공간은 연속 표본공간(continuous sample space)라고 한다. Definition 4.2 (사건) 사건(event)란 표본공간 \\(\\Omega\\)의 임의의 부분집합(subset)을 의미한다. Example 4.4 (사건의 예) - 앞서 동전을 두 번 던지는 실험에서 앞면이 하나만 나올 사건을 \\(A\\)라고 하면 \\(A=\\{ HT, TH \\}\\)이다. 앞서 동전을 두 번 던지는 실험에서 적어도 한 번 앞면이 나올 사건을 \\(B\\)라고 하면 \\(A=\\{ HH, HT, TH \\}\\)이다. "],
["4-2-sigma-field.html", "4.2 시그마-체(sigma-field)", " 4.2 시그마-체(sigma-field) 앞서 표본공간 \\(\\Omega\\)의 임의의 부분집합인 사건을 생각했는데, 그러면 이 사건들의 집합 \\(\\mathcal{F}\\)에 대해서도 생각해 볼 수 있을 것이다. 그리고 사건들의 집합이 가져야 할 바람직한 성질들을 잘 정의하기 위해 시그마-체라는 개념을 도입한다. Definition 4.3 (대수(체)) 어떤 집합(set) \\(\\Omega\\)의 non-empty collection (즉 \\(\\Omega\\)의 subset들의 모임)을 \\(\\mathcal{F}\\)라고 하자. 그러면 \\(\\mathcal{F}\\)가 \\(\\Omega \\in \\mathcal{F}\\) (또는 \\(\\emptyset \\in \\mathcal{F}\\)) \\(A \\in \\mathcal{F}\\)이면 \\(A^{C} \\in \\mathcal{F}\\), \\(A, B \\in \\mathcal{F}\\) 이면 \\(A\\cup B \\in \\mathcal{F}\\) 를 만족할 때 \\(\\mathcal{F}\\)를 대수(algebra) 또는 체(field)라고 부른다. 시그마-체는 앞선 대수의 정의에서 두 번째 조건이 조금 바뀐 것이다. Definition 4.4 (시그마-체) 어떤 집합(set) \\(\\Omega\\)의 non-empty collection을 \\(\\mathcal{F}\\)라고 할 때, \\(\\mathcal{F}\\)가 \\(\\Omega \\in \\mathcal{F}\\) (또는 \\(\\emptyset \\in \\mathcal{F}\\)) \\(A \\in \\mathcal{F}\\)이면 \\(A^{C} \\in \\mathcal{F}\\), \\(A_{1}, A_{2}, \\ldots \\in \\mathcal{F}\\) 이면 \\(\\bigcup_{i=1}^{\\infty}A_{i} \\in \\mathcal{F}\\) 를 만족할 때 \\(\\mathcal{F}\\)를 시그마-대수(sigma-algebra) 또는 시그마-체(sigma-field)라고 부른다. 다음은 체와 시그마-체에 대한 간단한 사실들이다. Corollary 4.1 (시그마-체에 대한 사실들) 1. 모든 체는 finite union에 대해 닫혀있다. 또한 같은 논리를 적용해 finite intersection에 대해서도 닫혀있다. 모든 시그마-체 \\(\\mathcal{F}\\)는 countable intersection에 대해서도 닫혀있다. 즉, \\[A_{1}, A_{2}, \\ldots \\in \\mathcal{F} \\text{, then } \\bigcap_{i=1}^{\\infty}A_{i} = (\\bigcap_{i=1}^{\\infty}A_{i}^{C})^{C} \\in \\mathcal{F}.\\] 물론 모든 \\(A_{1}^{C}, A_{2}^{C},\\ldots\\) 또한 \\(A_{1}^{C}, A_{2}^{C}, \\ldots \\in \\mathcal{F}\\) 이다. \\(\\mathcal{F}\\)가 non-void일 경우에는 모든 체 또는 시그마-체가 \\(A\\)를 포함하고 있으면 \\(A^{C}\\) 또한 포함하고 있기 때문에 \\(\\Omega=A \\cup A^{C}\\)와 \\(\\emptyset=\\Omega^{C}\\) 또한 \\(\\mathcal{F}\\)에 포함되어 있다. 따라서 첫 번째 조건을 생략해도 된다. Example 4.5 (시그마-체의 예) - 어떤 집합 \\(\\Omega\\)에 대해, \\(\\{\\emptyset, \\Omega\\}\\)는 시그마-체가 된다. 이 시그마-체는 \\(\\Omega\\)의 부분집합으로 만들 수 있는 가장 작은 시그마-체이다. \\(\\Omega\\)의 멱집합(power set, 어떤 집합의 모든 부분집합을 모은 집합) 또한 시그마-체이며 이는 \\(\\Omega\\)의 부분집합으로 만들 수 있는 가장 큰 시그마-체이다. \\(A\\in\\Omega\\)일 때 collection \\(\\{\\emptyset, A, A^{C}, \\Omega\\}\\) 또한 간단히 만들 수 있는 시그마-체의 예다. Example 4.6 (체이나 시그마-체가 아닌 예) 다음은 \\(\\mathcal{F}\\)가 체이나 시그마-체가 아닌 예이다. \\(\\Omega=(0,1]\\)이고, \\(\\mathcal{F}\\)는 \\(\\emptyset\\)과 모든 \\[(a,b], \\qquad{a,b\\in\\mathbb{Q}, a,b\\in [0,1], a&lt;b}\\] 와 \\((a,b]\\)의 모든 finite union을 포함한다고 하자. 그리고 \\([z]\\)를 z와 가장 가까운 정수로 반올림해주는 연산자라고 하자. 그러면 정의에 의해 \\(\\mathcal{F}\\)는 체가 된다. 그러나 \\(A_{n}=(a_{n},1]\\), \\(a_{n}=\\frac{10^{n}}{[10^{n}\\pi]}\\)라고 하면 \\[A_{n}\\in\\mathcal{F} \\text{but } \\cup_{n=1}^{\\infty}A_{n}=(\\pi,1]\\notin \\mathcal{F}\\] 이다. 따라서 \\(\\mathcal{F}\\)는 시그마-체가 아니다. Example 4.7 (표본공간이 셀 수 있는 집합이면 멱집합이 사건들의 집합) 표본공간 \\(\\Omega\\)가 셀 수 있는 집합, 예를 들면 \\(\\{0,1,2,\\ldots, \\}\\)라고 가정하자. 그리고 이 때 사건들의 집합 \\(\\mathcal{F}\\)가 모든 singleton \\(\\omega_{i}, i=1,2,\\ldots\\)들을 포함하는 시그마-체가 되길 원한다고 가정하자. 그러면 \\(\\Omega\\)의 모든 부분집합 \\(E\\)는 \\(\\cup_{i=1}^{\\infty}\\omega_{i}\\)로 만들 수 있다. 즉 singleton들의 countable union으로 만들 수 있다. 그리고 countable union에 대해 시그마-체가 닫혀있기 때문에, \\(\\mathcal{F}\\)가 \\(\\Omega\\)의 어떤 부분집합 \\(E\\)들을 모두 포함한다는 결론에 이른다. 즉, 표본공간이 셀 수 있는 집합이면, 우리는 항상 멱집합을 사건들의 집합으로 써야 한다. "],
["4-3-generators.html", "4.3 생성기들(generators)", " 4.3 생성기들(generators) 시그마-체에 대해 좀 더 자세히 살펴보기 위해, 생성기(generator)에 대해 알아보자. 표본공간 \\(\\Omega\\)의 subset들의 collection \\(\\mathcal{A}\\)가 있다고 하자. 그러면 멱집합은 항상 시그마-체이기 때문에, \\(\\mathcal{A}\\)를 포함하는 시그마-체가 적어도 한 개 이상 있을 것이다. \\(\\mathcal{F}^{*}\\)를 \\(\\mathcal{A}\\)를 포함하는 모든 시그마-체의 모임, 즉 \\[\\mathcal{F}^{*}=\\{\\sigma\\text{-algebras } \\supset \\mathcal{A}\\}\\] 라고 하자. 여기서 \\(\\mathcal{A}\\)를 포함하는 가장 작은 시그마-체를 생각해보자. 즉 \\[\\mathcal{F}=\\sigma(\\mathcal{A})=\\bigcap_{\\{\\mathcal{F}` \\text{ $\\sigma$-algebra }|\\mathcal{A}\\subset\\mathcal{F}` \\}}\\mathcal{F}`=\\bigcap_{\\mathcal{G}\\in\\mathcal{F}^{*}}\\mathcal{G}\\] 인 \\(\\mathcal{F}\\)가 존재하고 이를 \\(\\mathcal{A}\\)로부터 생성된 시그마-체(sigma alegbra genearted by \\(\\mathcal{A}\\))라고 부른다. Example 4.8 (생성기들) - 만약 \\(\\mathcal{A}=A\\), 즉 \\(\\mathcal{A}\\)가 single set일 경우 \\(\\sigma(\\mathcal{A})=\\{ \\emptyset, A, A^{C}, \\Omega\\}\\)이다. 만약 \\(\\mathcal{A}\\)가 시그마-체일 경우, \\(\\sigma(\\mathcal{A})=\\mathcal{A}\\)다. "],
["4-4-probability-space.html", "4.4 확률공간(probability space)", " 4.4 확률공간(probability space) Definition 4.5 (가측공간) 표본공간 \\(\\Omega\\)와 이와 연관된 시그마-체 \\(\\mathcal{A}\\)를 묶어 \\((\\Omega, \\mathcal{A})\\)를 가측공간(measurable space)이라고 한다. Definition 4.6 (확률측도) 가측공간 \\((\\Omega, \\mathcal{A})\\)가 주어졌을 때 확률측도(probability measure) \\(P\\)는 \\(P:\\mathcal{A}\\rightarrow [0,1]\\)인 함수로 \\(P(\\emptyset)=0\\) and \\(P(\\Omega)=1\\) 어떤 \\(A\\in\\mathcal{A}\\)에 대해 \\(P(A)\\geq 0\\) (가산가법성(countable additivity)): \\(\\{A_{n}, n\\geq 1\\}\\)이 disjoint라고 하면 \\(P(\\bigcup_{n=1}^{\\infty}A_{n})=\\sum_{n=1}^{\\infty}P(A_{n}).\\) 을 만족한다. 그리고 \\((\\Omega, \\mathcal{A}, P)\\)를 묶어 확률공간(probability space)라고 한다. 이 확률측도는 \\(\\mathcal{A}\\)가 시그마-체일 때 뿐 아니라 그냥 체 일때도 위 세 가지를 만족하면 정의할 수 있다. "],
["4-5-borel-sigma-field.html", "4.5 보렐 시그마-체(Borel sigma field)", " 4.5 보렐 시그마-체(Borel sigma field) 이제 \\(\\Omega\\)가 비가산집합(uncountable set)일 때 시그마-체에 대해 살펴보자. 비가산집합의 대표적인 예로 \\(\\mathbb{R}\\)이 있으니 \\(\\Omega=\\mathbb{R}\\)이라 놓고 전개하기로 한다. 앞서 얘기했듯이 시그마-체의 크기는 우리가 고려하고 싶은 모든 사건들과 그 사건들의 countable union, intersection을 적절히 잘 포함하는 정도여야 한다. 가장 쉽게 만들 수 있는 것은 \\(\\mathcal{F}\\)가 모든 countable subset \\(E\\)를 포함하게끔 만드는 것이다. 그러나 이 시그마-체는 충분히 크지 않다. 예를 들어 \\(\\Omega=[0,1]\\)일 경우, 앞서 말한 대로 \\(\\mathcal{F}\\)를 만들면 \\([0,0.5]\\)같은 사건은 countable이나 co-countable이 아니므로 \\(\\mathcal{F}\\)에 포함이 되지 않는 것이다. 즉 우리는 \\(\\Omega\\)의 모든 interval들을 포함하는 시그마-체를 만들고 싶어한다.예를 들면, \\(\\Omega=[0,1]\\)일 때 \\[(a,b)\\in\\mathcal{F}, \\qquad{(0\\leq a &lt; b \\leq 1),}\\] \\[P((a,b))=b-a, \\qquad{(0\\leq a &lt; b \\leq 1)}\\] 이 되길 원하는 것이다. 가장 간단한 방법으로, 멱집합을 \\(\\mathcal{F}\\)로 나용할 수 있다. 그러나 이 \\(\\mathcal{F}\\)은 너무 크다. \\(\\mathcal{F}\\)가 너무 클 경우, 확률측도가 잘 construct되지 않는 경우가 생길 수 있다고 한다. 4.5.1 연속 표본공간에서 시그마-체로 멱집합을 쓰지 않는 이유(no uniform probablity of power set on continous sample space) Michael Kozdron의 2013년 statistics 451 강의노트를 참조하였다. 멱집합이 시그마-체로 적합하지 않은 이유로 (\\([0,1], 2^{[0,1]}\\))에서 균등확률이 존재하지 않음을 보일 것이다. \\(P\\)를 (\\([0,1], 2^{[0,1]}\\))에서 균등확률의 한 후보라고 놓자. 우리는 \\(P\\)가 \\[P\\{[a,b]\\}=P\\{(a,b)\\}=P\\{[a,b)\\}=P\\{(a,b]\\}=b-a, \\qquad{\\text{for any }[a,b]\\subseteq [0,1]}\\] 을 만족하길 원한다. 또한 특별히 \\[P\\{a\\}=0, \\qquad{\\text{for every }0\\leq a \\leq 1}\\] 이다. 그리고 \\(P\\)는 확률의 공리(the axioms of probability) 중 하나인 가산가법성(countable additivity)을 만족시켜야 한다. 즉 \\(0\\leq a_{1}&lt;b_{1}&lt;\\cdots &lt;a_{n}&lt;b_{n}&lt;\\cdots \\leq 1\\)이면 \\(P\\)는 \\[P\\{\\bigcup_{i=1}^{\\infty}[a_{i},b_{i}]\\}=\\sum_{i=1}^{\\infty}P\\{[a_{i},b_{i}]\\}=\\sum_{i=1}^{\\infty}(b_{i}-a_{i})\\] 를 만족해야 한다. 또한 \\(P\\)는 이동불변(shift invariant) 성질을 가져야 한다. 즉, 확률은 interval의 length에만 영향을 받아야 한다. \\[P\\{[r,1/4 +r]\\}=\\frac{1}{4}, \\qquad{\\text{for every } 0 &lt; r \\leq 3/4.}\\] 그런데 한 가지 문제가 생기는데 \\(3/4 &lt;r &lt; 1\\)이면 \\([r,1/4+r]\\)이 \\([0,1]\\)의 부분집합이 되지 않는다. 이를 해결하기 위해 “wrapping around”라는 방법을 이용한다. 만약 “wrapping around”를 \\(\\oplus\\)로 나타낸다면 \\[ [0,1/4]\\oplus r = \\begin{cases} [r, 1/4 + r] &amp; \\text{if $0 &lt; r \\leq 3/4$} \\\\ [0,1/4+r-1]\\cup [r,1] &amp; \\text{if $3/4 &lt; r &lt; 1$}\\\\ \\end{cases} \\] 로 정의하는 것이다. 그러면 \\(A\\subseteq [0,1]\\)이라고 할 때 \\(A\\)를 \\(r (0&lt;r&lt;1)\\)만큼 이동하는 것을 \\[A\\oplus r = \\{ a+r : a \\in A, a+r \\leq 1 \\} \\cup \\{ a+r-1: a\\in A, a+r &gt; 1\\}\\] 로 정의할 수 있다. FIGURE 4.1: Shift invariance. “wrapping around”를 이용해 \\(A\\)를 \\(r\\)만큼 이동해도 길이가 보존되기 때문에, 확률 또한 \\[P\\{ A \\oplus r \\}=P\\{ A \\}, \\qquad{\\text{for any } 0 &lt; r &lt; 1}\\] 이 될 것이라 추론할 수 있다. 이제 모든 \\(A \\in 2^{[0,1]}\\)에 대해 균등확률이 존재하지 않음을 보이기 위해 동치관계(equivalence relation)라는 것에 대해 정의할 것이다. \\(x\\)와 \\(y\\) (\\(x,y \\in [0,1]\\))는 \\(y-x\\in\\mathbb{Q}\\)를 만족할 경우 동치관계라 정의하고 \\(x \\sim y\\)로 표시한다. 예를 들면 \\[\\frac{1}{2} \\sim \\frac{1}{4}, \\frac{1}{3} \\nsim \\frac{1}{\\pi}, \\frac{1}{\\pi}-\\frac{1}{4} \\sim \\frac{1}{\\pi}+\\frac{1}{2} \\] 인 것이다. 이 동치관계는 \\([0,1]\\)을 다음과 같이 분리(disjoint) 합집합들로 표현할 수 있다. \\(\\mathbb{Q}_{1}=[0,1]\\cap \\mathbb{Q}\\)라고 하자.우리는 분리 합집합을 다음과 같이 쓸 수 있다. \\[[0,1]=\\mathbb{Q}_{1} \\cup \\{ \\bigcup_{x\\in [0,1] \\backslash \\mathbb{Q}_{1}} \\{ (\\mathbb{Q}+x)\\cap [0,1] \\} \\}=\\mathbb{Q}_{1} \\cup \\{ \\bigcup_{x\\in [0,1] \\backslash \\mathbb{Q}_{1}} \\{ (\\mathbb{Q}+x)\\oplus x \\} \\}.\\] FIGURE 4.2: Collection of disjoint unions on [0,1] \\(H\\)를 선택공리(the Axiom of Choice)에 의해 \\([0,1]\\)의 모든 동치관계에서 원소를 한 개씩 잘 뽑아서 만든 \\([0,1]\\)의 부분집합이라고 하자. 편의상 \\(0\\notin H\\)라고 하자. 그러면 \\((0,1]\\)을 \\[(0,1]=\\bigcup_{r\\in\\mathbb{Q}_{1}, r\\neq 1}\\{ H \\oplus r\\} \\qquad{\\text{with }\\{H\\oplus r_{i}\\} \\cap \\{H\\oplus r_{j}=\\emptyset \\text{ for all } i\\neq j\\} } \\] 로 표현할 수 있다. 그러면 \\[1=P\\{(0,1]\\}=P\\Big\\{ \\bigcup_{r\\in\\mathbb{Q}_{1}, r\\neq 1}\\{ H \\oplus r\\} \\Big\\}=\\sum_{r\\in \\mathbb{Q}_{1},r\\neq 1}P\\{ H \\oplus r\\}=\\sum_{r\\in \\mathbb{Q}_{1},r\\neq 1}P\\{ H\\}\\] 가 된다. 만약 우리가 \\(p=P\\{H\\}\\)로 확률을 부여하고자 한다면 \\(p=0\\)일 때에는 \\(1=\\sum_{r\\in \\mathbb{Q}_{1},r\\neq 1}P\\{ H\\}=\\sum_{r\\in \\mathbb{Q}_{1},r\\neq 1} p \\sum_{r\\in \\mathbb{Q}_{1},r\\neq 1} 0 = 0\\) 이므로 모순이다. 마찬가지로 \\(0&lt;p\\leq 1\\)일 때에는 \\(\\sum_{r\\in \\mathbb{Q}_{1},r\\neq 1} p =\\infty\\)이므로 모순이다. 즉 \\(H\\)는 사건이 아닌 셈이 되고 \\(P\\{ H \\}\\)가 존재하지 않는다. 이상의 결과를 다음 정리로 요약해본다. Theorem 4.1 (연속 표본공간에서 시그마-체로 멱집합을 쓰지 않는 이유) 셀 수 없는 표본공간 \\([0,1]\\)에서 시그마-체 \\(2^{[0,1]}\\)을 고려할 경우 \\(P\\{[a,b]\\}=b-a, \\text{ for all } 0\\leq a \\leq b \\leq 1\\)과 \\(P\\{ A \\oplus r\\}=P\\{A\\}, \\text{ for all } A\\subseteq [0,1] \\text{ and } 0 &lt; r &lt; 1\\)을 동시에 만족하는 \\(P: 2^{[0,1]}\\rightarrow [0,1]\\)은 존재하지 않는다. 다시말하면, 모든 집합 \\(A\\subseteq [0,1]\\)에 대해 균등확률 \\(P\\{ A \\}\\)를 정의할 수 없다는 것이다. 4.5.2 실수공간에서 보렐 시그마-체(Borel sigma-field on R) 따라서, 모든 interval을 포함하는 시그마-체들 중 가장 작은 시그마-체 \\(\\mathcal{F}\\)를 찾는 것이 이상적일 것이다. 즉 우리는 \\(\\sigma(\\text{intervals})\\)를 찾고자 하는 것이다. 여기서 잠시 \\(\\mathbb{R}\\)에서의 보렐 시그마-체(Borel sigma-algebra)에 대해 살펴보자. \\(\\mathbb{R}\\)에서의 모든 열린 집합(open set)들의 모임을 \\(\\mathcal{O}\\)라고 하자. 그러면 \\(\\mathcal{O}\\)는 시그마-체가 아니다. (왜냐하면 \\(A\\in\\mathcal{O}\\)이면 \\(A^{C}\\)는 닫힌 집합이고 따라서 \\(A^{C}\\notin\\mathcal{O}\\)이다.) Definition 4.7 (보렐 시그마-체) \\(\\mathbb{R}\\)에서의 보렐 시그마-체(Borel sigma-field, Borel sigma-algebra) \\(\\mathcal{B}\\)는 \\(\\mathcal{B}=\\sigma(\\mathcal{O})\\)로 정의한다. 결론은 \\(\\mathbb{R}\\)에서의 보렐 시그마-체를 interval을 포함하는 시그마-체로 만들 수 있다는 것이다. 그 전에 증명을 위해 한 가지 정리를 언급하겠다. Theorem 4.2 (열린 집합과 열린 구간들) \\(E \\subseteq \\mathbb{R}\\)이 열린 집합이라고 하자. 그러면 기껏해야 셀 수 있는 정도로만 많은(at most countably many) 열린 구간들(open intervals) \\(I_{j}, j=1,2,\\ldots,\\)가 존재해 다음을 만족한다. \\[E=\\bigcup_{j=1}^{\\infty}I_{j}.\\] Proof. 이 정리의 증명은 \\(E=\\bigcup_{j=1}^{\\infty}I_{j}\\)를 만족하는 \\(I_{j}\\)들이 있음을 보이고 이것이 (1) at most countably many (2) disjoint (3) open (4) intervals 임을 보이면 된다. 증명 방법은 동치 관계를 이용하는 것이다. \\(a, b \\in E, (a &lt; b)\\)일 때 열린구간 \\((a,b)\\subseteq E\\)이면 \\(a \\sim b\\)로 놓는다. 그러면 \\(E\\)의 disjoint union of classes는 equivalence relationship partitions \\(E\\)가 된다. 아직 이것들이 countably many한지 모르므로 이들을 \\(I_{j}, j\\in J, J \\text{ is an arbitrary index set}\\)이라고 놓자. 임의의 \\(a_{j}&lt;b_{j}\\in I_{j}\\)에 대해 \\(a_{j} \\sim b_{j}\\)이고 \\((a_{j}, b_{j}) \\in I_{j}\\)이므로 \\(I_{j}\\)는 interval이다. 또 \\(x\\in I_{j}\\)를 임의로 뽑았을 때 \\(x\\in E\\)이고 \\(E\\)가 open이므로, \\((x-\\epsilon, x+\\epsilon)\\subseteq E\\)를 만족하는 \\(\\epsilon &gt;0\\)이 모든 \\(x\\)에 대해 존재함을 알 수 있고 모든 \\(a\\in (x-\\epsilon, x+\\epsilon)\\)에 대해 \\(a \\sim x\\)이므로 \\(x\\)의 \\(\\epsilon\\)-근방은 \\(I_{j}\\)에 포함됨을 알 수 있어 \\(I_{j}\\)는 open이다. 마지막으로 모든 \\(I_{j}\\)는 적어도 하나의 유리수를 포함하고 있어 이를 통해 \\(I_{j}\\)의 갯수는 countably many임을 알 수 있다. Theorem 4.3 (실수 구간에서의 보렐 시그마-체의 생성) \\(\\mathbb{R}\\)에서의 보렐 시그마-체(Borel sigma-field, Borel sigma-algebra) \\(\\mathcal{B}\\)는 \\((-\\infty, a], a\\in\\mathbb{Q}\\)로 생성할 수 있다. Proof. \\(\\mathcal{O}_{0}\\)을 \\(\\mathbb{R}\\)에서의 모든 열린 구간(open interval)들의 collection이라고 하자. 앞선 정리에 의해 \\(\\mathbb{R}\\)에서의 모든 열린 집합은 기껏해야 셀 수 있을 정도의 열린 구간의 합집합으로 나타낼 수 있으므로 \\(\\sigma(\\mathcal{O}_{0})=\\mathcal{B}\\)가 된다. \\(\\mathcal{D}\\)를 \\((-\\infty, a], a\\in \\mathbb{Q}\\)인 구간들의 collection이라고 하자. 그리고 구간 \\((a,b)\\)를 \\((a,b)\\in \\mathcal{O}_{0}, a,b \\in \\mathbb{Q}, a&lt;b\\)와 같이 정의하자. 여기서 \\[a_{n}=a+\\frac{1}{n} \\text{ and } b_{n}=b-\\frac{1}{n}\\] 으로 놓으면 \\[(a,b)=\\bigcup_{n=1}^{\\infty}(a_{n},b_{n}]=\\bigcup_{n=1}^{\\infty}\\{ (-\\infty, b_{n}] \\cap (-\\infty, a_{n}]^{c}\\}\\] 이다. 이것은 \\((a,b)\\in \\sigma (\\mathcal{D})\\)임을 의미한다. 즉 \\(\\mathcal{O}_{0}\\subseteq \\sigma(\\mathcal{D})\\)이고 \\(\\sigma(\\mathcal{O}_{0})\\subseteq \\sigma(\\mathcal{D})\\)이다. 그러나 \\(\\mathcal{D}\\)의 모든 원소는 닫힌 집합이고 이는 \\(\\sigma(\\mathcal{D})\\subseteq \\mathcal{B}\\)를 의미한다. 따라서 \\[\\mathcal{B} = \\sigma(\\mathcal{O}_{0})\\subseteq \\sigma(\\mathcal{D})\\subseteq \\mathcal{B}\\] 이므로 \\(\\sigma(\\mathcal{D})=\\mathcal{B}\\)이다. 이제 \\([0,1]\\subset \\mathbb{R}\\)에서의 보렐 시그마-체 \\(\\mathcal{B}_{1}\\)을 생각해보자. 이는 \\(\\mathcal{B}\\)와 마찬가지로 \\([0,1]\\)의 열린 부분집합들의 collection으로부터 생성된 시그마-체라고 생각할 수 있다. 한 가지 주의해야 할 점은 \\(\\mathcal{B}_{1}\\)은 \\(\\mathcal{B}\\)의 부분 시그마-체는 아니라는 것이다. 시그마-체에서 포함 관계를 얘기하려면 두 시그마-체의 표본공간이 같아야 한다. 4.5.3 실수공간에서 확률측도의 구성(construction of a probability measure on R) 이제 앞서 언급한 보렐 시그마-체 \\(\\mathcal{B}_{1}\\)을 이용해 균등한 확률을 만드는 작업을 진행할 것이다. 전략은 먼저 단조족정리(monotone class theorem)을 증명한 후 그것의 따름정리를 이용해 모든 \\(0\\leq a \\leq b \\leq 1\\)에서 균등확률 \\(P\\{[a,b]\\}=b-a\\)를 정의한 후 이것을 \\([0,1]\\)의 보렐집합으로 확장하는 것이다. \\(\\mathcal{F}_{0}\\)를 표본공간 \\(\\Omega\\)에서의 부분집합들의 collection이라고 하자. 그러면 \\(\\mathcal{F}_{0}\\)에서 확률측도 \\(P:\\mathcal{F}_{0} \\rightarrow [0,1]\\)을 정의한다. 그리고 \\(\\mathcal{F}=\\sigma(\\mathcal{F}_{0})\\)의 확률측도 \\(Q:\\mathcal{F} \\rightarrow [0,1]\\)가 \\(Q\\{A\\}=P\\{A\\} \\forall A\\in \\mathcal{F}_{0}\\)인 성질을 가진체로 정의된다는 것을 보인다. 마지막으로 이 \\(Q\\)가 유일함을 보일 것이다. 그 전에 몇 가지 개념들에 대해 정의하겠다. Definition 4.8 (유한한 교집합에 대해 닫혀있다) 표본공간 \\(\\Omega\\)의 부분집합들의 class \\(\\mathcal{C}\\)가 \\[\\bigcap_{i=1}^{n}A_{i}\\in\\mathcal{C}\\qquad{\\text{for every }n\\infty \\text{ and } A_{1},\\ldots ,A_{n}\\in\\mathcal{C}}\\] 를 만족하면 유한한 교집합에 대해 닫혀있다(closed under finite intersection)라고 한다. Definition 4.9 (증가하는 극한에 대해 닫혀있다) 표본공간 \\(\\Omega\\)의 부분집합들의 class \\(\\mathcal{C}\\)가 \\[\\bigcup_{i=1}^{\\infty}A_{i}\\in\\mathcal{C}\\qquad{\\text{for every collection } A_{1}, A_{2},\\ldots \\in \\mathcal{C} \\text{ with } A_{1}\\subseteq A_{2}\\subseteq \\ldots}\\] 를 만족하면 증가하는 극한에 대해 닫혀있다(closed under increasing limits)라고 한다. FIGURE 4.3: Closed under increasing limits. Definition 4.10 (유한한 차에 대해 닫혀있다) 표본공간 \\(\\Omega\\)의 부분집합들의 class \\(\\mathcal{C}\\)가 모든 \\(A,B\\in\\mathcal{C}, A\\subseteq B\\)에 대해 \\(B\\backslash A \\in \\mathcal{C}\\)를 만족하면 유한한 차에 대해 닫혀있다(closed under finite differences)라고 한다. FIGURE 4.4: Closed under finite differences. 다음은 단조족에 대한 정의다. Definition 4.11 (단조족) 표본공간 \\(\\Omega\\)의 부분집합들의 class \\(\\mathcal{C}\\)가 closed under countable increasing set이거나 closed under countable decreasing set이면, 즉 \\(E_{1},E_{2},\\ldots \\in \\mathcal{C}\\)일 때 \\[E_{i}\\uparrow E \\text{ or } E_{i}\\downarrow E \\Longrightarrow E \\in \\mathcal{C}\\] 이면 \\(\\mathcal{C}\\)를 단조족(monotone class)이라고 한다. 이에 대한 증명은 (Durrett 2010)의 Appendix 부분을 참고하자. References "],
["5-rv.html", "Chapter 5 확률변수", " Chapter 5 확률변수 확률변수(random variable)의 예로는 카드를 생각해 볼 수 있다. 확률변수 \\(X=X(\\omega)\\)는 실변수 함수로 정의역은 \\(\\Omega\\)이다. 각각의 \\(\\omega\\)가 특정한 5장의 카드 집합을 나타낸다고 할 때 \\(X(\\omega)=I\\{\\omega\\)가 네 개의 에이스를 가지고 있음\\(\\}\\)이라고 정의한다면 \\(X(\\omega)\\)는 random variable이다. Definition 5.1 (가측) \\((\\Omega_{1}, \\mathcal{F}_{1})\\), \\((\\Omega_{2}, \\mathcal{F}_{2})\\)가 두 가측공간(measurable)이라고 할 때, 함수 \\(X:\\Omega_{1} \\rightarrow \\Omega_{2}\\)가 임의의 집합 \\(E\\in \\mathcal{F}_{2}\\)에 대해 집합 \\(X^{-1}(E)\\)이 \\[X^{-1}(E)=\\{ \\omega \\in \\Omega_{1}: X(\\omega) \\in E\\} \\mathcal{F}_{1}\\] (또는 위 조건을 \\(X^{-1}(\\mathcal{F}_{2})\\in \\mathcal{F}_{1})\\)) 일 때 \\(X\\)가 가측(measurable)이라고 한다. (또는 \\(\\mathcal{F}_{1}\\)-가측 이라고도 부른다.) Definition 5.2 (확률변수) \\((\\Omega, \\mathcal{F}, P)\\)가 확률공간(probability space)이라고 하자. 그러면 어떤 실변수 함수 \\[X:\\Omega \\rightarrow \\mathbb{R}\\] 가 \\((\\Omega, \\mathcal{F})\\)에서 \\((\\mathbb{R}, \\mathcal{B})\\)로 가는 가측함수(measurable function)일 때(여기서 \\(\\mathcal{B}\\)는 \\(\\mathbb{R}\\)에서의 보렐 시그마-체) 이 \\(X\\)를 확률변수(random variable)라고 부른다. 다음 그림은 \\((\\Omega, \\mathcal{F}, P)= ((0,1), \\mathcal{B}_{(0,1)}, \\mu_{L})\\)에서의 확률변수 \\(X(\\omega) = \\frac{1}{\\omega(1-\\omega)}\\)의 역상(inverse image) 개념을 묘사한 것이다. 이 때 보렐 집합 \\(B=\\{ (6.25, \\infty)\\cup \\{4\\} \\}\\)이며, \\(X^{-1}(B)=\\{ (0,0.2)\\cup (0.8,1)\\cup \\{0.5\\} \\}\\)이며 이는 \\(\\mathcal{B}_{(0,1)}\\)안에 있다. FIGURE 5.1: 역상의 예. Example 5.1 (확률변수의 예) \\(\\Omega=[0,1]\\), \\(\\mathcal{F}=\\mathcal{B}_{[0,1]}\\)이며 \\(\\Omega\\)의 부분집합이라고 하자. 그러면 \\(X_{1}(\\omega)\\equiv=c\\). \\(X_{2}(\\omega)=I(\\omega \\leq 1/2)\\). \\(X_{3}(\\omega) = \\omega\\). 위 \\(X_{1}\\), \\(X_{2}\\), \\(X_{3}\\)은 모두 확률변수이다. \\(B\\in\\mathcal{B}\\)이면 \\(B\\)가 \\(c\\)를 포함할 경우 \\(X_{1}^{-1}(B)=\\Omega\\in\\mathcal{F}\\), 그렇지 않을 경우 \\(X_{1}^{-1}(B)=\\emptyset\\in\\mathcal{F}\\)이므로 \\(X_{1}\\)는 \\(\\mathcal{F}\\)-가측이다. 또한 \\[ X_{2}^{-1}(B) := \\begin{cases} \\emptyset\\in\\mathcal{F} &amp; \\text{if $B$ contains neither 0 nor 1} \\\\ \\Omega\\in\\mathcal{F} &amp; \\text{if $B$ contains both 0 and 1} \\\\ [1/2,1]\\in\\mathcal{F} &amp; \\text{if $B$ contains 1, but not 0} \\\\ [0,1/2]\\in\\mathcal{F} &amp; \\text{if $B$ contains 0, but not 1} \\\\ \\end{cases} \\] 이며 따라서 \\(X_{2}\\)는 \\(\\mathcal{F}\\)-가측이다. \\(B\\in\\mathcal{B}\\)일 떄 \\(X_{3}^{-1}(B)=B\\cap [0,1] \\in \\mathcal{B}_{[0,1]}\\in\\mathcal{F}\\)이므로 \\(X_{3}(\\omega)\\)또한 확률변수다. 앞선 예제에서 \\(X\\)가 확류변수임을 보이기 위해 \\(X^{-1}(\\mathcal{B})=\\{ X^{-1}(B), B\\in\\mathcal{B}\\}\\)를 계산하였다. 이 때 \\(\\mathcal{F}\\)의 부분집합인 \\(X^{-1}(\\mathcal{B})\\)는 \\(X\\)를 가측으로 만드는 관점에서 가장 작은 시그마-장이된다. Definition 5.3 (확률변수로부터 생성되는 시그마-장) 만약 \\(X\\)가 확률변수라면, \\(X\\)를 가측으로 만드는 가장 작은 시그마-장, 즉 \\(X^{-1}(\\mathcal{B})=\\{ X^{-1}(B), B\\in\\mathcal{B}\\}\\)를 \\(X\\)로부터 생성되는 시그마-장이라 하고 \\(\\sigma(X)\\)라 표기한다. 앞선 예제에서 확률변수 \\(X\\)에 대해 사건 \\(F\\in \\sigma(X)\\)을 결정할 수 있다. 예를 들면, \\(\\sigma(X_{1})=\\{ \\emptyset, [0,1] \\}\\subset \\{ \\emptyset, [0,1], [0,1/2), [1/2,1] \\}=\\sigma(X_{2})\\)이다. 이 말은 \\(X_{2}\\)가 \\(X_{1}\\)보다 \\(\\omega\\)에 대해 더 많은 정보를 준다는 것을 말해준다. \\(X_{1}\\)은 어떤 사건이 일어났는지 안일어났는지만 얘기해주지만, \\(X_{2}\\)는 \\(\\omega\\)가 1/2보다 큰지 작은지도 알려주는 것이다. 또한 \\(\\sigma(X_{2})\\subset\\sigma(X_{3})\\)이므로 \\(X_{3}\\)은 \\(X_{2}\\)보다 많은 정보를 주는 것이다. 실제로 \\(X_{3}\\)은 실험에서 나온 \\(\\omega\\)의 정확한 값을 알려준다. Definition 5.4 (보렐 측도가능과 르베그 측도가능 함수) 어떤 함수 \\(f:\\mathbb{R}^{k}\\rightarrow \\mathbb{R}\\)을 1차원 보렐 집합 \\(B\\in\\mathcal{B}\\)에 대해 \\(f^{-1}*B\\) 가 \\(k\\)차원 보렐 집할이 될 경우 보렐 측도가능(Borel measurable) 또는 보렐 함수(Borel function)이라고 부른다. 1차원 르베그 집합 \\(B\\in\\mathcal{B}\\)에 대해 \\(f^{-1}*B\\) 가 \\(k\\)차원 르베그 집할이 될 경우 르베그 측도가능(Lebesgue measurable) 또는 르베그 함수(Lebesguel function)이라고 부른다. "],
["5-1-borel-cantelli-lemma.html", "5.1 보렐-칸텔리 따름정리 (Borel-Cantelli lemma)", " 5.1 보렐-칸텔리 따름정리 (Borel-Cantelli lemma) Lemma 5.1 (보렐-칸텔리 따름정리) (Borel-Cantelli lemma) 만약 \\(\\sum_{n=1}^{\\infty}P(A_{n}) &lt; \\infty\\)라면 \\[P(A_{n} i.o.)=0\\] 이다. Lemma 5.2 (제 2 보렐-칸텔리 따름정리) (Second Borel-Cantelli lemma) 만약 사건 \\(A_{n}\\)들이 독립이라면 \\(\\sum P(A_{n})=\\infty\\)는 \\(P(A_{n} i.o.)=1\\)임을 내포한다. "],
["6-expectation.html", "Chapter 6 적분과 기댓값 ", " Chapter 6 적분과 기댓값 "],
["6-1-properties-of-integration.html", "6.1 적분의 성질(properties of integration)", " 6.1 적분의 성질(properties of integration) 어떤 상황에서 적분과 극한의 순서를 바꿀 수 있을까? Theorem 5.1 (단조수렴정리(MCT)) 1. null set \\(N\\) \\((\\mu(N)=0)\\) 바깥의 \\(\\omega\\)에 대해 \\(f_{n}(omega)\\geq 0,\\forall n\\)이고 \\(f_{n}(\\omega)\\uparrow f(\\omega)\\)라고 하자. 그러면 \\(\\int f_{n}(\\omega)d(\\omega)\\uparrow \\int f(\\omega)d\\mu(\\omega)\\)이다. 확률변수 버전으로는, 만약 모든 \\(n\\)에 대해 \\(P\\{\\omega: X_{n}(\\omega)\\geq 0 \\forall n \\text{ and } X_{n}(\\omega)\\uparrow X(\\omega)\\}=1\\)이라고 하자. 그러면 \\(E(X_{n})\\uparrow E(X)\\)이다. Theorem 5.2 (지배수렴정리(DCT)) 1. null set \\(N\\) \\((\\mu(N)=0)\\) 바깥의 \\(\\omega\\)에 대해 \\(f_{n}(omega) \\rightarrow f(\\omega)\\)이고 \\(|f_{n}(\\omega) | \\leq g(\\omega)\\), \\(\\int g(\\omega)d\\mu(\\omega) &lt; \\infty\\)일 때 \\(\\int f_{n}(\\omega)d\\mu(\\omega) \\rightarrow \\int f(\\omega)d\\mu(\\omega)\\)이다. 확률변수 버전으로는, 만약 모든 \\(n\\)에 대해 \\(P\\{\\omega: X_{n}(\\omega)\\rightarrow X(\\omega) \\text{ and } |X_{n}(\\omega)|\\leq Y(\\omega) \\forall n\\}=1\\)이고 \\(E(Y)&lt;\\infty\\)라고 하자. 그러면 \\(E(X_{n})\\rightarrow E(X)\\)이다. 지배수렴정리의 따름정리로 유계수렴정리(bounded convergence theorem, BCT)가 있다. Theorem 5.3 (유계수렴정리(BCT)) \\(X_{n}\\)이 확률변수이고 \\(P\\{X_{n}(\\omega)\\rightarrow X(\\omega)\\}=1\\)이며 각 \\(n\\)에 대해 \\(P\\{|X_{n}|\\leq c\\}=1\\) 일 때 (\\(c\\)는 상수), \\(E(X_{n})\\rightarrow E(X)\\)이다. "],
["6-2-inequalities.html", "6.2 부등식들(inequalities)", " 6.2 부등식들(inequalities) 확률론에서 부등식들은 중요한 역할을 하는데, 대부분의 일들은 다른 것들로부터 특정한 확률로 추정하는 문제들을 다루고 있기 때문이다. Lemma 5.3 (모멘트로부터 꼬리확률을 추정) \\(g\\)가 음이 아니고, 감소하지 않는 함수이며 \\(E\\{g(X)\\}&lt;\\infty\\)라고 하자. \\(x&gt;0\\)일 때 \\[P(|X|&gt;x)\\leq \\frac{E\\{g(|X|)\\}}{g(x)}\\] 이다. Proof. \\[\\begin{eqnarray} E\\{g(|X|)\\} &amp;=&amp; E\\{g(|X|)\\}I\\{|X|&gt;x\\}\\\\ &amp;=&amp; g(x)EI\\{|X|&gt;x\\}\\\\ &amp;=&amp; g(x)P(|X|&gt;x). \\end{eqnarray}\\] \\(g\\)를 특수하게 설정할 경우 다음 정리를 얻는다. Theorem 5.4 (마르코프 부등식) 어떤 \\(r&gt;0\\)에 대해 \\(E|X|^{r}&lt;\\infty\\)라고 하자. 만약 \\(x&gt;0\\)이면 다음 부등식이 성립한다. \\[P(|X|&gt;x)\\leq \\frac{E|X|^{r}}{x^{r}}.\\] Corollary 5.1 (체비셰프 부등식) 만약 \\(X\\)가 평균 \\(\\mu\\), 분산 \\(\\sigma^{2}\\)을 갖는 확률변수라면 \\(c&gt;0\\)에 대해 \\(P(|X-\\mu|\\geq c) \\leq \\sigma^{2}/c^{2}\\)이다. Theorem 5.5 (젠슨 부등식) \\(f(x)\\)가 convex 함수이고 \\(X\\)는 유한한 평균 \\(\\mu\\)를 갖는 확률변수라고 하자. 만약 \\(E(|f(X)|)&lt;\\infty\\)이면, \\(E\\{f(X)\\}\\geq f\\{E(X) \\}\\)이다. Corollary 5.2 (젠슨 부등식의 따름정리) 만약 \\(X\\)가 어떤 확률변수이고 \\(p\\geq 1\\)이면 \\(E(|X|)\\leq \\{ E(|X|^{p}) \\}^{1/p}\\)이다. "],
["7-convergencerv.html", "Chapter 7 확률변수의 수렴", " Chapter 7 확률변수의 수렴 (Proschan and Shaw 2016)의 내용을 따라간다. References "],
["7-1-almost-sure-convergence.html", "7.1 거의 확실한 수렴(Almost sure convergence)", " 7.1 거의 확실한 수렴(Almost sure convergence) \\(X_{1}, X_{2},\\ldots\\)가 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)에서의 확률변수의 수열이라고 하자. 고정된 \\(\\omega\\)에 대해 \\(X_{n}(\\omega)=x_{n}, n=1,2,\\ldots\\)은 숫자의 수열이라고 하자. 각 \\(\\omega\\)에 대해 \\(X_{n}(\\omega)\\)가 수렴할 수 있지만 극한 \\(X(\\omega)\\)는 \\(\\omega\\)에 따라 다를 수 있다. 예를 들면, \\((\\Omega, \\mathcal{F}, P)=([0,1],\\mathcal{B}_{[0,1]},\\mu_{L})\\) 이고 \\[\\begin{equation} X_{n}(\\omega)=\\omega^{n} \\tag{7.1} \\end{equation}\\] 이다. 그러면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}(\\omega) \\rightarrow I(\\omega=1)\\)이다. 그런데 어떤 \\(\\omega\\)에 대해서는 \\(X_{n}(\\omega)\\)는 극한이 없거나 무한대의 극한을 갖을 수 있다. 예를 들면 앞선 식 (7.1)을 다음과 같이 바꾸는 것이다. \\[\\begin{equation} X_{n}(\\omega)=(-\\omega)^{n} \\tag{7.2} \\end{equation}\\] 그러면 \\(\\omega &lt; 1\\)일 때 \\(n\\rightarrow 0\\)이나 \\(\\omega=1\\)일 때는 극한이 존재하지 않는다. 식 (7.1)과 (7.2)에서의 행동이 다르다고 하더라도 \\(\\{\\omega=1\\}\\)이 확률 0을 갖는다면 다른 행동을 무시할 수 있을 것이다. 이것을 확장시키면 확률 0인 집합들을 무시하는 것으로 이해할 수 있고, 거의 확실한 수렴(Almost sure convergence)의 정의를 이끈다. Definition 7.1 (거의 확실한 수렴) 1. 확률변수들 \\(X_{1}(\\omega), X_{2}(\\omega), \\ldots\\)가 \\(X(\\omega)\\)로 거의 확실한 수렴을 한다는 것은, 확률이 0인 집합을 제외한 나머지 부분에서 고정된 \\(\\omega\\)에 대해 숫자들의 수열 \\(X_{n}(\\omega)\\)가 \\(n\\rightarrow\\infty\\)함에 따라 \\(X(\\omega)\\)로 수렴하는 것을 의미한다. 특별히 이것을 \\(X_{n}\\rightarrow X a.s.\\) 또는 \\(X_{n}\\stackrel{a.s.}{\\rightarrow}X\\)라고 쓴다. 임의의 측도 공간 \\((\\Omega, \\mathcal{F}, \\mu)\\)위의 함수들 \\(f_{1}(\\omega), f_{2}(\\omega),\\ldots\\)의 수열이 \\(f(\\omega)\\)로 거의 확실한 수렴을 한다(converges almost everywhere)는 것은 \\(\\mu\\)-측도가 0인 집합 밖에 있는 모든 \\(\\omega\\)에 대해 실수 수열 \\(f_{n}(\\omega)\\)가 \\(f(\\omega)\\)로 수렴함을 의미한다. \\(\\mu\\)가 확률측도일 때에는 convergence almost surely, 아닐 때에는 convergence almost everywhere라고 많이 부른다. Example 7.1 (앞선 예의 거의 확실한 수렴) \\((\\Omega, \\mathcal{F}, P)=([0,1], \\mathcal{B}_{[0,1]}, \\mu_{L})\\)이라고 정의하자. 식 (7.1)과 (7.2) 모두 확률 0인 집합 \\(\\{\\omega = 1\\}\\) 바깥에서 \\(X_{n}(\\omega) \\rightarrow 0\\)이므로 \\(X_{n}\\stackrel{a.s.}{\\rightarrow}0\\)이다. 위 예제는 거의 확실한 수렴을 생각할 때 \\(\\omega\\)를 고정시키는 것이 큰 도움이 된다는 것을 보여준다. 한편, \\(X_{n}\\)의 거의 확실한 수렴을 보이기 위해서 underly 확률공간을 몰라도 될 때도 있다. Example 7.2 (확률공간을 모를때의 거의 확실한 수렴) \\(Y(\\omega)\\)를 임의의 확률공간에서 존재하는 유한 확률변수라고 하고 \\(X_{n}(\\omega)=Y(\\omega)/n\\)이라고 하자. 그러면 각 \\(\\omega\\)에 대해 \\(Y(\\omega)\\)는 유한한 값이므로 \\(n\\rightarrow\\infty\\)일 때 \\(Y(\\omega)/n \\rightarrow 0\\)이 된다. 그러면 모든 \\(\\omega\\)에 대해 \\(X_{n}\\stackrel{a.s.}{\\rightarrow}0\\)이다. 이번에는 \\(Y\\)가 모든 \\(\\omega\\)에서 유한하다는 가정을 완화해보자. \\(Y(\\omega)\\)가 확률 1로 유한하다고 가정하는 것이다. 그러면 \\(Y(\\omega)\\)가 유한한 모든 \\(\\omega\\)에 대해 \\(X_{n}(\\omega) = Y(\\omega)/n \\rightarrow 0\\)이고, \\(X_{n}\\)이 \\(0\\)으로 수렴하지 않을 집합은 확률 0이다. 따라서 이 경우에도 \\(X_{n}\\stackrel{a.s.}{\\rightarrow}0\\)이다. Example 7.3 (확률변수로의 거의 확실한 수렴) \\(X_{1}\\equiv X_{2}\\equiv \\ldots \\equiv X_{n} \\equiv \\ldots \\equiv X\\)라고 하면 \\(X_{n}\\stackrel{a.s.}{\\rightarrow}X\\) 이다. \\(Y\\)는 확률 1로 유한한 값을 가지는 확률변수라 하자. 그러면 \\(Y(\\omega)\\)가 유한한 값 \\(\\omega\\)에 대해 \\(X_{n}=\\{ 1+ Y(\\omega) /n\\}^{n} \\rightarrow X(\\omega) = \\exp \\{ Y(\\omega) \\}\\)이다. 왜냐하면 모든 유한한 상수 \\(a\\)에 대해 \\((1+a/n)^{n}\\rightarrow \\exp(a)\\)기 때문이다. 따라서, \\(X_{n}\\stackrel{a.s.}{\\rightarrow}X=\\exp(Y)\\)이다. Proposition 7.1 (거의 확실한 수렴의 기본적인 성질들) \\(X_{n}\\stackrel{a.s.}{\\rightarrow}X\\), \\(Y_{n}\\stackrel{a.s.}{\\rightarrow}Y\\)라고 하자. 그러면 만약 \\(X_{n}\\stackrel{a.s.}{\\rightarrow}X&#39;\\)이면 \\(P(X=X&#39;)=1\\)이다. 어떤 연속함수 \\(f\\)에 대해 \\(f(X_{n})\\stackrel{a.s.}{\\rightarrow}f(X)\\)이다. 실제로 \\(f:\\mathbb{R} \\rightarrow \\mathbb{R}\\)은 불연속인 지점들의 집합 D가 \\(\\{w:X(\\omega)\\in D\\}\\in\\mathcal{F}\\)일 때 \\(P(X\\in D)=0\\)인 보렐 함수이면 된다. \\(X_{n}\\pm Y_{n}\\stackrel{a.s.}{\\rightarrow} X\\pm Y\\). \\(X_{n} Y_{n}\\stackrel{a.s.}{\\rightarrow} X Y\\). 만약 \\(P(Y=0)=0\\)이면, \\(X_{n}/Y_{n}\\stackrel{a.s.}{\\rightarrow}X/Y\\)이다. "],
["7-2-convergence-in-probability.html", "7.2 확률수렴(Convergence in probability)", " 7.2 확률수렴(Convergence in probability) 많은 통계적 응용들은 모수 \\(\\theta\\)를 \\(n\\)개의 관찰값들의 표본에 기반한 통계량 \\(\\hat{\\theta}_{n}\\)으로 추정하는 것을 포함한다. 그러면 \\(n\\)이 클 때 \\(\\hat{\\theta}_{n}\\)이 \\(\\theta\\)에 어느 정도 가까워지는지를 수식화 할 수 있을까? 우리는 \\(\\hat{\\theta}_{n}\\)이 \\(\\theta\\)에 거의 확실한 수렴을 한다고 주장할 수 있으나, 이것은 너무 강한 조건이다. 거의 확실한 수렴은 무한대 수열 \\(\\hat{\\theta}_{1}(\\omega), \\hat{\\theta}_{2}(\\omega), \\ldots\\)들의 움직임을 포함해야 하고, 이것은 표본의 크기가 \\(n=1,2,\\ldots\\)처럼 무한히 커지는 것에 대응된다. 그러나 우리는 \\(n\\)개의 표본 크기만을 갖고 있다. 실제 던져야 할 질문은, 만약 \\(n\\)이 충분히 크다면, \\(\\hat{\\theta}_{n}\\)이 \\(\\theta\\)의 작은 오차 범위 \\(\\pm \\epsilon\\)이내에 얼마나 높은 확률로 있을까?에 대한 것이다. 이것은 확률수렴(Convergence in probability)에 대한 정의를 이끈다. Definition 7.2 (확률수렴) 1. 확률변수들 \\(X_{1}(\\omega), X_{2}(\\omega), \\ldots\\)가 \\(X(\\omega)\\)에 확률수렴한다는 것은 각 \\(\\epsilon &gt; 0\\)에 대해 \\(n\\rightarrow 0\\)일 때 \\(P(|X_{n}(\\omega) - X(\\omega)|\\geq \\epsilon)\\rightarrow 0\\)을 의미하며, \\(X_{n}\\stackrel{p}{\\rightarrow}X\\)로 쓴다. 좀 더 일반적으로, 측도공간 \\((\\Omega, \\mathcal{F},\\mu)\\)위의 가측함수들 \\(f_{1}(\\omega),f_{2}(\\omega),\\ldots\\)이 \\(f\\)에 측도수렴(converge in measure)한다는 것은 각 \\(\\epsilon &gt;0\\)에 대해 \\(n\\rightarrow \\infty\\)일 때 \\(\\mu \\{ \\omega : |f_{n}(\\omega)-f(\\omega)| \\geq \\epsilon \\}\\rightarrow 0\\)을 의미한다. Example 7.4 (경험분포함수의 일치성) 말기 암 환자들의 연구에서 \\(X_{i}\\)는 연구 시작으로부터 \\(i=1,\\ldots, n\\)번째 환자의 죽음에 이르는데 걸리는 시간이라고 하자. \\(X_{i}\\)는 i.i.d이며 분포함수 \\(F(x)\\)를 따른다고 가정하자. 우리는 다른 \\(x\\)들에 대해 \\(F(x)\\)를 추정하고 싶어한다. \\(x\\)를 고정하면 죽은 환자의 수는 성공 확률 \\(F(x)\\)인 binomial distribution을 따른다. 만약 \\(\\hat{F}_{n}(x)\\)가 시간 \\(x\\)에서 죽은 환자들의 비율을 나타낸다고 하면 Chebychev의 inequality에 의해 \\[\\begin{align*} P(|\\hat{F}_{n}(x) - F(x)|&amp;\\geq \\epsilon) \\leq \\frac{\\text{var}\\{\\hat{F}_{n}(x)\\}}{\\epsilon^{2}}\\\\ &amp;= \\frac{F(x)\\{1-F(x)\\}}{n\\epsilon^{2}}\\rightarrow 0 \\end{align*}\\] 이 된다. 즉 \\(\\hat{F}_{n}(x)=\\frac{1}{n}\\sum_{i=1}^{n}I(X_{i}\\leq x)\\)는 각 \\(x\\)에 대해 진짜 분포 함수 \\(F(x)\\)로 확률수렴한다. "],
["7-3-lp-convergence-in-lp.html", "7.3 Lp 수렴(Convergence in Lp)", " 7.3 Lp 수렴(Convergence in Lp) 추정량 \\(\\hat{\\theta}_{n}\\)이 모수 \\(\\theta\\)에 가까운 정도를 나타내는 또 다른 측도 중 하나는 평균제곱오차(mean squared error, MSE), \\(E(\\hat{\\theta}_{n}-\\theta)^{2}\\)이다. 이것은 두 개의 벡터 \\(\\mathbf{x},\\mathbf{y}\\)가 어느 정도 가까운지 나타내는 측도로 \\(\\sum_{i=1}^{k}(x_{i}-y_{i})^{2}\\)을 나타내는 것과 동일한 아이디어이다. 그러나 두 벡터 사이의 거리를 나타내기 위해서 제곱근을 취하는 것차럼, \\(\\hat{\\theta}_{n}\\)과 \\(\\theta\\)의 거리를 나타내기 위해 MSE에도 제곱근을 취한다. 이것이 \\(L^{p}\\)거리의 특수한 형태인 \\(L^{2}\\)거리를 유도한다. Definition 7.3 (Lp거리) 만약 \\(X, Y\\)가 유한한 \\(p\\)차 모멘트 \\((p&gt;0)\\)을 갖는 확률변수들이라고 하면 \\(X\\)와 \\(Y\\)의 \\(L^{p}\\)거리는 \\(\\{ E(|X-Y|^{p}) \\}^{1/p}\\)로 정의한다. Definition 7.4 (Lp수렴) 확률변수들의 수열 \\(X_{1},X_{2},\\ldots\\)가 \\(n\\rightarrow 0\\)일 때 \\(E(|X_{n}-X|^{p})\\rightarrow 0\\)을 만족할 경우 이 수열들이 \\(X\\)에 \\(L^{p}\\) 수렴한다고 정의한다. "],
["7-4-convergence-in-distribution.html", "7.4 분포수렴(Convergence in distribution)", " 7.4 분포수렴(Convergence in distribution) 분포수렴(Convergence in distribution)은 분포함수의 관계를 다룬다는 점에서 확률변수들의 관계를 고려하는 앞 수렴들과는 다른 타입의 수렴이라고 할 수 있다. \\(X_{n}\\)의 분포함수 \\(F_{n}(x)\\)가 \\(X\\)의 분포함수 \\(F(x)\\)로 수렴할 때 우리는 \\(X_{n}\\)이 \\(X\\)에 대해 분포적으로 가까워진다고 말한다. 가장 단순한 예로 \\(X_{n}=1+\\frac{1}{n}\\)이고 \\(X\\)는 1인 경우를 생각해 볼 수 있다. 이 때 \\(X_{n}\\)의 분포함수 \\(F_{n}(x)\\)는 다음과 같은 분포함수 \\(F(x)\\)로 가까워지는 것처럼 보인다. \\[\\begin{equation} F(x)= \\begin{cases} 0 &amp; \\text{if } x &lt; 1 \\\\ 1 &amp; \\text{if } x \\geq 1 \\end{cases} \\tag{7.3} \\end{equation}\\] 그러나 \\(F_{n}(x)=P(X_{n}\\leq x)\\)는 \\[\\begin{equation} F_{n}(x)= \\begin{cases} 0 &amp; \\text{if } x &lt; 1 + \\frac{1}{n} \\\\ 1 &amp; \\text{if } x \\geq 1 \\frac{1}{n} \\end{cases} \\tag{7.4} \\end{equation}\\] 이며 이는 \\[\\begin{equation} \\begin{cases} 0 &amp; \\text{if } x \\leq 1 \\\\ 1 &amp; \\text{if } x &gt; 1 \\end{cases} \\end{equation}\\] 로 수렴한다. 식 (7.3)과 식 (7.4)의 분포함수는 \\(x=1\\)에서 일치하지 않는다. 따라서, \\(F_{n}(x)\\)가 모든 \\(x\\)에서 \\(F(x)\\)로 수렴하는 것은 너무 강한 조건으로 보인다. 분포수렴을 정의할 때에는 앞선 예의 \\(x=1\\)처럼 불연속인 점들을 제외한 연속인 점들 \\(x\\)에서 \\(F_{n}(x) \\rightarrow F(x)\\)가 되는 것으로 정의한다. Definition 7.5 (분포수렴) \\(X_{n}, X\\)가 분포함수 \\(F_{n}(x), F(x)\\)를 갖는 확률변수들이라고 하자. 그러면 모든 연속인 점 \\(x\\)에 대해 \\(F_{n}(x)\\rightarrow F(x)\\)일 경우 \\(X_{n}\\)이 \\(X\\)에 분포수렴(converge in distribution)한다고 정의하고 \\(X_{n}\\stackrel{D}{\\rightarrow} X\\) 또는 \\(F_{n}\\stackrel{D}{\\rightarrow} F\\)로 쓴다. Example 7.5 (정규분포에서 나온 확률변수들의 분포수렴) \\(X_{n}\\)이 평균 \\(\\mu_{n}\\)이고 표준편차가 \\(\\sigma_{n}\\)인 정규확률변수라고 하자. 그리고 \\(\\mu_{n}\\rightarrow\\mu\\)이고 \\(\\sigma_{n}\\rightarrow\\sigma &gt;0\\)이다. 그러면 \\(P(X_{n}\\leq x) = P\\{\\frac{X_{n}-\\mu_{n}}{\\sigma_{n}}\\leq \\frac{x-\\mu_{n}}{\\sigma_{n}}\\}=\\Phi\\{ \\frac{x-\\mu_{n}}{\\sigma_{n}} \\}\\)이다. \\(\\Phi\\)는 연속이고 \\(\\frac{x-\\mu_{n}}{\\sigma_{n}}\\rightarrow \\frac{x-\\mu}{\\sigma}\\)이므로 \\(P(X_{n}\\leq x) \\rightarrow \\Phi\\frac{x-\\mu}{\\sigma}\\)이다. 즉 \\(X_{n}\\stackrel{D}{\\rightarrow}\\mathcal{N}(\\mu,\\sigma^{2})\\)이다. 7.4.1 Skorohod 표현 정리(Skorohod representation theorem) Skorohod 표현 정리(Skorohod representation theorem)이란 분포수렴이 확률변수의 다른 수열에서 거의 확실한 수렴을 보장해 주는 것이다. Theorem 7.1 (Skorohod 표현 정리) 만약 \\(X_{n} \\stackrel{D}{\\rightarrow} X\\)라면 \\((\\Omega, \\mathcal{F}, P)\\)에서 정의된 확률변수들 \\(Y_{n}\\), \\(Y\\)가 존재해 \\(Y_{n}\\)가 \\(X_{n}\\)이랑 같은 분포를 갖고 \\(Y\\)는 \\(X\\)랑 같은 분포를 갖으며 \\(Y_{n}&#39;\\)는 \\(Y\\)에 거의 확실한 수렴을 한다. 이를 수식으로 다시 쓰면, 우리가 \\(X_{n} \\stackrel{D}{\\rightarrow} X\\) 임을 안다면 \\(Y_{n}\\stackrel{D}{=}X_{n}\\), \\(Y\\stackrel{D}{=}X\\) 이며 \\(Y_{n}\\stackrel{a.s.}{\\rightarrow}Y\\)인 \\(Y_{n}\\)과 \\(Y\\)이 존재해 준다는 것을 보장해 준다는 것이다. "],
["7-5-connections-between-modes-of-convergence.html", "7.5 수렴 사이들의 관계(Connections between modes of convergence)", " 7.5 수렴 사이들의 관계(Connections between modes of convergence) FIGURE 7.1: Connections between modes of convergences. "],
["7-6-convergence-of-moments-uniform-integrability.html", "7.6 Convergence of moments: 일양적분가능성(uniform integrability)", " 7.6 Convergence of moments: 일양적분가능성(uniform integrability) \\(X_{n}\\)이 점근적으로 \\(\\mathcal{N}(\\mu_{n}, \\sigma_{n}^{2})\\)에 수렴한다는 문장을 생각해보자. 즉 이 얘기는 \\((X_{n}-\\mu_{n})/\\sigma_{n} \\stackrel{D}{\\rightarrow} \\mathcal{N}(0,1)\\)이라는 말이다. 그러나 이것이 \\(E(X_{n})=\\mu_{n}\\)이고 \\(\\text{var}(X_{n})=\\sigma_{n}^{2}\\)임을 의미하지는 않는다. 일반적으로 \\(X_{n} \\stackrel{D}{\\rightarrow} X\\)는 \\(E(X_{n}) \\rightarrow E(X)\\)임을 의미하지 않는다. Example 7.6 (추정량은 무한대의 평균을 갖으나 확률변수의 극한은 유한한 평균을 갖는 예) \\(\\hat{p}_{n}\\)이 iid 베르누이 확률변수 \\(X_{1}, \\ldots, X_{n}\\)로부터 나온 표본비(sample proportion)라고 하자. 그러면 CLT에 의해 \\(\\hat{p}_{n}\\)은 점근적으로 평균 \\(p=E(X_{1})\\)이고 분산 \\(p(1-p)/n\\)인 정규분포를 따른다. 델타 방법(delta method)에 의해 \\(\\text{ln}(\\hat{p})\\)는 점근적으로 평균 \\(\\ln(p)\\), 분산 \\((1-p)/(np)\\)인 정규분포를 따름을 안다. 그러면 \\[Z_{n} = \\frac{\\text{ln}(\\hat{p}_{n})-\\text{ln}(p)}{\\sqrt{(1-p)/(np)}} \\stackrel{D}{\\rightarrow} Z \\sim \\mathcal{N}(0,1)\\] 임을 안다. 그러나 모든 \\(n\\)에 대해 \\(E\\{\\text{ln}(\\hat{p}_{n}) \\}=-\\infty\\)인데, 이는 \\(\\hat{p}_{n}\\)은 0이 될 확률이 양수이기 때문이다. 그러므로 \\(E(Z_{n})=-\\infty\\)이나, \\(E(Z)=0\\)이다. (Skrohod 정리를 이용한 추가적 설명 필요, Essential of Probability Theory for Statisticians 193-194쪽) Definition 7.6 (일양적분가능) 만약 각 \\(\\epsilon &gt;0\\)에 대해 \\[E\\{ |X_{n}| I(|X_{n}|&gt;A)\\}&lt;\\epsilon \\forall n\\] 을 만족하는 \\(A\\)가 존재한다면 이 확률변수의 수열 \\(X_{n}\\)을 일양적분가능(uniformly integrable, UI)이라고 부른다. 또는 \\[\\lim_{A\\rightarrow\\infty}\\sup_{n}E\\{ |X_{n}| I(|X_{n}|&gt;A)\\}=0\\] 을 만족하는 것으로 정의하기도 한다. 그렇다면 일양적분가능이 말하고자 하는 것은 무엇인가? \\(|X_{n}| I(|X_{n}|&gt;A)\\)항부터 살펴보자. 이것은 \\(A\\)보다 작은 \\(|X_{n}|\\) 값은 0이 되도록 조절하는 것이다. 다음 그림을 참고하자. FIGURE 7.2: Case when function values bigger than A exist. 다음은 \\(E\\{|X_{n}| I(|X_{n}|&gt;A)\\}\\)에 초점을 맞춘다. 이것은 그림 의 그래프 아래 면적에 해당하는 것이다(물론 \\(\\omega \\in [0,M]\\)에서 균등한 확률 측도 \\(dP(\\omega)=\\frac{1}{M}\\)을 줬을 때의 이야기다). 이때 상한(\\(\\sup_{n}\\))의 쓰임은 \\(A\\)가 고정되었을 때 가장 큰 면적을 반환하는 \\(n\\)을 찾는 것이다. 마지막으로 극한을 취함으로써(\\(lim_{A\\rightarrow\\infty}\\sup_{n}E\\{ |X_{n}| I(|X_{n}|&gt;A)\\}\\)) \\(A\\)가 점점 커졌을 때 상한이 어떻게 변하는지 관찰할 수 있다. FIGURE 7.3: An example of sequence of random variables that is not uniformly integrable. 위 확률변수의 수열은 일양적분가능하지 않다. \\(A\\)가 커짐에 따라 항상 \\(E\\{|X_{n}| I(|X_{n}|&gt;A)\\}=1\\)을 만족하는 \\(n\\)이 존재한다. 즉 \\(|X_{n}| I(|X_{n}|&gt;A)=|X_{n}|\\)인 \\(n\\)이 항상 존재하는 것이다. 따라서 \\[\\sup_{n}E\\{ |X_{n}| I(|X_{n}|&gt;A)\\}=\\sup_{n}E\\{ |X_{n}|\\}=\\sup_{n}1=1.\\] 이다. FIGURE 7.4: An example of sequence of random variables that is uniformly integrable. 위 예들로부터 얻을 수 있는 직관적 사실들은 다음과 같다. 만약 \\(X_{n}\\)의 평균 면적이 \\(n\\)이 커짐에 따라 무한대로 발산하면 그 확률변수의 수열은 항상 일양적분가능하지 않을 것이다. 한편 모든 유한한 수열을 항상 일양적분가능하다(왜냐하면 모든 고정된 \\(n\\)에 대해 \\(P(X_{n}&gt;A)\\)는 \\(A\\)가 커짐에 따라 감소한다). 모든 유계(bounded)인 확률변수의 수열(반대로 유계가 아닌 경우를 생각해보면 \\(n\\)이 커짐에 따라 \\(X_{n}\\)은 어떤 확률로 점점 큰 값을 갖게 될 것이다)일양적분가능하다. 그러나 그 역은 성립하지 않는다. 마지막으로 유계가 아니나 일양적분가능한 확률변수의 수열의 예를 소개한다. FIGURE 7.5: An example of sequence of random variables that is not bounded but uniformly integrable. 7.6.1 Tight 여기서 tight의 정의는 (Proschan and Shaw 2016)의 6.48을 따른다. Definition 7.7 (Tight sequence of distribution functions) 분포함수들의 수열 $F_{1}(x), F_{2}(x),$가 모든 \\(\\epsilon &gt;0\\)에 대해 숫자 \\(M\\)이 존재해 \\(F_{n}(M) &lt;\\epsilon\\)이고 모든 \\(n\\)에 대해 \\(1-F_{n}(M) &lt;\\epsilon\\)일 경우 tight하다고 한다. (measure의 tight도 나중에 서술) References "],
["7-7-absolute-continuous.html", "7.7 절대연속(absolute continuous)", " 7.7 절대연속(absolute continuous) 확률변수 \\(X_{1}\\), \\(X_{2}\\)가 있을 때 \\(X_{1}\\)이 \\(X_{2}\\)에 대해 절대연속(absolute continuous)하다는 것은(정확히 얘기하면 \\(X_{1}\\)의 분포가 \\(X_{2}\\)의 분포에 대해 절대연속이다) 적당한 집합 \\(F\\)에 대해 \\(P(X_{2}\\in F)=0\\)이 \\(P(X_{1}\\in F)=0\\)임을 내포하는 것과 동치이다. "],
["7-8-law-of-large-numbers.html", "7.8 대수의 법칙(law of large numbers)", " 7.8 대수의 법칙(law of large numbers) Proposition 7.2 (대수의 약법칙과 대수의 강법칙) 대수의 약법칙(weak law of large numbers, WLLN)은 \\(\\bar{X}_{n}\\)이 \\(\\mu\\)에 확률수렴하는 것이고, 대수의 강법칙(strong law of large numbers, SLLN)은 \\(\\bar{X}_{n}\\)이 \\(\\mu\\)에 거의 확실한 수렴을 하는 것이다. "],
["7-9-convergence-of-functions-of-random-variables.html", "7.9 확률변수들의 함수의 수렴(convergence of functions of random variables)", " 7.9 확률변수들의 함수의 수렴(convergence of functions of random variables) 연속 사상 정리는 (Gut 2012)의 서술을 따른다. Theorem 7.2 (연속 사상 정리) \\(X_{1}, X_{2},\\ldots\\)가 확률변수들이라고 하고 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}\\stackrel{d}{\\rightarrow}\\)라고 하자. 만약 (실수 값을 갖는) 함수 \\(g\\)가 존재해 이것이 연속이라면, \\(n\\rightarrow \\infty\\)일 때 \\(g(X_{n})\\stackrel{d}{\\rightarrow}\\)이다. References "],
["8-markovchain.html", "Chapter 8 마르코프 체인 ", " Chapter 8 마르코프 체인 "],
["8-1-markov-chain.html", "8.1 마르코프 체인(Markov chain)", " 8.1 마르코프 체인(Markov chain) Definition 7.8 (마르코프 체인) 마르코프 체인(Markov chain)이란 \\[P(X_{n+1}=X|X_{1}=x_{1}, X_{2}=x_{2}, \\ldots , X_{n}=x_{n})=P(X_{n+1}=x|X_{n}=x_{n})\\] 을 만족하는 확률변수들의 수열 \\(X_{1},X_{2},\\ldots\\)를 일컫는다. 여기서\\(x_{i}\\)들은 countable set \\(S\\)에서 뽑힌 값들이며 \\(S\\)를 체인의 state space라고 부른다. "],
["9-stoprocess.html", "Chapter 9 확률과정론", " Chapter 9 확률과정론 참고할만한 책으로 (Moller and Waagepetersen 2012)가 있다. References "],
["9-1-stochastic-process.html", "9.1 확률과정이란?(stochastic process)", " 9.1 확률과정이란?(stochastic process) (Moller and Waagepetersen 2012)에 있는 그림이다. FIGURE 9.1: Overview of the threee types of worlds in which our processes live. 확률과정(stochastic process)란 확률공간에서 정의되는 확률변수들의 모임 \\(\\{ Z, t \\in T\\}\\)라고 할 수 있다. 이 때 \\(T=(-\\infty, \\infty)\\) 등과 같이 연속된 구간의 형태를 갖는 경우를 연속형 확률과정(continuous stochastic process), \\(T=\\{ 0, \\pm 1, \\pm 2 , \\ldots\\}\\) 등과 같이 이산 구간일 경우는 이산형 확률과정(discrete stochastic process)라고 한다. References "],
["9-2-continuity-of-stochastic-process.html", "9.2 확률과정에서의 연속성(continuity of stochastic process)", " 9.2 확률과정에서의 연속성(continuity of stochastic process) Definition 9.1 (연속표본경로) 과정 \\(X\\)가 \\(t_{0}\\)에서 연속이라 함은 \\[\\text{For almost all }\\omega, t \\rightarrow t_{0} \\text{ implies } X(t,\\omega) \\rightarrow X(t_{0},\\omega)\\] 를 의미한다. 과정 \\(X\\)가 연속이라 함은 \\[\\text{For almost all }\\omega, X(\\cdot, \\omega) \\text{ is a continuous function}\\] 임을 의미한다. Definition 9.2 (CADLAG (CAGLAD)) Well-ordered set \\(T\\)에 있는 sample function \\(x\\)가 모든점에서 continuous from the right (left)하고 limited from the left (right)일 때 CADLAG (CAGLAD)이라고 한다. 즉, 모든 \\(t_{0}\\in T\\)에서 \\(t\\downarrow t_{0}\\)이 \\(x(t) \\rightarrow x(t_{0})\\)를 의미하고 \\(t\\uparrow t_{0}\\)일 때 \\(\\lim_{t\\uparrow t_{0}} x(t)\\)가 존재하나 꼭 \\(x(t_{0})\\)일 필요는 없는 상황임을 의미한다. 어떤 확률과정 \\(X\\)가 CADLAG임은 그것의 almost all sample path가 CADLAG임을 의미한다. Definition 9.3 (확률과정의 version) Common index set \\(T\\)를 갖는 두 개의 확률과정 \\(X\\)와 \\(Y\\)이 서로의 version이라 함은 \\[\\forall t \\in T, \\mathbb{P}(\\omega: X(t,\\omega)=Y(t,\\omega))=1\\] 임을 의미한다. 이러한 과정들을 stochastically equivalent라고도 부른다. 이는 임의의 시간대에서 \\(X\\)와 \\(Y\\)는 almost surely equal이라는 것이다. Definition 9.4 (확률과정의 구분불가능성) 두 개의 확률과정 \\(X\\)와 \\(Y\\)가 구분불가능(indistinguishable) 또는 euqivalent up to evanescense하다는 것은 \\[\\mathbb{P}(\\omega: \\forall t, X(t,\\omega)=Y(t,\\omega))=1\\] 임을 의미한다. 쉽게 얘기하면 \\(X\\)와 \\(Y\\)의 표본 경로가 equal almost surely라는 것이다. 구분불가능성을 갖는 확률과정은 서로의 version이 되나, 그 반대는 성립하지 않는다. 그렇다면 확률과정에서 왜 연속성이 이슈가 되는가? 우리는 sample path를 보통 연속인 함수로 제한하고 싶어한다. 더 나아가 미분가능할 정도로 부드러운 함수를 다루고자 하는 경우가 많다. 물론 이는 수학적인 편리함을 위해서이다. Proposition 9.1 \\(X(t,\\omega)\\)를 실변수이며 연속 표본 경로를 갖는 연속 모수 과정이라고 하자. 그러면 모든 유한한 구간 \\(I\\)에 대해 \\(M(\\omega)=\\equiv \\sup_{t\\in I}X(t,\\omega)\\)이고 \\(m(\\omega)\\equiv \\inf_{t\\in I}X(t,\\omega)\\)는 가측 확률변수이다. 우리는 특정 시간에 관찰된 확률과정을 다룰 때 product \\(\\sigma\\)-field를 보통 쓴다. Product \\(\\sigma\\)-field는 countable question에 대해 답을 해 준다. 즉 어떤 measurable set \\(A\\)가 있으면 이 때 \\(x(\\cdot, \\omega)\\in A\\)는 countably many indices \\(t\\)의 \\(x(t,\\omega)\\) value들에 depend해야한다는 것이다. 이것은 모든 continuous sample path들의 class가 not product \\(\\sigma\\)-field measurable이 될 수도 있다는 것을 의미하는데, 그 이유는 \\(x(\\cdot, \\omega)\\)가 \\(t\\)에서 연속이라는 것은 모든 수열 \\(t_{n}\\rightarrow t\\)에 대해 \\(x(t_{n},\\omega)\\rightarrow x(t,\\omega)\\)라는 것을 의미하면 이것은 uncountably many coordinates들의 함숫값들을 포함하는 것이기 때문이다. 더 나아가 differentiable function들의 class 또한 \\(\\sigma\\)-field measurable이 아니다. "],
["9-3-separable-random-functions.html", "9.3 분리가능한 무작위 함수들(separable random functions)", " 9.3 분리가능한 무작위 함수들(separable random functions) 분리가능(separable)한 무작위 함수들의 기본 아이디어는 contable, dense subset만 다룬다는 것이다. Definition 9.5 (분리가능 함수들(separable functions) \\(\\Xi\\)와 \\(T\\)가 metric space라고 하고, \\(D\\)를 \\(T\\)의 countable, dense subset이라고 하자. 그러면 함수 \\(x: T\\rightarrow \\Xi\\)가 \\(\\forall t\\in T\\)에 대해 수열 \\(t_{i}\\in D\\)가 존재해 \\(t_{i}\\rightarrow t\\) 그리고 \\(x(t_{i})\\rightarrow x(t)\\)를 만족할 경우 함수 \\(x\\)를 D-분리가능(D-separable) 또는 D에 대해 분리가능하다고 한다. Lemma 9.1 다음 조건들은 분리가능성의 충분조건이다. \\(T\\) is countable \\(T\\) is continuous \\(T\\) is well-ordered and \\(x\\) is right-continuous. Proof. 1. \\(T\\) 자체를 separating set으로 잡으면 된다. 어떤 countable dense set \\(D\\)를 잡는다. Dense 성질에 의해 모든 \\(t\\)에 대해 다음과 같은 수열 \\(t_{i}\\in D\\)가 존재해 \\(t_{i}\\rightarrow t\\)이다. 연속성에 의해 \\(x(t_{i})\\rightarrow t\\)가 된다. 2와 마찬가지로 모든 coundtable dense \\(D\\)에 대해 \\(t_{i}&gt;t\\)가 되도록인 채로 2와 같은 논리를 따라가면 된다. Definition 9.6 (분리가능 과정) \\(\\Xi\\)-valued process \\(X\\) on \\(T\\)가 D에 대해 분리가능(separable with respect to D)하다는 것은 \\(D\\)가 \\(T\\)의 countable, dense subset이고 다음과 같은 measure-zero set \\(N\\in\\Omega\\)가 존재해 모든 \\(\\omega \\in N\\)에 대해 \\(X(\\cdot, \\omega)\\)가 \\(D\\)-분리가능이라는 것이다. 즉 \\(X(\\cdot, \\omega)\\)가 almost surely \\(D\\)-separable이라는 것이다. "],
["9-4-empirical-process.html", "9.4 경험과정(empirical process)", " 9.4 경험과정(empirical process) 이 부분은 (Jiang 2010) 7장을 참고했다. 확률변수들은 관찰값(observation)들의 형태로 얻어지는데, 관찰된 확률변수들로 구성된 함수를 우리는 특별히 통계적 함수(statistical function)이라고 부른다. 통계적 함수는 실제로 얻을 수 있다는 점에서 많은 사람들이 그 성질에 대해 관심을 갖는다. 보통은 통계적 함수들 중 경험과정(empriical process)이라고 부르는 것에 집중을 하게 된다. $X_{1},X_{2},$가 분포함수 \\(F\\)를 갖는 i.i.d. 확률변수들의 수열이라고 하자. 그러면 경험적 분포함수(empirical distribution function)은 다음과 같이 정의된다. Definition 9.7 (경험적 분포함수) 경험적 분포함수 \\(F_{n}(x)\\)는 다음과 같이 정의된다. \\[\\begin{equation} F_{n}(x)=\\frac{1}{n}\\sum_{i=1}^{n}1_{(X_{i}\\leq x)}, -\\infty &lt; x &lt; \\infty. \\tag{9.1} \\end{equation}\\] 식 (9.1)은 쉬워보이지만 이 식의 뜻을 쉽게 이해하기는 어렵다. 여기서 \\(X_{i}\\)들은 관찰값들이고 \\(x\\)는 함수값이다. \\(X_{i}\\)들의 실현(realization)에 대해 식 (9.1)은 계단함수를 정의한다. 그리고 \\(X_{i}\\)들이 무작위이므로 식 (9.1) 또한 무작위이다. 즉 \\(X_{1},\\ldots ,X_{n}\\)들이 매 번 실현될 때마다 다른 함수를 얻게 된다. 대수의 약법칙에 의해 각 \\(x\\)에 대해 경험적 분포함수는 \\(n\\rightarrow\\infty\\)일 때 \\(E\\{1_{(X_{1}\\leq X)}\\}=P(X_{1}\\leq x)=F(x)\\)에 거의 확실한 수렴(converge a.s)을 한다. 실제로는 더 강한 결과가 성립한다. 이 거의 확실한 수렴은 \\(n\\rightarrow\\infty\\)일 때 \\[\\sup_{x}|F_{n}(x)-F(x)|\\stackrel{\\text{a.s.}}{\\rightarrow}0\\] 이므로 uniform하게 수렴한다. 그러면 우리는 경험적 분포함수에 대해서도 다음과 같은 centeralized되어있고 normalized version의 경험적 분포함수를 정의할 수 있다. 이를 경험적 과정(empirical process)라고 부른다. Definition 9.8 (경험적 과정) 경험적 과정은 무작위 함수로 다음과 같이 정의된다. \\[\\sqrt{n}\\{ F_{n}(x) - F(x) \\},\\qquad{-\\infty &lt; x \\infty.}\\] References "],
["9-5-poisson-process.html", "9.5 포아송과정(Poisson process)", " 9.5 포아송과정(Poisson process) 우리의 휴대전화로 오는 문제메시지는 하루종일 불규칙한 간격으로 온다. 고속도로에서의 사고들은 시간과 공간에 독립적으로 일어난다. 이러한 현상들은 연속 구간(보통 시간)에서의 발생 또는 도착 사건들을 모델링하는 데 사용되는 확률과정인 포아송과정(Poisson process)으로 잘 모델링할 수 있다. 9.5.1 셈과정(counting process) 포아송 과정은 셈과정(counting process)의 특별한 타입이다. 어떤 사건들의 흐름이 \\(t=0\\)에서 시작하는 시간대에서 무작위로 도착한다고 가정해보자. 이 때 \\(t\\)시간까지 도착한 사건의 숫자를 \\(N_{t}\\)라고 하자. 모든 \\(t\\geq 0\\)에서 \\(N_{t}\\)는 확률변수다. 이런 확률변수들의 모임(collection) \\((N_{t})_{t\\geq 0}\\)은 연속이며 정수값을 갖는 확률과정이고 이를 셈과정이라고 부른다. \\(N_{t}\\)는 \\([0,t]\\) 사이의 사건을 세기 때문에 \\(t\\)가 증가함에 따라 \\(N_{t}\\) 또한 증가한다. Definition 9.9 (셈과정) 셈과정 \\((N_{t})_{t\\geq 0}\\)은 음이 아니고 정수값을 갖는 확률변수들의 모임으로 \\(0\\leq s \\leq t\\)일 때 \\(N_{s} \\leq N_{t}\\)이다. 확률변수들의 수열인 마르코프 체인과 다르게 셈과정은 연속인 시간 간격에서 indexed 되어 있으므로 셀 수 없는 모임이다. 9.5.2 포아송과정의 정의(definition of Poisson process) **포아송과정(Poisson process)을 정의하는 방법은 몇 가지가 있다. 고정된 간격에서의 사건 숫자의 초점을 맞추는 방법 이떤 사건이 일어났을 때 사건들 사이의 시간에 초점을 맞추는 방법 무한소(infinitesimal, 모든 양수보다는 작지만 0보다 큰 상태) 간격에서의 개별 사건들의 확률적 행동에 초점을 맞추는 방법 이에 따라 포아송과정의 정의도 세 가지가 있다. Definition 9.10 (포아송과정 (정의1)) 모수 \\(\\lambda\\)를 갖는 포아송 과정\\((N_{t})_{t\\geq 0}\\)은 다음 조건들을 만족하는 셈과정이다. \\(N_{0}=0\\). 모든 \\(t&gt;0\\)에 대해 \\(N_{t}\\)는 모수 \\(\\lambda t\\)를 갖는 포아송 분포를 따른다. (정상 증분) 모든 \\(s,t&gt;0\\)에 대해 \\(N_{t+s}-N_{s}\\)는 \\(N_{t}\\)와 같은 분포를 갖는다. 즉 다음을 만족한다. \\[P(N_{t+s}-N_{s} = k) = P(N_{t} = k) = \\frac{e^{-\\lambda t}(\\lambda t)^{k}}{k!},\\qquad{k=0,1,\\ldots}\\] (독립 증분) \\(0\\leq q &lt; r \\leq s &lt; t\\)인 \\(q,r,s,t\\)에 대해 \\(N_{t}-N_{s}\\)와 \\(N_{r}-N_{q}\\)는 독립인 확률변수들이다. 정상 증분(stationary increment) 성질은 어떤 구간에서의 도착 숫자의 분포는 오직 구간의 길이에만 관련이 있다는 것이다. 독립 증분(independent increment)성질은 disjoint intervals에서의 도착들의 숫자는 독립 확률 변수들이 된다는 것이다. 9.5.3 포아송 무작위 측도들(Poisson random measures) 다음 사이트의 9장을 참고하였다. (Mikhail 2014) 또한 참고할만하다. \\((E,\\mathcal{E})\\)를 가측공간이라고 하고, \\(\\nu\\)를 \\(\\mathcal{E}\\)에서의 \\(\\sigma\\)-finite 측도라고 하자. \\(\\mathcal{N}(E)\\)는 \\(E\\)에서의 counting measure의 collection이라고 하자, 즉 음이 아닌 정수값들의 측도이다. \\(\\xi\\)는 만약 각각의 \\(\\omega \\in \\Omega\\)에서 \\(\\xi(\\omega, \\cdot)\\in\\mathcal{N}(E)\\)이고 각각의 \\(A\\in\\mathcal{E}\\)에서 \\(\\xi(A)\\)가 \\(\\mathbb{N}\\cup\\{\\infty\\}\\)의 값을 갖는 확률변수일 때 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)에서의 \\(\\mathcal{N}(E)\\)-확률변수다. 편의를 위해 \\(\\xi(\\omega, A)\\)대신 \\(\\xi(A)\\)라고 쓰자. Definition 9.11 (포아송 무작위 측도) 어떤 \\(\\mathcal{N}(E)\\)-확률변수가 각각의 \\(A\\in\\mathcal{E}\\)에 대해 \\(\\xi(A)\\sim \\text{Poisson}(\\nu(A))\\)이다. 만약 \\(A_{1},A_{},\\ldots \\in \\mathcal{E}\\)가 disjoint이면 $(A_{1}), (A_{2}),$는 독립인 확률변수이다. 를 만족하면 평균측도(mean measure) \\(\\nu\\)를 갖는 포아송 무작위 측도(Poisson random measure)이다. \\(\\nu\\)는 \\(\\xi\\)가 존재할 경우 \\(\\xi\\)의 분포를 결정한다. 먼저 \\(\\nu\\)가 유한하게 존재한다면 \\(\\nu\\)가 \\(\\sigma\\)-finite한 것으로 고려한다. Proposition 9.2 \\(\\nu\\)가 \\((E,\\mathcal{E})\\)에서의 측도이고 \\(\\nu(E)&lt;\\infty\\)라고 하자. 그러면 평균측도 \\(\\nu\\)를 갖는 포아송 무작위 측도가 존재한다. 평균측도를 다른 말로 intensity measure라고 부르기도 한다. 9.5.4 공간 포아송 과정(spatial Poisson process) (Dobrow 2016)의 6.6절을 참고하였다. 공간 포아송 과정(spatial Poisson process)란 사건 또는 점의 분포에 관한 모형으로, 2차원 이상 공간에서 다뤄지는 것이 특징이다. 이러한 과정의 예로 숲에서의 나무들의 장소에 대한 모형이나, 밤하늘 은하의 위치에 대한 모형 그리고 미국의 암 군집에 대한 모형 등을 들 수 있다. \\(d\\geq 1\\)이고 \\(A\\subset \\mathbb{R}^{d}\\)라고 할 때 \\(N_{A}\\)를 집합 \\(A\\)에 속하는 점들의 갯수로 정의하자. 그리고 \\(|A|\\)를 \\(A\\)의 size (즉 \\(\\mathbb{R}^{2}\\)일 때에는 넓이, \\(\\mathbb{R}^{3}\\)일 때에는 부피가 된다.)로 정의하자. Definition 9.12 (공간 포아송 과정) 확률변수들 \\((N_{A})_{A\\subseteq \\mathbb{R}^{d}}\\)가 다음의 두 조건 각각의 유계집합 \\(A\\subseteq \\mathbb{R}^{d}\\)에 대해 \\(N_{A}\\)가 모수 \\(\\lambda |A|\\)인 포아송 분포를 갖는다. \\(A\\)와 \\(B\\)가 disjoint set일 때 \\(N_{A}\\), \\(N_{B}\\)는 독립인 확률변수들이 된다. 을 만족하는 모수 \\(\\lambda\\)를 갖는 공간 포아송 과정이라고 부른다. Example 9.1 (공간 포아송 과정에서의 확률계산) 모수 \\(\\lambda=0.5\\)인 공간 포아송 과정이 있다고 하자. \\((3,4)\\)를 중심으로 하고 반지름이 2인 디스크가 정확하게 5개의 점을 포함할 확률은 \\(|C|=\\pi r^{2}=4\\pi\\)를 이용하면 \\[P(N_{C}=5)=\\frac{e^{-\\lambda |C|}(\\lambda |C|)^{5}}{5!}=\\frac{e^{-2\\pi}(2\\pi)^{5}}{5!}=0.152.\\] 가 된다. 공간 과정에서 발생하는 균등분포는 1차원 포아송 과정에서 하는 일과 유사하다. 유계집합 \\(A\\subseteq \\mathbb{R}^{d}\\)이 주어졌을 때 \\(A\\)에 \\(n\\)개의 점이 있다고 조건을 달면 이 점들의 위치는 \\(A\\)에서 균등하게 분포되어 있어야 한다. 이러한 이유로 공간 포아송 과정을 때때로 complete spatial randomness (CSR) 모형이라고 부르기도 한다. 공간 포아송 과정은 공간상에서의 점의 분포를 모델링하는 일반적인 방법인 점과정(point process)의 특별한 경우이다. 때로는 주어진 포인트 패턴이 CSR과 얼마나 가까운지 측정하고 싶을 때도 있다. 그럴 때 사용할 수 있는 흔한 측도로 과정의 어떤 점과 그 점에서 가장 가까운 이웃과의 거리를 계산한 최근접 거리(nearest neighbor distance)가 있다. 모수가 \\(\\lambda\\)인 \\(\\mathbb{R}^{2}\\)에서의 공간 포아송 과정을 생각해보자. \\(x\\)를 plane에서의 고정된 점으로 둔다. \\(D\\)는 \\(x\\)의 최근접 거리라고 하자. 그러면 사건 \\(\\{ D &gt; t\\}\\)는 \\(x\\)를 중심으로 하고 반지름이 \\(t\\)인 원 안에 다른 점이 하나도 없는 사건과 동치이다. 따라서 확률을 \\[P(D&gt;t)=P(N_{C_{x}}=0)=e^{-\\lambda |C_{x}|} = e^{-\\lambda \\pi t^{2}}, \\qquad{\\text{for } t &gt; 0}\\] 과 같이 계산할 수 있다. 이것을 미분하면 최근접 거리에 대한 밀도함수를 얻을 수 있다. \\[f_{D}(t)=e^{-\\lambda \\pi t^{2}}2\\lambda \\pi t, \\qquad{\\text{for } t &gt; 0.}\\] 그리고 이것의 평균과 분산은 다음과 같다. \\[E(D) = \\frac{1}{2\\sqrt{\\lambda}}, \\text{Var}(D)=\\frac{4-\\pi}{4\\pi\\lambda}.\\] 9.5.5 공간 포아송 과정 생성 예제(example of simulating a spatial Poisson process) 다음 R 예제는 \\(\\lambda=100\\)인 포아송 과정을 영역 \\([0,1]\\times [0,1]\\) 내에서 \\((0.7,0.7)\\)을 중심으로 하고 반지름이 \\(r=0.2\\)인 원 안에 들어가 있는 점의 갯수를 100,000번 반복 생성하여 계산해보고 기댓값과 비교해 보는 예제이다. 실제 기댓값은 \\(\\lambda |C|=100\\pi (0.2)^{2}=12.567\\)이다. library(plotrix) # spatialPoisson.R lambda &lt;- 100 squarearea &lt;- 1 trials &lt;- 100000 simlist &lt;- numeric(trials) par(mfrow=c(2,2)) par(mar=c(5.1,4.1,4.1,2.1)/4) for (i in 1:trials) { N &lt;- rpois(1,lambda*squarearea) xpoints &lt;- runif(N,0,1) ypoints &lt;- runif(N,0,1) ct &lt;- sum(((xpoints-0.7)^2+(ypoints-0.7)^2)&lt;=0.2^2) simlist[i] &lt;- ct if(i &lt;=4){ plot(xpoints,ypoints, xlim=c(0,1), ylim=c(0,1), xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;&quot;,xaxt=&quot;n&quot;,yaxt=&quot;n&quot;) draw.circle(x=0.7,y=0.7,radius=0.2,nv=100,border=&quot;black&quot;,col=NA,lty=1,density=NULL, angle=45,lwd=1) } } # number of points in circle FIGURE 9.2: Samples of a spatial Poisson process. mean(simlist) &gt; [1] 12.55411 var(simlist) &gt; [1] 12.63448 # Compare with theoretical mean and variance lambda*pi*(0.2)^2 &gt; [1] 12.56637 9.5.6 비동질적 포아송 과정(nonhomogeneous Poisson process) 포아송 과정에서, 도착은 시간과 독립이다. 그러나 많은 응용에서 이는 비현실적인 가정이다. 대학 식당의 점심시간을 생각해보자. 문을 오전 11시에 연다고 했을 때 학생들의 도착을 정오까지 점점 증가하다가 상수를 이루다 문을 닫는 시간인 낮 3시까지 감소하게 될 것이다. 이러한 행동들은 율(rate)가 \\(\\lambda=\\lambda(t)\\)인 비동질적 포아송 과정(nonhomogeneous Poisson process)으로 모델링할 수 있다. 이러한 율 함수를 강도함수(intensity function)라고 부른다. Definition 9.13 (비동질적 포아송 과정) 셈과정(counting process) \\((N_{t})_{t\\geq 0}\\)은 다음 조건들을 만족할 때 \\(N_{0}=0\\). 모든 \\(t&gt;0\\)에 대해 \\(N_{t}\\)는 평균이 \\(E(N_{t})=\\int_{0}^{t}\\lambda(x)dx\\)인 포아송 분포를 갖는다. \\(0\\leq q &lt; r \\leq s &lt; t\\)인 \\(q,r,s,t\\)에 대해 \\(N_{r}-N_{q}\\) \\(N_{t}-N_{s}\\)가 독립인 확률변수다. 강도함수가 \\(\\lambda(t)\\)인 비동질적 포아송과정이다. 비동질적 포아송 과정인 독립 증분을 갖으나 정상 증분(stationary increment)을 가질 필요는 없다. 이는 \\(0&lt;s&lt;t\\)일때 \\(N_{t}-N_{s}\\)는 모수 \\(\\int_{s}^{t}\\lambda(x)dx\\)를 갖는 포아송 분포를 갖음으로부터 알 수 있다. 9.5.7 공간 포아송 과정 이론(theory of spatial Poisson process) 이 절은 Rasmussen의 2011년 강의노트를 따른다. References "],
["9-6-brownian-motion.html", "9.6 브라운운동(Brownian motion)", " 9.6 브라운운동(Brownian motion) 함수자료분석에서 다루는 가우스 무작위 함수(Gauss random function)들 중 가장 자주 일어나는 형태는 브라운운동(Brownian motion): 다른 말로 위너과정(Wiener process)이라고도 부른다. (Kokoszka and Reimherr 2017)의 11.4절 브라운 다리(Brownian bridge) 이다. Definition 9.14 (저차원에서의 브라운운동) 실수값을 갖는 확률과정 \\(\\{ B(t) : t\\geq 0\\}\\)이 다음 조건들을 만족할 때 \\(B(0)=x\\) 그 과정이 독립 증분(independent increment)을 갖는다. 즉 모든 시간 \\(0 \\leq t_{1} \\leq t_{2} \\leq \\cdots \\leq t_{n}\\)에 대해 증분 \\(B(t_{n})-B_(t_{n-1}),\\ldots, B(t_{2})-B_(t_{1})\\)이 독립 확률변수다. 모든 \\(t \\geq 0\\)과 \\(h &gt; 0\\)에 대해 증분 이 정규분포를 따른다. \\[B(t+h)-B(t) \\sim \\mathcal{N}(0,h).\\] 함수 \\(t \\rightarrow B(t)\\)가 연속이다. \\(x\\in\\mathbb{R}\\)에서 시작하는 (선형) 브라운운동(Brownian motion)이라고 한다. 특별히 \\(x=0\\)일 때 \\(\\{ B(t): t\\geq 0\\}\\)을 정규 브라운운동(standard Brownian motion)이라고 부른다. 브라운운동의 정의는 나중에 공간과정에도 잠시 나올 것이다. # bm.R n &lt;- 1000 t &lt;- 1 bm &lt;- c(0, cumsum(rnorm(n,0,sqrt(t/n)))) steps &lt;- seq(0,t,length=n+1) plot(steps,bm,type=&quot;l&quot;) FIGURE 9.3: Simulating Brownian Motion. 9.6.1 분수 브라운운동(fractional Brownian motion) 분수 브라운운동(fractional Brownian motion)이란 fractional derivative (또는 fractional integral) of Brownian motion을 일컫는 말이다. References "],
["9-7-martingale.html", "9.7 마팅게일(martingale)", " 9.7 마팅게일(martingale) 마팅게일(martingale)은 평균 0을 갖는 독립인 확률변수들의 합의 일반화이다. 마팅게일은 확률과 통계에서 중요한 역할을 하며, 과거의 모든 정보를 알고 있다면 미래의 기댓값이 현재 값과 동일한 과정이다. 마팅게일이라는 말은 원래 도박에서 유래하였다고 한다. 마팅게일을 정의할 때는 조건부 기댓값이 중요한 역할을 한다. Definition 9.15 (마팅게일) 확률과정 \\(\\{X_{n}\\}\\)가 \\(E |X_{n}| &lt; \\infty\\) \\(X_{n}\\) is adpated to \\(\\mathcal{F}_{n}\\). (즉 모든 \\(n\\)에 대해 \\(X_{n}\\in\\mathcal{F}_{n}\\)) \\(E(X_{n+1}|\\mathcal{F}_{n})=X_{n}, \\text{ for all } n\\) 을 만족할 때, 이 확률과정을 filtration \\(\\mathcal{F}_{n}\\)에 대한 마팅게일(martingale)이라 부른다. "],
["10-bigOsmallo.html", "Chapter 10 Big O 와 small o", " Chapter 10 Big O 와 small o Large-sample technique의 장점 중 하나는 중요한 부분과 minor한 부분으로 나눌 수 있게 한다는 점이다. 다음은 order에 관한 (Jiang 2010)의 예제이다. Example 10.1 (Order 고려의 중요성 (1)) \\(X_{1},\\ldots , X_{n}\\)이 i.i.d.로 얻어진 표본들이며 \\(\\mu=E(X_{1})\\neq 0\\)이라고 하자. 그러면 우리는 \\(\\sum_{i=1}^{n}X_{i}\\)로 기댓값들의 합 \\(E(\\sum_{i=1}^{n}X_{i})=n\\mu\\)를 대체할 수 있다. 이것은 \\(\\sum_{i=1}^{n}X_{i}-n\\mu\\)가 order \\(O(\\sqrt{n})\\)으로, \\(\\sum_{i=1}^{n}X_{i}\\)의 order보다 낮기 때문이다. 그러나 이러한 technique은 우리가 \\((\\sum_{i=1}^{n}X_{i})^{2}\\)를 고려할 때에는 완벽하게 실패한다. 예를 들면 \\(X_{i}\\sim \\mathcal{N}(0,1)\\)이라고 하자. 그러면 \\(E(\\sum_{i=1}^{n}X_{i})^{2}=n\\)이다. 그러나, \\(\\sum_{i=1}^{n}X_{i}\\sim\\mathcal{N}(0,n)\\)이고 \\((\\sum_{i=1}^{n}X_{i})^{2}=n\\{\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}X_{i} \\}^{2} \\sim n\\chi_{1}^{2}\\)이므로, \\((\\sum_{i=1}^{n}X_{i})^{2}-E(\\sum_{i=1}^{n}X_{i})^{2}=n(\\chi_{1}^{2}-1)\\)이고 이는 \\(E(\\sum_{i=1}^{n}X_{i})^{2}\\)와 같은 order이다. 따라서 \\((\\sum_{i=1}^{n}X_{i})^{2}\\)은 \\(E(\\sum_{i=1}^{n}X_{i})^{2}\\)의 좋은 근사가 아니다. Example 10.2 (Order 고려의 중요성 (2)) 앞선 예제를 다시 생각해보자. \\(X_{1},\\ldots , X_{n}\\)이 i.i.d.로 얻어진 표본들이며 \\(\\mu=E(X_{1})\\neq 0\\)이라고 하자. 이때 우리가 \\(\\sum_{i=1}^{n}X_{i}\\)로 기댓값들의 합 \\(E(\\sum_{i=1}^{n}X_{i})=n\\mu\\)를 대체할 수 있는 이유는 쉽게 생각하면, WLLN으로 인해 \\(\\bar{X}=\\frac{\\sum_{i=1}^{n}X_{i}}{n}\\)이 \\(\\mu\\)의 consistent estimator이기 때문이다. 따라서 \\(E(\\sum_{i=1}^{n}X_{i})=n\\mu\\)를 \\(n\\bar{X}=\\sum_{i=1}^{n}X_{i}\\)로 추정하는 것은 일리가 있다. 이 방법을 다른 관점에서 바라보자. 만약 \\(X_{i}\\)들이 not i.i.d.일 경우, 어떻게 일반화 할 것이다. 우리는 앞 기대값을 다음과 같이 쓸 수 있다. \\[ \\begin{eqnarray} E(\\sum_{i=1}^{n}X_{i})&amp;=&amp;\\sum_{i=1}^{n}X_{i}-\\{ \\sum_{i=1}^{n}X_{i}-E(\\sum_{i=1}^{n}X_{i})\\}\\\\ &amp;=&amp;I_{1}-I_{2}. \\end{eqnarray} \\] 이제 \\(I_{1}\\)과 \\(I_{2}\\)의 order를 비교해보자. \\(X_{i}\\)들이 유한한 분산 \\(\\sigma, 0&lt;\\sigma^{2}&lt;\\infty\\)을 갖는다고 하자. 그러면 \\(I_{1}\\)의 order는 \\(O_{n}\\)이고 \\(I_{2}\\)의 order는 \\(O(\\sqrt{n})\\)이다. 좀 더 자세히 보자면 WLLN으로 인해 \\(\\frac{\\sum_{i=1}^{n}X_{i}}{n}\\stackrel{p}{\\rightarrow}\\mu\\neq 0\\)이고, 이는 \\(I_{1}=O(n)\\)임을 의미한다. 한편, \\(E(I_{2}^{2})=n\\sigma^{2}\\)임을 보일 수 있고 이는 \\(E(\\frac{I_{2}}{\\sqrt{n}})^{2}=\\sigma^{2}\\)임을 의미한다. 이것은 \\(\\frac{I_{2}}{\\sqrt{n}}\\)이 \\(L^{2}\\)에서 유계(bounded)임을 의미한다. 따라서, \\(\\frac{I_{2}}{\\sqrt{n}}=O(1)\\)이고 이는 \\(I_{2}=O(\\sqrt{n})\\)으로 쓸 수 있다. (여기서 \\(I_{1}, I_{2}\\)는 모두 확률변수이다.) Order로 미루어 볼 때 \\(E(\\sum_{i=1}^{n}X_{i})\\)를 \\(I_{1}\\)으로 근사하는 것이 main part를 잡아준다는 점에서 reaseonable하다는 것을 알 수 있다. 한편, 두 번째 케이스로 넘어가서, \\(E(\\sum_{i=1}^{2}X_{i})^{2}\\)을 추정하는 문제를 생각해보자. 간단히 하기 위해 \\(\\mu=0\\)이라고 가정한다. 그러면 \\[ \\begin{eqnarray} E(\\sum_{i=1}^{n}X_{i})^{2}&amp;=&amp;(\\sum_{i=1}^{n}X_{i})^{2}-\\{ (\\sum_{i=1}^{n}X_{i})^{2}-E(\\sum_{i=1}^{n}X_{i})^{2}\\}\\\\ &amp;=&amp;I_{1}-I_{2}. \\end{eqnarray} \\] 으로 쓸 수 있다. 우리는 여기서 또 \\(I_{1}\\)과 \\(I_{2}\\)의 order를 비교해볼 수 있다. CLT에 의해 \\(\\frac{\\sum_{i=1}^{n}X_{i}}{\\sqrt{n}\\sigma}\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,1)\\)임을 안다. 그러면 연속사상정리(정리 7.2)에 의해 \\(n\\rightarrow\\infty\\)일 때 \\[ \\begin{equation} \\frac{(\\sum_{i=1}^{n}X_{i})^{2}}{n\\sigma^{2}}\\stackrel{d}{\\rightarrow}\\chi_{1}^{2}, \\tag{10.1} \\end{equation} \\] \\[ \\begin{equation} \\frac{(\\sum_{i=1}^{n}X_{i})^{2}}{n\\sigma^{2}}-1 \\stackrel{d}{\\rightarrow}\\chi_{1}^{2}-1 \\tag{10.2} \\end{equation} \\] 이다. 식 (10.1)은 \\(I_{1}=O(n)\\)임을 의미한다. 더 나아가 \\[\\frac{(\\sum_{i=1}^{n}X_{i})^{2}-E(\\sum_{i=1}^{n}X_{i})^{2}}{n\\sigma^{2}}=\\frac{(\\sum_{i=1}^{n}X_{i})^{2}}{n\\sigma^{2}}-1,\\] 이므로 식 (10.2)은 \\(I_{2}=O(n)\\)임을 의미한다. 그러므로 이 경우에는 \\(I_{1}\\)과 \\(I_{2}\\)가 같은 order를 갖으므로 \\((\\sum_{i=1}^{n}X_{i})^{2}\\)은 \\(E(\\sum_{i=1}^{n}X_{i})^{2}\\)의 좋은 근사가 아니다라는 결론을 얻을 수 있다. References "],
["10-1-big-o-small-o-big-o-and-small-o.html", "10.1 Big O와 small o (big O and small o)", " 10.1 Big O와 small o (big O and small o) (Jiang 2010) 책 3장에 나오는 big O와 small o의 정의다. Definition 10.1 (big O) (실수값을 갖는) 무한 수열 \\(a_{n},n=1,2,\\ldots\\)가 유계일 경우 \\(a_{n}=O(1)\\)이라고 한다. 즉 어떤 상수 \\(c\\)가 존재해 \\(|a_{n}|\\leq c, n\\geq 1\\)이면 \\(a_{n}=O(1)\\)이다. \\(b_{n},n=1,2,\\ldots\\)를 양의 값을 갖는 무한 수열이라고 하자. 그러면 수열 \\(a_{n}/b_{n}, n=1,2,\\ldots\\)가 유계일 때 \\(a_{n}=O(b_{n})\\)이라고 한다. Lemma 10.1 \\(a_{n}=O(b_{n})\\)은 \\(a_{n}=b_{n}O(1)\\)임과 동치이다. Definition 10.2 (small o) 수열 \\(a_{n},n=1,2,\\ldots\\)가 \\(n\\rightarrow\\infty\\)일 때 \\(a_{n}\\rightarrow 0\\)인 경우 \\(a_{n}=o(1)\\)이라고 한다. 좀 더 일반적으로, \\(b_{n},n=1,2,\\ldots\\)를 양의 값을 갖는 무한 수열이라고 할 때 수열 \\(a_{n}/b_{n}, n=1,2,\\ldots\\)가 \\(n\\rightarrow \\infty\\)일 때 \\(a_{n}/b_{n}\\rightarrow 0\\)일 경우 \\(a_{n}=o(b_{n})\\)이라고 한다. Lemma 10.2 \\(a_{n}=o(b_{n})\\)은 \\(a_{n}=b_{n}o(1)\\)임과 동치이다. 여기서 우리는 small o가 big O보다 좀 더 강한 조건임을 알 수 있다. Lemma 10.3 \\(a_{n}=o(b_{n})\\)이면 \\(a_{n}=O(b_{n})\\)이다. Lemma 10.4 (big O와 small o의 성질들) 1. 만약 \\(a_{n}=O(b_{n})\\)이고 \\(b_{n}=O(c_{n})\\)이면 \\(a_{n}=O(c_{n})\\)이다. 만약 \\(a_{n}=O(b_{n})\\)이고 \\(b_{n}=o(c_{n})\\)이면 \\(a_{n}=o(c_{n})\\)이다. 만약 \\(a_{n}=o(b_{n})\\)이고 \\(b_{n}=O(c_{n})\\)이면 \\(a_{n}=o(c_{n})\\)이다. 만약 \\(a_{n}=o(b_{n})\\)이고 \\(b_{n}=o(c_{n})\\)이면 \\(a_{n}=o(c_{n})\\)이다. 만약 \\(a_{n}=O(b_{n})\\)이면 임의의 \\(p&gt;0\\)에 대해 \\(|a_{n}^{p}|=O(b_{n}^{p})\\)이다. 만약 \\(a_{n}=o(b_{n})\\)이면 임의의 \\(p&gt;0\\)에 대해 \\(|a_{n}^{p}|=o(b_{n}^{p})\\)이다. 그러나 어떤 증가함수 \\(g\\)에 대해 \\(a_{n}=O(b_{n})\\)은 \\(g(a_{n})=O\\{g(b_{n})\\}\\)임을 의미하지는 않는다. 마찬가지로, \\(a_{n}=o(b_{n})\\)은 \\(g(a_{n})=o\\{g(b_{n})\\}\\)임을 의미하지는 않는다. Example 10.3 (증가함수와 big O) \\(a_{n}=n\\), \\(b_{n}=2n\\)이라고 하자. 그러면 \\(a_{n}=O(b_{n})\\)이다. 그러나 \\(n\\rightarrow\\infty\\)일 때 \\(e^{a_{n}}/e^{b_{n}}=e^{n}/e^{2n}=e^{-n}\\rightarrow 0\\)이다. 따라서 \\(e^{a_{n}}=o(e^{b_{n}})\\)이며 \\(O(e^{b_{n}})\\)이 아니다. Example 10.4 (증가함수와 small o) \\(a_{n}=n\\), \\(b_{n}=n^{2}\\)을 생각해보자. 그러면 \\(a_{n}=o(b_{n})\\)이다. 그러나 \\(\\log(a_{n})=\\log(b_{n})\\)이고 \\(\\log(b_{n})=2\\log(n)\\)이며 \\(\\log(a_{n})=O\\{\\log(b_{n})\\}\\)이며 \\(o\\{\\log(b_{n})\\}\\)이 아니다. 다음은 역수와 관련된 따름정리다. Lemma 10.5 (역수와 small o) 만약 \\(a_{n}\\), \\(b_{n}\\)이 0이 아닌 수열들이고 \\(a_{n}=o(b_{n})\\)이라고 하자. 그러면 \\(b_{n}^{-1}=o(a_{n}^{-1})\\)이다. Big O와 small o의 성질들을 좀 더 정리해 보겠다. 이것은 2009년 가을 Asymptotic Analysis 강의노트 2장에서 가져온 것이다. Constant in O-terms: 만약 \\(C\\)가 양의 상수라면, \\(f(x)=O(Cg(x))\\)는 \\(f(x)=O(g(x))\\)와 같다. 특별히 \\(f(x)=O(C)\\)는 \\(f(x)=O(1)\\)과 같다. Transitivity: O-estimate는 transitive한데 이 말인 즉슨 \\(f(x)=O(g(x))\\)이고 \\(g(x)=O(h(x))\\)이면 \\(f(x)=O(h(x))\\)이다. Multiplication of O-terms: 만약 \\(i=1,2\\)일 때 \\(f_{i}(x)=O(g_{i}(x))\\)이면 \\(f_{1}(x)f_{2}(x)=O(g_{1}(x)g_{2}(x))\\)이다. Pulling out factors: 만약 \\(f(x)=O(g(x)h(x))\\)이면, \\(f(x)=g(x)O(h(x))\\)이다. 이 성질은 다음과 같은 표현을 가능케한다. \\(f(x)=x+O(x/\\log x)\\)일 경우 이를 \\(f(x)=x(1+O(1/\\log x))\\)로 쓸 수 있는 것이다. Summation of O-terms: \\(i=1,2,\\ldots\\)일 때 \\(f_{i}(x)=O(g_{i}(x))\\)이고 \\(O\\) 상수가 \\(i\\)에 독립일 경우 \\[\\sum_{i=1}^{n}f_{i}(x)=O(\\sum_{i=1}^{n}|g_{i}(x)|)\\] 이다. 다시 말하면, \\(O\\)들은 sigma 바깥으로 나올 수 있고 이 때 \\(g\\)는 절대값을 씌우는 것으로 바뀐다. 이는 infinite series \\(\\sum_{i=1}^{\\infty}f_{i}(x)\\)에서도 성립한다. Integration of O-terms: \\(f(x)\\)와 \\(g(x)\\)가 유한한 구간에서 적분 가능하고 \\(x\\geq x_{0}\\)일 때 \\(f(x)=O(g(x))\\)를 만족한다면 \\[\\int_{x_{0}}^{x}f(y)dy=O(\\int_{x_{0}}^{x}|g(y)|dy)\\qquad{(x\\geq x_{0})}\\] 을 만족한다. o-estimate와 관련하여: o-estimate에서는 위에 언급된 것들 중 몇 개만 성립한다. 처음 네 개는 o-estimate에서도 성립한다. 그러나, 마지막 두 개에 대해서는 성립하지 않는다. 예를 들면, 만약 \\(f(x)=e^{-x}\\)이고 \\(g(x)=1/x^{2}\\)이면 \\(x\\rightarrow\\infty\\)일 때 \\(f(x)=o(g(x))\\)가 된다. 한면, 적분 \\(F(x)=\\int_{1}^{x}f(x)dy\\)와 \\(G(x)=\\int_{1}^{x}g(y)\\)는 각각 \\(e^{-1}-e^{-x}\\), \\(1-1/x\\)이고 \\(\\lim_{x\\rightarrow\\infty}F(x)/G(x)=e^{-1}\\)을 만족한다. 따라서 \\(F(x)=o(G(x))\\)가 성립하지 않게 된다. 이러한 점들은 o-estimate를 다루기 어렵게 만들기 되고 따라서 가능하면 o-estimate 대신 O-estimate에 대해 work하는 것을 선호하게 된다. References "],
["10-2-big-o-small-o-big-o-and-small-o-for-real-valued-functions.html", "10.2 실함수에서의 Big O와 small o (big O and small o for real valued functions)", " 10.2 실함수에서의 Big O와 small o (big O and small o for real valued functions) Big O와 small o 컨셉을 실함수에도 확장할 수 있다. 우선, \\(x\\rightarrow 0\\)인 경우를 고려해 보자. \\(x\\rightarrow 0\\)일 때 \\(f(x)/x\\)가 유계이면 \\(f(x)=O(x)\\)라고 한다. 유사하게, \\(x\\rightarrow 0\\)일 때 \\(f(x)/x\\rightarrow 0\\)일 경우 \\(f(x)=o(x)\\)라고 한다. 좀 더 일반적으로 임의의 \\(x_{0}\\)와 \\(p\\geq 0\\)에 대해 \\(f(x)/|x-x_{0}|^{p}\\)가 유계일 경우 \\(f(x)=O(|x-x_{0}|^{p})\\)라고 한다. 마찬가지로 \\(|x|\\rightarrow \\infty\\)임에 따라 \\(f(x)/|x-x_{0}|^{p}\\rightarrow 0\\)인 경우 \\(f(x)=o(|x-x_{0}|^{p})\\)라고 한다. "],
["10-3-big-o-small-o-big-o-and-small-o-for-vectors-and-matrices.html", "10.3 벡터와 행렬에서의 Big O와 small o (big O and small o for vectors and matrices)", " 10.3 벡터와 행렬에서의 Big O와 small o (big O and small o for vectors and matrices) \\(|v|\\)를 벡터의 유클리드 노름으로, 즉 \\(|v|=\\sqrt{\\sum_{j=1}^{k}v_{j}^{2}}\\)이라고 하자. 또한 행렬의 노름도 생각해보자. 여기서는 스펙트럴 노름(spectral norm) \\(\\|A\\|=\\{ \\lambda_{\\text{max}}(A^{T}A)\\}^{1/2}\\)와 2-노름(2-norm) \\(\\|A\\|_{2}=\\{ \\text{tr}(A^{T}A) \\}^{1/2}\\)를 생각한다. Definition 10.3 (벡터에서의 big O와 small o) \\(a_{n},n=1,2,\\ldots\\)를 양수들의 수열이라고 하자. \\(v_{n},n=1,2,\\ldots\\)를 벡터들의 수열이라고 하자. 그러면 \\(|v_{n}|/a_{n}\\)이 유계인 경우 \\(v_{n}=O(a_{n})\\)이라고 한다. 그리고 \\(n\\rightarrow \\infty\\)일 때 \\(|v_{n}|/a_{n}\\rightarrow 0\\)인 경우 \\(v_{n}=o(a_{n})\\)이라고 한다. Definition 10.4 (행렬에서의 big O와 small o) \\(a_{n},n=1,2,\\ldots\\)를 양수들의 수열이라고 하자. \\(A_{n},n=1,2,\\ldots\\)를 행렬들의 수열이라고 하자. 그러면 \\(\\|A_{n}\\|/a_{n}\\)이 유계인 경우 \\(A_{n}=O(a_{n})\\)이라고 한다. 그리고 \\(n\\rightarrow \\infty\\)일 때 \\(\\|A_{n}\\|/a_{n}\\rightarrow 0\\)인 경우 \\(A_{n}=o(a_{n})\\)이라고 한다. Definition 10.5 (벡터와 행렬에서의 부등호) \\(A\\)와 \\(B\\)를 \\(k \\times k\\) 행렬이라고 하자. 그러면 \\(A\\geq B\\)는 \\(A-B\\)가 nonnegative definite임을 의미한다. \\(A&gt;B\\)는 \\(A-B\\)가 positive definite이다. "],
["10-4-big-op-small-op-big-op-and-small-op.html", "10.4 Big Op와 small op (big Op and small op)", " 10.4 Big Op와 small op (big Op and small op) 확률변수들의 수열 \\(X_{n},n=1,2,\\ldots\\)이 \\(O_{P}(1)\\)인 것을 다른 말로 bounded in probability라고 부른다. Definition 10.6 (big Op) 확률변수들의 수열 \\(X_{n},n=1,2,\\ldots\\)이 어떤 \\(\\epsilon &gt;0\\)에 대해 \\(M&gt;0, N\\geq 1\\)이 존재해 \\[ \\begin{equation} P(|X_{n}|\\leq M)&gt; 1-\\epsilon,\\qquad{n\\geq N} \\end{equation} \\] 이면 \\(X_{n}=O_{P}(1)\\)이라고 한다. \\(a_{n}\\)을 양수들의 수열이라고 하자. 좀 더 일반적으로 \\(X_{n}/a_{n}=O_{P}(1)\\)이라고 할 때 \\(X_{n}=O_{P}(a_{n})\\)이다. Lemma 10.6 \\(X_{n}=O_{P}(1)\\)인 것은 모든 \\(\\epsilon &gt;0\\)에 대해 \\(M&gt;0\\)이 존재해 \\[ \\begin{equation} P(|X_{n}|\\leq M)&gt; 1-\\epsilon,\\qquad{n\\geq 1} \\end{equation} \\] 인 것과 동치이다. Definition 10.7 (small op) \\(a_{n}\\)을 양수들의 수열이라고 하자. 확률변수들의 수열 \\(X_{n},n=1,2,\\ldots\\)이 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}/a_{n}\\stackrel{P}{\\rightarrow}0\\)를 만족할 경우 \\(X_{n}=o_{P}(a_{n})\\)이라고 한다. 다음은 (Polansky 2011)의 8장의 예제들이다. Example 10.5 (이산확률변수의 small op (1)) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)를 독립 이산확률변수들의 수열이라고 하고 \\(X_{n}\\)은 모든 \\(n\\in\\mathbb{N}\\)에서 다음과 같은 확률밀도함수를 갖는다. \\[ f_{n}(x) := \\begin{cases} \\frac{1}{2} &amp; x\\in\\{0,n^{-1}\\} \\\\ 0 &amp; \\text{otherwise.}\\\\ \\end{cases} \\] 이 때 \\(n^{1/2}X_{n}\\)은 모든 \\(n\\in\\mathbb{N}\\)에서 다음과 같은 확률밀도함수를 갖는다. \\[ g_{n}(x) := \\begin{cases} \\frac{1}{2} &amp; x\\in\\{0,n^{-1/2}\\} \\\\ 0 &amp; \\text{otherwise.}\\\\ \\end{cases} \\] 그러면 모든 \\(\\epsilon &gt; 0\\)에 대해 \\[\\lim_{n\\rightarrow\\infty}P(n^{1/2}X_{n}&gt; \\epsilon)\\leq \\lim_{n\\rightarrow\\infty}n^{-1/2}=0\\] 이 되어 정의에 의해 \\(n^{1/2}X_{n} \\stackrel{P}{\\rightarrow}0\\)이다. 따라서 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=o_{p}(n^{-1/2})\\)이다. 이 때 \\(X_{n}\\)은 \\(o_{p}(n^{-1})\\)이 될 수 없는데 \\(nX_{n}\\)이 모든 \\(n\\)에서 베르누이(1/2) 분포를 따르게 되는데, 이 확률변수들은 \\(n\\)에 의존하지 않기 때문이다. Example 10.6 (이산확률변수의 small op (2)) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)를 독립 이산확률변수들의 수열이라고 하고 \\(X_{n}\\)은 모든 \\(n\\in\\mathbb{N}\\)에서 다음과 같은 확률밀도함수를 갖는다. \\[ f_{n}(x) := \\begin{cases} \\frac{1}{2} &amp; x\\in\\{0,n^{-1}\\} \\\\ 0 &amp; \\text{otherwise.}\\\\ \\end{cases} \\] 그리고 또 다른 독립 확률변수 \\(Y_{n}\\)을 다음과 같은 확률밀도함수를 갖도록 정의한다. \\[ g_{n}(x) := \\begin{cases} \\frac{1}{2} &amp; x\\in\\{n^{-1/2},1\\} \\\\ 0 &amp; \\text{otherwise.}\\\\ \\end{cases} \\] 이 때 모든 \\(n\\in\\mathbb{N}\\)에서 \\(X_{n}\\)은 \\(Y_{n}\\)와 독립이다. 다음과 같은 또 다른 확률변수들의 수열 \\(\\{Z_{n}\\}_{n=1}^{\\infty}, Z_{n}=X_{n}Y_{n}^{-1}\\)을 생각해보자. \\(X_{n}\\)과 \\(Y_{n}\\)은 독립이므로, \\(Z_{n}\\)의 분포는 모든 \\(n\\in\\mathbb{N}\\)에 대해 다음과 같다. \\[ h_{n}(x) := \\begin{cases} \\frac{1}{2} &amp; z=0 \\\\ \\frac{1}{4} &amp; z\\in \\{n^{-1/2}, n^{-1}\\} \\\\ 0 &amp; \\text{otherwise.}\\\\ \\end{cases} \\] 그러면 모든 \\(\\epsilon &gt; 0\\)에 대해 \\[\\lim_{n\\rightarrow\\infty}P(Z_{n}&gt; \\epsilon)\\leq \\lim_{n\\rightarrow\\infty}n^{-1/2}=0\\] 이 되어 정의에 의해 \\(Z_{n} \\stackrel{P}{\\rightarrow}0\\)이다. 따라서 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=o_{p}(Y_{n})\\)이다. Example 10.7 (대수의 약법칙과 small op) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)가 분포 \\(F\\), 평균 \\(\\mu\\)를 갖는 독립 확률변수들의 수열이라고 하자. 대수의 약법칙(weak law of large numbers)에 따라 표본평균은 \\(n\\rightarrow\\infty\\)일 때 \\(\\mu\\)에 확률수렴함을 안다. 따라서, Slutsky 정리에 의해 \\(n\\rightarrow\\infty\\)일 때 \\(\\bar{X}_{n}-\\mu \\stackrel{P}{\\rightarrow}0\\)이다. 따라서 정의에 의해 \\(\\bar{X}_{n}-\\mu=o_{p}(1)\\)이다. Theorem 10.1 (big Op 관련 정리) 확률변수들의 수열 \\(X_{n},n=1,2,\\ldots\\)이 있다고 할 때 다음 중 하나라도 성립하면 \\(X_{n}=O_{P}(1)\\)이다. \\(p&gt;0\\)이 존재해 \\(E(|X_{n}|^{p}),n\\geq 1\\)이 유계다. \\(n\\rightarrow \\infty\\)일 때 어떤 확률변수 \\(X\\)에 대해 \\(X_{n}\\stackrel{P}{\\rightarrow} X\\)이다. \\(n\\rightarrow \\infty\\)일 때 어떤 확률변수 \\(X\\)에 대해 \\(X_{n}\\stackrel{d}{\\rightarrow} X\\)이다. 다음은 (Polansky 2011)에 있는 big Op 관련 예제다. Example 10.8 (조건부 분포와 BigOp) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)와 \\(\\{ Y_{n} \\}_{n=1}^{\\infty}\\)가 확률변수의 수열이라고 하자. \\(Y_{n}\\)은 모든 \\(n\\in\\mathbb{N}\\)에서 \\(\\text{Poisson}(\\theta)\\) 확률변수를 따른다고 하자. \\(Y_{n}\\)을 conditioning했을 때 \\(X_{n}\\)의 조건부 분포는 \\(\\text{Uniform}\\{1,2,\\ldots, Y_{n}\\}\\) 분포를 따른다고 하자. 그러면 \\(X_{n}Y_{n}^{-1}\\)은 모든 \\(n\\in\\mathbb{N}\\)에 대해 \\(P(0\\leq X_{n}Y_{n}^{-1}\\leq 1)=1\\)이 된다. \\(\\varepsilon &gt;0\\)이라고 하고 \\(b_{\\varepsilon}=1\\)이라고 해보자. 그러면 모든 \\(n\\in\\mathbb{N}\\)에 대해 \\(P(|X_{n}Y_{n}^{-1}|\\leq b_{\\varepsilon})=1\\)이고 Helly and Bray의 정리에 의해 \\(|X_{n}Y_{n}^{-1}|\\)는 bounded in probability가 된다. 정의에 의해 \\(X_{n}Y_{n}^{-1}=O_{p}(1)\\)이며 \\(X_{n}=O_{p}(Y_{n})\\)이다. Example 10.9 (균등분포에서의 BigOp) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)가 독립 확률변수들의 수열이며 \\(X_{n}\\)은 모든 \\(n\\in\\mathbb{N}\\)에서 \\(\\text{Uniform}(-n^{-1},1+n^{-1})\\)분포를 따른다고 하자. \\(\\varepsilon&gt;0\\)이라고 하고 양의 실수 \\(b_{\\varepsilon}=2\\)가 있다고 하자. 그러면 모든 \\(n\\in\\mathbb{N}\\)에서 \\(P(|X_{n}|\\leq b_{\\varepsilon})=1\\)이다. 그러면 정의에 의해 \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)는 bounded in probability이며 \\(n\\rightarrow\\infty\\)일 때 \\(X_{n}=O_{p}(1)\\)이다. Example 10.10 (정규분포에서의 BigOp) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)가 독립 확률변수들의 수열이며 \\(X_{n}\\)은 모든 \\(n\\in\\mathbb{N}\\)에서 \\(\\mathcal{N}(0,n^{-1})\\)을 따른다고 하자. \\(\\varepsilon &gt;0\\)이고 \\(b\\)가 어떤 양의 실수라고 하자. 그러면 \\[\\lim_{n\\rightarrow\\infty}P(|X_{n}|&lt;b)=\\lim_{n\\rightarrow\\infty}P(|Z|\\leq n^{1/2}b)=1\\] 이 된다. 이 때 \\(Z\\)는 표준정규분포를 따르는 확률변수이다. 그러면 양의 실수 \\(b_{\\varepsilon}\\)과 양의 정수 \\(n_{\\varepsilon}\\)이 존재해 모든 \\(n&gt;n_{\\varepsilon}\\)인 모든 \\(n\\)에서 \\(P(|X_{n}|\\leq b_{\\varepsilon})&gt;1-\\varepsilon\\)이며 \\(n\\rightarrow\\infty\\)일 때 \\(X_{n}=O_{p}(1)\\)이다. Theorem 10.2 (분포수렴이면 BigOp가 됨) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)와 \\(\\{ Y_{n} \\}_{n=1}^{\\infty}\\)가 확률변수의 수열이고 \\(n\\rightarrow\\infty\\)일 때 \\(X\\)로 분포수렴한다고 하자. 그러면 \\(n\\rightarrow\\infty\\)일 때 \\(X_{n}=O_{p}(1)\\)이다. Proof. 모든 \\(n\\in\\mathbb{N}\\)에 대해 \\(F_{n}\\)을 \\(X_{n}\\)의 분포함수라고 하고 \\(X\\)의 분포함수를 \\(F\\)라고 하자. \\(n\\rightarrow\\infty\\)일 때 \\(X_{n}\\stackrel{d}{\\rightarrow}X\\)이므로 분포수렴의 정의에 의해 모든 \\(x\\in C(F)\\)에서 \\(\\lim_{n\\rightarrow\\infty}F_{n}(x)=F(x)\\)이다. \\(F\\)가 분포함수라는 가정에 의해 \\(\\lim_{n\\rightarrow\\infty}F(x)=1\\), \\(\\lim_{n\\rightarrow -\\infty}F(x)=0\\)이다. 그리므로 \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)는 bounded in probability이며 \\(n\\rightarrow\\infty\\)일 때 \\(X_{n}=O_{p}(1)\\)이다. 다음은 (Polansky 2011)에 있는 big Op와 small op 사이의 관계에 대한 정리이다. Theorem 10.3 (small op가 big Op보다 강한 조건) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)와 \\(\\{ Y_{n} \\}_{n=1}^{\\infty}\\)가 확률변수의 수열이라고 하자. 만약 \\(n\\rightarrow\\infty\\)일 때 \\(X_{n}=o_{p}(Y_{n})\\)이라면 \\(X_{n}=O_{p}(Y_{n})\\)또한 성립한다. Theorem 10.4 (big Op와 small op 사이의 관계들) \\(\\{X_{n}\\}_{n=1}^{\\infty}\\)과 \\(\\{Y_{n}\\}_{n=1}^{\\infty}\\)를 확률변수들의 수열이라고 하고 \\(\\{ y_{n}\\}_{n=1}^{\\infty}\\)를 실수들의 수열이라고 하자. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=O_{p}(n^{-a})\\)이고 \\(Y_{n}=O_{p}(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}Y_{n}=O_{p}(n^{-(a+b)})\\)이다. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=O_{p}(n^{-a})\\)이고 \\(y_{n}=o(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}y_{n}=o_{p}(n^{-(a+b)})\\)이다. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=O_{p}(n^{-a})\\)이고 \\(Y_{n}=o_{p}(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}Y_{n}=o_{p}(n^{-(a+b)})\\)이다. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=o_{p}(n^{-a})\\)이고 \\(y_{n}=o(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}y_{n}=o_{p}(n^{-(a+b)})\\)이다. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=O_{p}(n^{-a})\\)이고 \\(y_{n}=O(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}y_{n}=O_{p}(n^{-(a+b)})\\)이다. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=o_{p}(n^{-a})\\)이고 \\(y_{n}=O(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}y_{n}=o_{p}(n^{-(a+b)})\\)이다. 만약 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}=o_{p}(n^{-a})\\)이고 \\(Y_{n}=o_{p}(n^{-b})\\)이면 \\(n\\rightarrow \\infty\\)일 때 \\(X_{n}Y_{n}=o_{p}(n^{-(a+b)})\\)이다. References "],
["11-reg.html", "Chapter 11 회귀분석", " Chapter 11 회귀분석 AIC, AICc, BIC "],
["11-1-linear-model.html", "11.1 선형모형(linear model)", " 11.1 선형모형(linear model) 11.1.1 단순선형모형(simple linear model) 이 절의 내용은 (Yee 2015)를 따른다. (S. Wood 2017)도 참고한다. 다음과 같이 \\(n\\)개의 관찰값 \\(x_{i},y_{i}, i=1,\\ldots,n\\)이 있다고 하자. 이 때 \\(y_{i}\\)는 평균이 \\(\\mu_{i}=E(Y_{i})\\)인 확률변수 \\(Y_{i}\\)의 관찰값이라고 하자. 그러면 \\(x\\)와 \\(y\\) 사이에 가장 단순한 형태의 선형모형을 세울 수 있다. \\[Y_{i}=\\mu_{i}+\\epsilon_{i}, \\qquad{\\mu_{i}=x_{i}\\beta}.\\] 이 때 \\(\\beta\\)는 알려지지 않은 모수(parameter)이며 \\(\\epsilon_{i}\\)는 보통 상호 독립이면 평균이 0인 확률변수라고 가정한다. \\(Y\\)는 보통 설명변수(response variable)라고 부르며, \\(x\\)는 예측변수(predictor variable)라고 부른다. 11.1.2 단순 최소제곱 추정(simple least squares estimation) 그렇다면 우리는 자료 \\((x_{i},y_{i})\\)들로부터 \\(\\beta\\)를 어떻게 추정할 수 있을까? 가장 합리적인 방법으로 자료를 가장 잘 적합(fit)하는 \\(\\hat{\\beta}\\)로 \\(\\beta\\)를 추정할 수 있다. References "],
["12-penalshrink.html", "Chapter 12 벌점화 및 축소방법", " Chapter 12 벌점화 및 축소방법 때때로 설명변수들이 너무 많아져 특이 관찰값보다도 많아지는 경우가 존재한다. 이런 경우에는 전체 모형을 적합할 경우 prediction interval이 커지고 최소제곱 추정량이 유일하지 않을 수도 있는 등 문제점들이 생기게 된다. 이런 문제점들을 해결하는 방법들을 벌점화(penalization)라고 한다. 최소제곱 추정량은 \\((X^{T}X)^{-1}\\)에 depend하므로 만약 \\((X^{T}X)^{-1}\\)이 비정칙(singular)이거나 거의 비정칙일 때 \\(\\beta_{LS}\\)를 계산하는 데 어려움을 겪을 수 있다. 이런 경우에 \\(X\\)에 약간의 변화만 있어도 \\((X^{T}X)^{-1}\\)은 크게 달라지게 된다. 이 때 최소제곱 추정량 \\(\\hat{beta}_{LS}\\)는 training data에 적합할 때에는 큰 문제가 되지 않으나 test data에 적합할 때에는 문제가 생길 수도 있다. "],
["12-1-overfitting.html", "12.1 과적합(overfitting)", " 12.1 과적합(overfitting) 너무 복잡한 모형은 training data에서의 error를 줄여주지만, test error를 증가시킬 수 있다. FIGURE 12.1: 과적합의 예. "],
["12-2-bias-variance-tradeoff.html", "12.2 Bias-Variance tradeoff", " 12.2 Bias-Variance tradeoff "],
["12-3-ridge-regression.html", "12.3 능형회귀(ridge regression)", " 12.3 능형회귀(ridge regression) 앞서 말한 문제점의 한 가지 해결방법으로 추정량의 불편성을 약간 깨는 방법이 있다. (Hoerl and Kennard 1970)은 \\(X^{T}X\\)에 작은 상수값 \\(\\lambda\\)를 더해 역을 취해 추정량의 불안정성을 해결할 수 있다고 생각하고 다음과 같은 추정량을 제안하였다. \\[\\hat{\\beta}_{ridge}=(X^{T}X+\\lambda I_{p})^{-1}X^{T}Y.\\] 이를 능형회귀(ridge regression) 추정량이라고 부른다. 참고로 수학에서는 이 방법을 Tikhonov regularization이라고 부른다. \\(\\hat{\\beta}_{ridge}\\)는 다음 벌점화제곱합 \\[\\hat{\\beta}^{rodge}=\\text{arg}\\min_{\\beta}\\{\\sum_{i=1}^{n}(y_{i}-\\beta_{0}-\\sum_{j=1}^{p}x_{ij}\\beta_{j})^{2}+\\lambda\\sum_{j=1}^{p}\\beta_{j}^{2}\\}\\] 을 최소화하여 얻을 수 있다. 또 다른 표현으로는 \\[\\hat{\\beta}^{rodge}=\\text{arg}\\min_{\\beta}\\sum_{i=1}^{n}(y_{i}-\\beta_{0}-\\sum_{j=1}^{p}x_{ij}\\beta_{j})^{2}\\text{ for some } t, \\sum_{j=1}^{p}\\beta_{j}^{2}&lt;t^{2}\\] 로도 쓸 수 있다. 벌점화 항을 살펴보면, \\(\\lambda\\)는 미리 선택된 상수(constant)에 벡터 \\(\\beta\\)의 제곱합이 곱해진 형태이다. 이는 \\(\\beta_{j}\\)가 큰 값을 가지면 페널티를 주겠다는 뜻이다. \\(\\beta_{j}\\)가 0에 가까울수록 벌점화 항은 작을 것이다. 12.3.1 능형회귀의 기하학적 해석(geometrical interpretation of ridge regression) FIGURE 12.2: Geometric interpretation of ridge regression. \\(p=2\\)인 경우를 생각해보자. 등고선이 있는 붉은색 타원이 residual sum of squares (RSS)에 해당하며 가장 안쪽에 있는 원이 작은 RSS를 가지고 그 중심에 \\(\\hat{\\beta}_{OLS}\\)가 있다. \\(p=2\\)일 때 능형회귀의 제약조건은 원에 대응된다. 능형회귀의 해는 타원과 원이 만나는 지점이 될 것이다. 여기서 penalty term과 RSS 사이에는 trade-off가 있다고 한다. 12.3.2 능형회귀추정량의 성질들(properties of ridge estimator) 12.3.3 SVD를 이용한 능형회귀 해의 계산(computing the ridge solutions via the SVD) 능형회귀의 해 \\[\\hat{\\beta}_{ridge}=(X^{T}X+\\lambda I_{p})^{-1}X^{T}Y\\] 를 다시 상기해보자. \\(\\hat{\\beta}_{ridge}\\)를 구할 때 피하고 싶은 역행렬의 계산이 있다. 수치적으로 불안정할 뿐더러 계산량이 대략 \\(\\mathcal{O}(p^{3})\\) 정도 된다. 역행렬의 계산을 피할 수 있는 방법으로 SVD를 이용하는 방법이 있다. 즉 \\[X=UDV^{T}\\] 임을 이용해 해를 계산하는 것이다. References "],
["12-4-lasso.html", "12.4 라쏘(LASSO)", " 12.4 라쏘(LASSO) 능형회귀는 축소 추정치를 주지만 변수선택은 하지 않는다. 따라서 고차원 자료의 경우 최종 모형에 대한 해석이 그리 용이하지 않다. "],
["13-lmm.html", "Chapter 13 선형혼합모형 ", " Chapter 13 선형혼합모형 "],
["13-1-linear-mixed-model.html", "13.1 선형혼합모형(linear mixed model)", " 13.1 선형혼합모형(linear mixed model) 이 부분의 내용은(S. Wood 2017)를 참고하였다. 일반적으로 선형혼합모형(linear mixed model)은 선형모형을 확장한 것이다. \\[\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}, \\qquad{\\boldsymbol{\\epsilon}\\sim\\mathcal{N}(0,\\boldsymbol{\\Lambda}_{\\theta})}.\\] 이 때 \\[\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\mathbf{Zb}+\\boldsymbol{\\epsilon},\\] \\[\\mathbf{b}\\sim\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\psi}_{\\theta}),\\] \\[\\boldsymbol{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Lambda}_{\\theta})\\] 이다. \\(\\mathbf{b}\\)는 무작위 벡터로 무작위 효과(random effects)를 나타낸다. \\(\\mathbf{b}\\)는 기댓값이 0이고 공분산 행렬은 알려지지 않은 모수 \\(\\theta\\)를 포함한 \\(\\boldsymbol{\\psi}_{\\theta}\\)를 갖는다. \\(\\mathbf{Z}\\)는 무작위 효과를 나타내는 모형 행렬(model matrix)이다. \\(\\boldsymbol{\\Lambda}_{\\theta}\\)는 양정치(positive definite) 행렬로 residual의 autocorrelation을 모델링하는데 사용한다. 만약 \\(\\boldsymbol{\\Lambda}_{\\theta}=\\mathbf{I}\\sigma^{2}\\)이면 \\(\\mathbf{b}\\)와 \\(\\boldsymbol{\\epsilon}\\)은 독립이다. 13.1.1 무작위 요인인 한 개일 때(a single random factor) (S. Wood 2017)를 참고하였다. 이 때의 모형은 \\[y_{ij}=\\alpha +b_{i}+\\epsilon_{ij}\\] 이다. 이때 \\(\\alpha\\)는 모집단의 평균에 대한 고정된 모수 \\(i=1,\\ldots, I, j=1,\\ldots, J\\)이고 \\(b_{i}\\sim\\mathcal{N}(0,\\sigma_{b}^{2})\\), \\(\\epsilon_{ij}\\sim\\mathcal{N}(0,\\sigma^{2})\\)이다. 그리고 모든 \\(b_{i}\\)와 \\(\\epsilon_{e}_{ij}\\)는 서로 독립이다. 13.1.2 무작위 요인인 두 개일 때(a model with two factors) References "],
["13-2-maximum-likelihood-estimaton-for-mixed-model.html", "13.2 혼합모형에 대한 최대가능도 추정(maximum likelihood estimaton for mixed model)", " 13.2 혼합모형에 대한 최대가능도 추정(maximum likelihood estimaton for mixed model) 최소자승법보다 혼합모형에 대한 좀 더 일반적인 접근 방법은 일반화선형모형처럼 최대가능도 추정(maximum likelihood estimaton, MLE)을 하는 것이다. 자료 벡터 \\(\\mathbf{y}\\)에 대한 통계적 모형은 확률밀도함수 \\(f_{\\theta}(\\mathbf{y})\\)를 정의한다. \\(\\boldsymbol{\\theta}\\)는 모형의 알려지지 않은 모수에 해당한다. MLE의 가장 키가 되는 아이디어는 \\(f_{\\theta}(\\mathbf{y})\\)가 큰 쪽에 진짜 \\(\\boldsymbol{\\theta}\\)가 있을 가능성이 높다는 것이다. 13.2.1 가능도 최대화의 수치적 방법(numerical likelihood maximization) 로그-가능도를 직접 최대화할 수 있는 경우는 흔치 않으며, 주로 수치적 최적화 방법이 필요하다. 속도와 신뢰성 향상을 위해 뉴턴 방법의 변형된 방법들이 주로 선택되어진다. 또한 이 방법은 로그-가능도의 헤시안을 구해야 한다. 그리고 \\(l(\\boldsymbol{\\theta})\\)를 최대화하는 것은 \\(-l(\\boldsymbol{\\theta})\\)를 최소화하는 것과 같다. 뉴턴 방법의 기본 원리는 \\(l(\\boldsymbol{\\theta})\\)를 지금 상태의 모수 추측 \\(\\boldsymbol{\\theta}_{0}\\)을 이용해 2차 테일러 전개로 근사하는 것이다. 그리고 \\(l(\\boldsymbol{\\theta}&#39;)&lt;l(\\boldsymbol{\\theta}_{0})\\)일 경우 새로 얻어진 \\(l(\\boldsymbol{\\theta}&#39;)\\)가 \\(l(\\boldsymbol{\\theta}_{0})\\)보다 작지 않을 때까지 \\(\\boldsymbol{\\theta}&#39; \\leftarrow \\frac{\\boldsymbol{\\theta}&#39; + \\boldsymbol{\\theta}_{0}}{2}\\)로 바꿔준다. 이런 과정들은 \\(\\frac{\\partial l}{\\partial \\boldsymbol{\\theta}}\\approx 0\\)이 될때까지 반복한다. "],
["13-3-linear-mixed-model-in-general.html", "13.3 일반적인 선형 혼합모형(linear mixed model in general)", " 13.3 일반적인 선형 혼합모형(linear mixed model in general) "],
["13-4-maximum-likelihood-estimaton-for-linear-mixed-model.html", "13.4 선형 혼합모형의 최대가능도추정(maximum likelihood estimaton for linear mixed model)", " 13.4 선형 혼합모형의 최대가능도추정(maximum likelihood estimaton for linear mixed model) 13.4.1 REML 분산성분들에 관한 최대가능도 추정의 가장 큰 문제는 과소추정(underestimate)할 가능성이 높다는 것이다. 가장 명백한 예제로 선형모형의 \\(\\sigma^{2}\\)에 대한 최대가능도추정은 \\(\\hat{\\theta}^{2} = \\frac{\\|\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta} \\|^{2}}{n}\\)이다. 이것은 분명히 불편추정량이 아니다. Restricted maximum likelihood (REML)은 최대가능도 대신 편차를 줄이기 위해 고안되었다. 제한된 가능도는 \\(f(\\mathbf{y}, \\mathbf{b}|\\boldsymbol{\\beta})\\)를 \\(\\mathbf{b}\\)와 \\(\\boldsymbol{\\beta}\\)에 대해 적분함으로써 얻을 수 있다. 결과는 다음과 같다. \\[\\begin{align*} 2l_{r}(\\boldsymbol{\\theta})&amp;=-\\|\\mathbf{y}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}}-\\mathbf{Z}\\hat{\\mathbf{b}} \\|_{\\Lambda_{\\theta}^{-1}}^2-\\hat{\\mathbf{b}}^{T}\\boldsymbol{\\psi}_{\\theta}^{-1}\\hat{\\mathbf{b}}-\\log|\\boldsymbol{\\Lambda}_{\\theta}|-\\log |\\boldsymbol{\\psi}_{\\theta}|\\\\ &amp;- \\log \\begin{bmatrix} \\mathbf{Z}^{T}\\boldsymbol{\\Lambda}_{\\theta}^{-1}\\mathbf{Z}+\\boldsymbol{\\psi}_{\\theta}^{-1} &amp; \\mathbf{Z}^{T}\\boldsymbol{\\Lambda}_{\\theta}^{-1}\\mathbf{X}\\\\ \\mathbf{X}^{T}\\boldsymbol{\\Lambda}_{\\theta}^{-1}\\mathbf{Z} &amp; \\mathbf{X}^{T}\\boldsymbol{\\Lambda}_{\\theta}^{-1}\\mathbf{X} \\end{bmatrix} -(n-M)\\log(2\\pi). \\end{align*}\\] 이 때 \\(M\\)은 \\(\\boldsymbol{\\beta}\\)의 차원이며 \\(\\hat{\\boldsymbol{\\beta}}\\)와 \\(\\hat{\\mathbf{b}}\\)는 \\(\\boldsymbol{\\theta}\\)에 의존적이므로 각각의 \\(\\boldsymbol{\\theta}\\)에 대해서 다 계산해줘야 한다. Restrict log likelihood \\(l_{r}\\)은 AIC 등의 test statistic을 사용할 수 있다. 그러나 different fixed effect structure를 가진 모형끼리는 비교할 수 없다. "],
["13-5-r-linear-mixed-models-in-r.html", "13.5 R 예제 (linear mixed models in R)", " 13.5 R 예제 (linear mixed models in R) "],
["14-glm.html", "Chapter 14 일반화선형모형", " Chapter 14 일반화선형모형 (Nelder and Wedderburn 1972)는 몇가지 중요한 회귀분석 모형들을 통합한 개념인 일반화선형모형(generalized linear model, GLM)을 발표하였다. 이 논문에서 포아송 회귀(Poisson regression)와 로지스틱 회귀(logistic regression)가 GLM의 특수한 경우임을 보이고 추정을 위해 반복재가중최소제곱(iteratively reweighted least squares, IRLS) 알고리즘이 사용될 수 있음을 보였다. References "],
["14-1-glm-basics.html", "14.1 일반화선형모형의 기본(GLM basics)", " 14.1 일반화선형모형의 기본(GLM basics) 다음과 같은 독립인 샘플 자료 \\((\\mathbf{x}_{i}, y_{i}), i=1,\\ldots, n\\)이 있다고 하자. 이 떄 \\(y_{i}\\)는 반응변수, \\(n\\)은 표본의 크기 그리고 \\(\\mathbf{x}_{i}=(x_{i1},\\ldots, x_{ip})^{T}\\)는 \\(p\\)개의 설명변수들의 벡터이다. (\\(x_{i1}=1\\)로 보통 놓는다) 일반화선형모형(generalized linear model)은 일반적으로 다음의 세 개의 파트로 구성된다. random component: \\(f(y;\\mu)\\)는 \\(Y\\)의 분포를 특정한다. systematic component: \\(\\eta = \\boldsymbol{\\beta}^{T}\\mathbf{x}\\)는 알려진 설명변수들로 설명될 수 있는 \\(Y\\)의 variation을 특정한다. link function: \\(g(\\mu)=\\boldsymbol{\\beta}^{T}\\mathbf{x}\\)는 이 둘을 묶는 역할을 한다. 종종 \\(g\\)는 단순히 링크(link)라고 불리기도 한다. \\(\\eta\\)는 선형예측변수(linear predictor)로 알려져있다. 무작위 성분 \\(f(y;\\mu)\\)는 보통 \\(E(Y|\\mathbf{x})=\\mu(\\mathbf{x})\\)인 지수족분포(평균함수)로 모델링한다. GLM은 \\(g\\)가 알려져 있을 때 다음과 같은 모형을 적합한다. \\[g(\\mu(\\mathbf{x}_{i}))=\\eta_{i}=\\boldsymbol{\\beta}^{T}\\mathbf{x}_{i}=\\beta_{1}x_{i1}+\\ldots+\\beta_{p}x_{ip}.\\] 이 때 \\(g\\)는 strictly monotonicity해야 하고 \\(\\mu\\)의 range에서 적어도 두 번 미분이 가능해야 한다. \\(g\\)의 주된 역할은 평균을 변환시켜 최적화 문제가 잘 작동하도록 하는 것이다. 벡테 GLM 표현으로는 위 식을 다음과 같이 표현한다. \\[g_{1}(\\mu(\\mathbf{x}_{i}))=\\eta_{i1}=\\boldsymbol{\\beta}_{1}^{T}\\mathbf{x}_{i}=\\beta_{(1)1}x_{i1}+\\ldots+\\beta_{(1)p}x_{ip}.\\] 즉 모형에 한 개 이상의 선형번수를 허락하는 것이다. 관찰값이 한 개 있을때, 지수족의 확률밀도함수는 다음과 같이 쓸 수 있다. \\[f(y;\\theta, \\phi)=\\exp\\{ \\frac{y\\theta-b(\\theta)}{a(\\phi)} +c(y,\\phi) \\}.\\] 이 때 \\(\\theta\\)는 자연모수(natural parameter) 또는 정준모수(canonical parameter)로 불리고, \\(\\phi\\)는 산포모수(dispersion parameter)라고 불린다. 그리고 \\(a,b,c\\)는 알려진 함수들이다. \\(\\phi\\)가 알려졌으면, \\(Y\\)의 분포는 one-parameter canonical exponential family member가 된다. \\(\\phi\\)가 알려져있지 않을 때에는 이것은 nuisance parameter가 되며 주로 method of moments로 추정된다. 많은 GLM 이론에서 \\(\\phi\\)는 알려져 있지 않다고 하다라도 모수로 취급하지 않고 상수로 취급하는 경향이 있다. Example 14.1 (정규분포는 지수족의 멤버) 정규분포는 다음과 같이 지수족으로 표현할 수 있다. \\[\\begin{align*} f(y;\\mu)&amp;=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp[-\\frac{(y-\\mu)^{2}}{2\\sigma^{2}}]\\\\ &amp;=\\exp[\\frac{-y^{2}+2y\\mu -\\mu^{2}}{2\\sigma^{2}}-\\log (\\sigma\\sqrt{2\\pi})]\\\\ &amp;=\\exp[\\frac{y\\mu -\\mu^{2}/2}{\\sigma^{2}}-\\frac{y^{2}}{2\\sigma^{2}}-\\log (\\sigma\\sqrt{2\\pi})] \\end{align*}\\] 이 때 \\(\\theta=\\mu\\), \\(b(\\theta)=\\theta^{2}/2\\equiv \\mu^{2}/2\\), \\(a(\\phi)=\\phi=\\sigma^{2}\\)이고 \\(c(\\phi,y)=-y^{2}/(2\\phi) -\\log(\\sqrt{\\phi 2\\pi})\\equiv -y^{2}/(2\\sigma^{2})-\\log(\\sigma\\sqrt{2\\pi})\\)가 된다. 지수족 분포의 평균과 분산에 대해 \\(a,b,\\phi\\)를 이용하여 좀 더 일반적인 표현을 얻는 것도 가능하다. \\(y\\)가 주어졌을 때 \\(\\theta\\)의 로그 가능도를 추정하는 것은 단순히 \\(\\log\\{f(y;\\theta)\\}\\)를 \\(\\theta\\)에 대한 함수로 생각하면 된다. 즉 \\[l(\\theta)= \\frac{y\\theta-b(\\theta)}{a(\\phi)} +c(y,\\phi)\\] 이며 따라서 이것의 편미분은 \\(l\\)을 확률변수로 다룸으로써 얻을 수 있다. \\[\\frac{\\partial l}{\\partial \\theta}=\\frac{y-b&#39;(\\theta)}{a(\\phi)}.\\] 특별한 관찰값 \\(y\\)를 확률변수로 대체하면 \\(\\frac{\\partial l}{\\partial \\theta}\\)의 기댓값을 구하는 것이 가능하다. \\[\\mathbb{E}(\\frac{\\partial l}{\\partial \\theta})=\\frac{\\mathbb{E}(Y)-b&#39;(\\theta)}{a(\\phi)}.\\] \\(\\mathbb{E}(\\frac{\\partial l}{\\partial \\theta})=0\\)으로 하고 다시 정렬하면 다음과 같은 식을 얻을 수 있다. \\[\\mathbb{E}(Y)=b&#39;(\\theta).\\] 이 말은 즉슨, 어떤 지수족 확률변수의 기댓값은 \\(b\\)를 \\(\\theta\\)에 대해 한 번 미분함으로써 얻을 수 있다는 것이다. 가능도를 한 번 더 미분하면 다음 식을 얻는다. \\[\\frac{\\partial^{2} l}{\\partial \\theta^{2}}=-\\frac{b&#39;&#39;(\\theta)}{a(\\phi)}.\\] 이것을 일반적인 결과에 넣으면, \\(\\mathbb{E}(\\frac{\\partial^{2} l}{\\partial \\theta^{2}})=-\\mathbb{E}\\{(\\frac{\\partial l}{\\partial \\theta})^{2}\\}\\)를 얻는다. 또한 이것을 이용해 다음 식을 얻을 수 있다. \\[\\frac{b&#39;&#39;(\\theta)}{a(\\phi)}=\\frac{\\mathbb{E}[\\{Y-b&#39;(\\theta)\\}^{2}]}{a(\\phi)^{2}}.\\] 잘 정리하면 다음과 같은 일반적인 결과를 얻을 수 있다. \\[\\text{var}(Y)=b&#39;&#39;(\\theta)a(\\phi).\\] 만약 우리가 \\(\\theta\\)를 알고 있다면 GLM을 다루는 데 어떤 어려움도 없다. 그러나 만약 우리가 \\(\\phi\\)를 모르고 있다면 \\(a(\\phi)=\\frac{\\phi}{A}\\) (\\(A\\)는 알려진 상수)로 표현할 수 있지 않는 이상 상황이 어려워진다. 14.1.1 일반화선형모형의 적합(fitting generalized linear models) 이 부분은 (S. Wood 2017)을 참고하였다. 독립 설명변수들의 \\(n\\)-벡터 \\(\\mathbf{Y}\\)의 GLM 모형이 \\[g(\\mu_{i})=\\mathbf{X}_{i}\\boldsymbol{\\beta}, \\qquad{Y_{i}\\sim f(y_{i};\\theta_{i})}\\] 라고하자. 이 때 \\(f(y_{i};\\theta_{i})\\)는 지수족 분포를 나타내며 \\(\\theta\\)는 \\(\\mu_{i}\\)에 의해(즉 궁극적으로 \\(\\boldsymbol{\\beta}\\)에 의해)결정되는 정준모수다. \\(\\mathbf{Y}\\)의 관찰값 \\(\\mathbf{y}\\)가 주어졌을 때, \\(\\boldsymbol{\\beta}\\)의 최대우도추정이 가능하다. \\(Y_{i}\\)는 상호 독립이라고 했으므로, \\(\\boldsymbol{\\beta}\\)의 가능도는 다음과 같다. \\[L(\\boldsymbol{\\beta})=\\prod_{i=1}^{n}f(y_{i};\\theta_{i}).\\] 따라서 \\(\\boldsymbol{\\beta}\\)의 로그-가능도는 \\[l(\\boldsymbol{\\beta})=\\sum_{i=1}^{n}\\log \\{ f(y_{i};\\theta_{i}) \\}=\\sum_{i=1}^{n}\\frac{y_{i}\\theta_{i}-b_{i}(\\theta_{i})}{a_{i}(\\phi)}+c_{i}(\\phi,y_{i})\\] 이다. 어떤 경우에는 \\(a,b,c\\)가 \\(i\\)에 따라 달라질 수도 있다. 한편 \\(\\phi\\)는 \\(i\\)에 따라 보통 같다고 놓는다. 앞 절에서 논의한대로 가장 간단한 \\(a_{i}(\\phi)=\\frac{\\phi}{A_{i}}\\) (이 때 \\(A_{i}\\)는 알려진 상수, 주로 1)를 가정하자. 그러면 \\[l(\\boldsymbol{\\beta})=\\sum_{i=1}^{n}A_{i}\\frac{y_{i}\\theta_{i}-b_{i}(\\theta_{i})}{\\phi}+c_{i}(\\phi,y_{i})\\] 가 된다. 이 로그-가능도를 최대화하기 위해서는 보통 뉴턴의 방법(Newton’s method)를 사용한다. 이것은 \\(l\\)의 그라디언트 벡터와 헤시안을 계산해야 한다. \\[\\frac{\\partial l}{\\partial \\beta_{j}}=\\frac{1}{\\phi}\\sum_{i=1}^{n}A_{i}\\Big( y_{i}\\frac{\\partial \\theta_{i}}{\\partial \\beta_{j}}-b_{i}&#39;(\\theta_{i})\\frac{\\partial \\theta_{i}}{\\partial \\beta_{j}} \\Big).\\] 또한 체인룰(chain rule)에 따라 \\[\\frac{\\partial \\theta_{i}}{\\partial \\beta_{j}}=\\frac{d\\theta_{i}}{d\\mu_{i}}\\frac{\\partial\\mu_{i}}{\\partial \\beta_{j}} =\\frac{d\\theta_{i}}{d\\mu_{i}}\\frac{\\partial\\eta_{i}}{\\partial \\beta_{j}}\\frac{d\\mu_{i}}{d\\eta_{i}}=\\frac{X_{ij}}{g&#39;(\\mu_{i})b&#39;&#39;(\\theta_{i})}.\\] 마지막 등식은 \\(\\frac{d\\mu_{i}}{d\\eta_{i}}=g&#39;(\\mu_{i})\\) 그리고 \\(\\frac{\\partial\\eta_{i}}{\\partial \\beta_{j}}=X_{ij}\\), \\(\\frac{d\\theta_{i}}{d\\mu_{i}}=\\frac{1}{b;;(\\theta_{i})}\\)라는 사실로부터 얻어진다. 이들을 잘 정리하면, \\[\\frac{\\partial l}{\\partial \\beta_{j}}=\\frac{1}{\\phi}\\sum_{i=1}^{n}\\frac{y_{i}-b_{i}&#39;(\\theta)}{g&#39;(\\mu_{i})b_{i}&#39;&#39;(\\theta_{i})/A_{i}}X_{ij}=\\frac{1}{\\phi}\\sum_{i=1}^{n}\\frac{y_{i}-\\mu_{i}}{g&#39;(\\mu_{i})V(\\mu_{i})}X_{ij}\\] 를 얻는다. 다시 미분하면 다음을 얻는다. \\[\\begin{align*} \\frac{\\partial^{2}l}{\\partial \\beta_{j}\\partial \\beta_{k}}&amp;=-\\frac{1}{\\phi}\\sum_{i=1}^{n}\\Big\\{ \\frac{X_{ik}X_{ij}}{g&#39;(\\mu_{i})^{2}V(\\mu_{i})} - \\frac{(y_{i}-\\mu_{i})V&#39;(\\mu_{i})X_{ik}X_{ij}}{g&#39;(\\mu_{i})^{2}V(\\mu_{i})^{2}}+\\frac{(y_{i}-\\mu_{i})X_{ij}g&#39;&#39;(\\mu_{i})X_{ik}}{g&#39;(\\mu_{i})^{3}V(\\mu_{i})} \\Big\\}\\\\ &amp;-\\frac{1}{\\phi}\\sum_{i=1}^{n}\\frac{X_{ik}X_{ij}\\alpha(\\mu_{i})}{g&#39;(\\mu_{i})^{2}V(\\mu_{i})}. \\end{align*}\\] 이 때 \\(\\alpha(\\mu_{i})= 1+ (y_{i}-\\mu_{i})\\{ \\frac{V&#39;(\\mu_{i})}{V(\\mu_{i})} + \\frac{g&#39;&#39;(\\mu_{i})}{g&#39;(\\mu_{i})} \\}\\)이다. 표현 \\(\\mathbb{E}(\\frac{\\partial^{2}l}{\\partial \\beta_{j}\\partial \\beta_{k}})\\) 또한 똑같지만, \\(\\alpha(\\mu_{i})= 1\\)이다. 따라서 \\(\\mathbf{W}=\\text{diag}(w_{i})\\), \\(w_{i}=\\frac{a(\\mu_{i})}{g&#39;(\\mu_{i})^{2}V(\\mu_{i})}\\)로 정의하면, 로그-가능도의 헤시안은 \\(-\\frac{\\mathbf{XWX}}{\\phi}\\)가 되며, 헤시안의 기댓값은 \\(\\alpha(\\mu_{i})=1\\)로 놓음으로써 얻을 수 있다. \\(\\alpha(\\mu_{i})=1\\)로 계산된 가중치들을 피셔 가중치(Fisher weight)들이라고 부른다. \\(\\mathbf{G}=\\text{diag}\\{\\frac{g&#39;(\\mu_{i})}{\\alpha(\\mu_{i})}\\}\\)로 정의함으로써, 그라디언트 벡터의 로그-가능도는 \\(\\frac{\\mathbf{X}^{T}\\mathbf{WG}(\\mathbf{y}-\\boldsymbol{\\mu})}{\\phi}\\)가 된다. 그러면 뉴턴 업데이트는 다음과 같은 형태를 갖는다. \\[\\begin{align*} \\boldsymbol{\\beta}^{[k+1]}&amp;=\\\\boldsymbol{\\beta}^{[k]}+(\\mathbf{XWX})^{-1}\\mathbf{X}^{T}\\mathbf{WG}(\\mathbf{y}-\\boldsymbol{\\mu})\\\\ &amp;=(\\mathbf{XWX})^{-1}\\mathbf{X}^{T}\\mathbf{W}\\{\\mathbf{G}(\\mathbf{y}-\\boldsymbol{\\mu})+\\mathbf{X}\\boldsymbol{\\beta}^{[k]}\\}\\\\ &amp;-(\\mathbf{XWX})^{-1}\\mathbf{X}^{T}\\mathbf{W}\\mathbf{z}. \\end{align*}\\] 이 때 \\(z_{i}=g&#39;(\\mu_{i})\\frac{y_{i}-\\mu_{i}}{\\alpha(\\mu_{i})}+\\eta_{i}\\)이다. (\\(\\boldsymbol{\\eta}\\equiv\\mathbf{X}\\boldsymbol{\\beta}\\)이다.) 결국 이 이생 방정식은 \\(\\boldsymbol{\\beta}\\)에 대한 가중 최소자승방법 중 하나라고 볼 수 있다. 결국 GLM은 반복 재가중 최소자승(iteratively re-weighted least squares) 알고리즘으로 추정되 수 있으며, 다음과 같다. \\(\\hat{\\mu}_{i}=y_{i}+\\delta_{i}\\), \\(\\hat{\\eta}_{i}=g(\\hat{\\mu}_{i})\\)로 초기화한다. \\(\\delta_{i}\\)는 보통 0으로 놓으며, \\(\\hat{\\eta}_{i}\\)가 유한함을 보장하기 위해 작은 상수일 수도 있다. 수렴할 때까지 아래 두 단계를 반복한다. Pseudo-data \\(z_{i}=g&#39;(\\hat{\\mu}_{i})\\frac{y_{i}-\\hat{\\mu}_{i}}{\\alpha(\\hat{\\mu}_{i})}+\\hat{\\eta}_{i}\\)와 반복 가중치 \\(w_{i}=\\frac{a(\\hat{\\mu}_{i})}{g&#39;(\\hat{\\mu}_{i})^{2}V(\\hat{\\mu}_{i})}\\)를 계산한다. 가중 최소자승 \\[\\sum_{i=1}^{n}w_{i}(z_{i}-\\mathbf{X}_{i}\\boldsymbol{\\beta})^{2}\\] 을 최소화하는 \\(\\hat{\\boldsymbol{\\beta}}\\)를 찾는다. 그리고 \\(\\hat{\\boldsymbol{\\eta}}=\\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\)로, \\(\\hat{\\mu}_{i}=g^{-1}(\\hat{\\eta}_{i})\\)로 갱신한다. References "],
["14-2-univariate-smoothing.html", "14.2 일변량 스므딩(univariate smoothing)", " 14.2 일변량 스므딩(univariate smoothing) (Yee 2015)에 따르면 스므더(smoother)의 종류에는 다음이 있다. Regression or series smoothers (polynomial regression, regression splines, P-splines, Fourier regression, filtering, wavelets) Smoothing splines (with roughness penalties, e.g., cubic smoothing splines, O-splines, P-splines) Local regression (Nadaraya-Watson estimator, kernel smoothers, Lowess, Loess, it generalizes to local likelihood) Nearest-neighbour smoothers (running means, running lines, running medians) 고전적인 스므딩 문제(classical smoothing problem)는 다음 모형에 대해 임의의 부드러운 함수(smooth function) \\(f\\)를 추정하는 문제이다. \\[y_{i}=f(x_{i})+\\epsilon_{i}, \\qquad{\\epsilon_{i} \\sim (0, \\sigma_{i}^{2})}\\] 일반적으로 자료를 \\(x_{1}&lt;x_{2}&lt;\\ldots &lt;x_{n}\\) 등으로 크기에 따라 정렬할 수 있다고 가정하면, 모든 스므딩 방법의 기본 아이디어는 이웃(neighbourhood)을 정의하는 것이다. 타겟 포인트 \\(x_{0}\\)가 있을때 이것의 이웃의 크기를 정하는 일은 함수의 부드러움을 결정하는 문제와 같이 때문에 매우 중요하다. References "],
["14-3-vector-generalized-linear-models.html", "14.3 벡터 일반화선형모형(vector generalized linear models)", " 14.3 벡터 일반화선형모형(vector generalized linear models) 이 절의 내용은 (Yee 2015)를 따른다. References "],
["14-4-limations-of-glm.html", "14.4 일반화선형모형의 한계점(limations of glm)", " 14.4 일반화선형모형의 한계점(limations of glm) (Yee 2015)에 의하면 GLM은 잘 알려진 지수족 내의 일차원 분포에서만 잘 적용된다는 한계점을 가지고 있다. References "],
["15-gam.html", "Chapter 15 일반화가법모형", " Chapter 15 일반화가법모형 일반화가법모형을 처음 다룬 논문들로는 (Hastie and Tibshirani 1986)이 있다. 일반화가법모형에 대한 참고문헌으로는 (S. Wood 2017)이 있다. 최근에 나온 좋은 책으로는 (Yee 2015)가 있으며 이 책은 주로 벡터 일반화선형모형(vector genearlized linear model, VGLMs) 및 벡터 일반화가법모형(vector generalized addtive model, VGAMs)에 초점을 맞추고 있고 R 코드를 포함하고 있다. 일반화가법모형은 일반화 선형모형이며 선형 predictor가 smooth functions of covariate의 합(sum) 형태로 표현된 모형을 말한다. 일반적으로는 \\[g(\\mu_{i})=\\mathbf{A}_{i}\\boldsymbol{\\theta}+f_{1}(x_{1i})+f_{2}(x_{2i})+f_{3}(x_{3i})+\\ldots\\] 로 모형 structure를 표현할 수 있다. 이 때 \\(\\mu_{i}\\equiv E(Y_{i})\\)이고 \\(Y_{i}\\sim \\text{EF}(\\mu_{i},\\phi)\\)이다. \\(Y_{i}\\)는 설명변수들이고, \\(\\text{EF}(\\mu_{i},\\phi)\\)는 평균 \\(\\mu_{i}\\)와 척도모수(scale parameter) \\(\\phi\\)인 지수족 분포(exponential family distribution)를 나타낸다. \\(\\mathbf{A}_{i}\\)는 어떤 strictly parametric model components의 모형 행렬의 행(row)를 나타낸다. \\(\\theta\\)는 대응되는 모수 벡터이다. \\(f_{j}\\)는 covariates들 \\(x_{k}\\)들의 smooth functions이다. References "],
["15-1-additive-models.html", "15.1 가법모형들(additive models)", " 15.1 가법모형들(additive models) 회귀분석의 가법모형(additive model)은 \\[E[Y|\\mathbf{X}=\\mathbf{x}]=\\alpha+\\sum_{j=1}^{p}f_{j}(x_j)\\] 로 표현한다. 선형모형은 \\(f_{j}(x_{j})=\\beta_{j}x_{j}\\)인 가법모형의 특별한 경우이다. \\(f_{j}\\)는 임의의 비선형 함수도 될 수 있다는 점에서 가법모형이 좀 더 일반적인 형태의 모형이라고 할 수 있다. "],
["15-2-vector-gams.html", "15.2 벡터 일반화가법모형(vector GAMs)", " 15.2 벡터 일반화가법모형(vector GAMs) 스므딩에는 다음과 같은 네 가지 종류가 있다. \\(y\\)는 스칼라, \\(x\\)는 일변량 \\(y\\)는 스칼라, \\(\\mathbf{x}\\)는 다변량 \\(\\mathbf{y}\\)는 벡터, \\(x\\)는 일변량 \\(\\mathbf{y}\\)는 벡터, \\(\\mathbf{x}\\)는 다변량 일반적으로 얘기하는 벡터 일반화가법모형은 (3)에 해당한다. "],
["15-3-backfitting.html", "15.3 퇴각 적합화(backfitting)", " 15.3 퇴각 적합화(backfitting) 퇴각 적합화(backfitting)는 가우스-자이델 방법(Gauss-Seidel method)이라고도 불리는 방법으로, GAM을 적합하기 위한 단순하면서도 아름다운 방법이다. 이 알고리즘의 기본 아이디어는 가법모형의 각 smooth component들에 대해 iteratively하게 가법모형의 smooth partial residuals를 계산하는 것이다. 다음과 같은 가법모형에서 추정을 하고 싶다고 가정하자. \\[y_{i}=\\alpha + \\sum_{j=1}^{m}f_{j}(x_{ji})+\\epsilon_{i},\\] 여기서 \\(f_{i}\\)는 부드러운 함수들(smooth functions)이며 공변량 \\(x_{j}\\)는 때때로 벡터이기도 하다. \\(\\hat{\\mathbf{f}}_{j}\\)를 \\(i\\)째 원소의 추정값이 \\(f_{j}(x_{ji})\\)인 벡터라고 하자. 그러면 기본적인 퇴각 적합화 알고리즘은 다음과 같다. Set \\(\\alpha=\\bar{y}\\) and \\(\\hat{\\mathbf{f}}_{j}=\\mathbf{0}\\) for \\(j=1,\\ldots , m\\). Repeat step 3 to 5 until teh estimates \\(\\hat{\\mathbf{f}}_{j}=\\mathbf{0}\\) stop changing. For \\(j=1,\\ldots ,m\\), repeat steps 4 and 5. Calculate partial residuals: \\[\\mathbf{e}_{P}^{j}=\\mathbf{y}-\\hat{\\alpha}-\\sum_{k\\neq j}\\hat{\\mathbf{f}}_{k}.\\] Set \\(\\hat{\\mathbf{f}}_{j}\\) equal to the result of smoothing \\(e_{p}^{j}\\) with respect to \\(x_{j}\\). "],
["15-4-r-r-gam.html", "15.4 R 예제(R-gam)", " 15.4 R 예제(R-gam) 알고리즘을 짜면 다음과 같다. f&lt;-x*0;alpha&lt;-mean(y);ok &lt;- TRUE while (ok) { # backfitting loop for (i in 1:m) { # loop through the smooth terms ep &lt;- y - rowSums(f[,-i]) - alpha b &lt;- smooth.spline(x[,i],ep,df=edf[i]) f[,i] &lt;- predict(b,x[,i])$y } rss &lt;- sum((y-rowSums(f))ˆ2) if (abs(rss-rss0)&lt;1e-6*rss) ok &lt;- FALSE rss0 &lt;- rss } "],
["16-smoothing.html", "Chapter 16 스므딩 ", " Chapter 16 스므딩 "],
["16-1-univariate-smoothing-1.html", "16.1 일변량 스므딩(univariate smoothing)", " 16.1 일변량 스므딩(univariate smoothing) 함수 모형의 표현은 보통 다음과 같은 기본적인 모형에서 출발한다. \\[\\begin{equation} y_{i}=f(x_{i})+\\epsilon_{i}. \\tag{15.1} \\end{equation}\\] 여기서 \\(y_{i}\\)는 종속변수, \\(x_{i}\\)는 공변량, \\(f\\)는 부드러운 함수이며 \\(\\epsilon_{i}\\)는 독립이며 \\(\\mathcal{N}(0,\\sigma^{2})\\)을 갖는 확률변수들이다. 16.1.1 함수를 기저로 표현하기(representing a function with basis expansions) \\(f\\)를 추정하기 위해 \\(f\\)를 식 (15.1)를 선형모형처럼 해석하는 방법이 있다. 이렇게 하기 위해 사용하는 것이 기저(basis)다. 기저라 함은 \\(f\\)가 원소로 있는 함수 공간을 정의하는 데 필요한 것이다. 기저 함수(basis function)들은 매우 잘 알려져 있다고 단정한다. 만약 \\(b_{j}(x)\\)가 \\(j\\)번째 기저함수라고 하면, \\(f\\)는 다음과 같이 표현할 수 있다고 가정한다. 16.1.2 회귀 스플라인(regression spline) (Yee 2015)에 따르면 회귀 스플라인(regression spline)은 다음과 같은 장점들을 같고 있다. 이 방법은 계산적, 통계적으로 단순하고 표준적인 모수 추론이 가능하다. 왜냐하면 이 방법은 부드러운 함수의 LM 표현 방법이기 때문이다. 두 번째 장점으로 어떤 매듭(knot)이 없어도 무방한지에 대한 검정이 가능하다는 것이 있다. 그러나 이 방법에서 매듭의 숫자와 위치를 고르는 데에 어려움이 있고, 부드러움의 정도가 한 개의 스므딩 모수로는 연속적으로 조절될 수 없다는 단점도 있다. References "],
["16-2-b-b-spline.html", "16.2 B-스플라인(B-spline)", " 16.2 B-스플라인(B-spline) 이 부분의 내용은 (Yee 2015)를 참고하였다. B-스플라인(B-spline)을 사용하는 이유는 주로 계산적인 문제 때문이라고 한다(minimal support). B-스플라인은 minimal support (또는 compact support)를 갖고 이는 spline basis끼리 the amount of overlap를 minimal하게 만드므로 안정적인 계산을 가능하게 한다고 한다. FIGURE 15.1: 매듭의 위치가 0.3, 0.5, 0.6이고 Q=1,2,3,4일때의 B-스플라인 기저들. 이것은 general order \\(Q\\)를 갖는 스플라인으로 생각하면 편하다. 몇 가지 특별한 경우들을 나열해 본다. \\(Q=1\\): unit rectangle 또는 boxcar 함수의 shifted된 버전이다. \\(Q=2\\): linear spline이며 매듭에서 \\(Q-2=0\\)차 연속 미분값을 갖는다. 즉 조각별 선형함수다. \\(Q=3\\): quadratic spline이며 매듭에서 \\(Q-2=1\\)차 연속 미분값을 갖는다. \\(Q=4\\): cubic spline이며 \\(f^{(Q-1)}(\\xi_{s})\\)안의 불연속점을 인지할 수 없는 가장 낮은 차수의 스플라인이다. (Hastie, Tibshirani, and Friedman 2009) Natural spline은 cubic spline의 잘 알려진 예로 양 끝지점에서 2계, 3계도함수가 0인 스플라인이다. \\(\\xi_{s}, s=1,\\ldots, K\\)를 \\(K\\) interior knots라고 하고 \\(\\xi_{0}\\), \\(\\xi_{K+1}\\)를 boundary knots라고 하자. 그러면 이러한 knots들이 다음과 같은 부등식을 만족하는 \\[\\begin{alignat*}{2} \\tau_{1}\\leq \\tau_{2} \\leq \\cdots \\leq \\tau_{Q} &amp;\\leq \\xi_{0} &amp;&amp; \\\\ &amp;&lt; \\xi_{1} \\leq \\cdots \\leq &amp;&amp;\\xi_{K}\\\\ &amp; &amp;&amp;&lt; \\xi_{K+1} \\leq \\tau_{K+Q+1} \\leq \\cdots \\leq \\tau_{K+2Q} \\end{alignat*}\\] \\(\\boldsymbol{\\tau}=(\\tau_{1}, \\ldots, \\tau_{K+2Q})^{T}\\) 벡터를 얻기 위해 \\(2Q\\)개의 다른 매듭들을 더 필요로 한다는 것을 알 수 있다. \\(B_{s,q}(x)\\)를 order \\(q\\) (차수 \\(q-1\\), \\(q=1,\\ldots, Q\\))을 갖고 knot sequence가 \\(\\boldsymbol{\\tau}\\)인 B-spline basis function이라고 하자. 그러면 \\(B_{s,q}(x)\\)는 다음과 같이 정의된다. \\(s=1,\\ldots, K+2-1\\)일 때 \\[B_{s,1}(x)= \\begin{cases} 1 &amp; \\qquad{\\tau_{s} \\leq x &lt; \\tau_{s+1}}\\\\ 0 &amp; \\qquad{\\text{o.w.}} \\end{cases}\\] \\(s=1,\\ldots, K+2Q-q\\), \\(q&gt;1\\)일 때 \\[\\begin{align*} B_{s,q}(x)&amp;=\\omega_{s,q}B_{s,q-1}(x)+(1-\\omega_{s+1,q}B_{s+1,q-1}(x))\\\\ &amp;=\\frac{x-\\tau_{s}}{\\tau_{s+q-1}-\\tau_{s}}B_{s,q-1}(x) + \\frac{\\tau_{s+q}-x}{\\tau_{s+q}-\\tau_{s+1}}B_{s+1,q-1}(x), \\end{align*}\\] 여기서 \\(\\omega_{s,q}\\equiv (x-\\tau_{s})/(\\tau_{s+q-1}-\\tau_{s})\\) for \\(\\tau_{s+q-1}&gt;\\tau_{s}\\)이고 만약 \\(\\tau_{s+q-1}=\\tau_{s}\\)이면 \\(\\omega_{s,q}\\equiv 0\\)이 된다. 이것들은 안정적이고 효육적인 재귀 알고리즘으로 구할 수 있다. 여기서 \\(B_{s,q}\\)는 \\(q+1\\)개의 매듭들 \\(\\tau_{s},\\ldots, \\tau_{s+q}\\)에만 관련이 있고 구간 \\([\\tau_{s},\\tau_{s+q})\\) 바깥에서는 감쇄하며 구간 안에서는 양의 값을 갖는다. 만약 \\(\\tau_{s}=\\tau_{s+q}\\)이면 \\(B_{s,q}=0\\)이다. 16.2.1 P-spline P-스플라인(P-spline)은 penalized B-spline이라는 의미를 갖고 있다. References "],
["16-3-soap-film-soap-film-smoothing-over-finite-domains.html", "16.3 유한 도메인에서의 soap film 스므딩(soap film smoothing over finite domains)", " 16.3 유한 도메인에서의 soap film 스므딩(soap film smoothing over finite domains) 때때로 domain이 복잡한 boundary를 갖을 때가 있다. 이 때에는 boundary feature를 not to smooth across하는 것이 중요하다. (S. N. Wood, Bravington, and Hedley 2008)은 이를 해결하기 위해 soap film 스므딩(soap film smoothing)을 제안하였다. 함수 \\(f\\)가 주어졌을 때 boundary 안쪽의 soap film의 높이는 다음을 만족한다고 한다. \\[\\frac{\\partial^{2}f}{\\partial x^{2}}+ \\frac{\\partial^{2}f}{\\partial y^{2}}=0.\\] 그리고 boundary condition 또한 만족한다. 즉 soap film은 minimum surface tension configuration을 만족한다. 정의역의 모든 영역에 걸쳐 잡음이 들어간 \\(z\\)가 부드럽게 존재하기 위해 soap film은 다음 왜곡 degree 측도를 만족해야 한다. \\[J_{\\Omega}(f)=\\int_{\\Omega}(\\frac{\\partial^{2}f}{\\partial x^{2}}+ \\frac{\\partial^{2}f}{\\partial y^{2}})^{2}dxdy.\\] 이것이 thin plate spline과 soap film smoothing을 구분하는 부붅이다. TPS는 \\(\\Omega\\)에 대해 적분하지만 soap film smoothing은 그렇지 않다. FIGURE 15.2: Soap film smoothing 설명 그림. \\(n\\)개의 자료가 \\(z_{k}\\)가 있고 이것이 \\(h(x_{k},y_{k})\\)의 잡음이 있는 관찰값들이라고 할 때(물론 \\(h\\)는 정의역에서 부드러운 함수라고 가정한다), 우리는 \\(h\\)를 다음 조건을 최소화 하는 것으로 추정하려고 한다. \\[\\begin{equation} \\sum_{i=1}^{n}\\{ z_{i}-f(x_{i},y_{i})\\}^{2}+\\lambda J_{\\Omega}(f). \\tag{15.2} \\end{equation}\\] References "],
["17-ts.html", "Chapter 17 시계열분석", " Chapter 17 시계열분석 내용과 표기는 (Shumway and Stoffer 2010)를 따른다. (Cryer and Chan 2008)또한 R 예제가 이쓴 시계열분석 교재로써 참고할 만 하다. 시계열에서 다루는 대부분의 확률모형들은 확률과정을 설명하는 모형이라고 한다. 관측된 시계열은 표본공간의 각 원소에 대응하는 확률과정 \\(\\{ Z_{t}(\\omega), t=1,2,\\ldots \\}\\)의 관측값으로 시간의 함수이며, 이를 확률과정의 실현값(realization) 또는 표본통로(sample path)라고 부른다. 우리가 과거로 돌아갈 수 있어 반복 관측을 할 수 있다면 현재 관측된 시계열은 무한히 많은 관측 가능한 확률변수들의 모임 중에서 특별히 실현된 하나에 해당된다. 시계열 분석의 가장 큰 특징은 분석의 대상이 되는 자료가 반복 관측될 수 없다는 점이다. References "],
["17-1-stationary-time-series.html", "17.1 정상시계열(stationary time series)", " 17.1 정상시계열(stationary time series) 다음 설명은 DODOMIRA에서 따온 것이다. 안정적인 시계열이란 다음 세 가지 특징을 가진 시계열을 말한다. 시간의 추이와 관계 없이 평균이 불변한다. FIGURE 17.1: Time invariant mean. 시간의 추이와 관계 없이 분산이 불변한다. FIGURE 17.2: Time invariant variance. 시간의 추이와 관계 없이 공분산이 불변한다. FIGURE 17.3: Time invariant covariance. Definition 17.1 (강정상성) 시계열 \\(\\{ x_{t}\\}\\)가 있을 때 두 collection \\[\\{ x_{t_{1}}, x_{t_{2}}, \\cdots x_{t_{k}}\\}, \\{ x_{t_{1+h}}, x_{t_{2+h}}, \\cdots x_{t_{k+h}}\\}\\] 가 identical하다면, 즉 모든 \\(k=1,2,\\ldots\\), 모든 숫자 \\(c_{1},c_{2},\\ldots , c_{k}\\) 그리고 \\(h=0, \\pm 1, \\pm 2,\\ldots\\)에 대해 \\[P \\{ x_{t_{1}} &lt;c_{1}, \\ldots , x_{t_{k}} \\leq c_{k}\\}=P \\{ x_{t_{1+h}} &lt;c_{1}, \\ldots , x_{t_{k+h}} \\leq c_{k}\\}\\] 일 때 이 시계열을 강정상성(strictly stationary)이라고 한다. (Huser 2013)에 따르면 강정상성은 translation이 그 과정의 확률적 성질에 영향을 미치지 않는 것을 의미한다. 다시 말하면 변수들이 상호 관련있는 수열이라고 하더라도 그것의 확률적 성질들은 시간에 따라 동일한 것이다. 그러나 강정상성의 정의는 대부분의 응용에서 너무 강한 조건인데, 특히 single data set으로부터 강정상성을 assess하기 어렵다고 한다. 시계열에서는 series의 첫 두 moment에만 관련된 약정상성을 생각하여 조건을 부드럽게 한다. (Huser 2013)에 따르면 강정상성과 달리 약정상성은 처음 2개의 모멘트에서만 temporal homogeneity가 성립함을 가정하는 것이다. Definition 17.2 (약정상성) 시계열 \\(x_{t}\\)가 finite variance를 갖는 process이며 평균함수 \\(\\mu_{t}\\)가 상수이며 시간에 따라 변하지 않고 자기공분산함수 \\(\\gamma(s,t)\\)가 이들의 차이 \\(|s-t|\\)에만 depend할 때 이 시계열을 약정상성(weekly stationary)이라고 한다. 비정상 시계열 자료는 다루기 어려우므로 보통 분석하기 쉬운 정상성 시계열 자료로 변환해서 분석한다. Definition 17.3 (자기공분산함수) 정상시계열의 자기공분산함수(autocovariance function)는 \\[\\gamma(h)=Cov(x_{t+h}, x_{t})=E[(x_{t+h}-\\mu)(x_{t}-\\mu)]\\] 로 정의된다. Definition 17.4 (자기상관함수) 정상시계열의 자기상관함수(autocorrelation function)는 \\[\\rho(h)=\\frac{\\gamma(t+h,t)}{\\sqrt{\\gamma(t+h,t_h)\\gamma(t,t)}}=\\frac{\\gamma(h)}{\\gamma(0)}\\] 이다. 이는 \\(h\\) 기간 떨어진 값들의 상관계수를 의미한다. 특별히 서로 다른 두 시점의 중간에 있는 값들의 영향을 제외시킨 상관계수를 부분자기상관함수(partial ACF)라고 부른다. linear process, guassian process ACF, PACF, CCF References "],
["17-2-characteristics-of-time-series.html", "17.2 시계열자료의 특성(characteristics of time series)", " 17.2 시계열자료의 특성(characteristics of time series) "],
["17-3-time-series-regression.html", "17.3 시계열 회귀분석(time series regression)", " 17.3 시계열 회귀분석(time series regression) 회귀분석 모형은 시간 영역 모형과 주파수 영역 모형에서 모두 중요한 역할을 한다. 만약 \\(x_{t}\\)를 \\(x_{t-1}, \\ldots, x_{t-p}\\)의 선형결합으로 표현한다면 이것은 시간 영역에의 응용이 된다. 물론 일반적인 시계열 분석에서는 회귀분석과 달리 설명변수에 해당하는 \\(x_{t-1}, \\ldots, x_{t-p}\\)들 또한 무작위라는 차이점이 있다. 만약 우리가 사인, 코사인 함수를 투입값으로 둔다면, 주파수 영역의 아이디어는 피리오도그램과 스펙트럼을 이끌어내고 이것은 회귀모형으로부터 얻어진다. 필터를 무한한 정도로 확장하면 주파수 영역에서의 회귀분석을 다룰 수 있다. 실제로, 주파수 영역에서의 많은 회귀분석 문제들은 투입과 산출 함수들을 주기 성분의 함수들로 나타는 것이다. \\(x_{t},t=1,\\ldots ,n\\)을 시계열 자료라고 하자. 그리고 이 자료가 다른 투입량 또는 독립적인 시계열 \\(z_{t1}, z_{t2}, \\ldots ,z_{tq}\\)의 영향을 받는다고 하자. 이 가정은 일반적인 회귀분석에서 놓는 가정이다. 이 관계를 회귀분석 모형으로 쓰면 \\[\\begin{equation} x_{t}=\\beta_{1}z_{t1}+\\beta_{2}z_{t2}+\\ldots + \\beta_{q}z_{tq}+w_{t} \\tag{17.1} \\end{equation}\\] 로 놓을 수 있다. 이 때 \\(\\beta_{1},\\beta_{2}.\\ldots , \\beta_{q}\\)는 알려지지 않은 고정된 회귀계수(regression coefficients)들이고 \\(\\{ w_{t}\\}\\)는 i.i.d. 정규분포\\((0,\\sigma_{w}^{2})\\)를 따르는 무작위 오류나 잡음과정(noise process)이라고 놓는다. 선형모형 (17.1)은 일반적으로 벡터 \\(\\mathcal{z}_{t}=(z_{t1},z_{t2},\\ldots , z_{tq})^{T}\\), \\(\\boldsymbol{\\beta}(\\beta_{1},\\beta_{2},\\ldots ,\\beta_{q})^{T}\\)를 써서 나타낸다. 그러면 ((17.1))은 \\[\\begin{equation} x_{t}=\\boldsymbol{\\beta}^{T}\\mathcal{z}_{t}+w_{t} \\tag{17.2} \\end{equation}\\] 으로 간단히 쓸 수 있다. 이 때 알려지지 않은 모수 \\(\\boldsymbol{\\beta}\\)의 추정은 다음 식 \\[\\begin{equation} Q=\\sum_{t=1}^{n}w_{t}^{2}=\\sum_{t=1}^{n}(x_{t}-\\boldsymbol{\\beta}^{T}\\mathbf{z}_{t})^{2} \\tag{17.3} \\end{equation}\\] 를 \\(\\beta_{1},\\beta_{2},\\ldots ,\\beta_{q}\\)에 대해 풀어 얻을 수 있다. 다시 식 (17.1)를 행렬 형태로 바꿔서 풀어보자. \\(n\\times q\\) 행렬 \\(Z= [\\mathbf{z}_{1} | \\mathbf{z}_{2} | \\cdots | \\mathbf{z}_{n} ]^{T}\\)과 \\(n \\times 1\\) 벡터 \\(\\mathcal{x}=(x_{1},x_{2},\\ldots , x_{n})^{T}\\), \\(n \\times 1\\) 오차의 벡터 \\(\\mathcal{w}=(w_{1},w_{2}, \\ldots, w_{n})^{T}\\)를 이용해 식 (17.3)를 \\[\\begin{equation} \\mathbf{x}=Z\\boldsymbol{\\beta}+\\mathbf{w} \\tag{17.4} \\end{equation}\\] 로 바꿔 쓸 수 있다. 이것을 정규방정식(normal equation)이라고 쓴다. ((17.4))의 해는 \\(Z^{T}Z\\)이 nonsingular일 때 \\[\\hat{\\boldsymbol{\\beta}}=(Z^{T}Z)^{-1}Z^{T}\\mathbf{x}\\] 로 얻을 수 있다. 오차 \\(w_{t}\\)가 정규분포를 따르면, \\(\\hat{\\boldsymbol{\\beta}}\\)는 \\(\\beta\\)의 최대가능도추정량(maximum likelihood estimator)을 따르며 \\[Cov(\\hat{\\boldsymbol{\\beta}})=\\sigma_{w}^{2}(\\sum_{t=1}^{n}\\mathbf{z}_{t}\\mathbf{z}_{t}^{T})^{-1}=\\sigma_{w}^{2}(Z^{T}Z)^{-1}=\\sigma_{w}^{2}C\\] 이다. 여기서 \\[C=(Z^{T}Z)^{-1}\\] 은 나중에 식을 전개하기 위해 미리 정의해 둔다. 선형 예측을 위해 많이 쓰는 사영 정리(projection theorem)을 여기에 적어둔다. Theorem 17.1 (사영 정리) \\(\\mathcal{M}\\)이 힐버트 공간 \\(\\mathcal{H}\\)의 닫힌 부분 공간이고 \\(y\\)는 \\(\\mathcal{H}\\)의 원소라고 하자. 그러면 \\(y\\)는 \\[\\begin{equation} y=\\hat{y}+z \\end{equation}\\] 로 유일하게 표현할 수 있다. 이 때 \\(\\hat{y}\\)는 \\(\\mathcal{M}\\)에 속하며 \\(z\\)는 \\(\\mathcal{M}\\)과 직교한다. 즉, 모든 \\(w\\in\\mathcal{M}\\)에 대해 \\(\\langle z,w \\rangle=0\\)이다. 더불어 점 \\(\\hat{y}\\)는 \\(y\\)와 가장 가까운 점이다. 이 말인 즉슨, 모든 \\(w\\in\\mathcal{M}\\)에 대해 \\(\\| y-w\\|\\geq \\|y-\\hat{y}\\|\\)이고 등호는 \\(w=\\hat{y}\\)일 때 성립한다는 말이다. "],
["17-4-differencing.html", "17.4 차분(differencing)", " 17.4 차분(differencing) 시계열 자료가 정상성(stationary)을 유지하기 위해서 인접한 시간들에 있는 값들의 차이를 활용하는 경우가 많다. 왜냐면 이는 자기상관(autocorrelation)과도 관련이 있기 때문이다. library(astsa) fit = lm(gtemp~time(gtemp), na.action=NULL) # regress gtemp on time par(mfrow=c(2,1)) plot(resid(fit), type=&quot;o&quot;, main=&quot;detrended&quot;) plot(diff(gtemp), type=&quot;o&quot;, main=&quot;first difference&quot;) FIGURE 17.4: Detrended (top) and differenced (bottom) global temperature series. par(mfrow=c(3,1)) # plot ACFs acf(gtemp, 48, main=&quot;gtemp&quot;) acf(resid(fit), 48, main=&quot;detrended&quot;) acf(diff(gtemp), 48, main=&quot;first difference&quot;) FIGURE 17.5: Sample ACF (top) detrended sample ACF (middle) and differenced (bottom) global temperature series. "],
["17-5-armia-arima-models.html", "17.5 ARMIA 모델들(ARIMA models)", " 17.5 ARMIA 모델들(ARIMA models) 17.5.1 AR 모형(AR models) 이 모형은 현재의 관측값을 과거의 관측값들의 함수형태로 나타내는 것이다. Definition 17.5 (자기회귀모형) AR(p) 차수 p를 갖는 자기회귀모형(autoregressive model, AR model)은 \\[x_{t}=\\phi_{1}x_{t-1}+\\phi_{2}x_{t-2} + \\cdots + \\phi_{p}x_{t-p}+w_{t}\\] 와 같은 형태를 갖는다. 여기서 \\(x_{t}\\)는 정상과정이며, \\(\\phi_{1},\\ldots , \\phi_{p}\\)는 상수이다. \\((\\phi_{p}\\neq 0)\\). 그리고 \\(w_{t}\\)는 보통 평균이 0이고 분산이 \\(\\sigma_{w}^{2}\\)인 백색잡음이라고 놓는다. 따로 언급하지 않으면, \\(x_{t}\\)의 평균은 0이라고 둔다. 만약 평균이 0이 아니고 \\(\\mu\\)라고 할 때는 다음과 같이 \\(x_{t}\\) 대신 \\(x_{t}-\\mu\\)를 사용하여 \\[x_{t}-\\mu = \\phi_{1}(x_{t-1}-\\mu)+\\phi_{2}(x_{t-2}-\\mu) + \\cdots + \\phi_{p}(x_{t-p}-\\mu)+w_{t}\\] 또는 \\(\\alpha=\\mu(1-\\phi_{1}-\\cdots - \\phi_{p})\\)로 놓아 \\[x_{t}=\\alpha + \\phi_{1}x_{t-1}+\\phi_{2}x_{t-2} + \\cdots + \\phi_{p}x_{t-p}+w_{t}\\] AR 모형이 시계열 회귀분석의 정의와 유사하므로 자기회귀(autoregression)라는 이름이 붙은 것이다. 그러나 모형을 적용하기엔 어려운데 \\(x_{t-1}, \\ldots, x_{t-p}\\)는 무작위 요인들인데, \\(\\mathbf{z}_{t}\\)는 고정된 요인이었기 때문이다. 일반적으로 AR과정의 ACF는 지수적으로 감소하며, PACF는 AR과정의 차수에 해당되는 차수 이후에는 0이 되는 성질을 갖고 있다. par(mfrow=c(3,2)) ARsim01 &lt;- arima.sim(list(order=c(1,0,0), ar=.9), n=100) ARsim02 &lt;- arima.sim(list(order=c(1,0,0), ar=-.9), n=100) plot(ARsim01, ylab=&quot;x&quot;, main=(expression(AR(1)~~~phi==+.9))) plot(ARsim02, ylab=&quot;x&quot;, main=(expression(AR(1)~~~phi==-.9))) acf(ARsim01); acf(ARsim02); pacf(ARsim01); pacf(ARsim02) FIGURE 17.6: Simulated AR model. 17.5.2 MA 모형(MA models) AR과정과 더불어 생각해 볼 수 있는 모형으로 이동평균모형(moving average model, MA model)이라는 것이 있다. \\(q\\)차 MA 모형은 \\(\\text{MA}(q)\\)로 보통 쓰며 백색 잡음 \\(w_{t}\\)가 선형결합 된 것을 관찰한다고 생각한다. Definition 17.6 (이동평균모형) 차수 \\(q\\)를 갖는 이동평균모형(moving average model)은 다음과 같이 정의된다. \\[x_{t}=w_{t}+\\theta_{1}w_{t-1}+\\theta_{2}w_{t-2}+\\ldots \\theta_{q}w_{t-q}.\\] 이때 \\(w_{t}\\sim \\text{WM}(0,\\sigma_{w}^{2})\\)이며 \\(\\theta_{1},\\ldots, \\theta_{q}(\\theta_{q}\\neq 0)\\)은 모수들이다. 또한 다음과 같이 이동평균작용소(moving average operator)를 정의하여 식을 간단히 쓸 수 있다. Definition 17.7 (이동평균작용소) 이동평균작용소(moving average operator) \\(\\theta(B)\\)는 \\[\\theta(B)=1+\\theta_{1}B+\\theta_{2}B^{2}+\\ldots +\\theta_{q}B^{q}\\] 로 정의된다. 이동평균작용소를 이용해 \\(\\text{MA}(q)\\)과정을 다시쓰면 다음과 같다. \\[x_{t}=\\theta(B)w_{t}.\\] Example 17.1 (MA(1)과정) MA과정 중에서 가장 간단한 모형으로 MA(1) 과정이 있으며 다음과 같이 쓴다. \\[x_{t}=w_{t}+\\theta w_{t-1}.\\] 그러면 \\(E(x_{t})=0\\)이다. 이것의 자기공분산함수는 다음과 같다. \\[ \\gamma(h) = \\begin{cases} (1+\\theta^{2})\\sigma_{w}^{2} &amp; h=0,\\\\ \\theta \\sigma_{w}^{2} &amp; h=1,\\\\ 0 &amp; h&gt;1. \\end{cases} \\] ACF는 다음과 같다. \\[ \\rho(h) = \\begin{cases} \\frac{\\theta}{(1+\\theta^{2})} &amp; h=1,\\\\ 0 &amp; h&gt;1. \\end{cases} \\] 한편 모든 \\(\\theta\\)에서 \\(|\\rho(1)|\\leq 0.5\\)이다. 그리고 \\(x_{t}\\)는 \\(x_{t-1}\\)과는 연관되어 있지만, \\(x_{t-2}, x_{t-3},\\ldots\\)등과는 연관되어 있지 않다. 이는 \\(AR(1)\\)과정에서 \\(x_{t}\\)와 \\(x_{t-k}\\) 사이의 상관관계가 0이 되지 않는 것과는 대조적이다. 예를 들어 \\(\\theta=0.9\\)일 때 \\(x_{t}\\)와 \\(x_{t-1}\\)은 양의 상관관계를 갖으며 \\(\\theta_{1}=0.497\\)이다. 한편 \\(\\theta=-0.9\\)일 때에는 \\(x_{t}\\)와 \\(x_{t-1}\\)은 음의 상관관계를 갖으며 \\(\\theta_{1}=-0.497\\)이다. MA과정의 PACF는 AR과정의 ACF 형태와, MA과정의 ACF는 AR과정의 PACF 형태와 같다. 참고로 유한 개의 항을 가지는 MA과정은 항상 정상과정이므로 AR과정과는 달리 유한차수의 MA과정에 대해서는 정상성 조건을 논의할 필요가 없다. par(mfrow=c(3,2)) MAsim01 &lt;- arima.sim(list(order=c(0,0,1), ma=.9), n=100) MAsim02 &lt;- arima.sim(list(order=c(0,0,1), ma=-.9), n=100) plot(MAsim01, ylab=&quot;x&quot;, main=(expression(MA(1)~~~theta==+.9))) plot(MAsim02, ylab=&quot;x&quot;,main=(expression(MA(1)~~~theta==-.9))) acf(MAsim01); acf(MAsim02); pacf(MAsim01); pacf(MAsim02) FIGURE 17.7: Simulated MA model. Example 17.2 (유일하지 않은 MA 모형들과 가역성) 한편 \\(\\sigma_{w}^{2}=1\\)이고 \\(\\theta=5\\)인 MA(1) 모형은 \\(\\sigma_{w}^{2}=25\\)이고 \\(\\theta=1/5\\)인 MA(1) 모형과 같은 autocovariance function을 갖는다. 즉 이 때는 \\[ \\gamma(h) = \\begin{cases} 26 &amp; h=0,\\\\ 5 \\sigma_{w}^{2} &amp; h=1,\\\\ 0 &amp; h&gt;1. \\end{cases} \\] 이다. 즉 다음 두 MA(1) 과정 \\[x_{t}=w_{t}+\\frac{1}{5}w_{t-1}, \\qquad{w_{t}\\stackrel{\\text{i.i.d}}{\\sim}\\mathcal{N}(0,25)}\\] \\[y_{t}=v_{t}+5v_{t-1}, \\qquad{v_{t}\\stackrel{\\text{i.i.d}}{\\sim}\\mathcal{N}(0,1)}\\] 은 같은 것이다. 우리는 시계열 \\(x_{t}\\), \\(y_{t}\\)만 관찰할 수 있고 잡음들 \\(w_{t}\\), \\(v_{t}\\)은 관찰 못하므로 이들을 구분해낼 수 없다. 편의를 위해 \\(x_{t}\\)와 \\(w_{t}\\)의 역할을 바꾸면 MA(1) 모형을 \\[w_{t}=-\\theta w_{t-1}+x_{t}\\] 로 쓸 수 있다. 이러면 AR 모형처럼 되고, \\(|\\theta|&lt;1\\)인 조건을 적용시키면 \\(w_{t}=\\sum_{j=0}^{\\infty}(-\\theta)^{j}x_{t-j}\\)임을 알 수 있다. 따라서 여러 가지 MA 모형이 있을 경우, 가역(invertible)한 \\(\\sigma_{w}^{2}=25\\)이고 \\(\\theta=1/5\\) 모형을 고르게 된다. 17.5.3 ARMA 모형(ARMA models) 비정상 시계열 모형 중 하나로, 차분이나 변환을 통해 AR, MA 또는 이 둘을 합한 ARMA 모형으로 정상화 시켜 모델링한다. It also possible to obtain a homogeneous difference equation directly in terms of \\(\\gamma(h)\\). First, we write \\[ \\begin{eqnarray} \\gamma(h)&amp;=&amp;\\text{cov}(x_{t+h},x_{t})\\\\ &amp;=&amp;\\text{cov}(\\sum_{j=1}^{p}\\phi_{j}x_{t+h-j}+\\sum_{j=0}^{q}\\theta_{j}w_{t+h-j},x_{t})\\\\ &amp;=&amp;\\sum_{j=1}^{p}\\phi_{j}\\gamma(h-j)+\\sigma_{w}^{2}\\sum_{j=h}^{q}\\theta_{j}\\psi_{j-h}, h \\geq 0. \\end{eqnarray} \\] general homoegeneous equations for the ACF of the ARMA process \\[\\gamma(h)-\\phi_{1}\\gamma(h-1)-\\cdots - \\phi_{p}\\gamma(h-p)=0, h\\geq \\max(p,q+1)\\] 17.5.3.1 ARMA 모형의 추정(estimation of ARMA models) Definition 17.8 (Yule-Walker equations) \\[\\gamma(h)=\\phi_{1}\\gamma(h-1)+\\cdots +\\phi_{p}\\gamma(h-p), h=1,2,\\ldots, p, \\] \\[\\sigma_{w}^{2}=\\gamma(0)-\\phi_{1}\\gamma(1)-\\cdots - \\phi_{p}\\gamma(p).\\] Matrix notation으로는 \\[\\Gamma_{p}\\phi=\\gamma_{p}, \\sigma_{w}^{2}=\\gamma(0)-\\phi&#39;\\gamma_{p}\\] 이며 \\(\\Gamma_{p}=\\{ \\gamma (k-j) \\}_{j,k=1}^{p}\\)는 \\(p\\times p\\) 행렬이며 \\(\\phi=(\\phi_{1},\\ldots , \\phi_{p})&#39;\\)는 \\(p\\times 1\\) 벡터이며 \\(\\gamma(p)=(\\gamma(1),\\ldots ,\\gamma(p))&#39;\\)는 \\(p\\times 1\\) 벡터이다. 17.5.4 ARIMA 모형(ARIMA models) "],
["17-6-arima-seasonal-arima-models.html", "17.6 계절성이 있는 ARIMA 모델링(seasonal ARIMA models)", " 17.6 계절성이 있는 ARIMA 모델링(seasonal ARIMA models) 시계열이 일정한 계절적인 주기를 가지고 변할 때 사용하는 분석 방법으로는 삼각함수 또는 지시함수를 이용한 회귀모형, 계절형 지수평활법 등이 있다. 이러한 방법들은 계절형 시계열이 \\[x_{t}=T_{t}+S_{t}+C_{t}+I_{t}\\] 와 같이 서로 독립적인 여러 성분들로 구성되어 있을 때 사용 가능하다고 한다. \\(T_{t}\\): 추세성분 \\(S_{t}\\): 계절성분 \\(C_{t}\\): 순환성분 \\(I_{t}\\): 불규칙성분 각 성분들은 회귀분석 또는 이동평균법 등을 이용한 전통적인 분해법에 의해 분석할 수 있다. 그러나 이러한 분석법은 시계열을 구성하고 있는 성분들이 결정적이며 서로 독립이라는 가정 하에서 출발하고 있는데, 우리가 접하는 시계열들은 그 구성성분들이 확률적이거나 다른 성분들과 상관이 있는 경우가 많다. 이러한 경우에는 확률적 분석 방법인 ARIMA를 이용한 분석을 한다. "],
["17-7-coherency-section-3-9.html", "17.7 Coherency (section 3.9)", " 17.7 Coherency (section 3.9) 결맞음(coherency) 분석은 두 자료의 관계를 quantify하기 위해 많이들 사용한다. 신호 사이의 결맞음 추정은 중요햐며 "],
["17-8-self-similar-process.html", "17.8 Self-Similar Process", " 17.8 Self-Similar Process "],
["17-9-linear-filter.html", "17.9 선형 필터(linear filter)", " 17.9 선형 필터(linear filter) 이 절의 내용은 (Shumway and Stoffer 2010)를 참고하였다. 이전의 많은 예제들은 시계열에서 분산 또는 파워의 분포를 선형 변환을 만듬으로써 변형시킬 수 있는 가능성에 대한 힌트를 제시했다. 여기서는 선형 필터가 시계열로부터 신호를 어떻게 뽑아내는지에 대해 설명한다. 선형 필터는 시계열 자료의 스펙트럼 특성을 변형시켜 예측 가능하게끔 한다고 한다. 선형필터는 특정화한 계수들 \\(a_{j}, j=0,\\pm 1, \\pm 2, \\ldots\\)를 사용한다. 이것은 투입된 시계열 \\(x_{t}\\)를 다음 관계를 통해 \\[y_{t}=\\sum_{j=-\\infty}^{\\infty}a_{j}x_{t-j}, \\sum_{j=-\\infty}^{\\infty}|a_{j}| &lt;\\infty\\] \\(y_{t}\\)라는 시계열로 변화시킨다. 통계 용어로 이 식은 convolution에 해당한다. 이 계수들은 특별히 임펄스 응답 함수(impulse response function)이라고 부른다. References "],
["18-transfer.html", "Chapter 18 전이함수모형", " Chapter 18 전이함수모형 시차회귀분석(lagged regression) 입력시계열과 출력시계열로 사용되는 시계열 사이의 관계를 회귀모형의 형태로 표현한 것을 전이함수(transfer function)라고 하며, 이 떄의 모형을 전이함수모형(transfer function model)이라고 한다. 일반적으로 전이함수 모형은 입력시계열이 출력시계열에는 영향을 미치나 반대의 영향은 없다는 가정 하에서 사용한다. 만약 출력시계열도 입력시계열에 영향을 미치는 경우에는 전이함수 모형 대신 벡터 ARIMA 모형을 이용한 분석을 한다. \\[\\begin{equation} y_{t}=\\sum_{j=0}^{\\infty}\\alpha_{j}x_{t-j}+\\eta_{t}=\\alpha(B)x_{t}+\\eta_{t} \\tag{18.1} \\end{equation}\\] 라고 모형을 세우자. 이 때 \\(x_{t-j}\\)는 입력시계열, \\(\\eta_{t}\\)는 잡음과정이 되며 \\[\\alpha(B)=\\sum_{j=0}^{\\infty}\\alpha_{j}B^{j}\\] 는 전이함수가 된다. 이 때 \\(\\alpha_{j}\\)를 충격반응가중값(impulse response weight)이라고 부른다. Box와 Jenkins에 따르면, \\(x_{t}\\)와 \\(\\eta_{t}\\)에 ARIMA모형을 적합한다. 이 때 \\[\\phi(B)x_{t}=\\theta(B)w_{t} \\text{ and }\\] \\[\\phi_{\\eta}(B)\\eta_{t}=\\theta_{\\eta}(B)z_{t}\\] 로 표현할 수 있다. 이 때 \\(w_{t},z_{t}\\)는 독립이고 분산이 \\(\\sigma_{w}^{2}\\), \\(\\sigma_{z}^{2}\\)인 백색잡음과정이다. Box와 Jenkins는 \\(\\alpha_{j}, j=1,2,\\ldots\\)의 형태로 systematic patteren들이 관찰될 수 있고 이들을 a ratio of polynomials involving a small number of coefficients, along with a specified delay \\(d\\)로 표현할 수 있다고 한다. 따라서 \\[\\alpha(B)=\\frac{\\delta (B)B^{d}}{\\omega(B)}\\] 로 표현할 수 있고(이렇게 표현하면 추정해야 할 모수의 숫자를 줄일 수 있다고 한다), 여기서 \\[\\omega(B)=1-\\omega_{1}B-\\omega_{2}B^{2}-\\cdots -\\omega_{r}B^{r}\\] 이며 \\[\\delta(B)=\\delta_{0}+\\delta_{1}B+\\cdots +\\delta_{s}B^{s}\\] 들이 지시연산자가 된다. 식 ((18.1))를 정리하면 \\[\\tilde{y}_{t}=\\frac{\\phi(B)}{\\theta(B)}y_{t}=\\alpha(B)w_{t}+\\frac{\\phi(B)}{\\theta(B)}\\eta_{t}=\\alpha(B)w_{t}+\\tilde{\\eta}_{t}\\] 를 얻게 된다. 이 때 \\(\\alpha(B)=\\sum_{j=0}^{\\infty}\\alpha_{j}B^{j}\\): 전이함수 \\(\\tilde{\\eta}_{t}\\): 변환된 잡음으로 \\(w_{t}\\)와 독립 \\(\\frac{\\phi(B)}{\\theta(B)}\\): 선형필터(linear filter)라 부름 \\(w_{t}\\): 사전백색화된 input series \\(\\tilde{y}_{t}\\): 변환된 output series 전이함수모형의 기본 가정은 입력시계열과 반응시계열이 모두 정상시계열이라는 것이다. 따라서 먼저 분석에 사용될 시계열들이 정상성을 갖는지 여부를 판단해야 한다. "],
["18-1-stability-and-causality.html", "18.1 안정성과 인과성(stability and causality)", " 18.1 안정성과 인과성(stability and causality) (조신섭 교수님 책 참고) "],
["18-2-cross-covariance-function.html", "18.2 교차상관함수(cross-covariance function)", " 18.2 교차상관함수(cross-covariance function) 전이함수의 형태를 식별하기 위해서는 충격반응가중값을 먼저 구해야 하는데, 이를 위해 두 개의 시계열 사이의 상관의 정도와 방향을 나타내는 교차상관함수를 이용한다. Definition 18.1 (교차상관함수) 정상인 두 시계열 \\(X_{t}\\)와 \\(Y_{t}\\) 사이의 교차상관함수는 \\[\\gamma_{XY}(t)=E[(X_{t}-\\mu_{X})(Y_{t+k}-\\mu_{Y})], \\qquad{k=0,\\pm 1, \\pm 2, \\ldots}\\] 이다. 단 모든 \\(t\\)에 대해 \\(\\mu_{X}=E[X_{t}]\\), \\(\\mu_{Y}=E[Y_{t}]\\)이다. 교차상관함수의 성질 중 중요한 것은 자기상관함수와는 달리 대칭이 아니라는 점이다. 따라서 교차상관함수는 자기상관함수와는 달리 상관의 정도와 영향을 미치는 방향을 같이 측정한다는 점이 특징이다. Definition 18.2 (교차상관계수) 정상인 두 시계열 \\(X_{t}\\)와 \\(Y_{t}\\) 사이의 교차상관함수는 \\[\\rho_{XY}(k)=Corr(X_{t},Y_{t+k})=\\frac{\\gamma_{XY}(k)}{\\sigma_{X}\\sigma_{Y}}=\\frac{\\gamma_{XY}(k)}{\\sqrt{\\gamma_{X}(0)\\gamma_{Y}(0)}}\\] 으로 정의한다. 앞선 모형에서 \\(\\tilde{y}_{t}\\)와 \\(w_{t}\\)의 교차상관계수는 \\[\\gamma_{\\tilde{y} w}(h)=E[\\tilde{y}_{t} w_{t}]=E[\\sum_{j=0}^{\\infty}\\alpha_{j}w_{t+h-j}w_{t}]=\\sigma_{w}^{2}\\alpha_{h}\\] 로 쓸 수 있다. 이는 \\(j=h\\)일 때를 제외하고 백색잡음의 ACF가 0임을 이용하는 것이다. 이 관계식을 보면 \\[\\hat{\\alpha}_{h}=\\frac{\\hat{\\gamma}_{\\tilde{y}w}(h)}{\\hat{\\sigma}_{w}^{2}}\\] 임을 유추해 낼 수 있다. "],
["18-3-fitting-transfer-function-model.html", "18.3 전이함수모형의 적합(fitting transfer function model)", " 18.3 전이함수모형의 적합(fitting transfer function model) 먼저 분석에 이용될 시계열들이 정상이라는 가정을 만족하도록 정상화한다. 전이함수모형의 식별을 위해 시계열을 사전백색화(prewhitening)한다. 잠정적인 전이함수모형을 추정한다. 장차를 이용하여 오차모형을 식별하고 추정한다. "],
["19-kalman.html", "Chapter 19 칼만 필터", " Chapter 19 칼만 필터 자연계에서 나타나는 시계열은 많은 경우, 직전의 상태와 밀접하 관계를 갖으면서 끊임없이 변화하는 형태를 보이고 있어 선형모형으로는 예측의 정확도를 높이는 데 한계가 있을 때가 있다. 실제와 닮은 모형이 더 우수하다는 원칙에서 동적모형에 대한 연구와 적용이 예보의 정확성을 높여줄 것이다. 칼만필터(kalman filter)란 공정제어를 위해 칼만(Kalman)이 1960년 제안한 알고리즘으로, 시간의 흐름에 따라 모형식이 변화하는 동적 모형(dynamic model)으로 선형과 비선형의 중간 형태를 지니고 있다고 한다. 예측 문제도 해결하는 등 여러 가지 장점이 있어 경제 에측, 신호 처리, 기상 예보 등 응용 범위가 넓은 동적 모형이라고 한다. 칼만 필터 모형은 다음의 생성 구조로 이루어진다. 초기치가 필요하다. 주어진 상태방정식(state equation)에 의해 전 상태로부터 내적오차와 합하여 현 상태값이 결정되며, 주어진 출력방정식(output equation)에 의해 고려된 입력변수값과 동적회귀계수 역할을 하는 현 상태의 내적과 출력오차의 합 형태로 관측치가 생성된다는 가정 아래 구성된 모형으로, 새로운 관측치가 얻어지면, 모형이 최신화(updating)되도록 알고리즘이 주어져야 한다. \\(F_{t}\\), \\(G_{t}\\), \\(W\\), \\(V\\), \\(m_{0}\\), \\(C_{0}\\), \\(t=1,2,\\ldots,\\) 가 주어진 경우 다음의 생성식으로 이루어진 모형식을 칼만필터 모형이라고 한다. \\[\\text{(초기 분포) } \\theta_{0} \\sim \\mathcal{N}(m_{0},C_{0})\\] \\[\\text{(상태방정식) } \\theta_{t}=G_{t}\\theta_{t-1}+w_{t}, \\qquad{w_{t} \\sim \\mathcal{N}(0,W)}\\] \\[\\text{(출력방정식) } Y_{t}=F_{t}\\theta_{t}+v_{t}, \\qquad{v_{t}\\sim \\mathcal{N}(0,V)}\\] 여기에서 \\(\\theta_{t}\\): 상태벡터(state vector) \\(G_{t}\\): 전이행렬(transition matrix) \\(w_{t}\\): 내적오차벡터(innovational error vector) \\(Y_{t}\\): 관측치(observation) \\(F_{t}\\): 입력벡터(input vector)로 상태벡터가 관측치에 영향을 주는 설명변수들로 이루어져있음 \\(v_{t}\\): 출력오차(output error) \\(\\theta_{t-1}\\)과 \\(w_{t}\\)는 독립이며, \\(\\theta_{t}\\)는 \\(v_{t}\\)와 독립이고, 두 오차는 서로 독립이다. 칼만필터 모형은 두 개 이상의 선형식의 모임으로 연결되어 있으므로 전체적으로는 비선형적 특성을 지니고 있고, 각 식은 선형모형이므로 모형의 설명력과 예측력이 우수하며, 이론적 전개가 용이하다. Example 19.1 (칼만필터 모형의 예) 시간에 따라 생성되는 종속변수가 하나이며 설명변수가 두 개인 선형모형을 생각해보자. 회귀모형은 회귀계수가 미지의 상수인 경우로 정적 모형이다. 즉 \\[Y_{t}=m_{0}+m_{1}X_{1t}+m_{2}X_{2t}+v_{t}\\] 인 형태가 된다. 회귀동적모형은 회귀계수가 시간에 따라 변화하는 경우로 동적모형이다. 즉 \\[Y_{t}=m_{0t}+m_{1t}X_{1t}+m_{2t}X_{2t}+v_{t}\\] 인 형태가 되며 각 회귀계수들을 함수형태로 추정해 주어야 한다. 회귀동적선형모형은 회귀계수가 전 시점의 회귀계수에 의하여 결정되는 경우로 회귀동적모형의 특수한 경우가 된다. 예를 들어, 전이행렬이 단위행렬인 경우(상태벡터가 임의보행인 경우) \\[Y_{t}=m_{0t}+m_{1t}X_{1t}+m_{2t}X_{2t}+v_{t}\\] 그리고 \\[ \\theta_{t} = \\begin{pmatrix} m_{0t} \\\\ m_{1t} \\\\ m_{2t} \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} m_{0,t-1} \\\\ m_{1,t-1} \\\\ m_{2,t-1} \\end{pmatrix} + \\begin{pmatrix} w_{0t} \\\\ w_{1t} \\\\ w_{2t} \\end{pmatrix} \\] 이와 같은 형태를 지닌다. "],
["19-1-types-of-kalman-filter.html", "19.1 칼만필터 모형의 종류(types of Kalman filter)", " 19.1 칼만필터 모형의 종류(types of Kalman filter) 19.1.1 은닉 마르코프 모형(hidden Markov model) 오차항이 없는 칼만필터 모형으로 다음과 같다. \\[ \\begin{cases} \\mu_{t}=G\\mu_{t-1} \\\\ Y_{t}=F\\mu_{t}.\\\\ \\end{cases} \\] 여기서 전이행렬 \\(G\\)와 출력행렬 \\(F\\)는 시간에 따라 변화하지 않으므로 상태방정식은 확률과정에서의 상태벡터 \\(\\mu_{t}\\)의 전이행렬이 \\(G\\)인 마르코프 연쇄로 생각할 수 있다. 관측치 \\(Y_{t}\\)만 주어져 있고 \\(\\mu_{t}\\)는 모르는 경우 모수 \\(G\\)와 \\(F\\)를 추정하여 생성구조를 완성하는 과정을 이룬다. 은닉 마르코프 모형은 범주형 자료에도 적용이 가능하며, 신호처리에 바탕을 두고 있는 음성인식, 영상인식, 문장인식에 널리 사용되고 있는 통계적 기법이다. 19.1.2 일차 칼만필터 모형(simple Kalman filter model) 일차 칼만필터 모형(simple Kalman filter model)은 오차항을 포함한 칼만필터 모형 중 가장 간단한 형태로 \\(t\\) 시점의 상태열이 임의보행과정(random walk)으로 직전 상태값 주위에서 흔들리며 변화할 때 사용한다. \\[ \\begin{cases} \\mu_{t}=\\mu_{t-1}+w_{t} \\\\ Y_{t}=\\mu_{t}+v_{t}.\\\\ \\end{cases} \\] 19.1.3 회귀 칼만필터 모형(regression Kalman filter model) 회귀 칼만필터 모형(regression Kalman filter model)은 입력변수(설명변수)가 있는 경우에 사용하는 동적모형으로 계수(상태열)가 시간에 따라 변화하는 동적 계수가 된다. \\[ \\begin{cases} \\theta_{t}=\\theta_{t-1}+w_{t} \\\\ Y_{t}=F_{t}\\theta_{t}+v_{t}.\\\\ \\end{cases} \\] 19.1.4 일반적 칼만필터 모형(general Kalman filter model) 일반적 칼만필터 모형(general Kalman filter model)은 회귀 칼만필터 모형에서 동적 계수가 임의보행이 아닌 경우에 전이행렬을 고려하는 동적모형이다. \\[ \\begin{cases} \\theta_{t}=G_{t}\\theta_{t-1}+w_{t} \\\\ Y_{t}=F_{t}\\theta_{t}+v_{t}.\\\\ \\end{cases} \\] 19.1.5 확장된 칼만필터 모형(extended Kalman filter model) 칼만필터 모형에서 상태방정식과 출력방정식이 선형모형이 아닌 비선형모형인 경우를 확장된 칼만필터 모형(extended Kalman filter model)이라고 한다. 추정과 최시노하는 주어진 식을 선형화하여 해결하며, 시스템에 대한 물리적 이해가 필요하다. \\[ \\begin{cases} \\theta_{t}=f(\\theta_{t-1},w_{t}) \\\\ Y_{t}=h(\\theta_{t},v_{t})\\\\ \\end{cases} \\] "],
["19-2-updating-algorithm.html", "19.2 최신화 알고리즘(updating algorithm)", " 19.2 최신화 알고리즘(updating algorithm) 칼만필터링(Kalman filtering)은 칼만필터 모형의 상태열 \\(\\{ \\theta_{t}\\}\\)의 추정에 사용된다. 칼만필터링은 다음의 특징을 지니고 있어 이공계 분야 모델링에 많이 응용된다. 미지의 상태열 \\(\\{\\theta_{t}\\}\\)를 추정하는 반복처리과정이다. 동적처리기법이다. 즉 시간의 흐름에 따라 진행하면서 과거와 현재의 출력값들을 보고 현재의 상태를 추정해간다. 평균제곱오차를 최소로 하는 최적 상태열을 추정하는 통계적 이론을 바탕으로 한다. 체계적 기법(systematic method)이다. 즉 일단 칼만필터 모형이 만들어지면 칼만필터 알고리즘을 쉽게 사용할 수 있다. 나쁜 초기치의 영향이 오래가지 않는다. 즉 로버스트하다. 프로그래밍이 쉽다. 칼만필터링은 다변량 정규분포이론에 근거하며 최적 상태값을 추정하는 아래와 같은 동적순환과정(dynamic recursive procedure)으로 이루어진다. 이를 최신화 알고리즘(updating algoritm)이라고 한다. \\(t=1,2,\\ldots\\)로 변화시키며 \\(t-1\\)시점까지의 모든 정보 \\(D_{t}\\)에 의한 \\(\\theta_{t-1}\\)의 분포 \\[\\theta_{t-1}|Y_{t-1} \\sim \\mathcal{N}(m_{t-1},C_{t-1})\\] \\(t\\)시점에서의 \\(\\theta_{t}\\)의 사전분포: 상태방정식 \\(\\theta_{t}=G_{t}\\theta_{t-1}+w_{t}, w_{t} \\sim \\mathcal{N}(0,W_{t})\\)에 의하여, \\[\\theta_{t}|D_{t-1} = (G_{t}\\theta_{t-1}+w_{t})|D_{t-1}\\sim \\mathcal{N}(a_{t},R_{t})\\] 여기에서 \\(a_{t}=G_{t}m_{t-1}, R_{t}=G_{t}C_{t-1}G_{t}&#39;+W_{t}\\)이다. "],
["19-3-dynamic-linear-model.html", "19.3 동적선형모형(dynamic linear model)", " 19.3 동적선형모형(dynamic linear model) "],
["19-4-r-r-dlm.html", "19.4 R-예제(R-dlm)", " 19.4 R-예제(R-dlm) "],
["20-spectral.html", "Chapter 20 스펙트럼 분석", " Chapter 20 스펙트럼 분석 이 절의 내용은 (Shumway and Stoffer 2010)를 참고하였다. 시간영역의 분석 방법이 자기상관함수 등을 이용해 시간에 따른 상관 정도를 분석하고 변수들 사이의 관계를 가장 잘 설명해 주는 모형을 찾는 데 반해, 진동수영역의 분석 방법은 시계열이 다양한 주기를 갖는 성분들(주로 싸인과 코싸인)의 선형결합으로 표현될 수 있다는 성질을 이용해 어떤 주기성분이 중요한 역할을 하는지 알아보는 데 초점을 둔다. 진동수영역의 분석에서는 자기공분산의 푸리에변환(Fourier transform)으로 정의되는 스펙트럼(spectrum)을 추정하여 각 진동수에 대응되는 주기성분들의 선형결합으로 시계열을 표현한다. 즉, 시계열이 긴 주기 또는 짧은 주기를 갖는지를 각 주기성분들의 기여도를 이용하여 설명 및 분석하는 데, 이 기여도를 자기공분산의 형태로 표현하는 것이 스펙트럼분석(spectral analysis)이다. References "],
["20-1-cyclical-behavior-and-periodicity.html", "20.1 순환 움직임과 주기성(cyclical behavior and periodicity)", " 20.1 순환 움직임과 주기성(cyclical behavior and periodicity) 다음과 같은 주기과정(periodic process)을 생각해보자. \\[x_{t}=A\\cos(2\\pi\\omega t + \\phi), \\qquad{\\text{for } t=0,\\pm 1, \\pm 2, \\ldots,}\\] 여기서 \\(\\omega\\): 진동수 지수(frequency index) (단위 시간 당 순환의 갯수, 일례로 \\(\\omega=1/50\\)이면 50 포인트마다 한 번씩 주기가 돈다는 뜻이다) \\(A\\): 진폭(amplitude) (신호의 높이 결정) \\(\\phi\\): 위상(phase) (코사인 함수의 시작 지점) 이다. 다음과 같은 삼각함수 공식 \\(\\cos (\\alpha \\pm \\beta)= \\cos (\\alpha) \\cos (\\beta) \\mp \\sin(\\alpha)\\sin(\\beta)\\)을 이용하면 위 식은 \\[\\begin{equation} x_{t}=U_{1}\\cos(2\\pi\\omega t) + U_{2}\\sin(2\\pi\\omega t) \\tag{20.1} \\end{equation}\\] 가 되며 \\(U_{1}=A\\cos \\phi\\), \\(U_{2}=-\\sin\\phi\\)는 종종 정규분포를 따르는 확률변수로 취급한다. 그리고 이 때 \\(A=\\sqrt{U_{1}^{2}+U_{2}^{2}}\\), \\(\\phi=\\tan^{-1}(-U_{2}/U_{1})\\)이다. 이 사실로부터, \\(A\\)와 \\(\\phi\\)가 독립인 확률변수면, \\(A^{2}\\sim \\chi_{2}^{2}\\), \\(\\phi \\sim \\text{Unif}(-\\pi, \\pi)\\)이며 \\(U_{1}\\)과 \\(U_{2}\\)는 독립인 표준 정규분포를 따른다. 만약 우리가 \\(U_{1}\\), \\(U_{2}\\)를 평균 0, 분산 \\(\\sigma^{2}\\)인 서로 관련이 없는 확률변수라고 두면 식 (20.1)에 있는 \\(x_{t}\\)는 평균이 \\(E(x_{t})=0\\)인 정상과정이 된다. 앞선 랜덤과정(random process)는 진동수 \\(\\omega\\)를 모수로 하여 표현할 수 있다. \\(\\omega=1\\)일 경우 이 시계열은 1 시간 단위 당 1 사이클을 갖게 된다. 일반적으로 어떤 주기를 결정하기 위해선 적어도 두 개의 관측점이 필요한다. 그래서 가장 관심이 있는 높은 주기는 1 점당 0.5 주기가 되는데 이를 중첩 주파수(folding frequency)라고 부른다. 그런데 높은 진동수는 낮은 진동수에서도 나타나는데 이를 앨리어싱(aliasing)이라고 한다. 이번엔 다양한 진동수와 진폭을 갖는 주기 수열들의 혼합으로 식 (20.1)를 일반화시켜보자. \\[\\begin{equation} x_{t}=\\sum_{k=1}^{q}[U_{1l}\\cos(2\\pi\\omega_{k} t) + U_{k2}\\sin(2\\pi\\omega_{k} t)]. \\tag{20.2} \\end{equation}\\] 이때 \\(U_{k1},U_{k2},\\ldots, k=1,\\ldots, q\\)는 평균이 0이고 분산이 \\(\\sigma_{k}^{2}\\)인 독립인 확률변수이고 \\(\\omega_{k}\\)는 서로 다른 주파수를 나타낸다. 식 (20.2)는 과정을 분산이 \\(\\sigma_{k}^{2}\\), 주파수가 \\(\\omega_{k}\\)인 독립 성분들의 합으로 나타내는 것이다. 이때 이 과정의 공분산은 다음과 같이 표현할 수 있다고 한다. \\[\\begin{equation} \\gamma_{x}(h)=\\sum_{k=1}^{q}\\sigma_{k}^{2}\\cos(2\\pi \\omega_{k}h). \\tag{20.3} \\end{equation}\\] 이 표현으로부터 공분산함수는 주기성분들에 분산 \\(\\sigma_{k}^{2}\\)에 비례하는 가중치의 합으로 표현됨을 알 수 있다. 따라서, \\(x_{t}\\)가 평균이 0이고 분산이 \\[\\begin{equation} \\gamma_{x}(0)=\\text{var}(x_{t})=\\sum_{k=1}^{q}\\sigma_{k}^{2} \\tag{20.4} \\end{equation}\\] 인 정상과정이라면 이 분산은 각 성분들의 분산의 합임을 알 수 있다. 가장 단순한 경우로, 우리가 만약 \\(U_{k1}=a_{k}\\), \\(U_{k2}=b_{k}, k=1,\\ldots, q\\)를 관찰했다고 하자. 그러면 \\(k\\)번쨰 분산 \\(\\sigma_{k}^{2}\\) (또는 \\(\\text{var}(x_{t})\\))의 추정은 표본분산 \\(S_{k}^{2}=a_{k}^{2}+b_{k}^{2}\\)을 이용해 할 수 있을 것이다. 더 나아가 우리가 \\(x_{t}\\)의 총 분산, 즉 \\(\\gamma_{x}(0)\\)은 다음과 같이 표본분산들의 합으로 추정할 수 있을 것이다. \\[\\begin{equation} \\hat{\\gamma}_{x}(0)=\\text{var}(x_{t})=\\sum_{k=1}^{q}(a_{k}^{2}+b_{k}^{2}). \\tag{20.5} \\end{equation}\\] FIGURE 20.1: Periodic components and their sums. 다음 예제는 식 (20.2)에서 \\(q=3\\)일때의 예제다. Example 20.1 (주기 시계열) \\(t=1,\\ldots,100\\)까지 다음의 수열들을 생성해보자. \\[x_{t1}=2\\cos (2\\pi t 6/100) +3\\sin (2\\pi t 6 / 100)\\] \\[x_{t2}=4\\cos (2\\pi t 10/100) +5\\sin (2\\pi t 10 / 100)\\] \\[x_{t3}=6\\cos (2\\pi t 40/100) +7\\sin (2\\pi t 40 / 100)\\] 이들의 시계열들은 위 그림에 나타나있다. \\(x_{t1}\\)의 진폭은 \\(2^{2}+3^{2}=13\\)이다. 따라서 \\(x_{t1}\\)의 최대, 최소값은 \\(\\pm \\sqrt{13}=\\pm 3.61\\)이다. 마지막으로 \\[x_{t}=x_{t1}+x_{t2}+x_{t3}\\] 을 고려해본다. 이것의 그림은 위 그림의 오른쪽 아래에 있다. 스펙트럼 분석의 역할은 이렇게 섞여있는 주기 성분들을 분류하고 그들의 상대적 기여도를 계산하는 것이다. Autocovariance function (20.3)를 따라 식 (20.2)에 주어진 모형의 population을 만들어낼 수 있다. 앞으로는 자료 \\(x_{1},\\ldots , x_{n}\\)이 주어졌을 때 실제로 식 (20.4)를 어떻게 추정할 수 있는가에 대해 살펴볼 것이다. FIGURE 20.2: Periodogram of the above data. 앞선 예제의 피리오도그램을 계산해보자. 참고로 scaled periodogram은 다음과 같이 계산된다. Example 20.2 (추정과 피리오도그램) 어떤 시계열의 표본 \\(x_{1},\\ldots, x_{n}\\) (\\(n\\)은 홀수)이 있다고 하자. 그러면 우리는 다음과 같이 정확하게 쓸 수 있을 것이다. "],
["20-2-spetral-density.html", "20.2 스펙트럼 밀도(spetral density)", " 20.2 스펙트럼 밀도(spetral density) 스펙트럼 밀도(spectral density)는 기초적인 frequency domain tool 중 하나다. 스펙트럼 표현 정리(spectral representation theorem)은 정상시계열을 주기성분들로 분해하는 것에 대한 이론적 근거를 제공한다. Definition 20.1 (자기공분산함수의 스펙트럼 표현) 만약 \\(\\{x_{t} \\}\\)가 정상시계열이고 자기공분산 \\(\\gamma(h)=\\text{cov}(x_{t+h},x_{t})\\)를 갖는다면 스펙트럼 분포(spectral distribution)이라 불리는 유일한 단조증가 함수가 존재해 \\(F(-\\infty)=F(-1/2)=0\\)이고 \\(F(\\infty)=F(1/2)=\\gamma(0)\\)이며 \\[\\begin{equation} \\gamma(h)=\\int_{-1/2}^{1/2}e^{2\\pi i \\omega h}dF(\\omega) \\tag{20.6} \\end{equation}\\] 이다. 자기공분산함수가 absolutely summable일 경우 스펙트럼 분포함수는 absolutely continuous하며 \\(dF(\\omega)=f(\\omega)d\\omega\\)이고 식 (20.6)는 스펙트럼 밀도(spectral density)를 유도한다. Definition 20.2 (스펙트럼 밀도) 자기공분산함수 \\(\\gamma(h)\\)가 정상과정이며 \\[\\begin{equation} \\sum_{h=-\\infty}^{\\infty}|\\gamma(h)|&lt;\\infty \\tag{20.7} \\end{equation}\\] 를 만족한다고 하면 자기공분산함수는 다음과 같은 표현 \\[\\begin{equation} \\gamma(h)=\\int_{-1/2}^{1/2}e^{2\\pi i \\omega h}f(\\omega)d\\omega, h=0,\\pm 1,\\pm 2,\\ldots \\tag{20.8} \\end{equation}\\] 을 갖고, 스펙트럼 밀도(spetral density)는 그것의 역변환 \\[\\begin{equation} f(\\omega)=\\sum_{h=-\\infty}^{\\infty}\\gamma(h)e^{-2\\pi i \\omega h}, -1/2 \\leq \\omega \\leq 1/2 \\tag{20.9} \\end{equation}\\] 으로 정의한다. 스펙트럼 밀도는 확률밀도처럼 \\(\\gamma(h)\\)가 non-negative definite이므로 \\[f(\\omega) \\geq 0, \\qquad{\\forall\\omega}\\] 을 만족한다. 또한 정의로부터 \\[f(\\omega)=-f(\\omega)\\] 이며 이는 스펙트럼 밀도함수가 우함수임을 보여준다. 이런 우함수 성질 덕분에 우리는 보통 \\(0&lt;\\omega \\leq 1/2\\)인 \\(\\omega\\)에 대해서만 \\(f(\\omega)\\)를 그리게 된다. 더 나아가 식 (20.8)에 \\(h=0\\)을 넣으면 다음을 얻을 수 있다. \\[\\gamma(0)=\\text{var}(x_{t})=\\int_{-\\frac{1}{2}}^{\\frac{1}{2}}f(\\omega)d\\omega.\\] 이 말인 즉슨 총분산은 모든 주파수에서의 스펙트럼 분포의 적분 형태로 나타낼 수 있다는 것이다. 이제 자기공분산과 스펙트럼 분포가 같은 정보를 갖고 있다는 것이 분명해졌다. 그러나 그 정보는 다른 형태로 표현된다. 자기공분산 함수는 정보를 lag로 표현하고, 스펙트럼 분포에서는 같은 정보를 cycle을 이용해 표현한다. 또 한가지 중요한 사실은 식 (20.8)의 자기공분산 함수 \\(\\gamma(h)\\)와 식 (20.9)의 스펙트럼 밀도는 푸리에 변환의 짝이라는 것이다. 이것은 두 개의 스펙트럼 분포 \\(f(\\omega),g(\\omega)\\)가 존재해 \\[\\gamma_{f}(h)=\\int_{-\\frac{1}{2}}^{\\frac{1}{2}}f(\\omega)e^{2\\pi i\\omega h}d\\omega = \\int_{-\\frac{1}{2}}^{\\frac{1}{2}}g(\\omega)e^{2\\pi i\\omega h}d\\omega =\\gamma_{g}(h), \\qquad{\\forall 0,\\pm1, \\pm2,\\ldots}\\] 을 만족하면 \\[f(\\omega)=g(\\omega)\\] 라는 것이다. 마지막으로 식 (20.7)의 absolutely summable condition 식 (20.3)로 만족되어지지 않는다. 그러나 ARMA 모형에 대해서는 만족된다. Example 20.3 (백색잡음의 스펙트럼) 가장 쉬운 예제로 분산이 \\(\\sigma_{w}^{2}\\)인 uncorrelated 확률변수 \\(w_{t}\\)의 수열의 이론적인 power spectrum을 구해볼 수 있다. 이러한 경우의 자기공분산함수는 \\[ \\gamma_{w}(h)= \\begin{cases} \\sigma_{w}^{2}, &amp; h\\neq 0\\\\ 0, &amp; h=0 \\end{cases} \\] 이므로 식 (20.9)로부터 \\[f_{w}(\\omega$)=\\sigma_{w}^{2}, \\qquad{-0.5\\leq \\omega \\leq 0.5}\\] 를 얻을 수 있다. 즉 백색잡음에서는 모든 진동수들의 기여도가 같다. 스펙트럼을 이용해 확률과정의 총분산(또는 total power)을 각 진동수별로 분해할 수 있다. 스펙트럼은 자기상관함수의 푸리에 변환이므로 자기상관함수와 일대일 관계에 있으며 다음의 성질을 가지고 있다. \\(f(\\omega)\\geq 0\\): 음의 값을 갖지 않는 연속 실수함수 \\(f(\\omega)=f(\\omega + 2\\pi)\\): 주기가 \\(2\\pi\\)인 주기함수 (\\(f(\\omega)=f(-\\omega)\\)인 우함수이므로 일반적으로 \\(0\\leq \\omega \\leq \\pi\\)일 때만 고려한다.) \\(f(\\omega)\\)는 확률과정의 분산분해(variance decomposition)으로 해석할 수 있으며, \\(f(\\omega)d\\omega\\)는 \\((\\omega, \\omega+d\\omega)\\)에 속하는 진동수들을 갖는 성분들의 분산에 대한 기여도를 의미한다. 다시 말해 스펙트럼이 어느 영역의 진동수에서 큰 값을 갖는다는 것은 해당 진동수들의 분산에 대한 기여도가 크다는 것을 의미하며, 이 진동수에 해당되는 주기성분이 시계열의 구성하는 데 가장 중요한 역할을 한다는 것을 의미한다. 스펙트럼과 자기공분산함수는 쌍을 이루어 존재하기 때문에 동일한 정보를 제공하는 것이다. 다만 자기공분산함수는 정보를 lag를 이용해 제공하고, 스펙트럼 밀도는 주기를 이용해 정보를 제공한다는 차이점이 있다. 어느 통계량이 더 유용한지는 사용하고자 하는 상황에 따라 다르다고 할 수 있다. "],
["20-3-periodogram-and-discrete-fourier-transform.html", "20.3 피리오도그램과 이산 푸리에 변환(periodogram and discrete Fourier transform)", " 20.3 피리오도그램과 이산 푸리에 변환(periodogram and discrete Fourier transform) Definition 20.3 (이산 푸리에 변환) 자료 \\(x_{1},\\ldots, x_{n}\\)이 주어졌을 때, 이산 푸리에 변환(discrete Fourier transform, DFT)은 \\[d(\\omega_{j})=\\frac{1}{\\sqrt{2}}\\sum_{t=1}^{n}x_{t}e^{-2\\pi i \\omega_{j}t}, j=0,1,\\ldots, n-1\\] 이며 이 때 도수(빈도, frequency) \\(\\omega = j/n\\)는 근본빈도(fundamental frequencies) 또는 푸리에(Fourier)라고 부른다. 때때로 이산 푸리에 변환의 역버전을 생각하는 것이 편리할 때도 있다. Definition 20.4 (이산 푸리에 변환의 역버전) \\[x_{t}=\\frac{1}{\\sqrt{2}}\\sum_{j=0}^{n-1}d(\\omega_{j})e^{2\\pi i \\omega_{j}t}, t=1,\\ldots, n.\\] 피리오도그램은 DFT의 squared modulus다. Definition 20.5 (피리오도그램) \\[I(\\omega_{j})=|d(\\omega_{j})|^{2}, j=0,1,2,\\ldots,n-1.\\] \\(I(0)=n\\bar{x}^{2}\\)이다. "],
["20-4-linear-filters.html", "20.4 선형 필터들(linear filters)", " 20.4 선형 필터들(linear filters) "],
["20-5-using-regression-to-discover-a-periodic-signal.html", "20.5 주기가 있는 시계열의 회귀분석(using regression to discover a periodic signal)", " 20.5 주기가 있는 시계열의 회귀분석(using regression to discover a periodic signal) 다음과 같은 모형 \\[x_{t}=A\\cos (2\\pi\\omega t + \\phi) + w_{t}\\] 을 생각해보자. \\(\\omega=1/50, A=2,\\phi=0.6\\pi, \\sigma_{w}=5\\)일 때 모형은 \\[x_{t}=2\\cos (2\\pi t /50 + 0.6 \\pi) + w_{t}\\] 가 되며 그림으로 출력하면 다음과 같다. FIGURE 20.3: Cosine wave with period 50 points (top) with standard Gaussian noise (middle) and with heavy Gaussian noise (bottom). 진동수 \\(\\omega=1/50\\)이 알려져 있다고 가정하자. 그러나 \\(A\\)와 \\(\\phi\\)는 모르는 모수라고 가정하자. 삼각함수 공식에 의해 \\[A\\cos (2\\pi \\omega t + \\phi)=\\beta_{1}\\cos (2\\pi \\omega t) + \\beta_{2}\\sin (2\\pi\\omega t)\\] 이며 \\(\\beta_{1}=A\\cos(\\phi), \\beta_{2}=-A\\sin(\\phi)\\)이다. 따라서 이 모형은 intercept term을 넣지 않은 일반적인 회귀분석으로 적합할 수 있다. "],
["20-6-quantile-periodogram.html", "20.6 분위수 피리오도그램(quantile periodogram)", " 20.6 분위수 피리오도그램(quantile periodogram) 분위 회귀분석에 숨어있는 가정은 시계열 \\(Y_{t}\\)의 \\(\\alpha\\)-분위수가 regressor와 선형 관계를 갖는다는 것이다. 즉 어떤 \\(\\boldsymbol{\\beta}_{0}\\neq\\mathbf{0}\\)에 대해 \\(\\lambda_{t}=\\mathbf{x}_{t}^{T}\\boldsymbol{\\beta}_{0}\\)이 성립한다는 것이다. 분위수 피리오도그램(quantile periodogram)에서는 분위수가 숨계진 주기를 포함하고 있는 상황에 관심이 있는 것이다. "],
["20-7-composite-quantile-periodogram.html", "20.7 복합 분위수 피리오도그램(composite quantile periodogram)", " 20.7 복합 분위수 피리오도그램(composite quantile periodogram) 20.7.1 스펙트럼의 추정: 피리오도그램(estimation of spectrum) 20.7.1.1 푸리에분석(Fourier analysis) 시계열이 관측되었을 때 이들을 진동수에서 정의된 주기성분들로 분해하는 방법을 푸리에분석(Fourier analysis)이라고 한다. 이를 통해 어느 진동수가 중요한 성분이지 따라서 어떤 주기가 시계열에서 중요한 역할을 하는지를 알아낼 수 있다. 20.7.1.2 피리오도그램(periodogram) 스펙트럼을 추정하는 방법을 이해하기 위해서는 피리오도그램(periodogram)에 대한 이해가 필요하다. 이 절의 서술은 (Lim 2013)을 참고하였다. 또 다른 참고자료로는 (Shumway and Stoffer 2010)이 있다. 다음과 같은 시계열 자료의 수열 \\(\\{Y_{1}, \\ldots, Y_{n}\\}\\)을 관측한다고 하자. 그러면 피리오도그램(periodogram) \\(I_{n}(\\omega)\\)는 \\[I_{n}(\\omega)=\\frac{1}{n}| \\sum_{i=1}^{n}Y_{i}e^{-it\\omega}|^{2}\\] 로 정의된다. 이 때 \\(\\omega\\in (0,\\pi)\\)는 진동수모수(frequency parameter)이다. \\(\\omega\\)가 푸리에 진동수(\\(\\omega=\\frac{2\\pi k}{n}, k\\in\\mathbb{Z}\\))일 때 이 피리오도그램은 \\[I_{n}(\\omega)=\\frac{n}{4}\\| \\tilde{\\boldsymbol{\\beta}}_{n}(\\omega)\\|^{2}\\] 으로 표현할 수 있다고 한다(Li 2008). 여기서 \\(\\| \\cdot \\|\\)은 벡터의 \\(l_{2}\\) 노름이며 \\(\\tilde{\\boldsymbol{\\beta}}_{n}(\\omega)\\)은 최소자승법 \\[\\tilde{\\boldsymbol{\\beta}}_{n}(\\omega)=\\text{arg}\\min_{\\boldsymbol{\\beta}\\in\\mathbb{R}^{2}}\\sum_{i=1}^{n}| Y_{i}-\\mathbf{x}_{t}^{T}(\\omega)\\boldsymbol{\\beta}|^{2}\\] 의 해다. 그리고 이 때 \\(\\mathbf{x}_{t}(\\omega)=(\\cos(\\omega t), \\sin (\\omega t))^{T}\\)로 harmonic regressor다. References "],
["20-8-r-r-periodogram.html", "20.8 R 예제(R-periodogram)", " 20.8 R 예제(R-periodogram) 여기서는 R에서 피리오도그램을 그리는 방법에 대해 다뤄보겠다. 직접 구현 다음 예제는 (Shumway and Stoffer 2010)에 있는 scaled periodogram을 구하는 예제이다. 이미 구현된 패키지 안의 함수들을 이용하는 경우 여기서는 서울특별시 PM10의 1998년 1월부터 2014년 12월까지의 월별 시계열 자료를 이용해 피리오도그램을 그려보겠다. dataspec &lt;- read.csv(&#39;~/Dropbox/Data/PM/MonthlyPMSeoul.csv&#39;, header=T) dataspec &lt;- dataspec[,-1] dataspec &lt;- t(dataspec) time_index_month &lt;- seq(from = as.POSIXct(&quot;1998-01-01&quot;), to = as.POSIXct(&quot;2014-12-01&quot;), by = &quot;month&quot;) dataspec &lt;- xts(dataspec[,1], order.by=time_index_month) plot(dataspec, type=&#39;o&#39;, ylim=c(0,150), xlab=&quot;Month&quot;, main=&quot;Monthly&quot;) FIGURE 20.4: Time series of Seoul PM10. TSA, kza, itsmr 패키지를 이용한다. 같은 이름의 함수를 사용하기 때문에 실행할 때 주의해야 한다. TSA::periodogram(dataspec, log=&#39;yes&#39;) FIGURE 20.5: Periodogram (using R package TSA). plot(kza::periodogram(as.numeric(dataspec)), type=&#39;o&#39;) FIGURE 20.6: Periodogram (using R package kza). plot(itsmr::periodogram(dataspec)) FIGURE 20.7: Periodogram (using R package itsmr). FIGURE 20.7: Periodogram (using R package itsmr). References "],
["21-fouriertowavelet.html", "Chapter 21 푸리에로부터 웨이블릿으로", " Chapter 21 푸리에로부터 웨이블릿으로 이 절의 초반부 내용은 (Ogden 2012)를 참고하였다. References "],
["21-1-discrete-fourier-transform.html", "21.1 이산 푸리에변환(discrete Fourier transform)", " 21.1 이산 푸리에변환(discrete Fourier transform) Definition 21.1 (L2) 어떤 함수 \\(f\\)가 \\(L^{2}[a,b]\\)에 속한다는 것은 \\[\\int_{a}^{b}f^{2}(x)dx &lt;\\infty\\] 를 만족할 때이다. 푸리에 급수는 푸리에 변환의 inversion formula이다. (Jiang 2010) 푸리에 변환은 \\(f\\in L^{2}[-\\pi, \\pi]\\)인 어떤 함수 \\(f\\)는 다음과 같이 지수함수로 표현할 수 있다는 것이다. \\[\\hat{f}(k)=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}f(x)e^{-ikx}dx,\\] 이 때 \\(k=0,\\pm 1, \\pm 2\\) 등이고 \\(i=\\sqrt{-1}\\)이다. \\(f\\)는 적분가능한 함수이다. 푸리에 변환이 주어지면 푸리에 급수로 \\(f\\)를 복원할 수 있다. \\[f(x)=\\sum_{k=-\\infty}^{\\infty}\\hat{f}(k)e^{ikx}=\\sum_{k=-N}^{N}\\hat{f}(k)e^{ikx}+o(1),\\] 이때 \\(N\\)은 양의 정수이고 remaining term은 \\(N\\rightarrow\\infty\\)일 때 \\(o(1)\\)이다. 같은 방법으로 사인함수와 코사인함수의 무합급수로 표현할 수 있다는 것이다. \\[f(x)=\\frac{1}{2}a_{0}+\\sum_{j=1}^{\\infty}(a_{j}\\cos (jx) + b_{j}\\sin (jx)),\\] 여기서 \\(\\{ a_{0}, a_{1}, b_{1}, \\ldots \\}\\)들은 계수다. Definition 21.2 (직교) 두 함수 \\(f_{1},f_{2}\\in L^{2}[a,b]\\)는 \\(&lt;f_{1},f_{2}=0\\)일 때 직교(orthogonal)라고 부른다. Definition 21.3 (직교정규) 함수들의 수열 \\(\\{ f_{j} \\}\\)는 모든 \\(f_{j}\\)들이 짝지은 직교(pairwise orthogonal)이며 \\(\\| f_{j}\\|=1\\)일 때 직교정규(orthonormal)이라고 한다. References "],
["21-2-time-frequency-analysis.html", "21.2 시간주파수해석(time-frequency analysis)", " 21.2 시간주파수해석(time-frequency analysis) 신호를 시간의 관점에서 해석하는 것을 시간해석(time analysis)라고 한다. 반면에 푸리에해석은 주파수의 관점에서 해석하는 주파수해석(frequency analysis)이다. 우리가 일상생활에서 접하는 신호들은 시간과 주파수를 동시에 고려해야 하는 것들이 많다. 예를 들어, 악보의 각 음표는 어느 시점에 그 음을 발성할 것인지를 나타내는 동시에 어떤 음높이로 발성할 것인지를 나타낸다. 즉 발성할 시점은 시간해석의 관점에서 보는 것이고, 음높이는 주파수해석의 관점에서 보는 것이다. 따라서, 노래라는 신호를 시간해석 또는 주파수해석 각각으로 해석해서는 결코 만족스러운 결과를 얻을 수 없을 것이다. 오늘날 가장 널리 연구되고 사용되는 시간주파수해석법은 웨이블릿의 사용하는 것이다. "],
["21-3-wavelet.html", "21.3 웨이블릿(wavelet)", " 21.3 웨이블릿(wavelet) 웨이블릿은 뒷장에서도 다시 설명하겠지만, 여기서는 (Shima 2016)의 내용을 다룬다. 앞서 보았듯이, 푸리에 변환은 시간 영역에서 진동이 있는 요소들을 추출해낸다는 점에서 효율적인 툴로 알려져있다. 그러나 푸리에 변환은 시간 영역과 주파수 영역을 동시에 보지 못한다는 한계가 있고, 이를 극복하고자 웨이블릿이 등장했다. 웨이블릿 분석의 큰 장점은 신호에 있는 복잡한 정보들을 웨이블릿(wavelet)이라고 하는 기본적인 함수들로 분해(decomposition)할 수 있다는 것이다. 웨이블릿은 localized waveform으로 시간 및 주파수 스케일의 다양한 범위를 컨트롤할 수 있게 해준다. 또 이 성질은 복구(reconstruction)를 가능하게 해 준다. 푸리에 해석에서의 주파수와는 달리, 웨이블릿 해석에서는 척도(scale)가 중요한 역할을 한다. 척도가 큰 창(window)을 통해서 신호를 관찰하면, 그 신호의 전반적인 특징을 관찰할 수 있다. 즉 웨이블릿이라는 창을 사용해서 신호를 분석하면 신호의 전체적인 모습뿐 아니라 세부적인 모습까지도 분석할 수 있다. 따라서 신호가 가지고 있는 비정상적(nonstationry) 성질들을 나타내는 데 웨이블릿이 유용하다. 예를 들어, 푸리에 해석에서는 신호의 불연속성, 단절(rupture) 등을 잘 식별할 수 없지만 웨이블릿 해석을 사용하면 식별이 가능하다. 이는 웨이블릿이 단순히 신호의 자세한 부분까지를 반영하기 때문이 아니라 신호가 변화하는 부분을 잘 나타내기 때문이다. Definition 21.4 (웨이블릿) 웨이블릿(wavelet) \\(\\psi(t)\\)는 실변수함수로, localized waveform을 갖으며 \\(\\int_{-\\infty}^{\\infty}\\psi(t)dt=0\\) \\(\\int_{-\\infty}^{\\infty}\\psi(t)^{2}dt=1\\) \\(\\psi(t)\\)의 푸리에 변환 결과인 \\(\\Psi(t)\\)가 admissibility condition이라 불리는 다음 성질 \\[C_{\\Psi}\\equiv\\int_{0}^{\\infty}\\frac{|\\Psi(\\omega) |^{2}}{\\omega}d\\omega &lt;\\infty\\] 를 만족한다. 이 때 \\(C_{\\Psi}\\)를 admissibility constant라고 부르며 이 값은 \\(\\psi(t)\\)의 explicit t-dependence에 의존한다고 한다. Example 21.1 (Haar 웨이블릿) Haar 웨이블릿(Haar wavelet)은 \\[\\begin{equation} \\psi(t) \\equiv \\begin{cases} \\frac{1}{\\sqrt{2}} &amp; \\quad t\\in (0,1],\\\\ \\frac{-1}{\\sqrt{2}} &amp; \\quad t\\in (-1,0],\\\\ 0 &amp; \\quad \\text{otherwise} \\\\ \\end{cases} \\end{equation}\\] 으로 정의된다. FIGURE 21.1: Haar wavelet function. 한 마디로 정리하자면 웨이블릿은 localized oscillating wave라고 볼 수 있다. References "],
["21-4-wavelet-transform.html", "21.4 웨이블릿 변환(wavelet transform)", " 21.4 웨이블릿 변환(wavelet transform) 수학적 용어로 웨이블릿 변환은 웨이블릿의 합성곱(convolution)이다. 여기서 잠시 합성곱에 대해 살펴보면, \\(f\\), \\(g\\)라는 두 함수의 \\([0,t]\\)까지 범위에서 합성곱은 \\[\\int_{0}^{\\tau}f(\\tau)g(t-\\tau)d\\tau\\] 이다. 이 합성곲은 웨이블릿의 모양을 변화시키기 위해 두 모수를 갖는다. 하나는 \\(a\\)로 표시되는 팽창모수(dilatation parameter)이며, domain에서 웨이블릿의 팽창과 수축을 결정해준다. 다른 하나는 \\(b\\)로 표시되는 이동모수(translation parameter)로, 축을 따라 웨이블릿을 움직여준다. FIGURE 21.2: (a) Dilatation and (b) translation of a wavelet. 일례로 이동하고 전이된 버전의 Mexican hat wavelet은 \\[\\psi(\\frac{t-b}{a})=[1-(\\frac{t-b}{a})^{2}]e^{[-\\frac{1}{2}\\cdot (\\frac{t-b}{a})^{2}]}\\] 이 된다. (\\(\\sigma=1\\)인 경우) Definition 21.5 (웨이블릿 변환) 연속신호 \\(x(t)\\)의 웨이블릿 \\(\\psi(t)\\)에 대한 웨이블릿 변환(wavelet transform) \\(T(a,b)\\)는 \\[T(a,b)=w(a)\\int_{-\\infty}^{\\infty}x(t)\\psi(\\frac{t-b}{a})dt\\] 로 정의된다. 여기서 \\(w(a)\\)는 가중치함수(weighted function)이라고 부른다. 여기서 좀 더 컴팩트한 표현으로 \\[\\psi_{a,b}(t)=\\frac{1}{\\sqrt{a}}\\psi(\\frac{t-b}{a})\\] 를 정의해 앞선 식을 \\[T(a,b)=\\int_{-\\infty}^{\\infty}x(t)\\psi_{a,b}(t)dt\\] 로 쓸 수 있다. 앞으로 \\(\\psi_{a,b}(t)\\)을 단순히 웨이블릿으로 부르기로 한다. 일반적으로 \\(w(a)=\\frac{1}{\\sqrt{a}}\\)로 정의하는데 그 이유는 \\[\\int_{-\\infty}^{\\infty}[\\frac{1}{\\sqrt(a)}\\psi(\\frac{t-b}{a})]^{2}dt=\\int_{-\\infty}^{\\infty}\\psi(u)^{2}du = 1 \\qquad{ \\text{ with } u=\\frac{t-b}{a}}\\] 이기 때문이다. 정리하면 웨이블릿 변환은 time-varying signal에 대한 현미경 역할을 한다. "],
["21-5-wavelet-space.html", "21.5 웨이블릿 공간(wavelet space)", " 21.5 웨이블릿 공간(wavelet space) 21.5.1 다중해상도 분석(multiresolution analysis) 다중해상도 분석은 사실 함수공간의 집합(a set of function space)이다. 혼란스럽게 용어가 정의되어 있어 주의를 필요로 한다. Definition 21.6 (다중해상도 분석) 다중해상도 분석(multiresolution analysis)란 \\(L^{2}(\\mathbb{R})\\)의 닫힌 부분공간(closed subspace)의 함수공간의 집합 \\(\\mathcal{V}_{j}:j\\in\\mathbb{Z}\\)으로 \\(\\mathcal{V}_{j}\\)는 다음 조건을 만족한다. \\(\\cdots \\subset \\mathcal{V}_{-2} \\subset \\mathcal{V}_{-1} \\subset \\mathcal{V}_{0} \\subset \\mathcal{V}_{1} \\subset \\mathcal{V}_{2} \\ldots \\subset L^{2}(\\mathbb{R})\\) \\(\\bigcap_{j=-\\infty}^{\\infty}\\mathcal{V}_{j}=\\{0\\}\\) \\(f(t)\\in\\mathcal{V}_{j}\\) if and only if \\(f(2t)\\in\\mathcal{V}_{j+1}\\) for all integer \\(j\\) 집합 \\(\\{ \\phi (t-n), n \\in \\mathbb{Z}\\}\\)가 \\(\\mathcal{V}_{0}\\)의 직교정규기저(orthonormal basis)가 되도록 하는 함수 \\(\\phi(t)\\in\\mathcal{V}_{0}\\)이 존재한다. 이 때 \\(\\phi(t)\\)를 척도함수(scaling function) 또는 부웨이블릿(father wavelet)이라고 부른다. 참고할만한 사항으로 다중해상도 분석의 정의는 \\(\\phi(t)\\)의 존재에 대한 어떤 정보도 주지 않는다. 그러나 우리가 만약 바람직한 함수 \\(\\phi(t)\\)를 찾는다면 \\(\\{ \\phi(t-n), n\\in\\mathbb{Z}\\}\\)가 span하는 함수공간 \\(\\mathcal{V}_{0}\\)를 정의할 수 있고 앞선 정의의 3번을 이용해 \\(V_{j}\\)들을 계속해서 만들어내 다중해상도 분석 \\(\\mathcal{V}_{j}\\)를 만들 수 있다. 즉 다시말하면 척도함수 \\(\\phi(t)\\)가 다중해상도 분석 \\(\\{ \\mathcal{V}_{j}\\}\\)를 생성한다. Definition 21.7 (다중해상도 분석의 예) \\(L^{2}(\\mathbb{R})\\)에서 어떤 구간 \\([2^{-m}n, 2^{-m}(n+1)], \\forall n\\in\\mathbb{Z}\\)에서만 상수값을 갖는 모든 함수들의 집합 \\(\\mathcal{V}_{m}\\)을 생각해보자. 그러면 \\(\\mathcal{V}_{m}\\)은 다중해상도 분석의 조건 1부터 3까지를 만족시킨다(\\(\\phi\\)들은 기저이다. 잘 생각해 볼 것) FIGURE 21.3: (a) Dilatation and (b) translation of a wavelet. 위 그림에 나오는 \\(\\{\\phi(t-n),n\\in\\mathbb{Z}\\}\\)는 \\[\\begin{equation} \\phi(t) \\equiv \\begin{cases} 1 &amp; \\quad 0 \\leq t \\leq 1\\\\ 0 &amp; \\quad \\text{otherwise} \\\\ \\end{cases} \\end{equation}\\] 로 정의되며 다중해상도분석의 4번 조건을 만족한다. 즉, 어떤 함수 \\(f\\in\\mathcal{V}_{0}\\)은 \\[f(t)=\\sum_{n=-\\infty}^{\\infty}c_{n}\\phi(t-n)\\] 으로 표현가능하다. 여기서 \\(c_{n}\\)은 적절한 상수이다. 따라서 공간 \\(\\mathcal{V}_{m}\\)은 \\(\\phi(t)\\)로 생성되어지는 다중해상도 분석이다. 21.5.2 직교분해(orthogonal decomposition) 다중해상도 분석이 중요한 것은 이것이 \\(L^{2}(\\mathbb{R})\\)에서의 직교정규 기저(orthonormal basis, i.e. a complete orthonormal set of functions)를 구성할 수 있게 해준다는 것이다. 이 말을 입증하기 위해 우선 다중해상도 분석 \\(\\{\\mathcal{V}_{j}\\}\\)가 다음 관계 \\[\\mathcal{V}_{0}\\subset\\mathcal{V}_{1}\\subset\\mathcal{V}_{2}\\subset\\cdots \\subset L^{2}\\] 를 만족한다는 것이다. 이제 다음과 같이 \\(\\mathcal{V}_{0}\\)와 \\(\\mathcal{V}_{1}\\)의 직교 여공간(orthogonal complement) \\(\\mathcal{W}_{0}\\) \\[\\mathcal{V}_{1}=\\mathcal{V}_{0}\\oplus\\mathcal{W}_{0}\\] 을 정의한다. 여기서 \\(\\oplus\\)는 주어진 벡터공간들의 직합(direct sum)이다. 공간 \\(\\mathcal{W}_{0}\\)을 0차원에서의 웨이블릿 공간(wavelet space)이라고 부른다. FIGURE 21.4: Hierarchical structure of the space V and W as subspace of L2. 위 식은 \\[\\mathcal{V}_{2}=\\mathcal{V}_{1}\\oplus\\mathcal{W}_{1}=\\mathcal{V}_{0}\\oplus\\mathcal{W}_{0}\\oplus\\mathcal{W}_{1}\\] 으로 확장할 수 있으며, 일반적으로 확장하면 \\[L^{2}=\\mathcal{V}_{\\infty}=\\mathcal{V}_{0}\\oplus \\mathcal{W}_{0} \\oplus \\mathcal{W}_{1} \\oplus \\mathcal{W}_{2} \\oplus \\cdots\\] 로 쓸 수 있다. 여기서 \\(\\mathcal{V}_{0}\\)은 함수들의 집합 \\(\\{ \\phi(t-n), n\\in\\mathbb{Z}\\}\\)으로 span하는 initial space이다. 최초 공간을 임의로 설정할 수 있기 때문에, 다음과 같이 \\[L^{2}=\\mathcal{V}_{5}\\oplus \\mathcal{W}_{5} \\oplus \\mathcal{W}_{6}\\cdots\\] 으로 높게 고르거나 또는 \\[L^{2}=\\mathcal{V}_{-3}\\oplus \\mathcal{W}_{-3} \\oplus \\mathcal{W}_{-2}\\cdots\\] 와 같이 낮은 해상도를 고를 수도 있다. 극단적으로는 \\[L^{2}=\\cdots\\oplus \\mathcal{W}_{-1} \\oplus \\mathcal{W}_{0} \\oplus \\mathcal{W}_{1}\\cdots\\] 로 \\(-\\infty\\)를 취하기도 한다. 이와 같은 표현을 \\(L^{2}\\)에서의 직교분해(orthogonal decomposition)으로 부른다. 이것은 즉 어떤 함수 \\(x\\in L^{2}(\\mathbb{R})\\)은 다음과 같이 \\[x(t)=\\cdots + g_{-1}(t)+g_{0}(t)+g_{1}(t)+\\cdots .\\] \\(g_{j}\\in\\mathcal{W}_{j}\\)의 무한합으로 분해할 수 있다. FIGURE 21.5: Hierarchical structure of the space V and W. 21.5.3 직교정규 기저 구성(orthonormal basis construction) 웨이블릿 공간 \\(\\{ W_{j} \\}\\)들의 직교 성질에 대해 좀 더 자세히 살펴보자. 앞선 직합으로 표시된 식들에 의해 \\[\\mathcal{W}_{0}\\subset \\mathcal{V}_{1} \\text{ and } \\mathcal{W}_{1} \\subset \\mathcal{V}_{2}\\] 관계를 갖는다. 다중해상도 분석 \\(\\{\\mathcal{V}_{j}\\}\\)의 정의의 관점에서 봤을 때, \\[f(t)\\in \\mathcal{V}_{1} \\Longleftrightarrow f(2t)\\in \\mathcal{V}_{2}\\] 이고 그러므로 \\[f(t)\\in \\mathcal{W}_{0} \\Longleftrightarrow f(2t)\\in \\mathcal{W}_{1}\\] 이다. 더 나아가서, 다중해상도 분석의 4번 조건은 \\[f(t)\\in \\mathcal{W}_{0} \\Longleftrightarrow f(t-n)\\in\\mathcal{W}_{0} \\text{ for any } n\\in\\mathbb{Z}\\] 가 되게 만든다. 이제 위 사실들을 가지고 \\(L^{2}(\\mathbb{R})\\)에서의 직교정규 기저들을 만들어보자. 우선 \\(\\mathcal{W}_{0}\\)에서 직교정규 기저 \\(\\{\\psi(t-n),n\\in\\mathbb{Z}\\}\\)를 만드는 함수\\(\\psi(t)\\)가 있다고 하자. 그러면 다음과 같은 표기 \\[\\phi_{0,n}(t)\\equiv\\psi(t-n)\\in\\mathcal{W}_{0]}\\] 를 이용해 이것의 scaled version을 \\[\\phi_{1,n}(t)=\\sqrt{2}\\psi(2t-n)\\] 으로 정의하고 이것은 \\(\\mathcal{W}_{1}\\)의 직교정규 기저가 된다. \\(\\sqrt{2}\\)는 정규 조건을 유지하기 위해 들어간 상수다. \\[\\int_{-\\infty}^{\\infty}\\psi_{0,n}(t)^{2}dt=\\int_{-\\infty}^{\\infty}\\psi_{1,n}(t)^{2}dt=1.\\] 같은 과정들을 반복하면 \\[\\psi_{m,n}(t)=2^{m/2}\\psi(2^{m}t-n)\\] 이라는 관계식을 얻을 수 있으며 이 때 \\(\\psi_{m,n}\\)은 \\(\\mathcal{W}_{m}\\)의 직교기저가 된다. 이러한 결과물들을 앞선 함수 \\(x\\in L^{2}(\\mathbb{R})\\)의 직교분해 식에 넣을 경우 \\[\\begin{eqnarray*} x(t)&amp;=&amp; \\cdots + g_{-1}(t)+g_{0}(t)+g_{1}(t)+\\cdots\\\\ &amp;=&amp;\\cdots + \\sum_{n=-\\infty}^{\\infty}c_{-1,n}\\psi_{-1,n}(t)+\\sum_{n=-\\infty}^{\\infty}c_{0,n}\\psi_{0,n}(t) + \\sum_{n=-\\infty}^{\\infty}c_{1,n}\\psi_{1,n}(t)+\\cdots \\\\ &amp;=&amp;\\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty}c_{m,n}\\psi_{m,n}(t). \\end{eqnarray*}\\] 결과적으로 family \\(\\psi_{m,n}(t)\\)가 \\(L^{2}(\\mathbb{R})\\)의 직교정규 기저가 된다. 위 결과를 다음 정리로 요약할 수 있다. Theorem 21.1 (직교정규 기저의 구성) \\(\\{ \\mathcal{V}_{j}\\}\\)를 다중해상도 분석이라고 하고 공간 \\(\\mathcal{W}_{0}\\)를 \\(\\mathcal{W}_{0}=\\mathcal{V}_{1}/\\mathcal{V}_{0}\\)으로 정의한다. 만약 어떤 함수 \\(\\psi(t)\\)가 \\(\\mathcal{W}_{0}\\)의 정규직교 기저 \\(\\{ \\psi(t-n),n\\in\\mathbb{Z}\\}\\)를 만들어 낸다면, 함수들의 집합 \\(\\{\\psi_{m,n},m,n\\in\\mathbb{Z}\\}\\)는 \\[\\psi_{m,n}(t)=2^{m/2}\\psi(2^{m}t-n)\\] \\(L^2{\\mathbb{R}}\\)에서의 직교정규 기저를 구성한다. 여기서 소개된 \\(\\psi(t)\\)는 웨이블릿을 결정하는 데, 즉 Haar wavelet이냐 mexican hat wavelet이냐 등을 결정하는 데 쓰이므로, \\(\\mathcal{W}_{m}\\)을 웨이블릿 공간(wavelet space)이라고 부르며 함수 \\(\\psi(t)\\)를 모웨이블릿(mother wavelet)이라고 부른다. 21.5.4 두-스케일 관계(two-scale relation) 앞서 언급한 내용들은 \\(L^{2}(\\mathbb{R})\\)에서의 직교정규 기저 \\(\\{\\psi_{m,n} \\}\\)을 모웨이블릿 \\(\\psi(t)\\)의 명시적 함수 형태를 특정지음으로써 구성할 수 있다는 것을 암시한다. 그럼 이제 남아있는 일은 모웨이블릿 \\(\\psi(t)\\)를 이용해 다중해상도 분석이 주어졌을 때 \\(\\mathcal{W}_{0}=\\mathcal{V}_{1}/\\mathcal{V}_{0}\\)이 포함된 공간에서 정규직교 기저 \\(\\{ \\psi(t-n), n\\in\\mathbb{Z}\\}\\)를 이끌어내는 일이다. 우리는 \\(\\psi(t)\\)를 척도함수 \\(\\phi(t)\\)를 잘 살펴봄으로써 찾아낼 수 있었음을 상기해야 한다. 다음에는 주어진 다중해상도 분석에서 모웨이블릿 \\(\\psi(t)\\)를 구성하기 위한 척도함수의 중요한 특징인 두-스케일 관계(two-scale relation)에 대해 언급하겠다. 우리는 \\(\\mathcal{V}_{m}\\)에 있는 모든 함수들이 \\(\\mathcal{V}_{0}\\)에 있는 것들에서 \\(2^{m}\\)만큼 스케일링하여 얻을 수 있다는 걸 안다. 이 결과를 스케일링 함수에 적용시키면 \\[\\phi_{0,n}(t)\\equiv \\phi(t-n) \\in \\mathcal{V}_{0}\\] 이고 이것은 \\[\\phi_{m,n}(t)=2^{m/2}\\phi(2^{m}t-n), m\\in\\mathbb{Z}\\] 가 \\(\\mathcal{V}_{m}\\)의 직교정규 기저가 되는 것으로 이어진다. 특히 \\(\\phi \\in \\mathcal{V}_{0}\\subset \\mathcal{V}_{1}\\)이고 \\(\\phi_{1,n}(t)=\\sqrt{2}\\phi(2t-n)\\)이 \\(\\mathcal{V}_{1}\\)의 직교정규 기저이기 때문에, \\(\\phi(t)\\)는 \\(\\phi_{1,n}(t)\\)에 의해 확장되어질 수 있다. 이것은 다음 정리로 요약할 수 있다. Theorem 21.2 (두-스케일 관계) 척도함수 \\(\\phi(t)\\)가 다중척도 해석 \\(\\{ \\mathcal{V}_{j}\\}\\)을 생성할 때, 다음과 같은 관계식을 얻을 수 있다. \\[\\phi(t)=\\sum-{n=-\\infty}^{\\infty}p_{n}\\phi_{1,n}(t)=\\sqrt{2}\\sum_{n=-\\infty}^{\\infty}p_{n}\\phi(2t-n),\\] 이 때 \\[p_{n}=\\int_{-\\infty}^{\\infty}\\phi(t)\\phi_{1,n}(t)dt\\] 이다. 이 식을 \\(\\phi(t)\\)의 두-스케일 관계(two-scale relation)식이라고 부른다. 그리고 계수 \\(p_{n}\\)을 척도함수계수(scaling function coefficients)라고 부른다. Example 21.2 (두-스케일 관계의 예) 다음과 같이 \\(L^{2}(\\mathbb{R})\\)의 함수들을 모두 포함하고 구간 \\([2^{-m}n, 2^{-m}(n+1)], n\\in\\mathbb{Z}\\)에서 상수값을 갖는 공간 \\(\\mathcal{V}_{m}\\)에 대해 생각해보자. 이 다중해상도 해석은 앞 예제에서 등장했던 척도함수 \\(\\phi(t)\\)에 의해 생성됨이 알려져있다. \\[p_{0}=p_{1}=\\frac{1}{2} \\text{ and } p_{n}=0 \\text{ for }n\\neq 0,1.\\] 따라서, 이 예의 두-스케일 관계식은 \\[phi(t)=\\phi(2t)+\\phi(2t-1)\\] 이 된다. FIGURE 21.6: Two-scale relation of phi(t). 21.5.5 모웨이블릿(mother wavelet) 이제 \\(L^{2}(\\mathbb{R})\\)에서 직교정규 기저를 만들 수 있도록 하는 모웨이블릿 \\(\\psi(t)\\)를 결정할 차례다. 모웨이블릿 \\(psi(t)=\\psi_{0,0,}(t)\\in\\mathcal{W}_{0}\\)가 \\(\\mathcal{V}_{1}\\)에 의해 spanned되어짐을 상기하자. 즉 \\(\\mathcal{W}_{0}\\subset \\mathcal{V}_{1}\\)이다. 정리하면, \\(\\psi(t)\\)는 \\(\\phi(2t)\\)들의 가중합으로 표현할 수 있다. \\[\\psi(t)=\\sum_{n=-\\infty}^{\\infty}q_{n}\\sqrt{2}\\phi(2t-n), n\\in\\mathbb{Z}.\\] 이 때 계수 \\(q_{n}\\)은 웨이블릿 계수(wavelet coefficients)라고 불리며 \\[q_{n}=(-1)^{n-1}p_{-n-1}\\] 로 주어진다. Theorem 21.3 (모웨이블릿) 만약 \\(\\{ \\mathcal{V}_{m}\\}\\)이 척도함수 \\(\\phi(t)\\)를 갖는 다중해상도 해석이라고 한다면, 모웨이블릿 \\(\\psi(t)\\)는 \\[\\psi(t)=\\sqrt{2}\\sum_{n=-\\infty}^{\\infty}(-1)^{n-1}p_{-n-1}\\phi(2t-n), n\\in\\mathbb{Z}\\] 로 주어진다. 이 때 \\(p_{n}\\)은 척도함수 \\(phi(t)\\)의 계수이다. 그리고 이 \\(p_{n}\\)은 유일하게 정해진다. 즉 위 정리에 의하면 모웨이블릿 \\(\\psi(t)\\)는 주어진 다중해상도 해석에서 척도함수 \\(\\phi(t)\\)를 특정화하면 얻을 수 있다. 21.5.6 다중해상도 표현(multiresolution representation) 앞서 했던 내용들을 종합하면, \\(L^{2}(\\mathbb{R})\\)을 span하는 척도함수들 \\(\\phi_{j,k}(t)\\)와 웨이블릿들 \\(\\psi_{j,k}(t)\\)의 직교정규 기저를 얻을 수 있었다. \\[L^{2}=\\mathcal{V}_{j_{0}}\\oplus\\mathcal{W}_{j_{0}}\\oplus\\mathcal{W}_{j_{0}+1}\\oplus\\cdots,\\] 이 식을 이용해, 어떤 함수 \\(x(t)\\in L^{2}(\\mathbb{R})\\)은 \\[x(t)=\\sum_{k=-\\infty}^{\\infty}S_{j_{0},k}\\phi_{j_{0},k}(t)+\\sum_{k=-\\infty}^{\\infty}\\sum_{j=j_{0}}^{\\infty}T_{j,k}\\psi_{j,k}(t)\\] 로 확장해 표현할 수 있다. 이 때, 최초의 척도 \\(j_{0}\\)은 0 또는 다른 정수 또는 어떤 척도함수를 쓰지 않을때에는 \\(-\\infty\\)까지 될 수도 있다. 계수 \\(T_{j,k}\\)는 이산 웨이블릿 변환이 이미 주어졌을때 identified 되어진다. 종종 \\(T_{j,k}\\)를 웨이블릿 계수(wavelet coefficient)라고 부르며, 대응되는 \\(S_{j,k}\\)를 근사계수(approximation coefficient)라고 부른다. 앞의 식을 좀 더 단순화하기 위해 \\[x_{j_{0}}(t)=\\sum_{k=-\\infty}^{\\infty}S_{j_{0},k}\\phi_{j_{0},k}(t)\\] 신호 \\(x(t)\\)의 척도 \\(j_{0}\\)에 대한 연속 근사(continous approximation)을 생각하자. 연속 근사를 보면 \\(j_{0}\\rightarrow \\infty\\)일 때 \\(x_{j_{0}}(t)\\rightarrow x(t)\\)가 된다. (왜냐면 \\(L^{2}=\\mathcal{V}_{\\infty}\\)이기 때문이다) 더불어, 다음과 같이 \\[z_{j}(t)=\\sum_{k=-\\infty}^{\\infty}T_{j,k}\\psi_{j,k}(t)\\] 라는 표기를 도입한다. 이 때 \\(z_{j}(t)\\)는 척도 \\(j\\)에서의 신호 상세(signal detail)라고 부른다. 그러면 다중해상도 표현은 \\[x(t)=x_{j_{0}}(t)+\\sum_{j=j_{0}}^{\\infty}z_{j}(t)\\] 가 된다. 이 표현은 원래 신호 \\(x(t)\\)를 이것의 연속 근사인 임의의 척도 색인 \\(j_{0}\\)에서의 \\(x_{j_{0}}\\)와 척도 \\(j_{0}\\)에서 무한대까지의 신호 상세를 더한 값으로 내타낼 수 있다다. 또한 \\(\\mathcal{V}_{j+1}=\\mathcal{V}_{j}\\oplus\\mathcal{W}_{j}\\)를 이용해 \\[x_{j+1}(t)=x_{j}(t)+z_{j}(t)\\] 로 쓸 수 있다. 이것은 우리가 어떤 척도 \\(j\\)에서의 연속 근사 신호에 신호 상세를 더하면 더 작은 척도 \\(j+1\\)에서의 연속 근사식을 얻을 수 있다는 것이다. 이 식을 다중해상도 표현(multiresolution representation)이라고 부른다. "],
["22-multiscale.html", "Chapter 22 다중척도 방법론", " Chapter 22 다중척도 방법론 이 장에서는 통계학에서의 다중척도 방법론을 다룬다. 주된 내용은 2015년 지도교수님의 특강 수업 내용이다. 이 문서에 담겨있는 그림들은 (G. Nason 2010)을 참고하였다. References "],
["22-1-multiscale-transform.html", "22.1 다중척도 변환(multiscale transform)", " 22.1 다중척도 변환(multiscale transform) 다음과 같은 형태의 벡터 자료를 생각해보자. \\[ \\mathbf{y}=(y_{1},\\ldots,y_{n}), n=2^{J}\\] 여기서 \\(n=2^{J}\\)는 굉장히 강하고 불편한 조건이다. 예를 들어, 자료의 길이가 800개 또는 900개 정도라면 자료의 길이가 2의 배수라는 조건에 맞게 데이터를 일부를 버려야 한다. 또한 \\(\\mathbf{y}\\)는 등간격 자료(equally spaced data)여야 한다. 예를 들어, 시계열 자료의 경우 오늘 10시, 내일 10시에 관측된 값이 자료에 있으면 그 다음 값은 모레 10시에 관측된 값이여야 하며, 11시에 관측된 값이 와서는 안 된다는 것이다. 다중척도 방법론에서 알고 싶어하는 가장 중요한 정보는 각기 다른 척도(scale)와 위치(location)에서의 \\(\\mathbf{y}\\)의 상세(detail)이다. 여기서 척도는 수준(level), 해상도(resolution) 등으로 불리기도 하며 통계학 용어로 번역하자면 분산, 파워(power), 도수(frequency) 등으로 말할 수 있다. 장소라는 것은 관측값을 관찰한 정의역(domain)을 의미하며, 시간 자료면 시간, 공간 자료면 공간이 로케이션이 된다. 한편 상세의 정의는 다음과 같다. Definition 22.1 (상세) 주어진 자료 \\(\\mathbf{y}\\)의 상세(detail) \\(d_{k}\\)는 \\[\\begin{equation} d_{k}=y_{2k}-y_{2k-1},\\qquad{k=1,2,\\ldots,\\frac{n}{2}} \\end{equation}\\] 이다. Example 22.1 (상세의 계산) 다음과 같이 길이 8인 자료 \\(\\mathbf{y}=(y_{1},y_{2},\\ldots,y_{8})\\)가 있다고 하자. 그러면 이 자료의 상세는 \\[\\begin{equation} d_{1}=y_{2}-y_{1}, d_{2}=y_{4}-y_{3}, d_{3}=y_{6}-y_{5}, d_{4}=y_{8}-y_{7} \\end{equation}\\] 와 같이 4개가 존재한다. 여기서 특이한 점은 \\(y_{3}-y_{2}\\)와 같은 값들은 고려하지 않는다는 것이다. 이는 어떻게 관측하느냐에 따라 \\(d_{k}\\)가 완전히 달라질 수도 있다는 말이다. 즉 상세는 평행 이동 불변(translation invariant)하지 않다. 한편, 상세와 유사한 개념으로 성김(coarser)을 정의한다. Definition 22.2 (성김) 주어진 자료 \\(\\mathbf{y}\\)의 성김(coarser) \\(c_{k}\\)은 \\[\\begin{equation} c_{k}=y_{2k}+y_{2k-1},\\qquad{k=1,2,\\ldots,\\frac{n}{2}} \\end{equation}\\] 이다. 성김은 매끄러움(smooth)으로 불리기도 하며, +의 개념이다. 상세는 차이(difference)로 불리기도 하며, -의 개념이다. \\(c_{k}\\)와 \\(d_{k}\\)를 알고 있으면 원래 자료들의 원소 \\(y_{i}\\)들도 다 알아낼 수 있다. 이렇게 다중척도 변환은 원래 신호를 재구성(reconstruction)할 수 있어야 한다. 한편, 앞선 예제에서처럼 자료의 길이가 8일 때, (특정 수준에서) 얻을 수 있는 최대 상세는 4개이다. 이것을 가장 섬세한 상세(finest-detail)라고 한다. 그런데 우리가 \\(c_{k}\\)를 이용해서 \\(d_{k}(=d_{J-1})\\)보다 좀 더 엉성한 상세를 얻고 싶을 수 있다. 그러면 그 것보다 낮은 수준, 즉 \\(J-2\\) 수준을 생각하면 된다. \\(J-2\\) 수준에서의 상세는 \\[\\begin{eqnarray} d_{J-2,l}&amp;=&amp;c_{J-1,2l}-c_{J-1,2l-1},l=1,2,\\ldots,\\frac{n}{4}\\nonumber\\\\ &amp;=&amp;(y_{4l}+y_{4l-1})-(y_{4l-2}+y_{4l-3}) \\end{eqnarray}\\] 로 정의된다. 예를 들어, \\(d_{J-2,1}=(y_{4}+y_{3})-(y_{2}+y_{1})\\)이다. 마찬가지로 \\(J-2\\) 레벨에서의 성김은 \\[\\begin{equation} c_{J-2,l}=c_{J-1,2l}+c_{J-1,2l-1},l=1,2,\\ldots,\\frac{n}{4} \\end{equation}\\] 이다. 앞서 말한 다중척도 과정을 그림으로 요약하면 다음과 같다. FIGURE 22.1: Generic step in multiscale transform. 다중척도 변환은 다음과 같이 같은 차원의 새로운 벡터를 정의하는 과정으로 볼 수 있다. \\[(1,1,7,9,2,8,8,6) \\rightarrow (42,6,14,4,0,2,6,-2).\\] 바뀐 벡터를 살펴보면, 42는 평균(global trend)에 해당되고, 6은 \\(J=0\\)일 때의 상세, \\((14,4)\\)는 \\(J=1\\)일 때의 상세, \\((0,2,6,-2)\\)는 \\(J=2\\)일 때의 상세이다. \\(d_{j,k}\\)는 웨이블릿 계수(wavelet coefficient)로, \\(c_{j,k}\\)는 압축 계수(scaling coefficient) 또는 부드러움 계수(smooth coefficient)라 부른다. 여기서 \\(j\\)는 수준(level), 척도(scale), 또는 해상도(resolution)을 나타내며, \\(k\\)는 위치(location)를 나타낸다. "],
["22-2-inverse.html", "22.2 역(inverse)", " 22.2 역(inverse) 우리는 \\(\\{ d_{j,k} \\}\\)와 \\(\\{ c_{j,k} \\}\\)를 가지고 \\(\\mathbf{y}\\)를 구할 수 있다. 이를 위해서는 \\[c_{j-1,2k}=\\frac{(c_{j-1,2k}+d_{j-2,k})}{2}, c_{j-1,2k-1}=\\frac{(c_{j-1,2k}+-d_{j-2,k})}{2}\\] 이 두 가지만 알고 있으면 된다. Example 22.2 (다중척도 역변환) 앞서 다룬 자료 \\(\\mathbf{y}=(1,1,7,9,2,8,8,6)\\)를 생각해보자. 이것의 다중척도 변환 결과는 \\((c_{01},d_{0,1},d_{11},d_{12},d_{21},d_{22},d_{23},d_{24})=(42,6,14,4,0,2,6,-2)\\)였다. 이를 가지고 역변환을 해 보면, \\[\\begin{eqnarray*} c_{12}&amp;=&amp;\\frac{(42+6)}{2}=24, c_{11}=\\frac{(42-6)}{2}=18,\\\\ c_{24}&amp;=&amp;\\frac{(24+4)}{2}=14, c_{23}=\\frac{(24-4)}{2}=10, c_{22}=\\frac{(18+14)}{2}=16, c_{21}=\\frac{(18-14)}{2}=2,\\\\ c_{38}&amp;=&amp;\\frac{(14-2)}{2}=6, c_{37}=\\frac{(14+2)}{2}=8, c_{36}=\\frac{(10+6)}{2}=8, c_{35}=\\frac{(10-6)}{2}=2,\\\\ c_{34}&amp;=&amp;\\frac{(16+2)}{2}=9, c_{33}=\\frac{(16-2)}{2}=7, c_{32}=\\frac{(2+0)}{2}=1, c_{31}=\\frac{(2-0)}{2}=1. \\end{eqnarray*}\\] 이다. 여기서 알 수 있는 사실 중 하나는 가장 섬세한 부드러움 계수는 데이터, 즉 자료라는 것이다. 그런데 데이터를 부드러움 계수로 다루는 것이 과역 적절한가? 라는 의문이 들 수 있다. 예를 들어, 자료에 잡음이 너무 많은 경우 부드러움 계수 또한 오류가 많이 생길 것이다. 통계학에서는 이를 보완하기 위해 \\(\\mathbf{y}\\) 또는 \\(d\\)에 적절한 추정을 한 \\(\\hat{y}\\) 또는 \\(\\hat{d}\\) 등을 고려하기도 한다. (통계학자들은 데이터를 언제나 잡음이 끼어있는 신호라고 생각하고 있음을 명심해야 한다. 이 점이 통계학자와 다른 분야의 학자들이 자료를 보는 관점의 가장 큰 차이점 중 하나이다.) "],
["22-3-sparsity.html", "22.3 희소성(sparsity)", " 22.3 희소성(sparsity) FIGURE 22.2: Example of sparse function. 위 그림은 희소성을 갖는 함수의 전형적인 예 중 하나이다. 이 자료는 왼쪽은 항상 1, 오른쪽은 항상 2의 값을 갖고 있는 부드러운(smooth) 함수이며 변화가 없다. 그러나 가운데 지점에서는 함숫값이 1에서 2로 바뀌면서 급격한 점프가 일어난다. 이 지점은 다른 지역과는 달리 굉장히 다른 정보를 갖고 있는 것이다. 기존 회귀분석에서는 근본적인 함수(underlying function)들의 동질성(homogeneous) 가정을 바탕으로 분석한다. 이 말은 변동이 항상 일정하다는 뜻으로, 함수가 어떤 지역에서 두 번 미분 가능하면 다른 지역에서도 똑같이 두 번 미분 가능해야 한다는 것이다. 그러나 위 그림의 함수처럼 어떤 지역에서는 한 번만 미분 가능하거나 아예 미분 가능하지 않을 수도 있다. 이런 함수들을 다룰 때에는 다중척도 방법으로 접근하는 것이 필요하다. (Donoho and Johnstone 1994)의 논문 이전까지 통계학자들의 관심사는 부드러운 함수의 평균 추정에 집중되어 있었다. Donoho는 논문에서 몇 가지 혁신적인 개념들을 제시했는데, 임계화(thresholding), 희소성(sparsity) 등이 그것이다. 그의 아이디어는 당시에는 이해하기 힘든 것들이었다. 그러나 이 논문은 후대에 들에 고차원 자료 분석의 밑거름이 되게 해 주었고, least absolute sharinkage and selection operator (LASSO)와 거의 같은 개념을 먼저 제시하였다. Donoho의 제자인 Fan은 후에 스승의 아이디어를 알기 쉽게 해석하여 smoothly clipped absolute deviation (SCAD)라는 것을 제안하기도 하였다. 우리가 지금까지 일반적으로 배운 회귀분석 모형은 다음과 같이 나타낼 수 있다. \\[y=f+\\epsilon, \\qquad{\\epsilon \\sim \\mathcal{N}(0,\\sigma^{2}).}\\] 다시 말하면, 우리가 지금까지 다뤘던 모든 자료에는 오차(\\(\\epsilon\\))와 \\(f\\)가 공존하는 형태의 모형이다. 이러한 모형에서는, 평균이 매우 중요하며 큰 의미를 갖게 된다. 그러나 성긴 모형에서는 상황이 조금 달라진다. 어떤 \\(y\\)는 \\(f\\)만 갖기도 하고, 또는 \\(\\epsilon\\)만 갖기도 한다. \\(\\mathbf{y}=(y_{1},y_{2},y_{3},y_{4})\\)라는 자료가 있을 때 이들 중 \\(y_{3}\\)만 \\(f\\)의 정보가 들어있는 진짜 신호이고 나머지 \\(y_{1},y_{2},y_{4}\\)는 잡음만 있을 수도 있는 것이다. 이런 자료에서 가장 좋은 추정량은 평균이 아니라 \\(y_{3}\\)이다. Theorem 22.1 (다중척도 변환의 희소성) 다음과 같은 자료 \\(\\mathbf{y}=(1,1,1,1,2,2,2,2)\\)를 생각해보자. 이 자료를 다중척도 변환해 보면 \\[(1,1,1,1,2,2,2,2) \\rightarrow (1,2,4,0,0,0,0,0)\\] 과 같이 0이 많은 벡터로 변환될 것이다. 위 예제와 같이 0이 많이 있는 자료들을 희소성(sparsity)이 있는 자료라 하며, 다중척도 변환은 희소성이 있는 자료를 다룰 때 많은 도움이 될 수 있다. References "],
["22-4-filter-in-signal-processing.html", "22.4 신호처리에서의 필터(filter in signal processing)", " 22.4 신호처리에서의 필터(filter in signal processing) 이 절의 내용은 위키피디아의 것을 참조하였다. 신호처리에서 필터(filter)란 신호에서 원하지 않는 특징들을 제거해주는 장치다. 필터는 linear or non-linear time-invariant or time-variant causal or not-causal: depending if present output depends or not on “future” input; of course, for time related signals processed in real-time all the filters are causal; it is not necessarily so for filters acting on space-related signals or for deferred-time processing of time-related signals. analog or digital discrete-time (sampled) or continuous-time passive or active type of continuous-time filter infinite impulse response (IIR) or finite impulse response (FIR) type of discrete-time or digital filter. 등으로 구분할 수 있다. 다음은 선형 필터(linear filter)에서 쓰이는 용어들이다. 여기서 원하지 않는 특징들은 주로 주파수를 의미하는 것이라 볼 수 있다. FIGURE 22.3: Various forms of linear filters. Low-pass filter – 낮은 주파수는 통과시키고(low frequencies are passed), 높은 주파수는 감쇠, 즉 약하게 한다(high frequencies are attenuated). High-pass filter – 높은 주파수는 통과시키고(high frequencies are passed), 낮은 주파수는 감쇠하도록 한다(low frequencies are attenuated). Band-pass filter – only frequencies in a frequency band are passed. Band-stop filter or band-reject filter – only frequencies in a frequency band are attenuated. Notch filter – rejects just one specific frequency - an extreme band-stop filter. Comb filter – has multiple regularly spaced narrow passbands giving the bandform the appearance of a comb. All-pass filter – all frequencies are passed, but the phase of the output is modified. Cutoff frequency is the frequency beyond which the filter will not pass signals. It is usually measured at a specific attenuation such as 3 dB. Roll-off is the rate at which attenuation increases beyond the cut-off frequency. Transition band, the (usually narrow) band of frequencies between a passband and stopband. Ripple is the variation of the filter’s insertion loss in the passband. "],
["22-5-r-r-multiscale.html", "22.5 R 예제(R-multiscale)", " 22.5 R 예제(R-multiscale) 웨이블릿과 관련된 R 예제를 담고 있는 책은 (G. Nason 2010)이 있다. 이 책의 저자는 wavethresh란 R 패키지를 만들기도 했다. 또 다른 R 패키지로 waveslim이라는 것도 있다. 여기서는 (G. Nason 2010)의 예제를 일부 다뤄보기로 한다. wavethresh 라이브러리를 실행시킨 상황에서, 다음 벡터의 웨이블릿 변환을 실행해본다. wd라는 함수가 이를 가능케 해 준다. wr이라는 함수는 reconstruction을 시킨다. y &lt;- c(1,1,7,9,2,8,8,6) ## wd: wavelet transform ywd &lt;- wd(y, filter.number=1, family=&quot;DaubExPhase&quot;) names(ywd) &gt; [1] &quot;C&quot; &quot;D&quot; &quot;nlevels&quot; &quot;fl.dbase&quot; &quot;filter&quot; &quot;type&quot; &gt; [7] &quot;bc&quot; &quot;date&quot; ## what filter produced a particular wavelet decomposition object ywd$filter &gt; $H &gt; [1] 0.7071068 0.7071068 &gt; &gt; $G &gt; NULL &gt; &gt; $name &gt; [1] &quot;Haar wavelet&quot; &gt; &gt; $family &gt; [1] &quot;DaubExPhase&quot; &gt; &gt; $filter.number &gt; [1] 1 ## level 2 detail coefficients accessD(ywd, level=2) &gt; [1] 0.000000 -1.414214 -4.242641 1.414214 ## plot wavelet decomposition coefficients plot(ywd) FIGURE 22.4: Wavelet decomposition coefficients. &gt; [1] 7 7 7 ## wr: wavelet reconstruction wr(ywd) &gt; [1] 1 1 7 9 2 8 8 6 References "],
["23-wavelettransform.html", "Chapter 23 웨이블릿 변환", " Chapter 23 웨이블릿 변환 웨이블릿은 ’Wave’와 프랑스어 ’let’의 합성어로, ’let’은 ’small’이라는 뜻을 가지고 있다. 즉 웨이블릿은 ’small wave’라는 뜻으로, 컴팩트 받침(compactly supported)인 함수들을 일컷는 말이다. 사인(Sine), 코사인(cosine) 기저(basis)는 \\((-\\infty, \\infty)\\)에서 정의되는 매우 큰 파동이므로 웨이블릿에 해당하지 않는다. 웨이블릿 변환(wavelet transform)이란 웨이블릿 기저함수를 이용해 데이터를 변환하는 것을 말한다. 여기서 웨이블릿 기저함수라는 건 적분하면 0이 되고, 진동하면서 진폭이 0으로 수렴하는 함수를 말한다. "],
["23-1-haar-discrete-haar-wavelet-transform.html", "23.1 이산 Haar 웨이블릿 변환(discrete Haar wavelet transform)", " 23.1 이산 Haar 웨이블릿 변환(discrete Haar wavelet transform) 가장 단순한 웨이블릿 변환으로 Haar 웨이블릿 변환(Haar wavelet transform)이 있다. 앞서 상세와 성김은 다음과 같이 구할 수 있었음을 상기하자. \\[d_{k}=y_{2k}-y_{2k-1}, c_{k}=y_{2k}+y_{2k-1}.\\] 에너지를 보존하기 위해 다음과 같이 \\(\\alpha\\)라는 상수를 고려하자. \\[d_{k}=\\alpha(y_{2k}-y_{2k-1}), c_{k}=\\alpha(y_{2k}+y_{2k-1}).\\] 그러면 \\[\\begin{eqnarray*} d_{k}^{2}+c_{k}^{2}&amp;=&amp;\\alpha^{2}(y_{2k}^{2}-2y_{2k}y_{2k-1}+y_{2k-1}^{2}+\\alpha^{2}(y_{2k}^{2}+2y_{2k}y_{2k-1}+y_{2k-1}^{2})\\\\ &amp;=&amp;2\\alpha^{2}(y_{2k}^{2}+y_{2k-1}^{2}) \\end{eqnarray*}\\] 즉 \\(2\\alpha^{2}=1 \\Rightarrow \\alpha=\\frac{1}{\\sqrt{2}}\\)이면 \\(y\\)와 \\(d\\)의 에너지가 보존(conserved)된다. 이렇게 \\[d_{k}=\\frac{1}{\\sqrt{2}}(y_{2k}-y_{2k-1}), c_{k}=\\frac{1}{\\sqrt{2}}(y_{2k}+y_{2k-1}).\\] 하는 것을 표준화(normalization)라고 말하기도 한다. 정리하면 Haar 웨이블릿 변환(Haar wavelet transform)의 이산 웨이블릿 계수(discrete wavelet coefficient) \\(d_{k}\\)는 \\[d_{k}=g_{0}y_{2k}+g_{1}y_{2k-1}=\\sum_{l=-\\infty}^{\\infty}g_{l}y_{2k-l}\\] 이며 여기서 \\[ g_{l} = \\begin{cases} \\frac{1}{\\sqrt{2}} &amp; \\text{if $l=0$} \\\\ -\\frac{1}{\\sqrt{2}} &amp; \\text{if $l=1$}\\\\ 0 &amp; \\text{o.w.}\\\\ \\end{cases} \\] 여기서 \\(g_{l}\\)을 고역 필터(high-pass filter)라고 부른다. 마찬가지로 성김에 대해서도 \\[ c_{k}= \\sum_{l=-\\infty}^{\\infty}h_{l}y_{2k-l}, h_{l} = \\begin{cases} \\frac{1}{\\sqrt{2}} &amp; \\text{if $l=0$}\\\\ \\frac{1}{\\sqrt{2}} &amp; \\text{if $l=1$}\\\\ 0 &amp; \\text{o.w.} \\end{cases} \\] 로 나타낼 수 있고 \\(h_{l}\\)을 저역 필터(low-pass filter)라 부른다. 세부와 성김은 앞서 언급한 피라미드 알고리즘으로 구할 수도 있지만 여기서는 \\(\\mathbf{d}=\\mathbf{Wy}\\)처럼 통계학자들에게 익숙한 행렬 꼴로 바꾸어 표현한다. Example 23.1 (행렬을 이용한 웨이블릿 계수의 계산) 행렬을 이용해 웨이블릿 계수를 계산해보자. 다음과 같은 자료 \\(\\mathbf{y}=(1,1,7,9,2,8,8,6)\\)에 행렬 \\(W\\)을 다음과 같이 정의하면 \\[ W = \\begin{bmatrix} \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4}\\\\ \\frac{1}{\\sqrt{2}} &amp; -\\frac{1}{\\sqrt{2}} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\frac{1}{\\sqrt{2}} &amp; -\\frac{1}{\\sqrt{2}} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\frac{1}{\\sqrt{2}} &amp; -\\frac{1}{\\sqrt{2}} &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\frac{1}{\\sqrt{2}} &amp; -\\frac{1}{\\sqrt{2}}\\\\ \\frac{1}{2} &amp; \\frac{1}{2} &amp; -\\frac{1}{2} &amp; -\\frac{1}{2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\frac{1}{2} &amp; \\frac{1}{2} &amp; -\\frac{1}{2} &amp; -\\frac{1}{2}\\\\ \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; \\frac{\\sqrt{2}}{4} &amp; -\\frac{\\sqrt{2}}{4} &amp; -\\frac{\\sqrt{2}}{4} &amp; -\\frac{\\sqrt{2}}{4} &amp; -\\frac{\\sqrt{2}}{4}\\\\ \\end{bmatrix} \\] \\(\\mathbf{d}=(\\frac{21\\sqrt{2}}{2},0,-\\sqrt{2},-3\\sqrt{2},\\sqrt{2},-7,-2,\\frac{3\\sqrt{2}}{2})\\)를 얻을 수 있다. (이 예제에서는 (G. Nason 2010)의 정의를 따라갔다.) 위 예제의 \\(W\\)처럼 Haar 웨이블릿의 \\(W\\)는 정규직교(orthonormal)라는 성질을 갖는데, 정규직교의 의미는 \\(W^{T}W=I\\)이다. 그러나 모든 웨이블릿의 \\(W\\)가 정규직교인 것은 아니다. 그리고 \\[\\| \\mathbf{d} \\|^{2}=\\mathbf{d}^{T}\\mathbf{d}=(W\\mathbf{y})^{T}(W\\mathbf{y})=\\mathbf{y}^{T}W^{T}W\\mathbf{y}=\\| \\mathbf{y} \\|^{2}.\\] 이 식은 Parseval 등식(Parseval’s identity)에 대응된다. 정규직교인 웨이블릿의 \\(W\\)은 다음과 같은 장점을 갖는다. 다음과 같이 원래 자료와 추정량에 대한 공식이 다음과 같이 주어졌을 때, \\[y=f+\\epsilon, \\epsilon \\sim (\\cdot, \\sigma^{2}I) \\rightarrow d=\\theta +e, Wy=d, Wf=\\theta, W\\epsilon=e\\] 정규직교인 \\(W\\)이면 \\[Var(W\\epsilon)=WVar(\\epsilon)W^{T}=\\sigma^{2}I=Var(\\epsilon)\\] 이다. 즉 원래 자료와 추정량의 분산 구조가 같다. References "],
["23-2-scaling-coefficient-translation-coefficient-.html", "23.2 압축계수(scaling coefficient)와 전이계수(translation coefficient) 개념", " 23.2 압축계수(scaling coefficient)와 전이계수(translation coefficient) 개념 \\(p(x)\\)라는 함수가 주어졌을 때, 이것의 압축 및 전이된 버전(scaled and translated version)은 다음과 같이 정의된다. \\[p_{j,k}(x)=2^{\\frac{j}{2}}p(2^{j}x-k)\\] \\[ \\| p_{j,k}(x) \\|^{2}=\\int_{\\infty}^{\\infty}p_{j,k}^{2}(x)dx=\\int_{\\infty}^{\\infty}2^{j}p^{2}(2^{j}x-k)dx=\\int_{\\infty}^{\\infty}p^{2}(y)dy=\\| p(y) \\|^{2} \\] "],
["23-3-fine-scale-approximation.html", "23.3 섬세한 척도 근사(fine-scale approximation)", " 23.3 섬세한 척도 근사(fine-scale approximation) 다음과 같이 Haar 함수(Haar function)를 정의한다. \\[ \\phi(x) = \\begin{cases} 1 &amp; \\text{if $x \\in [0,1]$}\\\\ 0 &amp; \\text{o.w.} \\end{cases} \\] FIGURE 23.1: Plot of Haar function. 이 때 \\(\\phi(x)=\\phi_{0,0}(x)\\)이다. 즉 척도도 바꾸지 않고 어떤 전이(translation)도 없을 때의 \\(\\phi\\)인 것이다. FIGURE 23.2: Scaling and translation version of Haar function. 가장 섬세한 레벨의 (Haar) 척도 웨이블릿(scaling wavelet, father wavelet)은 \\[c_{J,k}=\\int f(x) \\phi_{J,k}(x)dx=\\int f(x) 2^{\\frac{J}{2}}\\phi(2^{J}x-k)dx\\] 이다. 이것은 앞서 말한 \\(p\\)를 \\(\\phi\\)로 바꾸면 되며 또한 데이터와 같음을 알고 있다. 그리고 앞의 정의들을 이용하면 \\[ \\phi_{J,k} = \\begin{cases} 2^{\\frac{J}{2}} &amp; \\text{if $x \\in [2^{-J}k,2^{-J}(k+1)]$}\\\\ 0 &amp; \\text{o.w.} \\end{cases} \\] 이다. 여기서 정의하는 간격을 \\(I_{J,k}\\)라 한다. 우리는 다양한 척도에서 \\(f\\)를 근사할 수 있다. 가장 섬세한 척도로는 \\[f_{J}=\\sum_{k=0}^{2^{J}-1}c_{J,k}\\phi_{J,k}(x)\\] 가 있으며, 가장 성긴 척도로 근사하고 싶으면 \\[f_{0}=\\sum_{k=0}^{2^{0}-1}c_{0,k}\\phi_{J,k}(x)\\] 로 \\(f\\)를 근사한다. "],
["23-4-computing-coarser-scale-coefficients-from-fine-scale.html", "23.4 섬세한 척도로부터 성긴 척도 계수의 계산(computing coarser scale coefficients from fine scale)", " 23.4 섬세한 척도로부터 성긴 척도 계수의 계산(computing coarser scale coefficients from fine scale) 앞에서 말한대로, 우리는 섬세한 척도의 계수들로부터 좀 더 성긴 척도의 계수들을 구할 수 있다. \\[\\begin{eqnarray*} c_{J-1,k}&amp;=&amp;\\int_{2^{-(J-1)}k}^{2^{-(J-1)}(k+1)}f(x)\\phi_{J-1,k}(x)dx\\\\ &amp;=&amp;\\int_{2^{-J}(2k)}^{2^{-J}(2k+2)}f(x)2^{(\\frac{J-1}{2})}\\phi(2^{J-1}x-k)dx\\\\ &amp;=&amp;2^{-\\frac{1}{2}}\\int_{2^{-J}(2k)}^{2^{-J}(2k+2)}f(x)2^{\\frac{J}{2}}\\phi(2^{J-1}x-k)dx\\\\ &amp;=&amp;2^{-\\frac{1}{2}}[\\int_{2^{-J}(2k)}^{2^{-J}(2k+2)}f(x)2^{\\frac{J}{2}}\\phi(2^{J}x-2k)dx + \\int_{2^{-J}(2k)}^{2^{-J}(2k+2)}f(x)2^{\\frac{J}{2}}\\phi(2^{J}x-2k-1)dx]\\\\ &amp;=&amp;2^{-\\frac{1}{2}}(c_{J,2k}+c_{J,2k+1}).\\\\ \\end{eqnarray*}\\] 즉 \\({J-1}\\)척도 계수는 \\(J\\)척도 계수로부터 구할 수 있다. 여기서 중간에 \\[\\phi(x)=\\phi(2x)+\\phi(2x-1)\\] 이라는 사실을 이용하였는데, 이것은 매우 중요하다. 이것을 척도방정식(two-scale relationship) 또는 팽창방정식(dilation relationship)이라고 한다. FIGURE 23.3: Relationship between Haar scale function. "],
["23-5-defference-between-scale-approximations-.html", "23.5 척도 근사들 사이의 차이(defference between scale approximations)(이를 웨이블릿이라 부름)", " 23.5 척도 근사들 사이의 차이(defference between scale approximations)(이를 웨이블릿이라 부름) 척도 근사들의 차이에서 도출된 함수들이 작은 파도(small wave) 형태를 띄므로 이것을 웨이블릿이라 부른다. 앞서 근사식 \\(f_{J}=\\sum_{k=0}^{2^{J}-1}c_{J,k}\\phi_{J,k}(x)\\)과 \\(p_{j,k}(x)=2^{\\frac{j}{2}}p(2^{j}x-k)\\)으로부터 \\(J=1\\)일 때에는 \\[ f_{1}(x)=c_{10}\\phi_{10}(x)+c_{11}\\phi_{11}(x)=c_{10}2^{\\frac{1}{2}}\\phi(2x)+c_{11}2^{\\frac{1}{2}}\\phi(2x-1) \\] 이다. 여기서 \\(f_{0}(x)=c_{00}\\phi_{00}(x)\\)라 하고 \\(c_{J-1,k}=\\frac{c_{J,2k}+c_{J,2k-1}}{\\sqrt{2}}\\)를 이용하면 \\[\\begin{eqnarray*} f_{1}(x)-f_{0}(x)&amp;=&amp;c_{10}\\phi_{10}(x)+c_{11}\\phi_{11}(x)-c_{00}\\phi_{00}(x)\\\\ &amp;=&amp;c_{10}2^{\\frac{1}{2}}\\phi(2x)+c_{11}2^{\\frac{1}{2}}\\phi(2x-1)-c_{00}(\\phi(2x)+\\phi(2x-1))\\\\ &amp;=&amp;(c_{10}2^{\\frac{1}{2}}-c_{00})\\phi(2x)+(c_{11}2^{\\frac{1}{2}}-c_{00})\\phi(2x-1)\\\\ &amp;=&amp;(\\frac{c_{10}-c_{11}}{\\sqrt{2}})\\phi(2x)-(\\frac{c_{10}-c_{11}}{\\sqrt{2}})\\phi(2x-1)\\\\ &amp;=&amp;(\\frac{c_{10}-c_{11}}{\\sqrt{2}})(\\phi(2x)-\\phi(2x-1))\\\\ &amp;=&amp;d_{00}\\psi(x).\\\\ \\end{eqnarray*}\\] 여기서 \\((\\frac{c_{10}-c_{11}}{\\sqrt{2}})\\)은 웨이블릿 상수에 해당하고, \\(\\psi(x)=\\phi(2x)-\\phi(2x-1)\\)은 Haar 모웨이블릿(Haar mother wavelet)이라고 한다. \\[ \\psi(x) = \\begin{cases} 1 &amp; \\text{if $x \\in [0,\\frac{1}{2})$}\\\\ -1 &amp; \\text{if $x \\in [\\frac{1}{2},1)$}\\\\ 0 &amp; \\textrm{o.w.} \\end{cases} \\] FIGURE 23.4: Haar mother wavelet function. 우리는 웨이블릿을 가지고 어떤 함수를 분해(decompose)할 수 있다. 앞의 결과는 \\[ f_{1}(x)=f_{0}(x)+d_{00}\\psi(x)=c_{00}\\phi(x)+d_{00}\\psi(x) \\] 로 쓸 수 있으며 \\(f_{1}\\)을 좀 더 성긴 척도함수인 \\(f_{0}\\)과 차이(difference)에 해당하는 \\(\\psi(x)\\)로 분해할 수 있음을 보여준다. 일반적으로 \\(f_{j+1}(x)\\)는 다음과 같이 쓸 수 있다. \\[\\begin{eqnarray*} f_{j+1}(x)&amp;=&amp;\\sum_{k=0}^{2^{j}-1}c_{jk}\\phi_{jk}(x)+\\sum_{k=0}^{2^{j}-1}d_{jk}\\psi_{jk}(x)\\\\ &amp;=&amp;f_{j}(x)+g_{j}(x)\\\\ &amp;=&amp;f_{j-1}(x)+g_{j-1}(x)+g_{j}(x)\\\\ &amp;=&amp; \\vdots \\\\ &amp;=&amp;f_{0}(x)+\\sum_{l=0}^{j}g_{l}(x).\\\\ \\end{eqnarray*}\\] 즉 \\(f_{j+1}(x)\\)은 가장 성긴 근사함수인 \\(f_{0}\\)와 각 수준에서의 차이인 \\(g_{l}\\)들의 합으로 표현할 수 있다. "],
["23-6-types-of-wavelets.html", "23.6 웨이블릿의 종류들(types of wavelets)", " 23.6 웨이블릿의 종류들(types of wavelets) 23.6.1 Haar 웨이블릿(Haar wavelet) 다음과 같이 Haar 함수(Haar function)의 정의를 다시 상기하자. \\[ \\phi(x) = \\begin{cases} 1 &amp; \\text{if $x \\in [0,1]$}\\\\ 0 &amp; \\text{o.w.} \\end{cases} \\] \\(x\\)를 물리적 영역(physical domain) 또는 시간 영역(time domain, t)이라 생각하면, 시간에 대해 컴팩트 받침(compactly supported)인 함수이다. 우리의 궁금점은 이 함수과 과연 주파수 영역(frequency domain)에서도 컴팩트 받침인가이다. Definition 23.1 (유니터리 푸리에 변환) 주어진 함수의 각진동수(angular frequency)를 이용한 유니터리 푸리에 변환(Fourier transform with unitary and angular frequency)은 다음과 같다. \\[\\hat{f}(\\omega)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}f(x)e^{-i\\omega x}dx\\] 여기서 \\(\\frac{1}{\\sqrt{2\\pi}}\\)는 이 변환을 유니터리 푸리에 변환으로 만들기 위해 곱해지는 상수이다. 유니터리 변환과 푸리에 변환에 대한 보다 자세한 나용은 인터넷을 참조하기 바란다. 앞서 나온 푸리에 변환을 이용해 Haar 함수를 푸리에 변환한 결과는 다음과 같다. \\[\\hat{\\phi}(\\omega)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{i\\omega}{2}}\\text{sinc}(\\frac{\\omega}{2}).\\] 여기서 \\[ \\text{sinc}(\\omega)= \\begin{cases} \\frac{\\sin (\\omega)}{\\omega} &amp; \\text{if $\\omega \\neq 0$}\\\\ 1 &amp;\\text{if $\\omega = 0$} \\end{cases} \\] 이다. \\(\\hat{\\phi}(\\omega)\\)는 \\(| \\omega |^{-1}\\)만큼의 감쇠(decay)를 가지며 꼬리가 굉장히 긴 함수이다. 즉 주파수 영역에서 이 함수는 컴팩트 받침과 거리가 먼 함수가 된다. 시간 영역과 주파수 영역 사이에 불확정성 원리(uncertainty principle)이 있다는 것은 알려진 사실이다. FIGURE 23.5: Haar function (left) and Haar function in frequency domain after Fourier transform (right). "],
["24-generalDWT.html", "Chapter 24 일반적인 웨이블릿 변환 ", " Chapter 24 일반적인 웨이블릿 변환 "],
["24-1-the-general-fast-dwt.html", "24.1 일반적인 이산 웨이블릿 변환(the general fast DWT)", " 24.1 일반적인 이산 웨이블릿 변환(the general fast DWT) 앞선 내용들에서는 어떻게 성긴 스케일의 Haar 웨이블릿 계수들을 구하는지에 대해 설명했다. 여기서는 좀 더 일반적인 경우에 대해 설명한다. 24.1.1 이산웨이블릿 변환에서의 전방변환(the forward transform in DWT) 다음과 같은 함수 \\(f(x)\\in L^{2}(\\mathbb{R})\\)이 있다고 하자. 그러면 레벨 \\(J\\)의 웨이블릿 계수로부터 레벨 \\(J-1\\)의 웨이블릿 계수를 어떻게 구할 수 있을까? 일단 다시한 번 \\(J-1\\) 레벨의 척도웨이블릿 (또는 부웨이블릿) \\(c\\)를 구하는 방법에 대해 생각해보자. \\[\\begin{equation} c_{J-1,k}=\\int_{\\mathbb{R}}f(x)\\phi_{J-1,k}(x)dx \\tag{23.1} \\end{equation}\\] 왜냐하면 \\(\\{ \\phi_{J-1,k(x)}\\}_{k}\\)가 \\(V_{j-1}\\)의 직교정규기저이기 때문이다. (?) (\\(\\phi\\): 척도함수 또는 부웨이블릿) 이제 \\(J-1\\) 레벨의 \\(\\phi_{J-1,k}(x)\\)를 \\(\\phi_{J,l}(x)\\)와 dilation eqn \\(\\phi(x)=\\sum_{n\\in\\mathbb{Z}}h_{n}\\phi_{1n}(x)\\)를 이용해 나타내보자. \\[\\begin{eqnarray} \\phi_{J-1,k}(x)&amp;=&amp;s^{(J-1)/2}\\phi(2^{J-1}x-k)\\nonumber\\\\ &amp;=&amp;2^{(J-1)/2}\\sum_{n}h_{n}\\phi_{1,n}(2^{J-1}x-k)\\nonumber\\\\ &amp;=&amp;2^{(J-1)/2}\\sum_{n}h_{n}2^{1/2}\\phi\\{2(2^{J-1}x-k)-n\\}\\nonumber\\\\ &amp;=&amp;2^{J/2}\\sum_{n}h_{n}\\phi(2^{J}x-2k-n)\\nonumber\\\\ &amp;=&amp;\\sum_{n}h_{n}\\phi_{J,n+2k}(x). \\tag{23.2} \\end{eqnarray}\\] 이 때 위 식에 (23.1)을 넣으면 \\[\\begin{eqnarray} c_{J-1,k}&amp;=&amp;\\int_{\\mathbb{R}}f(x)\\sum_{n}h_{n}\\phi_{J,n+2k}(x)dx\\nonumber\\\\ &amp;=&amp;\\sum_{n}h_{n}\\int_{\\mathbb{R}}f(x)\\phi_{J,n+2k}(x)dx\\nonumber\\\\ &amp;+&amp;\\sum_{n}h_{n}c_{J,n+2k} \\tag{23.3} \\end{eqnarray}\\] 이며, 약간 재조정하면 \\[\\begin{equation} c_{J-1,k}=\\sum_{n}h_{n-2k}c_{J,n} \\tag{23.4} \\end{equation}\\] 으로 쓸 수 있다. 같은원리로 \\[\\begin{equation} d_{J-1,k}=\\sum_{n}g_{n-2k}c_{J,n} \\tag{23.5} \\end{equation}\\] 을 얻을 수 있다고 한다. 24.1.2 필터링, 이진 데시메이션, 그리고 다운스케일링(filtering, dyadic decimation, downscaling) 앞서 언급한 (23.4), (23.5)을 다른 방법으로 생각해 볼 수도 있다. 예를 들면, 우리는 (23.4)와 같은 결과를 처음에 수열 \\(\\{c_{J,n}\\}\\)에 대해 \\(\\{h_{n}\\}\\)이라는 필터를 적용함으로써 \\[c_{J-1,k}^{*}=\\sum_{n}h_{n-k}c_{J,n}\\] 이라는 결과를 얻을 수 있다는 것이다. 이는 일반적인 convolution 식이다. 여기서 ’every other one’을 pick해 \\(c_{J-1,k}=c_{J-1,2k}^{*}\\)을 만드는 것이다. 이 연산을 이진 데시메이션(dyadic decimation)이라고 한다(by an integer factor of 2). Definition 23.2 (이진 데시메이션) (even dyddic decimation operator) 어떤 수열 \\(x_{i}\\)에 대한 (even) 이진 데시메이션 연산자(dyadic decimation operator) \\(\\mathcal{D}_{0}\\)는 \\[(\\mathcal{D}_{0}x)_{l}=x_{2l}\\] 로 정의한다. 그러면 식 (23.4)와 (23.5)는 (even) 이진 데시메이션 연산자를 활용해 \\[c_{J-1}=\\mathcal{D}_{0}\\mathcal{H}c_{J} \\text{ and } d_{J-1}=\\mathcal{D}_{0}\\mathcal{G}c_{J}\\] 로 나타낼 수 있다. 이 때 \\(\\mathcal{H}\\)와 \\(\\mathcal{G}\\)는 정규 필터링 연산(regular filtering operation)을 나타낸다. 이러한 연산자의 사용은 식의 표현을 좀 더 효율적으로 만든다. 이를 응용해, DWT 계수들의 전체집합은 \\[d_{j}=\\mathcal{D}_{0}\\mathcal{G}(\\mathcal{D}_{0}\\mathcal{H})^{J-j-1}c_{J},\\] \\[c_{j}=(\\mathcal{D}_{0}\\mathcal{H})^{J-j}c_{J}\\] 로 표현할 수 있다. (\\(j=0,\\ldots , J-1\\)) 이 때 \\(d_{j}\\), \\(c_{j}\\)는 길이 \\(2^{j}\\)인 벡터임을 상기하자. 이런 벡터/연산자 개념은 유용하며 계산 단위들 \\(\\mathcal{D}_{0}\\mathcal{G}\\), \\(\\mathcal{D}_{0}\\mathcal{H}\\)가 컴퓨터 프로그램 안에서 부품화(compartmentalized)될 수 있어 쉽게 개발이 가능하다는 장점이 있다. 이러한 표현은 수학적으로 자유롭게 하고 비-데시메이티드 웨이블릿과 같은 좀 더 복잡한 알고리즘을 개발할 때 더 유용하게 사용할 수 있다. 24.1.3 최초의 부웨이블릿 계수 얻어내기(obtaining the initial fine-scale father coefficients) 앞에서 얘기했던 대로 웨이블릿 변환은 가장 상세한 스케일의 부웨이블릿 계수들 \\(\\{c_{J,k}\\}_{k\\in\\mathbb{Z}}\\)에서 시작되어야 한다. 그렇다면 이 미스테리한 가장 상세한 스케일의 부웨이블릿 계수들은 어디서 오는가? 여기에는 크게 두 가지 방법이 있다. 결정적 방법(deterministic approach)은 (Daubechies 1992)의 5장에 묘사되어 있다. 우리의 함수에 관한 정보가 표본으로부터 온다고 가정해보다. 즉 함수 \\(f\\)의 정보는 정수로 표현되는 함수값들 \\(f(n),n\\in\\mathbb{Z}\\)로부터 오는 것이다. 우리가 \\(f\\in V_{0}\\)의 부웨이블릿 계수들을 얻고자 한다고 가정해보자. (\\(V_{0}\\)와 직교인 정보는 실제 \\(f\\)가 \\(V_{0}\\) 안에 있는지와는 상관없이 복원될 수 없다.) 이제 \\(f\\in V_{0}\\)이므로 우리는 \\[\\begin{equation} f(x)=\\sum_{k}\\langle f, \\phi_{0,k} \\rangle \\phi_{0,k}(x) \\end{equation}\\] 와 같이 쓸 수 있다. 여기서 \\(\\langle\\cdot , \\cdot\\rangle\\)은 내적을 의미한다. 그러므로 \\[\\begin{equation} f(n)=\\sum_{k}\\langle f, \\phi_{0,k} \\rangle \\phi(n-k) \\end{equation}\\] 가 된다. 여기에 이산 푸리에 변환을 양 변에 적용한다면 다음과 같이 된다. \\[\\begin{eqnarray} \\sum_{n}f(n)e^{-i\\omega n}&amp;=&amp;\\sum_{k}\\langle f, \\phi_{0,k} \\rangle \\sum_{n}\\phi(n-k)e^{-i\\omega n}\\nonumber\\\\ &amp;=&amp;\\sum_{k}\\langle f, \\phi_{0,k} \\rangle \\sum_{m}\\phi(m)e^{-i\\omega (m+k)}\\nonumber\\\\ &amp;=&amp;\\{ \\sum_{k}\\langle f, \\phi_{0,k} \\rangle \\sum_{m}e^{-i\\omega k} \\}\\{ \\sum_{m} \\phi(m) e^{-i\\omega m}\\}\\\\ &amp;=&amp;\\Phi(\\omega)\\sum_{k}\\langle f, \\phi_{0,k} \\rangle e^{-i\\omega k} \\tag{23.6} \\end{eqnarray}\\] (특별하지 않으면 이것을 사용) stochastic approach 24.1.4 역 이산 웨이블릿 변환(inverse discrete wavelet transform) References "],
["24-2-the-epsilon-decimated-wavelet-transform.html", "24.2 엡실론-데시메이티드 웨이블릿 변환(the epsilon-decimated wavelet transform)", " 24.2 엡실론-데시메이티드 웨이블릿 변환(the epsilon-decimated wavelet transform) (Wavelet methods in statistics with R 57쪽) Dyadic decimation \\(\\mathcal{D}_{0}\\)는 벡터의 even element들만을 pick하게 된다. 그런데 반대로 벡터의 모든 odd element들만 이용해서 연산자를 만들 수도 있다. 이를 이용해 새로운 odd dyadic decimation operator \\(\\mathcal{D}_{1}\\)을 \\[(\\mathcal{D}_{1}x)_{l}=x_{2l+1}\\] 과 같이 정의한다. 그러면 level \\(j\\)의 부, 모웨이블릿 계수들 또한 \\(\\mathcal{D}_{0}\\)를 \\(\\mathcal{D}_{1}\\)으로 대체함으로써 모두 얻어낼 수 있을 것이다. 이것은 어떤 직교기저를 선택하느냐라는 것과 같은 문제이다. Nason과 Silverman (1995)는 더 나아가 모든 레벨에서 \\(\\mathcal{D}_{0}\\)를 쓸지 아니면 \\(\\mathcal{D}_{1}\\)를 쓸지 사용자가 결정할 수 있고 이에 따라 특별한 직교기저가 만들어진다고 지적했다. 이 논리에 따르면 특별한 기저는 \\[\\epsilon=\\epsilon_{J-1}\\epsilon_{J-2}\\cdots\\epsilon_{0}\\] 로 쓸 수 있으며 이 때 \\[ \\epsilon_{j} = \\begin{cases} 1 &amp; \\text{if $\\mathcal{D}_{1}$ is used} \\\\ 0 &amp; \\text{if $\\mathcal{D}_{0}$ is used}\\\\ \\end{cases} \\] 이다. 이 변환은 epsilon-decimated wavelet transform이라고 부른다. 다시 finest scale에서 일어나는 일들을 살펴보자. 이 때 \\(\\mathcal{D}_{1}\\)은 수열을 cyclically ’rotating’함으로써, 즉 \\[x_{k+1} \\leftarrow x_{k}, x_{0} \\leftarrow x_{2^{J}-1}\\] 로 놓고 \\(\\mathcal{D}_{0}\\)를 적용시키면 된다. 즉 \\[\\mathcal{D}_{1}=\\mathcal{D}_{0}\\mathcal{S}\\] 이며 이 때 \\(\\mathcal{S}\\)는 이동 연산자(shift operator)라고 하며 \\[(\\mathcal{S}x)_{j}=x_{j+1}\\] 로 정의한다. 이 논리를 확장하여, \\[\\mathcal{S}\\mathcal{D}_{0}=\\mathcal{D}_{0}\\mathcal{S}^{2}\\] 이며 \\(\\mathcal{S}\\)는 \\(\\mathcal{H}\\), \\(\\mathcal{G}\\)와 관련을 갖는다. Nason과 Silverman (1995)는 epsilon-decimated wavelet transform의 기저벡터를 DWT에 특별한 이동 연산자를 붙임으로써 얻을 수 있음을 보였다. 한 가지 상기해야 할 사실은 standard DWT는 origin의 선택에 의존한다는 점이다. 즉 input data를 이동시키면 완전히 다른 웨이블릿 계수를 얻을 수도 있다는 것이다. 그러나 비모수 회귀분석 등에서 우리는 우리의 회귀분석 방법이 origin의 선택에 민감하지 않았으면 할 것이다. 즉, 우리는 이동 불변(translation invariant)한 방법을 선호한다. "],
["24-3-the-non-decimated-wavelet-transform-ndwt.html", "24.3 비-데시메이티드 웨이블릿 변환(the non-decimated wavelet transform, NDWT)", " 24.3 비-데시메이티드 웨이블릿 변환(the non-decimated wavelet transform, NDWT) 일반적인 데시메이티드 웨이블릿 변환(the decimated wavelet transform, DWT)은 직교이며 어떤 기저에서 다른 기저로의 변환 정보를 담고 있는 것이다. Parseval 관계식은 변환 후에도 total energy가 보존됨을 보장해준다. 그러나 추가적인 정보를 더 담고 싶어할 수도 있다. \\[d_{2,1}=(y_{2}-Y_{1})/\\sqrt{2} \\text{ and } d_{2,2}=(y_{4}-y_{3})/\\sqrt{2}\\] 처음 두 개의 계수들은 \\((y_{1}, y_{2})\\)의 차, \\((y_{3}, y_{4})\\)의 차를 encoding하고 있다. 그렇다면 \\(y_{2}\\)와 \\(y_{3}\\)의 차이 정보는 담을 수 없는 것인가? 만약 \\(y_{2}\\)와 \\(y_{3}\\)의 차이가 심하다면 우리는 중요한 정보를 놓치고 있는 것일 수 도 있다. 비-데시메이티드 웨이블릿 변환(the non-decimated wavelet transform, NDWT)의 아이디어는 각 스케일에서 odd와 even decimation들을 모두 저장하는 것이다. FIGURE 23.6: Non-decimated wavelet transform flow diagram. 비-데시메이티드 웨이블릿 변환의 실행 절차는 다음과 같다. 주어진 자료를 \\(\\mathcal{y}=(y_{1},\\ldots ,y_{n})^{T}\\)라고 하자. 그러면 even and odd indexed ‘wavelet’ filtered observations \\[\\mathbf{d}_{0}=\\mathcal{D}_{0}\\mathcal{G}\\mathbf{y} \\text{ and }\\mathbf{d}_{1}=\\mathcal{D}_{1}\\mathcal{G}\\mathbf{y}\\] 를 저장해 놓는다. 이 두 상세계수는 각각 \\(\\frac{n}{2}\\)개로, 합치면 \\(n\\)개가 되고 임의 레벨에서의 계수 숫자는 줄지 않는다. \\(\\mathbf{c}_{0}=\\mathcal{D}_{0}\\mathcal{H}\\mathbf{y}\\), \\(\\mathbf{c}_{1}=\\mathcal{D}_{1}\\mathcal{H}\\mathbf{y}\\)를 계산한다. (역시 각각 \\(\\frac{n}{2}\\)개다) 계속 반복한다. 즉 \\(\\mathcal{D}_{0}\\mathcal{G}, \\mathcal{D}_{1}\\mathcal{G}, \\mathcal{D}_{0}\\mathcal{H}, \\mathcal{D}_{1}\\mathcal{H}\\)를 \\(\\mathbf{c}_{0}\\)와 \\(\\mathbf{c}_{1}\\)에 적용한다. 자세한건 그림을 참조하자. 참고로 \\(\\mathbf{d}_{00}, \\mathbf{d}_{01}, \\mathbf{d}_{10}, \\mathbf{d}_{11}\\)은 각각 \\(\\frac{n}{4}\\)개만큼 있다. 이러한 방법을 따라 계속하면, \\(J-j\\) scale에는 \\(2^{j}\\) set of 계수들이 존재하며 각각의 길이는 \\(2^{-j}n, j=1,\\ldots, J\\)이다. (참고 \\(n=2^{J}\\)) 각 레벨에서의 웨이블릿 계수들의 수는 \\(2^{-j}n\\times s^{j}=n\\)으로 항상 일정하다. 스케일이 \\(J\\)만큼 있으면 계수들의 총 수는 \\(Jn\\)이며, \\(J=\\log_{2}n\\)이므로, 계수들의 총 수는 다시 \\(n\\log_{2}n\\)으로 쓸 수 있다. 즉 NDWT를 위한 computational effort 또한 \\(\\mathcal{O}(n\\log_{2}n)\\)이다. 이는 DWT의 computation effort \\(\\mathcal{O}_{n}\\)보다는 느리나 그래도 빠른 편으로 생각할 수 있다. 우리는 종종 계수들의 set을 패킷(packet)으로 부르기도 한다. 그러나 이 패킷은 뒤에 나올 웨이블릿 패킷과는 다른 얘기다. 24.3.1 시간순서 NDWT와 패킷순서 NDWT(time and packet NDWT orderings) 다음과 같은 자료 \\(\\mathbf{y}=(y_{1}, \\ldots , y_{8})\\)이 있다고 하자. Time-ordered NDWT: 시간 순서에 따라 NDWT르 하는 것이다. 즉 \\[(y_{2}-y_{1}), (y_{3}-y_{2}), (y_{4}-y_{3}), (y_{5}-y_{4}), (y_{6}-y_{5}), (y_{7}-y_{6}), (y_{8}-y_{7}), (y_{1}-y_{8})\\] 이다. 이 방법은 시계열자료에 많이 사용한다. Packet-ordered NDWT: 패킷 두 개로 나누어 계산한다. \\[\\mathcal{D}_{0}\\mathcal{G}\\text{관련: } (y_{2}-y_{1}), (y_{4}-y_{3}), (y_{6}-y_{5}), (y_{8}-y_{7})\\] \\[\\mathcal{D}_{1}\\mathcal{G}\\text{관련: } (y_{3}-y_{2}), (y_{5}-y_{4}), (y_{7}-y_{6}), (y_{1}-y_{8})\\] 이 방법은 operator에 따라 함수의 특성을 잘 찾아내는 게 있으므로 함수자료에 좋다(ex.regression) 종합하면 두 방법은 같은 방법이다. 다만 순서가 다르다. "],
["24-4-r-r-ndwt.html", "24.4 R 예제(R-NDWT)", " 24.4 R 예제(R-NDWT) 데이터 \\(\\mathbf{y}=(1,1,7,9,2,8,8,6)\\)이 있다고 하자. R 패키지 wavethresh에서 시간순서 DWT를 하려면 wd 함수에서 type=&quot;station&quot;을 입력하면 된다. (filter number와 family에 대한 설명 필요) ywdS &lt;- wd(y, filter.number=1, family=&quot;DaubExPhase&quot;, type=&quot;station&quot;) accessD(ywdS, level=2) #finest-scale non-decimated wavelet coefficients(time-order) &gt; [1] 0.000000 -4.242641 -1.414214 4.949747 -4.242641 0.000000 1.414214 &gt; [8] 3.535534 이번에는 패킷순서 DWT이다. 이때는 wd 대신 wst 함수를 쓴다. ywst &lt;- wst(y, filter.number=1, family=&quot;DaubExPhase&quot;) accessD(ywst, level=2) #finest-scale non-decimated wavelet coefficients(packet-order) &gt; [1] 0.000000 -1.414214 -4.242641 1.414214 -4.242641 4.949747 0.000000 &gt; [8] 3.535534 이들 중 odd-decimated coefficient들만 뽑으려면 다음과 같이 하면 된다. getpacket(ywst, level=2, index=1) &gt; [1] -4.242641 4.949747 0.000000 3.535534 index를 바꾸어 레벨을 바꿀 수 있다. getpacket(ywst, level=1, index=3) &gt; [1] -2.5 -0.5 다음은 ywst로 얻은 계수들을 ywd타입으로 바꾸는 명령어다. accessD(convert(ywst), level=2) &gt; [1] 0.000000 -4.242641 -1.414214 4.949747 -4.242641 0.000000 1.414214 &gt; [8] 3.535534 24.4.1 chirp 신호 예제 대칭 chirp 함수를 \\[y(x)=\\sin(\\pi/x)\\] 로 정의한다. 이 때 \\(x=\\epsilon &#39; +(-1,-1,+\\delta,-1+2\\delta, \\ldots, 1-2\\delta)\\)이며 \\(\\epsilon &#39; =10^{-5}\\)이며 \\(\\delta=1/512\\)이다. 이 함수의 그림은 다음과 같다. y &lt;- simchirp() plot(y, type=&#39;l&#39;, xlab=&quot;Time&quot;, ylab=&quot;Chirp value&quot;) FIGURE 23.7: Simulated chirp signal. ywd &lt;- wd(y$y, filter.number=2, family=&quot;DaubExPhase&quot;) plot(ywd, scaling=&quot;by.level&quot;, main=&quot;&quot;) FIGURE 23.8: Discrete wavelet coefficients of simulated chirp signal. &gt; [1] 1.415688 1.704746 2.534105 3.084061 4.387454 5.564347 8.284556 &gt; [8] 7.484166 8.769223 4.756466 ywd &lt;- wd(y$y, filter.number=2, family=&quot;DaubExPhase&quot;, type=&quot;station&quot;) plot(ywd, scaling=&quot;by.level&quot;, main=&quot;&quot;) FIGURE 23.9: Time-ordered non-decimated wavelet coefficients of simulated chirp signal. &gt; [1] 1.570985 1.704746 2.534105 3.558442 5.030347 6.526141 8.756509 &gt; [8] 11.736733 13.175435 7.737538 ywst &lt;- wst(y$y, filter.number=2, family=&quot;DaubExPhase&quot;) plot(ywst, scaling=&quot;by.level&quot;, main=&quot;&quot;) FIGURE 23.10: Packet-ordered non-decimated wavelet coefficients of simulated chirp signal. "],
["24-5-wavelet-packet-transform.html", "24.5 웨이블릿 패킷 변환(wavelet packet transform)", " 24.5 웨이블릿 패킷 변환(wavelet packet transform) PCA의 경우 통계학자들은 차원축소를 위한 한다고 생각하고 통계학자가 아닌 사람들은 해석이 쉽기 떄문에 한다. 웨이블릿에서는 직교정규 웨이블릿 \\(\\{\\psi_{j,k}(x)\\}\\)가 \\(L^{2}(\\mathbb{R})\\)의 기저(basis)가 됨을 설명했다. 그러나 이것이 기저를 만드는 유일한 방법은 아니다. 기저를 만드는 방법은 여러 가지가 있어, 이들을 규합해 basis libraries를 구성하는 것을 생각해 볼 수 있다. 그 예 중 하나가 웨이블릿 패킷(wavelet packet)이다. 우선 Daubechies의 모웨이블릿(\\(\\psi\\))과 부웨이블릿(\\(\\phi\\))을 생각해보자. \\(W_{0}(x)=\\phi(x)\\), \\(W_{1}(x)=\\psi(x)\\)이다. 그러면 함수의 수열 \\(\\{ W_{k}(x)\\}_{k=0}^{\\infty}\\)를 \\[W_{2n}(x)=\\sqrt{2}\\sum_{k}h_{k}W_{n}(2x-k)\\] \\[W_{2n+1}(x)=\\sqrt{2}\\sum_{k}g_{k}W_{n}(2x-k)\\] 로 정의할 수 있다. 이를 웨이블릿 패킷(wavelet packet)이라 부른다. 교수님의 notation을 따라가면 다음과 같다. Translated (k; translation part) and scaled (j) wavelet packet function을 \\[W_{jbk}(t)=2^{j/2}W_{b}(2^{j}t-k)\\] 로 표현한다. 이 때 \\(W_{b}(t), b=0,1,2,\\ldots\\)는 웨이블릿 패킷 함수(wavelet packet function)이라고 한다. 이 때 \\(b\\)는 index for oscillation of frequency이다. 교수님이 좋아하시는 말로는 \\(b= \\text{number of zero-crossing}\\)이다. Example 23.2 (Haar wavelet) - Haar wavelet: time series에서 “Walsh function” 일반적인 웨이블릿은 \\(W_{j0k}, W_{j1k}(=\\psi_{jk})\\) 둘만 사용한다는 점에서 차이점이 있다고 한다. \\(W_{00k}=\\phi_{0k}\\)이며 \\[f(t)=\\sum_{k}c_{0k}\\phi_{0k}(t) +\\sum\\sum d_{jk}\\psi_{jk}(t)\\] 이다. Theorem 23.1 (Coifman and Wickerhauser (1992)) \\([2^{j}n, 2^{j}(n+1)]\\)이 \\([0,\\infty)\\)의 disjoint countable covering을 만드는 인덱스들의 collection \\((j,n,k)\\subset \\mathbb{N}\\times \\mathbb{N}\\mathbb{Z}\\) 있을 때 \\(\\{W_{jnk}(t)\\}\\)는 \\(L^{2}(\\mathbb{R})\\)의 직교정규 기저가 된다. 즉, 어떤 \\(f(t)\\in L^{2}(\\mathbb{R})\\)에 대해 \\[f(t)\\approx \\sum_{j}\\sum_{n}\\sum_{k}\\omega_{jnk}W_{jnk}\\] 로 표현할 수 있다고 한다. 이 때 \\(\\omega_{jnk}=\\int f(t)W_{jbk}(t)dt\\)이다. FIGURE 23.11: Illustration of wavelet packet transform applied to eight data points. 위 그림은 필터 \\(\\mathcal{H}\\), \\(\\mathcal{G}\\)를 이용해 어떻게 계수들과 기저함수들을 얻어내는지 묘사한 것이다. \\(\\mathcal{D}_{0}\\mathcal{H}\\), \\(\\mathcal{D}_{0}\\mathcal{G}\\) 필터가 smooth, detail operation을 수행한다. 이는 일반적인 웨이블릿과 똑같다. 그러나 달라진 점은 둘 다 recursively하게 applied하는 것이다. 24.5.1 Best basis algorithm (Nason 책 70쪽) (Coifman and Wickerhauser 1992)는 엔트로피에 기반한 best-basis 알고리즘을 제시하였다. 교수님은 이를 likelihoo-based method와 동일한 아이디어라고 설명했다. 즉 \\[\\text{minimize } \\sum c(W_{j,n,k})=\\sum_{k}W_{jnk}^{2}\\log W_{jnk}^{2}\\] 하는 \\(\\{j,n\\}\\)을 선택하는 것이다. 이 때 \\(c\\)는 cost function이다. 교수님은 더 나아가 벌점함수를 붙인 \\[\\sum c(W_{jbk})+\\lambda P(\\omega)\\] 또한 가능할 것이라고 했다. 24.5.2 Coifman-Wickerhauser best-basis method (Nason 책 72쪽) Shannon entroy는 vector의 sparsity를 재는 데 사용할 수 있으며, Coifman-Wickerhauser algorithm은 overall negative Shannon entropy를 minimize하는 기저를 찾는다. References "],
["24-6-non-decimated-wavelet-packet-transform.html", "24.6 Non-decimated wavelet packet transform", " 24.6 Non-decimated wavelet packet transform 이 알고리즘은 \\(\\mathcal{D}_{0}\\mathcal{H}\\), \\(\\mathcal{D}_{0}\\mathcal{G}\\), \\(\\mathcal{D}_{1}\\mathcal{H}\\), \\(\\mathcal{D}_{1}\\mathcal{G}\\)를 recursively하게 섞어서 실현 가능하다. 자세한 내용은 (G. P. Nason and Sapatinas 2002)를 참고하자. FIGURE 23.12: Systematic NWPT for N=8 points (j=3). References "],
["24-7-time-series-with-wavelet-packets.html", "24.7 웨이블릿 패킷과 시계열(time series with wavelet packets)", " 24.7 웨이블릿 패킷과 시계열(time series with wavelet packets) 웨이블릿 패킷 변환은 시계열 문제에 적용할 수 있다고 한다. (G. P. Nason and Sapatinas 2002)는 두 시계열 간의 전이함수모형을 개발하는 방법을 묘사했다. \\(Y_{t}\\): response series \\(X_{t}\\): explanatory series 여기서 쓴 모형은 다음과 같다. \\(X_{t}\\)를 웨이블릿 패킷(이것으로 \\(X_{t}\\)를 different scales, frequencies and locations에서 분석할 수 있음)으로 표현한다. \\(Y_{t}\\)와 non-decimated wavelet packet transform (NWPT) of \\(X_{t}\\) 사이에 일반적인 통계모델링 기법을 사용한다. (Appendix 1에 등장) (The selected model often reveals valuable information about which types of oscillatory behaviour in \\(X_{t}\\) influence \\(Y_{t}\\) and also supplies a method to predict future values of \\(Y_{t}\\) from future values of \\(X_{t}\\)) References "],
["24-8-matching-pursuit.html", "24.8 Matching pursuit", " 24.8 Matching pursuit Projection pursuit와 비슷하며 데이터를 여러 각도에서 보자(projection)라는 뜻이라고 한다. Matching pursuit은 (Mallat and Zhang 1993)에서 처음 제아냈으며 musical sound를 분석하면 더 잘 될 것이라고 생각한다고 한다. (Mallat and Zhang 1993)의 주된 아이디어는 다양한 형태의 웨이브폼들 \\(\\{g_{\\gamma}(t):\\gamma \\in\\mathcal{P}\\}\\)을 고려하는 것이다. 이 대상으로는 Mallat의 dictionary, wavelet packets, cosine packets 등이 포함된다. Matching pursuit는 함수 \\(f(t)\\)를 \\(N\\)개의 waveform의 합으로 근사하려고 한다. 즉 \\[f(t)=\\sum_{l=1}^{N}h_{l}g_{\\gamma_{l}}+e(t)\\] 를 생각한다. 알고리즘은 다음과 같다. initialization \\(e^{(0)}(t)=f(t)\\) and \\(l=1\\). 다음을 만족하는 \\(\\gamma_{l}\\)의 index \\(l\\)을 찾는다. \\[\\gamma_{l}=\\text{argmin}\\|e^{(l-1)}(t)-c_{\\gamma}^{l}g_{\\gamma_{l}}(t)\\|^{2}\\] \\(c_{l}=\\int e^{(l-1)}g_{\\gamma_{l}}(t)dt\\)라고 하면 \\(\\gamma_{l}=\\text{argmax}\\|c_{\\gamma}^{l}\\|^{2}\\)를 만족하는 waveform들을 뽑아낸 것과 같다. \\(e^{(l)}(t)=e^{(l-1)}(t)-h_{l}g_{\\gamma_{l}}(t)\\)를 계산한다. \\(l=N\\)이 되거나 \\(\\|e^{(l)}(t)\\|^{2}&lt;\\delta\\)가 될 때까지 반복한다. \\(f(t)\\approx \\sum_{l}h_{l}g_{\\gamma_{l}}(t)+e^{*}(t)\\)이다. \\(\\|f(t)\\|^{2}=\\sum_{l}h_{l}^{2}+\\|e^{*}(t)\\|^{2}\\)이므로 만약 \\(\\|e^{*}(t)\\|^{2}\\)이 무시할만큼 작으면 \\(h\\)가 \\(f\\)의 information을 모두 갖고 있는 것으로 볼 수 있다. closely related to projection pursuit regression (Friedman and Stuezle(1981)) Matching pursuit, projection pursuit regression and PCA regression 간에 유사점이 있다. (functional PCA와의 차이점 생각해 볼 것) References "],
["24-9-cosine-packet.html", "24.9 코싸인 패킷(cosine packet)", " 24.9 코싸인 패킷(cosine packet) 코싸인 패킷을 가장 잘 이해할 수 있는 방법으로 교수님의 ‘Time-Frequency Analysis for Bat Signals using Wavelet Methods’ 발표를 읽어보는 것이 가장 좋다. 24.9.1 local cosine basis "],
["24-10-r-r-wp.html", "24.10 R 예제(R-wp)", " 24.10 R 예제(R-wp) 다음은 R 패키지 wavethresh의 wp함수를 이용한 웨이블릿 패킷 예제이다. 그것은 dyadic-length vector를 transform하기 위해 사용하였고, underlying wavelet family를 특정화하고 number of vanishing moment를 결정하기 위해z &lt;- rnorm(256) argument filter.number와 family의 입력을 필요로한다. z &lt;- rnorm(256) zwp &lt;- wp(z, filter.number=2, family=&quot;DaubExPhase&quot;) plot(zwp, color.force=TRUE) FIGURE 23.13: Wavelet packet coefficients of the independent Gaussian sequence z. 위 그림은 독립 가우스 수열 \\(\\mathbf{z}\\)에 대해 웨이블릿 계수들을 구한 결과를 보여준다. 원 시계열은 맨 아래쪽에 있다. 이것의 scale은 8로 정했다. 그리고 한 줄씩 위로 올라가면서 scale(=resolution level)을 1씩 줄였을 때의 결과를 보여준다. 웨이블릿 패킷을 수직 점선으로 구분해 놓았다. 각 스케일 마다 첫 번째 웨이블릿은 scaling function coefficient들에 대응된다. 그래서 시계열로 표현했는데 이는 스케일 함수 계수들을 웟ㄴ 시계열의 연속적인 coarsening이라고 생각할 수 있기 때문이다. Regular wavelet coefficient들은 각 스케일마다 두 번째 패킷에 위치하도록 했다. 여기서 스케일 6에 있는 네 번째 패킷 (packet 3임, 0, 1, 2 순서로 번호를 매기므로)을 100인 값이 하나가 있고 나머지는 모두 0인 패킷으로 교체해보자. 우선 현재 있는 패킷 값을 얻으려면 getpacket 함수를 이용한다. getpacket(zwp, level=6, index=3) &gt; [1] 0.560166522 0.322792023 0.384622540 -0.049747177 -2.024547600 &gt; [6] 1.062273035 1.031954859 1.426719857 0.391942112 1.470480188 &gt; [11] 0.382877525 -0.692940440 0.889836028 0.715477087 -0.744806881 &gt; [16] 0.106357404 1.948017908 0.495772910 -0.772875293 0.494151404 &gt; [21] 0.923984200 0.518029220 1.900605749 1.130332430 0.211003871 &gt; [26] -1.080934365 0.564496855 1.877673793 -0.440326381 -0.153984643 &gt; [31] 2.064894192 -1.016416149 0.006856656 -0.097591335 -0.230165064 &gt; [36] -0.647862448 0.665384243 1.843509573 -2.242851320 1.061818089 &gt; [41] -0.414922338 -0.501783630 -0.319532833 -2.313708476 3.194687343 &gt; [46] -0.863666111 -0.783645410 -0.802141520 -0.034990659 0.446068632 &gt; [51] 0.304518313 -0.810437029 -0.362016578 0.096279600 -0.782998466 &gt; [56] 0.078060736 -0.333727615 0.429043516 -0.020618845 0.865348196 &gt; [61] 0.596744136 0.127990582 -0.164577069 0.224238446 100인 값이 하나가 있고 나머지는 모두 0인 벡터는 매우 sparse하다. zwp2에 앞서 말한 패킷을 넣어보자. zwp2 &lt;- putpacket(zwp, level=6, index=3, packet=c(rep(0,10), 100, rep(0,53))) plot(zwp2) FIGURE 23.14: Wavelet packet coefficients of zwp2. 여기서 출력되는 그림은 패킷 \\((6,3)\\) 지역을 제외하고는 앞선 그림과 똑같지만, 계수들의 크기가 상대적으로 정해지기 때문에, 크기 100인 계수들에 의해 sparse한 것처럼 출력된다. Coifman-Wikerhauser best-basis algorithm은 Shannon entropy를 이용하며 MaNoVe함수를 이요해 얻을 수 있다. zwp2.nv &lt;- MaNoVe(zwp2) zwp2.nv &gt; Level: 6 Packet: 3 &gt; Level: 5 Packet: 4 &gt; Level: 3 Packet: 5 &gt; Level: 3 Packet: 13 &gt; Level: 3 Packet: 15 &gt; Level: 2 Packet: 1 &gt; Level: 2 Packet: 2 &gt; Level: 2 Packet: 3 &gt; Level: 2 Packet: 6 &gt; Level: 2 Packet: 14 &gt; Level: 2 Packet: 19 &gt; Level: 2 Packet: 20 &gt; Level: 2 Packet: 23 &gt; Level: 2 Packet: 40 &gt; Level: 2 Packet: 42 &gt; Level: 2 Packet: 45 &gt; Level: 2 Packet: 47 &gt; Level: 1 Packet: 0 &gt; Level: 1 Packet: 8 &gt; Level: 1 Packet: 9 &gt; Level: 1 Packet: 10 &gt; Level: 1 Packet: 11 &gt; Level: 1 Packet: 17 &gt; Level: 1 Packet: 18 &gt; Level: 1 Packet: 30 &gt; Level: 1 Packet: 31 &gt; Level: 1 Packet: 33 &gt; Level: 1 Packet: 37 &gt; Level: 1 Packet: 43 &gt; Level: 1 Packet: 44 &gt; Level: 1 Packet: 48 &gt; Level: 1 Packet: 50 &gt; Level: 1 Packet: 56 &gt; Level: 1 Packet: 58 &gt; Level: 1 Packet: 82 &gt; Level: 1 Packet: 83 &gt; Level: 1 Packet: 93 &gt; Level: 0 Packet: 2 &gt; Level: 0 Packet: 3 &gt; Level: 0 Packet: 28 &gt; Level: 0 Packet: 29 &gt; Level: 0 Packet: 30 &gt; Level: 0 Packet: 31 &gt; Level: 0 Packet: 32 &gt; Level: 0 Packet: 33 &gt; Level: 0 Packet: 38 &gt; Level: 0 Packet: 39 &gt; Level: 0 Packet: 48 &gt; Level: 0 Packet: 49 &gt; Level: 0 Packet: 50 &gt; Level: 0 Packet: 51 &gt; Level: 0 Packet: 52 &gt; Level: 0 Packet: 53 &gt; Level: 0 Packet: 54 &gt; Level: 0 Packet: 55 &gt; Level: 0 Packet: 64 &gt; Level: 0 Packet: 65 &gt; Level: 0 Packet: 68 &gt; Level: 0 Packet: 69 &gt; Level: 0 Packet: 70 &gt; Level: 0 Packet: 71 &gt; Level: 0 Packet: 72 &gt; Level: 0 Packet: 73 &gt; Level: 0 Packet: 84 &gt; Level: 0 Packet: 85 &gt; Level: 0 Packet: 90 &gt; Level: 0 Packet: 91 &gt; Level: 0 Packet: 98 &gt; Level: 0 Packet: 99 &gt; Level: 0 Packet: 102 &gt; Level: 0 Packet: 103 &gt; Level: 0 Packet: 114 &gt; Level: 0 Packet: 115 &gt; Level: 0 Packet: 118 &gt; Level: 0 Packet: 119 &gt; Level: 0 Packet: 172 &gt; Level: 0 Packet: 173 &gt; Level: 0 Packet: 174 &gt; Level: 0 Packet: 175 &gt; Level: 0 Packet: 176 &gt; Level: 0 Packet: 177 &gt; Level: 0 Packet: 178 &gt; Level: 0 Packet: 179 &gt; Level: 0 Packet: 184 &gt; Level: 0 Packet: 185 \\((6,3)\\)이 basis element로 선택된 것을 확인할 수 있다. 왜냐면 이것이 extremely sparse하기 때문이다. 이 새로 선택된 zwp2.nv의 기저는 InvBasis(zwp2, zwp2.nv) 명령어를 통해 불러올 수 있다고 한다. head(InvBasis(zwp2, zwp2.nv)) &gt; [1] -1.4774883 0.3676913 -2.5268340 -0.5543775 -0.3297518 -0.4906710 plot(InvBasis(zwp2, zwp2.nv), type=&quot;o&quot;) FIGURE 23.15: Inversion plotting. 이 그림이 super-sparse \\((6,3)\\)의 결과다. "],
["24-11-biorthogonal-wavelet.html", "24.11 Biorthogonal wavelet", " 24.11 Biorthogonal wavelet 이 내용은 (Gomes and Velho 2015)를 참고하였다. Orthogonality는 wavelet을 만드는 데 매우 큰 제약조건이다. 이것은 wavelet basis를 고르는 데 큰 제약을 준다. 예를 들면, Haar wavelet은 symmetric compact support를 갖는 유일한 orthogonal basis다. 웨이블릿 함수의 바람직한 조건들을 유지시키면서 좀 더 flexible한 선택을 위해 orthogonality를 biorthogonality로 바꾼다. 24.11.1 Biorthogonal 기저 함수들(Biorthogonal basis functions) FIGURE 23.16: Dual basis. References "],
["25-waveletshrinkage.html", "Chapter 25 웨이블릿 수축", " Chapter 25 웨이블릿 수축 이 장의 주된 내용과 그림들은 (G. Nason 2010)를 참고하였다. 다음과 같이 자료를 관찰하는 도메인(domain)인 physical domain (physical model)에서의 모델 \\(y_{i}=g(x_{i})+e_{i}, i=1,\\cdots,n\\)에서 관측한 길이 \\(n\\)의 자료 \\(\\mathbf{y}=(y_{1},\\cdots,y_{n})^{T}\\)이 있다고 하자. 여기서 \\(x_{i}=\\frac{i}{n} \\text{ (designed point)}\\)이라고 하자. 이 공간(space)은 equally-spaced이고 \\(x \\in (0, 1]\\)이다. 우리의 목표는 알려지지 않은 함수 \\(g(x), x \\in [0,1]\\)를 추정하는 것이다. 일반적으로 \\(e_{i} \\stackrel{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\\)으로 가정한다. 독립 동일 분포 가정(independent and identically distributed, iid)이 없으면 모형이 좀 더 복잡해진다. 정규분포(normal distribution, Gaussian distribution) 가정도 중요한데, 정규분포처럼 대칭(symmetric)인 분포를 가정하지 않을 경우 평균 추정이 힘들어지므로 보통 분위수(quantile) 추정을 하게 된다. 우리가 얻는 자료 \\(\\mathbf{y}\\)가 noise가 전혀 없는 순수한 signal이라고 하면, wavelet transform후 바로 wavelet reconstruction을 통해 원래 자료를 얻을 수 있다. \\[\\mathbf{y} \\xrightarrow{W} \\boldsymbol{\\delta} \\xrightarrow{W^{-1}} \\mathbf{y}\\] 그런데 자료에 잡음(noise)이 있는 경우 얘기가 좀 달라진다. \\[\\mathbf{d}=\\mathbf{Wy} =\\mathbf{Wg}+\\mathbf{We}=\\boldsymbol{\\theta}+\\boldsymbol{\\epsilon}\\] 이 경우에는 위와 같은 방법을 적용하면 잡음이 낀 신호가 그대로 나오게 된다. 우리는 적당한 방법을 통해 noise가 거의 없는 \\(\\hat{\\mathbf{d}}\\)를 추정해 \\(\\mathbf{W}^{-1}\\hat{\\mathbf{d}} \\rightarrow \\hat{\\mathbf{g}}\\)를 하고 싶다. 이럴 떄 쓰는 방법이 임계화(thresholding)이다. References "],
["25-1-main-concept-of-wavelet-shrinkage.html", "25.1 웨이블릿 수축의 주된 개념(main concept of wavelet shrinkage)", " 25.1 웨이블릿 수축의 주된 개념(main concept of wavelet shrinkage) 다시 원래 얘기로 돌아가서 우리는 웨이블릿 변환을 통해 \\(g\\)를 추정하고자 한다. \\(\\mathbf{W}\\)를 이산 웨이블릿 변환 연산자(연산자)라고 하면, 다음과 같은 웨이블릿 변환을 생각해 볼 수 있다. \\[\\mathbf{y}=\\mathbf{g}+\\mathbf{e} \\rightarrow \\mathbf{Wy} =\\mathbf{Wg}+\\mathbf{We} \\text{ or } \\mathbf{d}=\\boldsymbol{\\theta}+\\boldsymbol{\\epsilon}.\\] 웨이블릿 변환 연산자는 physical domain에 있는 자료를 wavelet domain (model in the wavelet domain, wavelet-transformed model or wavelet model)으로 보내주는 역할을 한다. 웨이블릿 변환은 정규직교(orthonormal)이므로 변환된 오차항 또한 \\(\\epsilon \\sim \\mathcal{N}(0,\\sigma^{2}\\mathbf{I})\\)로 정규분포를 따르는 좋은 성질을 가진다. 또 웨이블릿 변환은 오차(error(가 약하게 correlated (stationary process)된 경우 웨이블릿 변환을 하면 변환된 오차가 de-correlated(whitening, 더 약하게 correlated되는 것)되는 좋은 성질이 있다. 웨이블릿 수축(wavelet shrinkage)을 위해 알아두어야 할 컨셉들은 다음과 같다. \\(\\boldsymbol{\\theta}\\)는 많은 함수들의 성긴 벡터(sparse vector)이다. 그리고 \\(\\boldsymbol{\\theta}\\)는 다음과 같이 Parseval’s identity를 만족시킨다. 즉 데이터의 에너지와 계수들의 에너지가 같다(보존된다). \\[\\sum g^{2}(x)=\\sum \\theta_{i}^{2}.\\] \\(\\boldsymbol{\\theta}\\)는 “concentrated”되어있다. \\(\\epsilon \\sim \\mathcal{N}(0,\\sigma^{2}\\mathbf{I})\\), 즉 웨이블릿 계수 \\(\\mathbf{d}\\)에는 \\(\\boldsymbol{\\theta}\\)뿐 아니라 \\(\\mathbf{\\epsilon}\\)의 정보도 들어있다. 위의 사실에 기초하여 \\(\\mathbf{d}\\)중 값이 큰 원소의 경우에는 진짜 신호 + 잡음의 형태로 이루어져 있을 것이다. \\(\\mathbf{d}\\)중 값이 작은 원소의 경우에는 잡음만 있을 것이다. 이런 상황에서는 평균이 틀리게 된다. 즉 \\(\\hat{\\theta}=\\frac{1}{n}\\sum_{i=1}^{n}d_{i}\\)가 \\(\\theta\\)의 좋은 추정량이 될 수 없다는 것이다. 그래서 이를 해결하기 위해 도입된 아이디어가 임계화(thresholding)이다. 임계화가 등장하기 전까지 모든 추정량에는 평균 개념이 있었다. (ex. Ridge) 기존의 자료분석들은 “aggregation”에 치중했다. 모든 변수에 다 신호가 존재한다고 생각한 것이다. 이런 방식으로는 위의 문제를 해결할 수 없다. 그러나 웨이블릿 변환의 등장 이후에는 “sparsity” 개념이 등장하였고 몇 개의 신호만 선택하게 되었다. 이 개념 덕분 에 고차원(high-dimensional) 자료(\\(n \\ll p\\))를 분석할 수 있게 되었다. 수축 방법에는 두 가지가 있다. 하드 임계화(hard thresholding)와 소프트 임계화(soft thresholding)가 그것이다. 두 임계화를 다음과 같이 정의한다. Definition 25.1 (하드 임계화와 소프트 임계화) 주어진 (empirical) 웨이블릿 상수 d와 threshold \\(\\mathbf{\\lambda}\\)가 있을 때, 그것의 하드 임계화(hard thresholding)는 \\[\\hat{\\theta}_{H}=\\eta_{H}(d,\\lambda)=d\\mathbb{I}\\{ |d| &gt; \\lambda \\}\\] 이다. 그리고 소프트 임계화(soft thresholding)는 \\[\\hat{\\theta}_{S}=\\eta_{S}(d,\\lambda)=\\text{sgn}(d)(|d|-\\lambda)\\mathbb{I}\\{ |d| &gt; \\lambda \\}\\] 이다. FIGURE 25.1: Hard thresholding (dotted line) and soft thresholding. 두 방법 다 공통적으로 \\(\\mathbf{d} \\in (-\\lambda, \\lambda)^{n}\\)이면 0이 된다. 하드 임계화는 “keep or kill” 방법이라고도 불린다. 그 이유는 값이 어떤 threshold(\\(\\mathbf{\\lambda}\\))보다 작을 경우 무조건 0으로 놓기 때문이다. 이것은 회귀분석의 변수 선택(variable selection)과 동일한 아이디어이다. 변수 선택에서도 변수를 넣기 또는 빼기 두 가지 선택지만 있다는 것을 생각하기 바란다. 그리고 하드임계화에서는 축소를 하지 않는다. 소프트 임계화는 하드 임계화를 함과 동시에 신호 변환 함수가 연속이 되도록 값이 큰 signal도 같이 축소(shrinkage)하는 방법이다. 이는 변수선택에서 LASSO와 대응되는 방법이다. 때때로 굉장히 큰 \\(\\mathbf{d}\\)에는 오차가 작게 들어있을 것이라 생각할 수도 있다. 이를 보완하기 위해 SCAD 같은 방법들이 나중에 제안되었는데, 원래 이는 웨이블릿을 연구하는 학자들이 생각했던 개념으로 이를 통계학 언어로 옮긴 것에 불과하다. 여기서 등장하는 \\(\\lambda\\)는 핵평활(kernel smoothing)이나 평활 스플라인(smoothing spline)에서 나오는 띠너비(bandwidth)와 비슷한 개념이라고 생각하면 된다. \\(\\lambda\\)의 선택 또한 중요한 이슈가 된다. 이것을 어떻게 선택하느냐에 따라 performance가 굉장히 변하고 \\(\\hat{g}\\)의 질(quality)에 영향을 미친다. \\[y \\xrightarrow{W} d \\xrightarrow{\\text{th}} \\hat{\\theta}_{Shrink} \\xrightarrow{W^{-1}} \\hat{g}.\\] "],
["25-2-oracle.html", "25.2 오라클(oracle)", " 25.2 오라클(oracle) 만약 우리가 \\(g\\)를 알고 있다면, \\(\\hat{g}\\)의 quality를 계산하는 방법 중 하나로 다음과 같은 적분제곱오차(integrated squared error, ISE, \\(\\hat{M}\\))를 생각해 볼 수 있다. \\[\\hat{M}=\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{g}(x_{i})-g(x_{i}))^{2}.\\] 그러나 우리는 \\(g\\)를 모르기 때문에 실제로 ISE를 계산할 수는 없다. 대신 ‘평균(average)’ 개념을 적용한 평균적분제곱오차(mean integrated squared err, MISE) \\(E(\\hat{M})\\)을 정의한다. \\[ M \\triangleq E(\\hat{M})=\\text{Risk of }\\hat{g}.\\] 웨이블릿에서 \\(\\hat{g}\\)는 \\(\\lambda, \\eta, \\theta\\)에 좌우(depend)한다. 참고로 보통 \\(g\\)가 정의되는 함수공간 \\(g \\in \\mathcal{F}\\)은 일반적으로 \\(L^{2}(\\mathbb{R})\\)에서만 생각한다. 웨이블릿은 점프가 있는 함수도 다룰 수 있긴 하다. 결국 통계적 추정의 목표는 이 MISE를 최소화하는 \\(\\hat{g}\\)를 찾는 것이다. 웨이블릿에서 \\(\\hat{M}=\\sum_{j,k}(\\hat{\\theta}_{jk}-\\theta_{jk})^{2}\\)이다. 여기서 웨이블릿 변환은 정규직교이므로 ’decoupling’이라는 성질을 이용할 수 있다. 이 얘기는 위의 값을 계산할 때 \\(j,k\\)를 무시하고 마치 하나만 있는 것처럼 계산해도 된다는 것이다. 마치 벡터(vector)를 스칼라(scalar)처럼 볼 수 있다는 것이다. 잠시 선형 회귀분석 모형을 복습해보자. 다음과 같은 선형 회귀분석 모형 \\[\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}\\] 이 있다고 하자. 여기서 \\(\\mathbf{y}\\)는 \\(n \\times 1\\) 행렬, \\(\\mathbf{X}\\)는 \\(n \\times d\\) 행렬, \\(\\boldsymbol{\\beta}\\)는 \\(d \\times 1\\) 행렬, 그리고 \\(\\boldsymbol{\\epsilon}\\)은 \\(n \\times 1\\) 행렬이다. 만약 여기서 \\(X\\)의 열(column)이 정규직교라고 해보자. 그러면 \\[\\begin{eqnarray*} \\hat{\\boldsymbol{\\beta}}&amp;=&amp;(\\hat{\\beta}_{1},\\cdots,\\beta_{d})^{T}=(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}=\\mathbf{X}^{T}\\mathbf{y}\\\\ &amp;\\Longrightarrow&amp; \\hat{\\beta}_{1}=\\sum X_{i1}y_{i}, \\hat{\\beta}_{2}=\\sum X_{i2}y_{i}, \\cdots \\end{eqnarray*}\\] 로 모든 \\(\\boldsymbol{\\beta}\\)의 원소들이 separate(decoupled)되는 것을 볼 수 있다. 참고로 \\((\\mathbf{X}^{T}\\mathbf{X})^{-1}\\neq \\mathbf{I}\\)인 경우 \\(\\hat{\\beta}\\)가 다 연결되므로 이렇게 분석할 수 없다. 그리고 \\[\\hat{\\boldsymbol{\\beta}}=\\min \\| \\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta} \\|^{2} \\Leftrightarrow \\min \\| \\mathbf{X}^{T}\\mathbf{y} - \\mathbf{X}^{T}\\boldsymbol{\\beta} \\|^{2}=\\min \\| \\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta} \\|^{2}\\] 가 된다. (Donoho and Johnstone 1994) 논문에 갑자기 이 사실을 이용해 전개하는 내용이 있다. 더 나아가 벌점화 최소자승법(penalized least square) 문제를 생각해보자. \\(\\mathbf{z}=\\mathbf{X}^{T}\\mathbf{y}\\), \\(\\hat{\\mathbf{y}}=\\mathbf{Xz}=\\mathbf{XX}^{T}\\mathbf{y}\\)를 정의하면 \\[\\begin{eqnarray*} \\| \\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta}\\|^{2}+\\lambda \\sum_{j=1}^{d}P(| \\beta_{j} |) &amp;=&amp; \\| \\mathbf{y}-\\hat{\\mathbf{y}}+\\hat{\\mathbf{y}}-\\mathbf{X}\\boldsymbol{\\beta}\\|^{2}+\\lambda \\sum_{j=1}^{d}P(|\\beta_{j}|)\\\\ &amp;=&amp;\\| \\mathbf{y} -\\hat{\\mathbf{y}} \\|^{2} + \\sum_{j}(z-{j}-\\beta_{j})^{2}=\\lambda\\sum_{j}P(|\\beta_{j}|)\\\\ \\end{eqnarray*}\\] 여기서 \\(\\| \\mathbf{y} -\\hat{\\mathbf{y}} \\|^{2}\\)는 \\(\\beta_{j}\\)와 관련 없으므로 뒤의 두 항만 최소화(minimize)하면 된다. 그런데 \\(\\beta_{j}\\)는 seperate되므로 벌점화 최소자승법의 해는 \\[\\hat{\\beta}=\\min_{\\beta}(z-\\beta)^{2}+\\lambda P(| \\beta |)\\] 이다. 다시 웨이블릿 문제로 돌아가서, 웨이블릿 변환 행렬 \\(\\mathbf{W}\\) (회귀분석에서 \\(\\mathbf{X}\\)와 같은 역할을 함)이 정규직교이므로, 우리는 \\(E(\\hat{\\theta}-\\theta)^{2}\\)(=risk)만 보면 된다. 참고로 \\(\\mathbf{W}\\)는 정방행렬(square matrix)이라는 점에서 \\(\\mathbf{X}\\)와 다르다. Separated 성질에 의해 \\[ M(\\hat{\\theta},\\theta)=E(\\hat{\\theta}-\\theta)^{2} = \\begin{cases} E(d-\\theta)^{2}=E\\epsilon^{2} &amp; \\text{if $|d| &gt; \\lambda$}\\\\ E(\\theta^{2})=\\theta^{2} &amp; \\text{o.w.} \\end{cases} \\] 이 된다. 결론적으로 임계화(thresholding)를 위해서는 신호와 오차의 크기를 비교해 보면 되는데, 만약 신호가 오차보다 굉장히 큰 경우, \\(\\theta \\gg \\sigma\\)인 경우면 우리는 \\(|d| &gt; \\lambda\\)인 경우를 취하는게 유리하므로 \\(\\lambda\\)를 작게 선택하면 된다. 반대의 경우에는 \\(\\lambda\\)를 크게 취하는 것이 유리하다. 통계학에서 오라클이라는 개념을 처음 사용한 사람은 Dave Donoho이다. 오라클이라는 개념이 처음 등장하는 논문은 (Donoho and Johnstone 1994)인데, 오라클을“With ideal spatial adaptation, an oracle furnishes information about how best to adapt a spatially variable estimator, whether piecewise constant, piecewise polynomial, variable knot spline, or variable bandwidth kernel to the unknown function”이라고 소개하고 있다. 교수님의 요약은 다음과 같다. “The oracle is notional device that tells you which coefficients you should select.” 오라클에 의한 ideal risk는(hard thresholding의 경우) \\(M_{ideal}=\\sum_{j,k}\\min(\\theta_{j,k}^{2},\\sigma^{2})\\)이다. 그렇다면 \\(\\hat{\\theta}\\)를 어떻게 구하는가? 이 문제는 결국 \\(\\eta_{H}, \\eta_{S}, \\lambda\\)를 선택하는 문제로 귀착된다. Donoho와 Johnstone은 \\(M_{ideal}\\approx M\\)이 되게 하는 \\(\\hat{\\theta}\\)를 몇 가지 제시하였다. (Donoho and Johnstone 1994)에서 \\(\\hat{\\theta}=\\eta_{x}(d,\\lambda)\\), \\(\\lambda=\\sigma\\sqrt{2\\log n}\\)으로 할 시 \\[M_{\\text{universal}}\\leq(2\\log n +1)(\\sigma^{2}+M_{\\text{ideal}})\\] 임을 증명하였다. 다시 말하면 이 \\(\\hat{\\theta}\\)가 오라클 성질(oracle property)과 굉장히 유사하며 \\(M_{\\text{ideal}}\\)에 가깝게(대략\\(2\\log n\\)배 보다 작다) 행동한다는 것이다. 위 논문에 따르면 핵평활(kernel smoothing)이나 평활 스플라인(smoothing spline)도 \\(2\\log n\\)을 만족하지 못한다(n). 가장 이상적인 fitting은 정확한 knot point들을 모두 알고 있는 piecewise polynomial이다. 그러나 ideal한 knot을 모두 안다는 것은 true을 안다는 것이므로 이는 불가능하다. Bandwidth나 knot selection을 잘 한다는 것은 true의 분산을 안다는 것과 거의 같은 얘기다. References "],
["25-3-universal-thresholding.html", "25.3 만능 임계화(universal thresholding)", " 25.3 만능 임계화(universal thresholding) 앞서 등장한 \\(\\lambda^{u}=\\sigma \\sqrt{2 \\log n}\\)을 특별히 만능 임계화(universal Thresholding)라고 한다. 실제로는 \\(\\sigma\\)를 모르므로 \\(\\hat{\\sigma}\\)를 사용한다. Theorem 25.1 (만능 임계화) \\(X_{1},\\cdots , X_{n}\\)을 \\(EX_{i}=0, EX_{i}^{2}=1, EX_{i}X_{i+k}=\\gamma(k)\\)인 stationary Gaussian process (Lag-k covariance structure를 갖는 Gaussian process)라고 하고 특별히 \\(X_{(n)}=\\max \\{ X_{i} \\}\\)라 하자. 만약 \\(\\lim_{k \\rightarrow \\infty} \\gamma (k) =0\\)이면, \\[\\frac{X_{(n)}}{\\sqrt{2 \\log n}} \\rightarrow 1 \\text{ as } n \\rightarrow \\infty\\] 이다. 위 정리는 n Gaussian 확률 변수들 중 가장 큰 것은(독립일 필요는 없다) 대략 \\(\\sqrt{2 \\log n}\\) 사이즈라는 것이다. 이 정리에 비추어 만능 임계화를 생각하면 이 임계화는 오차(error)가 Gaussian random variable을 따르는 것이라면 모두 다 임계화하겠다는 뜻으로 해석할 수 있다. 이 방법은 이론적으로는 완벽해 보이기는 하나 너무나 많은 잡음(noise)을 줄이는 underfit한 임계화이다. 결국 SURE와 같은 실용적인 임계화 방법을 생각하게 된 것이다. 이 얘기는 추후에 다시 나올 것이다. 만능 임계화로 돌아가서, 우리는 \\(\\sigma\\)를 모르므로 대신 \\(\\hat{\\lambda}^{u}=\\hat{\\sigma}\\sqrt{2 \\log n}\\)을 이용해야 할 것이다. 그렇다면 \\(\\sigma\\)를 어떻게 추정할 것인가? 대부분의 방법은 data를 제외한 가장 finest scale (ex.J-1)의 detail 웨이블릿 계수(\\(d_{J-1}\\))를 이용해 추정한다. \\(y\\)를 이용해 \\(\\epsilon\\)의 분산을 추정하려고 할 경우 \\(f\\)의 정보가 너무 강해서 \\(\\epsilon\\)의 분산구조를 알 수 없을 것이다. 그리고 좀 더 성긴 스케일(coarser scale)로 갈수록 잡음보다는 신호 정보가 많을 것이라는 생각을 하면, \\(d_{J-1}\\)를 이용해 분산 구조를 추정하는 것이 당연하다. 가장 널리 알려진 방법은 \\[\\hat{\\sigma}=\\sqrt{\\frac{1}{n/2-1}\\sum_{k=1}^{n/2}(d_{J-1,k}-\\bar{d_{J-1}})^{2}}\\] 이다. 이 방법은 자료가 희소(sparse)한 경우에는 잘 맞지 않음이 알려져 있다. 그런 경우에는 대신 중앙값(median)을 이용하여 \\[ \\hat{\\sigma}=1.4826 \\times \\text{median}(|d_{J-1,1}-\\tilde{d_{J-1}}|,\\cdots,|d_{J-1,\\frac{n}{2}}-\\tilde{d_{J-1}}|\\\\ \\text{ where } \\tilde{d}_{J-1}=\\text{median}(\\mathbf{d}_{J-1}) \\] 이런 식으로 추정하기도 한다. 지금까지 했던 방법은 universal threshold rule(\\(\\lambda^{u}\\))에 soft thresholding function \\(\\eta_{s}\\)를 적용한 \\(\\hat{\\theta}=\\eta_{s}(d,\\lambda^{u})\\)로 이것을 VisuShrink라고 부른다. 이 방법은 앞서 말한 대로 noise-free reconstrunction이나 oversmooth (underfit)하는 문제가 생긴다. 즉 noise-free하지만 signal도 너무 많이 죽일 가능성이 있다는 것이다. 한편 \\(\\lambda^{u}\\)는 noise-free reconstruction을 하는 최소의 \\(\\lambda\\)이므로, \\(0&lt; \\lambda^{*} \\ll \\lambda^{u}\\)인 \\(\\lambda^{*}\\)를 생각할 수 있을 것이다. 이런 \\(\\lambda^{*}\\) 중의 하나로 (Donoho and Johnstone 1994)에서는 RiskShrink라는 것을 제시했다. 이 방법은 \\(\\Lambda_{n}^{*}(=2 \\log n +1)\\)에 해당하는 \\(\\Lambda_{n}^{*}\\)과 이에 대응되는 \\(\\lambda^{*}\\)을 table 형태로 계산한 것이다. 예를 들어 \\(n=1024\\) 일 때 \\(\\lambda^{u}=3.72, \\lambda^{*}=2.23, \\Lambda_{n}^{*}=5.976\\)이다. 참고로 이 논문의 결과와 더불어 일반적으로 알려져 있는 사실은 함수가 부드럽(smooth)지 않을 때 웨이블릿이 다른 어떤 비모수 방법들보다 좋다는 것이다. References "],
["25-4-stein-steins-unbiased-risk-estimator-sure.html", "25.4 Stein의 불편 위험 추정량(Steins Unbiased Risk Estimator (SURE))", " 25.4 Stein의 불편 위험 추정량(Steins Unbiased Risk Estimator (SURE)) 앞서 얘기했던 VisuShirnk나 RiskShrink는 이론상으로는 완벽하나 실용성이 떨어져 실제로는 많이 쓰이지 않고 있다. 실제로 많이 쓰이는 shrinkage 방법 중 하나가 Steins Unbiased Risk Estimator (SURE)이다. Shrinkage 추정량들은 Bayesian과 밀접한 관련이 있다. Bayesian들이 주로 하는 것은 자료를 prior의 정보에 민감하게 반응하도록 수축(shrinkage)해 주는 것이다. SURE가 처음 등장한 논문은 (Donoho and Johnstone 1995)로, (C. M. Stein 1981)의 내용을 웨이블릿 도메인으로 갖고 온 것이다. 다음과 같은 data domain에서의 모델 \\(y_{i}=g(x_{i})+e_{i}, i=1,\\cdots,n,e_{i} \\stackrel{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\\)과 이를 웨이블릿 도메인(domain)으로 옮긴 \\(\\mathbf{d}=\\boldsymbol{\\theta}+\\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0,\\sigma^{2}\\mathbf{I})\\)를 생각하자. Stein의 논문에서는 이 notation을 다음과 같이 썼다. \\[\\mathbf{x}=\\boldsymbol{\\mu}+\\boldsymbol{\\epsilon}.\\] Theorem 25.2 (Stein) (C. M. Stein 1981) 만약 \\(\\hat{\\boldsymbol{\\mu}}\\mathbf{(x)}=\\mathbf{x}+\\mathbf{g(x)}\\), \\(g:\\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}\\) is weakly differentiable 조건이면 \\[E \\| \\hat{\\boldsymbol{\\mu}}\\mathbf{(x)}-\\boldsymbol{\\mu} \\|^{2} =n+ E\\{ \\|\\mathbf{g(x)}\\|^{2}+2\\bigtriangledown \\cdot \\mathbf{g(x)} \\}, \\bigtriangledown\\cdot \\mathbf{g}=\\sum_{i} \\frac{\\partial}{\\partial x_{i}}g_{i}\\] 이다. 그리고 \\(\\hat{\\mu}_{i}(\\lambda)=\\eta_{s}(x_{i},\\lambda) \\Rightarrow \\frac{\\partial}{\\partial x_{i}}\\hat{\\mu}_{i}(\\lambda)=I( |x_{i}|&gt;\\lambda)\\)과 \\(\\| \\mathbf{g(x)} \\|^{2}=\\sum \\hat{\\mu}_{i}(\\lambda, x)^{2}=\\sum_{i=1}^{n}(|x_{i}|-\\lambda)^{2}I(|x_{i}&gt;\\lambda)\\) 사실을 이용해 SURE를 정의한다. Theorem 25.3 (SURE) \\(\\text{SURE}(\\lambda,\\mathbf{x})=n-2\\#\\{ i: |x_{i}| \\leq \\lambda \\} + \\sum_{i=1}^{n}(|x_{i}| \\wedge \\lambda)^{2}\\)는 risk의 불편추정량이다. \\[E \\| \\eta_{s}(\\mathbf{x},\\lambda)-\\mu \\|^{2}=E\\text{SURE}(\\lambda, \\mathbf{x}).\\] 실제로, \\(\\lambda=\\text{argmin}_{0&lt;\\lambda \\leq lambda^{u}}\\text{SURE}(\\lambda,\\mathbf{x})\\)이며, 이 방법을 SUREShrink라고 한다. References "],
["25-5-r-r-waveletshrinkage.html", "25.5 R 예제(R-waveletshrinkage)", " 25.5 R 예제(R-waveletshrinkage) 다음은 R 패키지 wavethresh를 이용한 축소 예제이다. 임계화를 위해 threshold라는 함수를 사용하며 type 및 policy를 선택할 수 있다. par(mfrow=c(1,3)) set.seed(1234) data_bump &lt;- example.1() x &lt;- data_bump$x; y &lt;- data_bump$y plot(x,y, type=&#39;l&#39;, main=&quot;Original&quot;) y_noise &lt;- y + rnorm(length(y), sd=0.1) plot(x,y_noise, type=&#39;l&#39;, main=&quot;Noisy&quot;) y_noise_wd &lt;- wavethresh::wd(y_noise) y_noise_threshold &lt;- wavethresh::threshold(y_noise_wd, type=&quot;soft&quot;, policy=&quot;sure&quot;) y_sure &lt;- wavethresh::wr(y_noise_threshold) plot(x,y_sure, type=&#39;l&#39;, main=&quot;Soft Thresholding&quot;) FIGURE 25.2: Wavelet shrinkage example. "],
["26-advwaveletshrinkage.html", "Chapter 26 웨이블릿 수축의 고등 논제들", " Chapter 26 웨이블릿 수축의 고등 논제들 이 장의 내용은 앞 장의 내용과 이어진다. "],
["26-1-cross-validation.html", "26.1 교차타당성(cross-validation)", " 26.1 교차타당성(cross-validation) 다음과 같은 일반적인 모델 \\(y_{i}=f(x_{i})+e_{i}\\)이 있고, \\(f\\)를 회귀적합 \\(f_{lambda}\\)를 통해 추정하려고 한다(\\(\\lambda\\): smoothing parameter). 그렇다면 \\(\\lambda\\)를 어떻게 선택할 것인가? 이를 해결하기 위해 등장한 방법이 교차타당성(cross-validation)이다. 교차타당성의 정의는 다음과 같다. \\[\\text{CV}(\\lambda)=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{f}_{\\lambda}^{-i}(x_{i}))^{2}.\\] 여기서 \\(\\hat{f}_{\\lambda}^{-i}(x_{i})\\)는 i번째 자료를 제외하고 \\(f\\)를 적합한 다음 \\(x_{i}\\)의 예측값이다(\\(x_{i}\\)값이 없으므로 추정값이 아니라 예측값이 된다). 그렇다면 왜 교차타당성이 쓰이게 되었는가? 이것을 이해하기 위해서는 Mean squared error (MSE)와 Predicted squared error (PSE)에 대해 알아야 한다. 위와 같은 모형 하에서 MSE와 PSE는 \\[\\text{MSE}(\\lambda)=\\frac{1}{n}\\sum_{i=1}^{n}E(\\hat{f}_{\\lambda}(x_{i})-f(x_{i}))^{2}, \\text{PSE}(\\lambda)=\\frac{1}{n}\\sum_{i=1}^{n}E(y_{i}^{*}-\\hat{f}_{\\lambda}(x_{i}))^{2}\\] 이다. 여기서 \\(y_{i}^{*}\\)는 \\(x_{i}\\)에서의 새로운 관찰값이다. 즉, \\(y_{i}^{*}=f(x_{i})+\\epsilon_{i}^{*}, (\\epsilon_{i}^{*}\\)는 \\(\\epsilon_{i}\\)와 독립)이다. 위의 PSE를 약간 변형해 보면 \\[\\begin{eqnarray*} \\text{PSE}(\\lambda)&amp;=&amp;\\frac{1}{n}\\sum_{i=1}^{n}E(y_{i}^{*}-\\hat{f}_{\\lambda}(x_{i}))^{2}\\\\ &amp;=&amp;\\frac{1}{n}\\sum_{i=1}^{n}E(y_{i}^{*}-f(x_{i}))^{2}+\\frac{1}{n}\\sum_{i=1}^{n}E(f(x_{i})-\\hat{f}_{\\lambda}(x_{i}))^{2}\\\\ &amp;=&amp;\\sigma^{2}+\\text{MSE}(\\lambda). \\end{eqnarray*}\\] 중간에 두 항은 독립이라고 보고 cross-product term을 생략하였다. 이 전개는 회귀분석에서 prediction interval이 커지는 것과 일맥상통한다. 한편, CV의 기댓값은 \\[\\begin{eqnarray*} E(y_{i}-\\hat{f}_{\\lambda}^{-i}(x_{i}))^{2}&amp;=&amp;E(y_{i}-f(x_{i})+f(x_{i})-\\hat{f}_{\\lambda}^{-i}(x_{i}))^{2}\\\\ &amp;=&amp;E(y_{i}-f(x_{i}))^{2}+E(f(x_{i})-\\hat{f}_{\\lambda}^{-i}(x_{i}))^{2}+2E(y_{i}-f(x_{i}))(f(x_{i})-\\hat{f}_{\\lambda}^{-i}(x_{i}))\\\\ &amp;=&amp;\\sigma^{2}+E(f(x_{i})-\\hat{f}_{\\lambda}^{-i}(x_{i}))^{2}.\\\\ \\end{eqnarray*}\\] 만약 \\(\\hat{f}_{\\lambda}^{-i}(x_{i}) \\approx \\hat{f}_{\\lambda}(x_{i})\\)이면 \\(E(\\text{CV})=\\text{PSE}(\\lambda)\\)이고 \\(\\min_{\\lambda}E(\\text{CV}) \\approx \\min_{\\lambda}\\text{PSE}(\\lambda) \\approx \\min_{\\lambda}\\text{MSE}(\\lambda)\\)이다. 물론 \\(\\min_{\\lambda}E(\\text{CV}) \\neq \\min_{\\lambda}\\text{CV}\\)이나 아주 틀린 생각은 아니다. (G. P. Nason 1996)에서는 웨이블릿에서 교차타당성을 하기 위한 몇 가지 방법을 제시했다. 첫 번째 방법은 하나의 자료 대신 절반의 자료(\\(\\frac{n}{2}\\))를 제거하는 이다. 다음과 같은 \\(y_{1}, \\cdots, y_{n}, y_{i}=g(x_{i})+\\epsilon_{i}, n=2^{J}\\)이라는 자료가 있다고 가정하자. 그러면 two-fold CV를 하는 방법은 다음과 같다. \\(\\lambda\\)의 후보군 \\(\\lambda \\in (\\lambda_{L}, \\lambda^{U})\\)를 설정한다. 2 먼저 모든 홀수번째 항의 \\(y_{i}\\)를 제거하고 남은 \\(y_{j}\\)에 대해 re-index를 한다(\\(y_{j},j=1,\\cdots,\\frac{n}{2}\\)). 웨이블릿 축소를 이용해 \\(y_{j},j=1,\\cdots,\\frac{n}{2}\\)로부터 \\(\\hat{g}^{E}\\)를 얻는다(이 때 bound problem이 생기므로 bound treatment를 해 줘야 한다). \\[\\mathbf{y} \\xrightarrow{\\text{DWT}} \\mathbf{d} \\text{ (thresholding $\\lambda$) } \\xrightarrow{\\text{IDWT}} \\hat{g}^{E}\\] 4. Even-index 자료를 가지고 odd index의 함수값을 예측하기 위해 다음과 같은 예측값 \\(\\bar{g}_{\\lambda,j}^{E}=\\frac{(\\hat{g}_{\\lambda,j+1}^{E}+\\hat{g}_{\\lambda,j}^{E})}{2}, j=1,2,\\cdots,\\frac{n}{2}\\)를 계산한다. 비슷한 방법으로 \\(\\bar{g}_{\\lambda,j}^{O}\\)를 계산한다. \\(\\hat{M}(\\lambda)=\\sum_{j=1}^{\\frac{n}{2}}\\{(\\bar{g}_{\\lambda,j}^{E}-y_{2j+1})^{2}+(\\bar{g}_{\\lambda,j}^{O}-y_{2j})\\}^{2}\\)를 계산한다. 여기서 앞 항은 even-index 자료를 가지고 odd 자료를 예측한 것이고, 뒤 항은 odd-index 자료를 가지고 even 자료를 예측한 것이다. \\(\\hat{M}(\\lambda)\\)가 제일 작은 \\(\\lambda^{*}=\\text{argmin}_{\\lambda \\in (\\lambda_{L},\\lambda^{U})} \\hat{M}(\\lambda)\\)를 최종적으로 선택한다. FIGURE 26.1: Relation between the large number of folds and CV. FIGURE 26.2: Relation between the small number of folds and CV. Fold 수가 커지면 bias가 줄어드나(더 정밀함) estimator의 variance는 커지고 계산 시간도 길어진다. Fold 수가 작아지면 계산 시간도 작아지고 estimator의 variance는 작아지나 bias는 커진다. 보통 K-fold 방법이 K의 선택은 data-dependent하게 한다. 매우 큰 자료에서는 K=3이어도 정밀하며, 성긴 자료에서는 가능한 한 많은 자료를 training하기 위해 leave-one out cross-validation (LOCV)를 사용하게 된다. 일반적인 선택은 K=10이다. References "],
["26-2-multiple-testing.html", "26.2 다중 비교(multiple testing)", " 26.2 다중 비교(multiple testing) 다음과 같은 성긴 웨이블릿 모형 \\(\\mathbf{d}=\\mathbf{\\theta}+\\mathbf{\\epsilon}\\)을 고려하자. 여기서 다음과 같은 여러 개의 귀무가설을 동시에 생각해 볼 수 있다. \\[H_{0}=\\theta_{j,k}=0, \\forall j,k.\\] 이러한 여러 개의 귀무가설을 동시에 생각해보는 문제는 천문학, 뇌과학, 마이크로어레이, 전기공학 등에서 볼 수 있다. 이 문제를 좀 더 일반적으로 설명해보면 다음과 같이 \\(m\\)개의 귀무가설 \\(H_{0i} \\text{ vs. } H_{1i}, i=1,\\cdots ,m\\)의 검정을 하는 문제로 볼 수 있다. \\(p_{1},\\cdots , p_{m}\\)을 대응되는 p-value로 정의하자. 다중 비교(multiple testing) 중 가장 널리 알려진 본페로니 방법(Bonferroni method)은 \\(p_{i} &lt; \\frac{\\alpha}{m}\\)일 경우 \\(H_{0i}\\)를 기각하는 방법이다. 그러나 이 방법은 m이 많아지면 너무 보수적으로 바뀌는 경향이 있다. \\(H_{0}\\) 기각 안함 \\(H_{0}\\) 기각 계 \\(H_{0}\\)가 참 \\(U\\) \\(V\\) \\(m_{0}\\) \\(H_{0}\\)가 거짓 \\(T\\) \\(S\\) \\(m_{1}\\) \\(m-R\\) \\(R\\) \\(m\\) 오류 발견율(false discovery rate, FDR)을 정의하기 위해 다음과 같은 표를 생각해보자. False discovery proportion은 \\(H_{0}\\)를 기각한 가설들 중 실제 \\(H_{0}\\)가 true (false positive)인 것의 비율이다. 다시 말하면 \\[ \\text{FDP}= \\begin{cases} \\frac{V}{R} &amp; \\text{if R $&gt;$ 0}\\\\ 0 &amp; \\text{o.w.} \\end{cases} \\] 이다. 그리고 \\(E(\\text{FDP})=\\)FDR로 정의한다. Benjamini-Hocheberg 방법(Benjamini-Hocheberg method)은 level \\(\\alpha\\)에 맞춰 FDR을 조절하기 위해 고안되었다. 이 방법은 다음과 같이 진행된다. \\(m\\)개의 p-value들을 \\(p_{(1)}, &lt; \\cdots &lt; p_{(m)}\\)으로 순서를 매긴(ordering)다. \\(l_{i}=\\frac{i\\alpha}{c_{m}m}\\)과 \\(R=\\max \\{i: p_{(i)}&lt; l_{i}\\}\\)를 정의한다. 여기서 \\[ c_{m}= \\begin{cases} 1 &amp; \\text{if p-values are independent}\\\\ \\sum_{i=1}^{m}(\\frac{1}{i}) &amp; \\text{o.w.} \\end{cases} \\] 이다. 일반적으로 모든 가설들은 독립이니 거의 1을 쓴다고 봐도 무방하다. Threshold \\(T=p_{R}\\)을 정의한다. \\(p_{i} \\leq T\\)일 경우 \\(H_{0i}\\)를 기각한다. 이 방법은 다중 비교를 할 때 가장 안정적으로 값을 준다고 알려져 있다. 그러면 이 방법을 웨이블릿에 똑같이 적용해보자. 다음과 같은 다중 비교 문제에서의 FDR control 방법은 다음과 같다. \\[H_{0i}:\\theta_{jk}=0 \\text{ vs. } H_{1}:\\theta_{jk} \\neq 0, j=0,\\cdots, J-1 \\text{ and } k=0, \\cdots, 2^{j}-1.\\] 각각의 \\(d_{jk}\\)에 대해 양뱡향 p-value를 \\(p_{jk}=2(1-\\Phi (\\frac{| d_{jk}|}{\\sigma}))\\)와 같이 정의한다(\\(\\sigma\\)는 주로 MAD로 추정한다). \\(p_{(1)} \\leq \\cdots \\leq p_{(m)}\\)으로 순서를 매긴다. \\(i_{0}\\)을 \\(p_{(i)} \\leq (\\frac{i\\alpha}{m})\\)을 만족하는 가장 큰 \\(i\\)라고 정의한다. 각각의 \\(i_{0}\\)에 대해 \\(\\lambda = \\sigma \\Phi^{-1}(1-\\frac{p_{i0}}{2})\\)를 계산한다. 이는 \\(|d_{jk}|\\)를 \\(\\lambda\\)와 비교하기 위함이다. 각 level에서 \\(\\lambda\\)보다 작은 것을 kill하도록 \\(d_{jk}\\)를 threshold한다. "],
["26-3-bayesian-wavelet-shrinkage.html", "26.3 베이지안 웨이블릿 축소(Bayesian wavelet shrinkage)", " 26.3 베이지안 웨이블릿 축소(Bayesian wavelet shrinkage) 희소(sparse)한 성질을 갖는 웨이블릿 축소의 특징은 \\(\\theta\\)에 대한 사전 정보를 갖고 있다(거의 대부분의 \\(\\theta\\)는 0이다)고도 볼 수 있고, 따라서 Bayesian 방법을 적용할 수 있다. 여기서 다루는 모든 Bayesian 방법은 prior의 모수를 미리 추정하고 사후 평균(posterior mean)을 구해놓는 경험적 베이즈(empirical Bayes) 방법이다. 26.3.1 Prior mixture of Gaussian 가장 처음 등장한 베이지안 웨이블릿 축소 방법은 “prior mixture of Gaussian”이다. 이는 가우스 분포 두 개를 합성한 것을 prior로 생각한 것이다. \\[\\theta_{jk}|\\gamma_{jk} \\sim \\gamma_{jk} \\mathcal{N}(0,c_{j}^{2}, \\tau_{j}^{2})+(1-\\gamma_{jk}) \\mathcal{N}(0,\\tau_{j}^{2}).\\] 여기서 \\(\\gamma_{jk}\\)는 \\(P(\\gamma_{jk}=1)=p_{j}\\)를 만족시키는 베르누이 확률변수이다. 그리고 \\(p_{j},c_{j},\\tau_{j}\\)는 초모수(hyperparamer)이다. 초모수란 prior의 모수를 의미한다. 성김 성질을 만들기 위해서는 \\(\\tau_{j}\\)는 작게, \\(c_{j}\\)는 1보다 크게 설정한다. 초모수들을 data로부터 계산하는 방법을 경험적 베이지안(empirical Bayesian)이라고 한다. 그 후 우도 \\(d|\\theta\\)를 다음과 같이 계산한다. \\[d|\\theta \\sim \\mathcal{N}(\\theta, \\sigma^{2}).\\] 그 다음에는 posterior distribution \\(F(\\theta | d)\\)를 계산한다. 문제는 \\(F\\)의 계산이 쉽지 않다는 것이다. 그래서 대신 계산이 쉬운 점추정값 \\(E(\\theta | d)\\)를 주로 계산한다. \\[\\hat{d}\\approx \\hat{\\theta} \\approx E(\\theta | d)=s(d)d,\\] \\[s(d)=\\frac{(c\\tau)^{2}}{\\sigma^{2}+(c\\tau)^{2}}P(\\gamma=1 | d)+\\frac{\\tau^{2}}{\\sigma^{2}+\\tau^{2}}P(\\gamma=0 | d).\\] FIGURE 26.3: Posterior mean and variance of parameter uwing prior mixture of Gaussian. 여기서 \\(\\frac{(c\\tau)^{2}}{\\sigma^{2}+(c\\tau)^{2}}, \\frac{\\tau^{2}}{\\sigma^{2}+\\tau^{2}}\\)이 기울기(slope)를 결정해준다. 예를 들어 만약 \\(\\tau^{2}\\)이 작으면 \\(\\frac{\\tau^{2}}{\\sigma^{2}+\\tau^{2}}\\) 또한 작아질 것이다. \\(\\sigma^{2}\\)의 선택 또한 매우 중요하다. 그런데 이 방법은 그림에서 볼 수 있듯이 축소(shrinkage)는 하나 임계화(thresholding)는 하나도 못한다는 단점이 있다. 26.3.2 Prior mixture of point mass and Gaussian 이러한 단점을 보완하기 위해 등장한 방법이 “prior mixture of point mass and Gaussian”로, (Abramovich, Sapatinas, and Silverman 1998)이 제안한 방법이다. 이는 다음과 같이 prior를 바꾸는 것에서 출발한다. \\[\\theta_{j} \\sim \\gamma_{j}\\mathcal{N}(0,\\tau_{j}^{2})+(1-\\gamma_{j})\\delta_{0} \\text{ where $\\delta_{0}$ is a point mass at zero}.\\] 이를 이용해 posterior distribution \\(F(\\theta | d)\\)를 구한 후 그것의 median를 점추정값으로 삼는다. \\[\\text{median}(\\theta |d)=\\text{sgn}(d)\\max(0,\\xi),\\] \\[\\text{ where } \\xi =\\frac{t_{j}^{2}}{\\sigma^{2}+\\tau_{j}^{2}}|d| -\\frac{\\tau_{j}\\sigma}{\\sqrt{\\sigma^{2}+\\tau_{j}^{2}}}\\Phi^{-1}(\\frac{1+\\min(\\omega,1)}{2}).\\] 또 책에 의하면 \\(\\omega=\\frac{1-p}{p}\\frac{\\sigma^{2}+\\tau_{j}^{2}}{\\tau_{j}^{2}}\\exp(-\\frac{d^{2}(\\sigma^{2}+\\tau_{j}^{2})^{2}}{2\\sigma^{2}\\tau_{j}^{4}})\\)이다. FIGURE 26.4: Posterior median plot using prior mixture of point mass and Gaussian. 이 그림은 prior mixture of point mass and Gaussian 방법을 이용했을 때 모수의 posterior median 그림. 절대 \\(\\hat{d} = d\\)가 되지 않는다는 사실을 참고하자. 26.3.3 Mixture of point mass and heavy-tail distribution 또 다른 방법은 (I. Johnstone and Silverman 2005)에 등장하는 “Mixture of point mass and heavy-tail distribution”이다. 이 논문에는 sparse에 대한 설명도 잘 되어있다. 이 논문의 저자들은 이 방법의 idea를 건초더미에서 바늘 찾기(finding a needle in a haystack)로 요약하였다. 이 방법에서는 다음과 같은 spike-flat prior를 고려한다. \\[f_{\\text{prior}}(\\theta)=w \\tau(\\theta)+ (1-w)\\delta_{0}.\\] 여기서 \\(\\tau(\\theta)\\)는 Laplace distribution과 같은 두꺼운 꼬리 분포를 의미한다. 이는 “sparse signal을 Normal보다 두꺼운 꼬리를 갖는 분포로 표현하는 것이 더 정확할 것이다”라는 믿음을 가지고 있는 것이다. 이는 매우 훌륭한 임계화(thresholding) 방법이나 \\(F(\\theta |d), \\text{median}(\\theta |d)\\)계산이 복잡하다는 단점이 있다. 마지막으로 이들 Bayesian 방법들을 frequentist 방법들과 비교해보자. \\(p(\\theta,\\lambda)=l(\\theta, d)+\\lambda p(\\theta)\\)라는 벌점화 최소자승(penalized least square) 방법을 생각해보자. 여기서 목표는 \\(p(\\theta,\\lambda)\\)를 최소화 하는 것이다. 이 때 \\(d\\)와 \\(\\lambda\\) 사이에는 일대일 대응관계가 있어 \\(d\\)가 매우 크면 \\(d\\)의 분산 역할을 하는 \\(\\lambda\\) 또한 0이 된다. 따라서 웨이블릿 변환을 고려하는 것이다. 오라클을 이용할 경우 \\(p(\\theta)\\)에 대한 조건이 필요하며 SCAD 등 frequentist 방법들이 이를 만족한다. 미리 p를 정해놓는 것은 frequentist들의 접근 방법으로 오라클은 frequentist 관점에서의 성질이다. Bayesian에게 이를 적용하기에는 무리가 있다. Bayesian은 p를 자료에 맞게 정하자는 것이다. “EBayes”는 \\(\\lambda\\)와 p를 동시에 계산하는 매우 강력한 방법이다. 일반적으로 \\(E(\\hat{f}_{\\lambda, \\text{EBayes}}-f)^{2}\\)이 다른 방법보다 더 좋은 수렴속도를 자랑하며 EBayes 자체를 physical domain에서 써도 매우 우수하다. 그리고 change point of detection등 다른 문제에도 쓰일 수 있다. References "],
["26-4-linear-wavelet-smoothing.html", "26.4 선형 웨이블릿 평활화(linear wavelet smoothing)", " 26.4 선형 웨이블릿 평활화(linear wavelet smoothing) 다음과 같이 웨이블릿을 이용한 f의 추정 문제를 생각해보자. \\[f_{J}=\\sum c_{0k}\\phi_{k}(x)+\\sum_{j=1}^{J}\\sum d_{jk}\\psi_{jk}(x).\\] 이때 \\[y \\rightarrow Wy \\rightarrow d \\xrightarrow{\\text{계산}} \\hat{d} \\xrightarrow{\\text{IWT}} W^{T}\\hat{d} \\rightarrow \\hat{f}\\] 로 \\(\\hat{f}\\)를 얻는다. 결과적으로 얻어진 \\(\\hat{f}_{J}\\)는 \\[\\hat{f}_{J}=\\sum c_{0k}\\phi_{k}(x)=\\sum_{j=1}^{L}\\sum d_{jk}\\psi_{jk}(x), L&lt;J.\\] 즉 \\(L\\)보다 높은 레벨의 \\(\\mathbf{d}_{i}\\)들은 모두 영벡터로 만드는 것이다. 그 동안은 invidual에 대해 임계화(thresholding)를 했으나 이 방법은 각 레벨에 대해 thresholding을 하는 것으로 이해할 수 있다. 그러나 performance가 그리 좋지는 않다. 이 방법에서 L을 결정하는 방법은 cross-validation으로 하는 것이 괜찮다. 이 방법은 지금까지 방법과는 달리 선형 방법으로 회귀분석의 내용을 그대로 가져올 수 있어 asymptotic이 쉬워진다. 그러나 잘 맞지는 않는다. "],
["26-5-block-thresholding.html", "26.5 블록 임계화(block thresholding)", " 26.5 블록 임계화(block thresholding) 그림과 같은 모자 함수는 한 지점에서만 값이 달라지나 이 변하는 것을 나타내기 위해 여러 개의 nonzero 웨이블릿 계수를 써야한다는 문제점이 있다. FIGURE 26.5: Posterior median plot using prior mixture of point mass and Gaussian. 다음과 같은 모형 \\(y_{i}=g(x_{i})+e_{i}\\)를 생각해보자. \\(g(x_{i})\\)의 \\((j,k)\\)번째 true 웨이블릿 계수는 \\(\\theta_{jk}=\\int g(x)\\psi_{jk}(x)dx\\)이다. \\(\\theta_{jk}\\)를 잘 계산하기 위해 다음과 같은 경험적 quantity \\(\\hat{d}_{jk}=\\frac{1}{n}\\sum_{k=1}^{n}y_{i}\\psi_{jk}^{2}(x_{i})\\)를 생각해보자. 이것의 분산은 \\[\\begin{eqnarray*} var(\\hat{d}_{jk})&amp;=&amp;\\frac{1}{n}\\sum_{i=1}^{n}var(y_{i})\\psi_{jk}^{2}(x_{i})\\\\ &amp;=&amp;\\frac{1}{n}\\sum_{i=1}^{n}\\sigma^{2}\\psi_{jk}^{2}(x_{i})\\\\ &amp;\\simeq&amp; \\frac{1}{n}\\sigma^{2}\\int \\psi_{jk}^{2}(x)dx=\\frac{\\sigma^{2}}{n}. \\end{eqnarray*}\\] 로 분산이 커지는 문제가 발생한다고 한다. 이 방법에 대한 해결책으로 “blockwise”하는 방법이 있다. \\(j\\) 스케일(레벨)에서 길이 l인 겹치지 않는 블록들 \\(B_{b}\\)를 만드는 것이다. “block truth”를 다음과 같이 정의한다. \\[B_{jb}=\\frac{1}{l}\\sum_{(b)}\\theta_{jk}^{2}.\\] 여기서 \\(\\sum_{(b)}\\)는 \\(k \\in B_{b}\\)에 대해 모두 더하라는 것이다. 이것에 대한 추정량은 \\(\\hat{B}_{jb}=\\frac{1}{l}\\sum_{(b)}d_{jk}^{2}\\)이며 블록 웨이블릿 계수 contribution은 다음과 같이 구할 수 있다. \\[\\sum_{j=0}^{q}\\sum_{-\\infty &lt; b &lt; \\infty} \\{ \\sum_{(b)}\\hat{d}_{jk}\\psi_{jk}(x_{i})\\}I(\\hat{B}_{jb} &gt; \\lambda^{2}).\\] 물론 length \\(l\\)의 선택과 overlapping을 하는 것이 좋은지에 대한 문제가 남아 있다. "],
["27-multiscalets.html", "Chapter 27 다중척도 시계열분석", " Chapter 27 다중척도 시계열분석 \\(y_{i}=g(x_{i})+e_{i}\\)라는 자료 분석을 할때, 지금까지는 error가 independent인 자료들만을 주로 다루었으나, 이제는 correlated 되어있는 자료들을 생각해보자. 가장 간단한 경우로 \\(\\mathbf{e} \\sim \\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Gamma}), \\boldsymbol{\\Gamma}=[ \\gamma_{|r-s|}]_{r,s} \\neq \\sigma^{2}I\\) 가 정상 과정(stationary process) 이라고 가정하는 것이다. 이런 경우에 웨이블릿 임계화(thresholding)를 어떻게 될 것인가? 그 전에 왜 상관자료(correlated data)에서 웨이블릿을 고려하는지에 대해 잠시 설명하자면 이는 웨이블릿의 “whitening” 성질과 관련이 있다. \\(\\mathbf{y}\\)가 정상 과정일 경우 웨이블릿 계수 d가 독립에 가까워지는 \\(corr(d_{j},d_{j&#39;})\\approx 0\\)인 \\(|j-j&#39;|&gt;\\delta\\)를 만족하는 \\(\\delta\\)가 존재한다는 것이 “whitening”이다. 이로 인해 웨이블릿이 상관자료(correlated data)를 다룰 때 도움을 줄 수 있다. "],
["27-1-stationary-time-series.html", "27.1 시계열 자료의 정상성(stationary time series)", " 27.1 시계열 자료의 정상성(stationary time series) \\(\\{ X_{t} \\}\\)는 다음과 같은 자기공분산 함수(autocovariance function) \\[\\gamma_{X}(r,s)=Cov(X_{r},X_{s})=E(X_{r}-EX_{r})(X_{s}-EX_{s}) \\text{ is finite for any } r,s.\\] 를 갖는 랜덤 프로세스라고 하자. 여기서 staionary보다 조금 더 약한 약정상과정(weakly stationary process)에 대해 생각해보자. Definition 27.1 다음과 같은 세 가지 조건 \\(E|X_{t}|^{2} &lt; \\infty\\). \\(EX_{t}=m\\)(constant), \\(\\forall t\\). \\(Cov(X_{t+h},X_{t})=\\gamma_{X}(h) (\\text{ t에 독립})\\) 을 만족하는 \\(\\{ X_{t} \\}\\)를 약정상성(weakly stationary)을 갖는다라고 한다. 순정상 시계열(strictly stationary time seres)은 모든 \\(t_{i}, n\\) 그리고 \\(\\tau\\)에 대해 \\((X_{t_{1}}, \\ldots, X_{t_{n}})\\)의 결합분포가 \\(X_{t_{1}+\\tau}, \\ldots, X_{t_{n}+\\tau})\\)의 결합 분포와 항상 같은 것을 의미한다. 그러나 이 정의는 너무 강해 약정상 시계열(weakly stationary time seres)을 많이 쓰게된다. 보통 정상과정(stationary process)을 말하면 약정상성을 의미한다. Example 27.1 (백색 잡음 과정) 백색 잡음 과정 \\(\\{Z_{t}\\}\\)는 \\[E(Z_{t})=0, \\forall t,\\] \\[\\gamma(h)=\\sigma^{2}\\delta_{h}=E(Z_{t+h},Z_{t})=\\sigma^{2}I\\{h=0\\}\\] 이므로 정상 과정이다. Example 27.2 (AR(1) 과정) AR(1) 과정 \\(\\{X_{t}\\}\\)는 \\[X_{t}-\\phi X_{t-1}=Z_{t}, Z_{t} \\sim WN(0,\\sigma^{2}), \\] \\[\\gamma(h)=\\sigma^{2}\\frac{\\phi^{|h|}}{1-\\phi}\\] 이므로 정상 과정이다. 다시 상기하는 의미에서 \\(X(t)\\)의 이산 웨이블릿 변환은 \\(\\{ d_{jk} \\}=\\int_{\\mathbb{R}}X(t)\\psi_{jk}(t)dt\\)이고, \\[E d_{jk}d_{j&#39;k&#39;}=\\int \\int_{\\mathbb{R}^{2}}\\gamma(t,s)\\psi_{jk}(t)\\psi_{j&#39;k&#39;}(s)dtds\\] 이다. 다음은 웨이블릿 변환과 정상성에 관련된 정리이다. Theorem 27.1 (약정상과정 관련 정리) \\(X(t)\\)가 약한 정상 과정이고 \\(\\gamma(t,s)\\)가 \\(\\mathbb{R}^{2}\\)에서 유계(bounded)이고 연속이면, \\(X(t)\\)가 약정상과정인 것과 \\(\\{ d_{jk} \\}\\)가 약정상과정인 것은 동치이다(만약 \\(\\psi\\)가 compactly supported이면 당연히 유계이므로 유계 조건이 따로 필요 없다). "],
["27-2-whitening-of-stationary-process.html", "27.2 정상과정의 백색화(whitening of stationary process)", " 27.2 정상과정의 백색화(whitening of stationary process) \\(X(t)\\)를 정상 과정이라고 하자. 그러면 \\[X_{m}(t)=\\sum c_{mk}\\phi_{mk}(t)=\\text{ projection on $V_{m}$}=\\sum_{j}^{m}d_{jk}\\psi_{jk}(t)\\] 와 같이 웨이블릿의 선형 결합으로 나타낼 수 있다(\\(d_{jk}=\\int X(t)\\psi_{jk}(t)dt\\)). 그리고 \\[\\begin{eqnarray*} E d_{jk}d_{j&#39;k&#39;}&amp;=&amp;\\int \\int_{\\mathbb{R}^{2}}\\gamma(t,s)\\psi_{jk}(t)\\psi_{j&#39;k&#39;}(s)dtds\\\\ &amp;=&amp;\\frac{1}{2 \\pi}\\int_{\\mathbb{R}}\\hat{\\gamma}(\\omega)\\hat{\\psi}(\\frac{\\omega}{2^{j}})\\bar{\\hat{\\psi}}(\\frac{\\omega}{2^{j}})e^{-i\\omega k 2^{-j}}e^{-i\\omega k&#39; 2^{-j&#39;}}2^{-\\frac{j}{2}}2^{-\\frac{j&#39;}{2}}d\\omega.\\\\ \\end{eqnarray*}\\] 이다. 갑자기 notation들이 막 튀어나오는데 자세한 내용은 (J. Zhang and Walter 1994)를 참고하라. Theorem 27.2 (정상과정의 백색화) \\(d_{jk}\\)와 \\(d_{j&#39;k&#39;}\\)는 \\(|j-j&#39;|&gt;1\\)일 경우 무상관(uncorrelated)이다(에를 들어 \\(d_{1}\\)과 상관(correlated)된 것은 \\(d_{0}, d_{2}\\)이다). \\(|j-j&#39;|=1\\)일 경우 약간의 correlation을 갖는다. \\(j \\neq j&#39;\\)일 경우 \\(O(|j-j&#39;|^{-p})\\)의 correlation을 갖는다. (Johnstone and Silverman 1997)에서는 위 정리의 결과를 그대로 웨이블릿 축소에 가져왔다. 즉 각 level끼리 독립이므로 level별로 따로 임계화(thresholding)를 하는 방법을 생각한 것이다. 이 때 레벨 \\(j\\)에서 \\[\\hat{\\lambda}_{j}=\\sqrt{2\\log n_{j}}\\hat{\\sigma}_{j} \\text{ or } \\hat{\\lambda}_{j}=\\min_{\\lambda}\\text{SURE}(\\lambda_{j})\\] 를 이용한다. \\(n_{j}\\)는 레벨 \\(j\\)에서의 계수의 총 갯수이고, \\(\\hat{\\sigma}_{j}\\)는 MAD로 계산한다. 그러나 자료가 정상성이 아닐 경우 방법이 없다. 왜냐하면 비정상 시계열(nonstationary time series)은 너무 광범위한 개념이기 때문이다. 따라서 사람들은 비정상 시계열들 중 다루기 쉬운 일부를 제한해 그것을 분석한다. Evolutionary stationary process가 그 예이다. References "],
["27-3-spectral-representation-of-stationary-process.html", "27.3 정상과정의 스펙트럼 표현(spectral representation of stationary process)", " 27.3 정상과정의 스펙트럼 표현(spectral representation of stationary process) \\(\\{ X(t) \\}\\)를 평균이 0인 정상과정이라고 하자. 그러면 다음 \\[X(t)=\\int_{-\\infty}^{\\infty} e^{it\\omega}dZ(\\omega)\\] 를 만족시키는 직교과정(orthogonal process) \\(\\{Z(\\omega)\\}\\)가 존재한다. 여기서 잠시 직교증분과정(orthogonal increment process)라는 것에 대해 소개하겠다. Definition 27.2 (직교증분과정) 두개의 다른 주파수 \\(\\omega\\), \\(\\omega&#39;\\) \\((\\omega \\neq \\omega&#39;)\\)가 있다고 하자. 만약 두 개의 process \\[dZ(\\omega)=\\{Z(\\omega +d\\omega)-Z(\\omega)\\} \\text{ and } dZ(\\omega&#39;)=\\{Z(\\omega&#39; +d\\omega&#39;)-Z(\\omega&#39;)\\}\\] 가 무상관\\((\\text{Cov}(dZ(\\omega), dZ(\\omega&#39;))=0)\\)일 때 \\(dZ(\\omega)\\)는 직교증분과정이라고 한다. 다시 직교과정으로 돌아가서, \\(\\{Z(\\omega)\\}\\)는 다음 성질들을 만족시킨다. \\(E(dZ(\\omega))=0, \\forall \\omega\\). \\(E|dZ(\\omega)|^{2}=d H(\\omega)=h(\\omega), \\forall \\omega, \\text{ where } H(\\omega)=\\int h(\\omega)=\\text{integrated spectrum of } X(t)\\). \\(Cov(dZ(\\omega), dZ(\\omega&#39;))=0\\). (직교증분과정) (G. Nason 2010)에 의하면, 어떤 시계열 \\(\\{Z_{t} \\}_{t\\in \\mathbb{Z}}\\)가 정상확률과정이라면 다음과 같이 표현할 수 있다고 한다. 즉 \\(\\sin\\), \\(\\cos\\) basis function으로 expansion할 수 있는 것이다. \\[\\begin{equation} X_{t}=\\int_{-\\pi}^{\\pi}A(\\omega)e^{it\\omega}d\\xi(\\omega) \\end{equation}\\] 이 때 \\(A(\\omega)\\), \\(d\\xi(\\omega)\\)가 \\(dZ(\\omega)\\) 역할을 하게 되는 것이며, 가장 영향력 있는 계수들의 제곱이 스펙트럼(spectrum)이 된다. \\[|A(\\omega)|^{2}=\\hat{h}(\\omega): \\text{ periodogram (point estimator but not consistent)}\\] \\[|\\tilde{A}(\\omega)|^{2}: \\text{ smoothing시 consistent 해짐}\\] \\[Cov(X(t), X(t+\\tau))=\\int_{-\\infty}^{\\infty}e^{it\\omega}dH(\\omega)\\] 이며, 여기서 \\(Cov(X(t), X(t+\\tau))\\)는 \\(X(t)\\)의 공분산함수이며, \\(dH(\\omega)\\)는 \\(X(t)\\)의 스펙트럼이고, 이들은 \\(e^{it\\omega}\\) 라는 푸리에변환을 통해 일대일변환(one-to-one transform)된다. 다음 내용은 (Priestley 1981) 및 (Dahlhaus 1996)에서 발췌한 내용이다. 비정상과정 \\(X(t)\\)는 다음과 같이 간주할 수 있다. \\[\\phi_{t}(\\omega) \\text{ instead of } e^{it\\omega}\\] \\[\\begin{eqnarray*} X(t)&amp;=&amp;\\int \\phi_{t}(\\omega)dZ(\\omega)=\\int A(\\omega)e^{it\\omega}d\\xi(\\omega)\\\\ &amp;=&amp;\\int A_{t}(\\omega)e^{i\\theta(\\omega)t}dZ(\\omega) \\Longrightarrow \\text{ &quot;Oscillatory process&quot;}\\\\ \\end{eqnarray*}\\] 여기서 \\(A_{t}(\\omega)\\)는 일종의 가중치(weight)이며 시간에 따라 계속 바뀐다. 이 내용은 비정상과정의 시계열을 분할하여 스펙트럴 표현(spectral representation)이 되도록 제한할 수 있다는 것이다. 그러나 유일(unique)하게 정의되지 않는다는 것은 문제이다. 함수추정에서 웨이블릿은 희소(sparsity) 장점을 준다. 그러나 시계열에서의 웨이블릿 사용은 희소와는 큰 관련이 없다. 다만 다음과 같이 변환하였을 때, \\[X(t) \\stackrel{\\omega}{\\rightarrow}d_{jk}(t) \\text{ j: scale, k: location}\\] \\(d\\)는 \\(\\omega\\)와 \\(t\\)의 성질을 동시에 갖으며 이를 통해 비정상 시계열을 다룰 수 있지 않을까 하는 기대감 때문이다. 이러한 분석 방법을 time (k) - scale (j) analysis라고 한다. References "],
["27-4-non-decimated-discrete-wavelets.html", "27.4 압축 표본화되지 않은 이산 웨이블릿(non-decimated discrete wavelets)", " 27.4 압축 표본화되지 않은 이산 웨이블릿(non-decimated discrete wavelets) 일반적인 웨이블릿은 시계열 자료를 다루기에는 information이 너무 작아지는 경향이 있는데, 압축 표본화되지 않은 웨이블릿(non-decimated wavelets)은 그렇지 않아 temporal resolution에 좋다고 한다. (G. P. Nason, Sachs, and Kroisandt 2000)은 컴팩트 지지 웨이블릿(compactly supported wavelets)이라는 것을 만들었다. \\(\\psi_{j}=(\\psi_{j,0},\\ldots,\\psi_{j,N_{j}-1})\\)를 길이가 \\(N_{j}\\) (\\(j\\)는 scale)인 웨이블릿의 수열 값이라고 하자. 그러면 \\[\\psi_{-1,n}=\\sum_{k}g_{n-2k}\\delta_{0,k}=g_{n},\\qquad{n=0,\\ldots, N_{-1}-1},\\] \\[\\psi_{j-1,n}=\\sum_{k}h_{n-2k}\\psi_{j,k},\\qquad{n=0,\\ldots, N_{-1}-1},\\] \\[N_{j}=(2^{-j}-1)(N_{h}-1)+1,\\] 여기서 \\(\\delta_{0,k}\\)는 크로네커 델타(Kronecker delta)이며 \\(N_{h}\\)는 \\(\\{h_{k}\\}\\)의 0이 아닌 원소들의 수이다. Example 27.3 (이산 Haar 웨이블릿) 이산 Haar 웨이블릿의 경우 \\[\\psi_{-1}=(g_{0},g_{1})=(1,-1)/\\sqrt{2},\\] \\[\\psi_{-2}=(h_{0}g_{0},h_{1}g_{0},h_{0}g_{1},h_{1}g_{1})=(1,1,-1,-1)/2\\] 이다. References "],
["27-5-locally-stationary-wavelet-process.html", "27.5 국소 정상 웨이블릿 과정(locally stationary wavelet process)", " 27.5 국소 정상 웨이블릿 과정(locally stationary wavelet process) 국소 정상성의 정의는 (G. P. Nason, Sachs, and Kroisandt 2000)에 등장한다. References "],
["28-admultiscale.html", "Chapter 28 고급 다중척도 방법론", " Chapter 28 고급 다중척도 방법론 이 장에서는 앞 장에서 다룬 다중척도 방법론 중 심화된 웨이블릿 방법론 및 최신 동향에 대해 다룬다. 이 분야의 대표적인 참고문헌에는 (M. H. Jansen and Oonincx 2005)가 있다. References "],
["28-1-second-generation-wavelet-transform.html", "28.1 2세대 웨이블릿 변환(second-generation wavelet transform)", " 28.1 2세대 웨이블릿 변환(second-generation wavelet transform) 푸리에 변환을 가지고 만들어진 웨이블릿을 1세대 웨이블릿(first-generation wavelet)이라고 부른다. 이와 다르게 푸리에 변환을 이용하지 않고 만들어진 웨이블릿을 2세대 웨이블릿 변환(second-generation wavelet)이라고 부른다. 이 2세대 웨이블릿 변환은 다음에 소개될 리프팅 스킴이라는 것에 의해 만들어진다. "],
["28-2-lifting-scheme.html", "28.2 리프팅 스킴(lifting scheme)", " 28.2 리프팅 스킴(lifting scheme) 리프팅 스킴(lifting scheme)은 확장(enhancement)이라는 개념이다. 지금 존재하는 웨이블릿에 우리가 원하는 성질들을 추가하는 것이다. Haar 웨이블릿을 새로운 관점에서 보도록 하자. \\(s_{j+1}\\)을 \\(j+1\\) 스케일에서의 투입값이라고 하자. 그러면 Haar 변환은 이것들을 \\(j\\) 척도의 평균 \\(s_{j,k}\\)과 차이(detail) \\(d_{j,k}\\)로 바꿔준다. \\[\\begin{equation} s_{j,k}=\\frac{s_{j+1,2k}+s_{j+1,2k+1}}{2} \\end{equation}\\] \\[\\begin{equation} d_{j,k}=s_{j+1,2k+1}-s_{j+1,2k} \\end{equation}\\] 위 식들의 역변환(inverse transform)은 다음과 같다. \\[\\begin{equation} s_{j+1,2k+1}=s_{j,k}+\\frac{d_{j,k}}{2} \\end{equation}\\] \\[\\begin{equation} s_{j+1,2k}=s_{j,k}-\\frac{d_{j,k}}{2} \\tag{28.1} \\end{equation}\\] 식 ((28.1))를 이항하여 정리하면 다음과 같은 식을 얻는다. \\[\\begin{equation} s_{j,k}=s_{j+1,2k}+\\frac{d_{j,k}}{2}. \\end{equation}\\] 웨이블릿 변환에서는 \\(s_{j,k}\\)와 \\(d_{j,k}\\)를 동시에 얻지만 리프팅 스킴에서는 \\(d_{j,k}\\)를 얻은 후 순차적으로 \\(s_{j,k}\\)를 얻는다. FIGURE 28.1: Forward lifting scheme using Haar transform. 정리하면 \\[\\text{차이(difference)=홀(odd)-짝(even)} \\qquad{\\text{듀얼 리프팅(dual lifting)}}\\] \\[\\text{평균(average)=짝(even)+0.5차이} \\qquad{\\text{프라이멀 리프팅(primal lifting)}}\\] 이며 여기서 짝과 홀을 어떻게 정하느냐에 따라 계산값이 달라진다. 리프팅 스킴의 계산 절차를 다음과 같이 세 단계로 요약할 수 있다. 분할(split): 관찰값들을 짝과 홀 두 개의 분리 집합(disjoint set)으로 분할(partition)한다(꼭 짝과 홀로 나누지 않아도 된다). 에측(predict): 홀로 색인(index)된 투입값을 이 값과 짝의 데이터만을 이용해 예측된 값으로 대체한다. \\(d_{j,k}=s_{j+1,2k+1}-s_{j+1,2k}\\) (듀얼 리프팅) 갱신(update): \\(s_{j,k}=s_{j+1,2k}+\\frac{d_{j,k}}{2}\\) (프라이멀 리프팅) 일반적인 리프팅 스킴의 프라이멀 리프팅과 듀얼 리프팅의 정변환(forward transform)은 다음과 같다. \\[\\text{차이(difference)=홀(odd)-p짝(even)} \\qquad{\\text{듀얼 리프팅(dual lifting)}}\\] \\[\\text{평균(average)=짝(even)+u차이} \\qquad{\\text{프라이멀 리프팅(primal lifting)}}\\] 이 때 \\(p=1\\), \\(u=0.5\\)인 경우를 특별히 Haar 웨이블릿 변환(Haar wavelet transformation)이라고 부르는 것이다. FIGURE 28.2: Standard lifting scheme using primal and dual lifting. 리프팅의 역변환(backward transform)은 다음과 같다. \\[\\text{짝(even)=평균(average)-u차이(difference)} \\] \\[\\text{홀(odd)=차이(difference)+p짝} \\] FIGURE 28.3: Backward lifting scheme. 리프팅 스킴 방법은 데이터가 일정한 간격(equally space)으로 있어야 한다는 가정이 불필요하며 \\(n=2^{J}\\)일 필요도 없다. 그러나 \\(p\\)와 \\(u\\)를 바꿀 경우 직교성(orthogonality)이 안되기 시작하며 2차원 자료인 경우에도 잘 작동하지 않는다. 만약 시공간 자료(spatio-temporal data)에 리프팅을 적용할 수 있다면 군집 분석(clustering analysis)을 할 때 군집의 크기(clustering size)를 고민할 필요가 없다는 장점이 생긴다. Example 28.1 (리프팅 스킴) 다음과 같은 벡터 \\[\\mathbf{z}_{3}=(1,2,3,4,5,6,7,8), n=8, J=3.\\] 가 있다고 하자. 이 벡터에 리프팅 스킴을 적용하면 다음과 같다. Spilt: \\(\\mathbf{z}_{3}\\)을 \\(\\mathbf{y}=(1,3,5,7)\\) (홀에 해당)와 \\(\\mathbf{x}=(2,4,6,8)\\) (짝에 해당)로 나눈다. Predict: \\(\\mathbf{x}\\)의 주변값의 평균을 이용해 \\(\\hat{\\mathbf{y}}\\)를 만든다. 첫 번째 원소를 예측할 때에는 첫 번째 \\(\\mathbf{x}\\)값만 쓰기로 한다. 그러면 \\(\\hat{\\mathbf{y}}=(2,3,5,7)\\)가 되고 \\(\\mathbf{e}_{2}=\\mathbf{y}-\\hat{\\mathbf{y}}=(-1,0,0,0)\\)가 된다. Update: 평균을 맞춰주는 작업을 진행해 \\(\\mathbf{z}_{2}=\\bar{\\mathbf{x}}=\\mathbf{x}+\\mathbf{e}_{2}/2 = (1.5,4,6,8)\\)를 만든다. 이제 \\(\\mathbf{z}_{2}\\)를 가지고 같은 작업을 반복한다. 그러면 Spilt: \\(\\mathbf{y}=(1.5,6)\\), \\(\\mathbf{x}=(4, 8)\\). Predict: \\(\\hat{\\mathbf{y}}=(4,6)\\), \\(\\mathbf{e}_{1}=(-2.5,0)\\). Update: \\(\\mathbf{z}_{1}=\\bar{\\mathbf{x}}=(2.75,8)\\). 한 번 더 반복한다. Spilt: \\(\\mathbf{y}=(2.75)\\), \\(\\mathbf{x}=8\\) Predict: \\(\\hat{\\mathbf{y}}=(8)\\), \\(\\mathbf{e}_{0}=(-5.25)\\) Update: \\(\\mathbf{z}_{0}=\\bar{\\mathbf{x}}=(5.375)\\). 최종적으로 남는 detail과 global은 다음과 같다. 0이 많아져 리프팅 스킴으로 좋은 결과를 얻었다고 말할 수 있다고 한다. \\[\\mathbf{e}_{2}=(-1,0,0,0), \\mathbf{e}_{1}=(-2.5,0), \\mathbf{e}_{0}=(-5.25), \\mathbf{z}_{0}=(5.375).\\] Example 28.2 (리프팅 스킴의 복원) 다중척도 방법의 특징은 저장된 계수들을 가지고 원래 신호를 복원(reconstruction)할 수 있어야 한다는 것이다. 앞선 예제의 detail과 global 계수들을 가지고 신호복원을 해보자. \\(\\mathbf{x}=\\mathbf{z}_{0}-\\mathbf{e}_{0}/2=8\\), \\(\\mathbf{y}=\\mathbf{e}_{0}+\\hat{\\mathbf{y}}=2.75\\), \\(\\mathbf{z}_{1}=(2.75, 8)\\). \\(\\mathbf{x}=\\mathbf{z}_{1}-\\mathbf{e}_{1}/2=(4,8)\\), \\(\\hat{\\mathbf{y}}=(4,6)\\), \\(\\mathbf{y}=\\mathbf{e}_{1}+\\hat{\\mathbf{y}}=(1.5, 6)\\), \\(\\mathbf{z}_{2}=(1.5, 5, 6, 8)\\). \\(\\mathbf{x}=\\mathbf{z}_{2}-\\mathbf{e}_{2}/2=(2,4,6,8)\\), \\(\\hat{\\mathbf{y}}=(2,3,5,7)\\), \\(\\mathbf{y}=\\mathbf{e}_{2}+\\hat{\\mathbf{y}}=(1,3,5,7)\\). 따라서 \\(\\mathbf{z}_{3}=(1,2,3,4,5,6,7,8)\\) 신호를 성공적으로 복원할 수 있다. "],
["28-3-basis-functions.html", "28.3 기저함수들(basis functions)", " 28.3 기저함수들(basis functions) "],
["28-4-lifting-in-two-dimensions.html", "28.4 2차원 자료의 리프팅 스킴(lifting in two dimensions)", " 28.4 2차원 자료의 리프팅 스킴(lifting in two dimensions) 이 절의 내용은 (Jang 2012)의 서술을 참고하였다. 2차원 자료에서는 1차원 자료와 다르게 짝과 홀을 정할 수 없다는 문제점이 있다. 불규칙한 격자점에서, 이웃(neighborhood)은 삼각분할(triangulation)을 통해 정의된다. 리프팅 스킴은 모든 해상도 수준(resolution level)에서 다중척도 들로네 삼각분할(multiscale Delaunay triangulation)이라 부르는 꼭지점들의 이웃 구조를 사용한다. 삼각형 격자 위에 있는 자료를 다중척도 표현으로 분해(decomposition)하는 것은 현재 수준 \\(l\\)에서 \\(l+1\\)로 넘어갈 때 빼길 원하는 점 주변의 국소적 재삼각분할(local retriangulation)을 필요로 한다. 이 알고리즘은 수준이 고정되었을 때 이웃은 변하지 않는다라는 가정 하에서 진행된다. FIGURE 28.4: 2D lifting scheme example. 위 그림에서 빨간색 점들로 검은색 점을 포함하는 보로노이 다이어그램(Voronoi diagram)을 그린다. (a), (b), (c)는 각각 첫 번째, 두 번째 및 세 번째 리프팅 스킴에 대응된다. (d)는 투입된 자료를 네 가지 수준으로 구분한 그림이다. 빨간색 점들은 \\(s_{t,2k+1}\\)에 대응되며 검은색 점들은 \\(s_{t,2k}\\)에 대응된다. 갱신 단계에서, 우리는 검은색 지점의 상세 이미지(detail image) \\(d_{t+1,k}\\)를 얻을 수 있고, 빨간색 지점의 갱신된 근사 이미지(approximation image) \\(s_{t+1,k}\\)를 얻을 수 있다. 산재된 자료(scattered data)의 경우 척도(scale)은 ‘연속(continuous)’ 개념에 대응된다. 다시 말하면, 모든 자료는 각자 고유의 척도를 가지고 있고, 이 척도는 주변과의 거리에 관계되어 결정되는 것이다. References "],
["28-5-nonlinear-lifting.html", "28.5 비선형 리프팅(nonlinear lifting)", " 28.5 비선형 리프팅(nonlinear lifting) 28.5.1 최대-리프팅 스킴(max-lifting scheme) 최대-리프팅 스킴(max-lifting scheme)은 Haar 변환을 좀 더 유연하게 만들고자 하는 필요로부터 출발하였다. \\[s_{j,k}=\\frac{s_{j+1,2k}+s_{j+1,2k+1}}{2}\\] \\[d_{j,k}=s_{j+1,2k+1}-s_{j+1,2k}\\] Haar 변환은 data의 odd에서 even을 뺌으로써 detail signal을 generate하고 있다. FIGURE 28.5: Haar transform is not robust. 그러나 위 그림처럼 Haar 변환을 쓸 경우에는 odd/even의 선택에 따라 로버스트하지 않은 결과를 주기도 한다. 듀얼 리프팅의 가장 큰 상세계수(detail coefficient)들은 다음과 같이 주변 값들 중의 최대값을 이용해 얻을 수 있다. \\[d_{j,k}=s_{j+1,2k+1}-\\max(s_{j+1,2k},s_{j+1,2k+2})\\] 프라이멀 리프팅으로는 \\[\\begin{eqnarray*} s_{j,k}&amp;=&amp; s_{j+1,2k}+\\max (0,d_{j,k},d_{j,k-1})\\\\ &amp;=&amp;s_{j+1,2k}+\\max (0, s_{j+1,2k+1}-s_{j+1,2k}, \\\\ &amp; &amp;s_{j+1,2k+1}-s_{j+1,2k+2}, s_{j+1,2k-1}-s_{j+1,2k-2}, s_{j+1,2k-1}-s_{j+1,2k}) \\end{eqnarray*}\\] 다음은 최대-리프팅 스킴의 흥미로운 두 가지 성질들이다. Local maxima of \\(s_{j+1}\\) et even entries are conserved in \\(s_{j}\\). 2, Local maxima of \\(s_{j+1}\\) et odd entries are conserved in \\(s_{j}\\) if no other local maxima appear in a five-entry neighborhood. 또한 max-lifting does not generate new maxima in \\(s_{j}\\) compared with \\(s_{j+1}\\). Integer programming, image processing 등에 응용 가능 "],
["29-advlifting.html", "Chapter 29 고급 리프팅 스킴 방법론 ", " Chapter 29 고급 리프팅 스킴 방법론 "],
["29-1-adaptive-lifting-scheme.html", "29.1 적응적 리프팅 스킴(adaptive lifting scheme)", " 29.1 적응적 리프팅 스킴(adaptive lifting scheme) 우선 두 개의 예측연산자(prediction operator)들을 먼저 소개한다. Left Haar predictor or identity operator: \\(P_{1}(s_{j,2k})=s_{j,2k}\\) Right Haar operator or right shift operator: \\(P_{2}(s_{j,2k})=S_{j,2k+2}\\) 듀얼 리프팅이나 최대-리프팅 스킴은 적당한 prediction operator \\(P_{1}\\) 또는 \\(P_{2}\\) 고르는 과정이라고 볼 수 있다. 우리는 이것을 결정 연산자(decision operator, decision map) \\(D^{P}\\)를 도입함으로써 formalize 할 수 있다. \\[D_{j}^{P}(k)= \\begin{cases} 1 &amp; \\text{if $s_{j+1,2}\\leq s_{j+1,2k+2}$}\\\\ 2 &amp; \\text{if $s_{j+1,2} &lt; s_{j+1,2k+2}$} \\end{cases}\\] 모든 이웃들 \\(s_{j+1,2}\\), \\(s_{j+1,2k+2}\\)에 대해 결정연산자는 이들이 왼쪽 (1) 또는 오른쪽(2)에 있는지 알려주는 역할을 한다. 그러면 듀얼 리프팅은 \\[d_{j,k}=s_{j+1,2k+1}-P_{D_{j,k}^{P}}(s_{k+1,2k})\\] 로 쓰여진다. 또한 프라이멀 리프팅을 위해 결정연산자를 또 도입한다. \\[D_{j}^{U}(k)= \\begin{cases} 0 &amp; \\text{if $\\max (d_{j,k},d_{j,k-1})\\leq 0$}\\\\ 1 &amp; \\text{if $\\max (0, d_{j,k-1}) \\leq d_{j,k}$}\\\\ 2 &amp; \\text{if $\\max (0, d_{j,k}) \\leq d_{j,k-1}$} \\end{cases}\\] \\(U_{2}=R\\) (\\(R\\): shift operator)를 이용하면 프라이멀 리프팅은 \\[s_{j,k}=s_{j+1,2k}+U_{D_{j,k}^{U}}d_{j,k}\\] 가 된다. FIGURE 28.6: A general adaptive lifting scheme. Data in both branches of the scheme contribute to the choices of prediction and update filters. 프라이멀과 듀얼 리프팅 스텝에 모두 결정연산자를 사용하는 컨셉이 적응적 리프팅 스킴의 핵심이며 위 그림에 잘 나타나 있다. 그리고 이 두 결정연산자들은 \\(\\mathbf{s}_{j+1}\\)과 \\(\\mathbf{d}_{j}\\)에 모두 dependent되어있다는 것이 특징이다. (그러나 아마 perfect reconstruction의 문제가 있는 듯) 그렇다면 어떻게 결정연산자를 디자인하는가? Irregularities는 함수의 derivative의 갑작스런 변화로 감지될 수 있는데, 예측의 순서를 바꾸었을 때 \\(s_{j+1,2k+1}\\)과 근처 \\(s\\)의 차이가 도움이 될 수 있을 것이라고 한다. "],
["29-2-reconstruction-of-adaptive-lifting-scheme.html", "29.2 적응적 리프팅 스킴의 재구성(reconstruction of adaptive lifting scheme)", " 29.2 적응적 리프팅 스킴의 재구성(reconstruction of adaptive lifting scheme) FIGURE 28.7: Reconstruction with a general adaptive lifting scheme. Data in both branches of the scheme contribute to the choices of prediction and update filters. 적응적 리프팅 스킴에서 recounstruction하는 문제는 그렇게 간단하지는 않다. 스킴에서 자동적으로 역변환이 얻어지는 경우는 정말 특별한 경우이다. 역변환에서는 결정연산자 \\(\\tilde{D}_{j}^{U}\\)와 \\(\\tilde{D}_{j}^{P}\\)를 사용하는데 이는 일반적으로 \\(D_{j}^{U}\\) 및 \\(D_{j}^{P}\\)와는 다른 것이다. 어떤 경우에 역반환은 keeping track of the choices made for prediction and/or update filters를 해야만 보자이 되는 경우도 있다. 이것은 한 가지 단점이다. 29.2.1 자동 완전 재구성(automatic perfect reconstruction) FIGURE 28.8: Perfect reconstruction without book-keeping is easily achived by letting the decision maps only depend on the input data of the corresponding prediction and update filters. "],
["29-3-locaat-.html", "29.3 LOCAAT 알고리즘", " 29.3 LOCAAT 알고리즘 리프팅 스킴에 기초하여, (M. Jansen, Nason, and Silverman 2009)은 lifting one coefficient at a time (LOCAAT)라는 산재된 자료를 다중해상도로 다룰 수 있는 새로운 패러다임을 제시했다. 이 방법은 말 그대로 한 step에 한 개의 상세계수만을 계산한다. 우리는 \\(n\\)개의 점 또는 장소에서도 \\(f_{i}=f(\\mathbf{t}_{i})\\)를 관찰한다. 이 함수는 \\[f(\\mathbf{t})=\\sum_{k=1}^{n}c_{nk}\\phi_{nk}(\\mathbf{t})\\] 로 근사할 수 있다. 여기서 \\(\\phi_{nk}\\)는 척도함수(scaling function)로 \\[\\phi_{nk}(\\mathbf{t}_{i})=\\delta_{ik}\\] 이며 여기서 \\(\\delta_{ik}\\)는 크로네커 델타이다. LOCAAT는 \\(n, n-1, n-2, \\ldots\\)의 순서로 진행된다. \\(r\\)번째 단계에서, \\(\\mathcal{S}_{r}\\)을 척도계수의 인덱스, \\(\\mathcal{D}_{r}\\)을 상세계수에서의 인덱스라고 하자. 그러면 LOCAAT는 처음에 \\(\\mathcal{S}_{n}=\\{ 1,2,\\ldots, n\\}\\), \\(\\mathcal{D}_{n}=\\emptyset\\)이다. \\(r\\)번째 단계에서, \\(\\mathcal{D}_{r}=\\{ i_{r+1}, i_{r+2}, \\ldots, i_{n}\\}\\)을 이미 찾은 상세계수들의 인덱스라고 하자. 첫 번째 제게되는 점이 집합의 마지막 원소임에 유의하자. \\(r\\)번째 단계에서 함수 \\(f\\)는 \\[f(\\mathbf{t})=\\sum_{l\\in\\mathcal{D}_{r}}d_{l}\\psi_{l}(\\mathcal{t})+\\sum_{k\\in\\mathcal{S}_{r}}c_{rk}\\phi_{rk}(\\mathcal{t})\\] 이다. 계수들 \\(d_{l}\\)과 \\(c_{rk}\\)들이 어떻게 계산되는지는 나중에 설명하기로 하자. 다음 단계는 \\(r-1\\)이며 제거되어야 하는 점을 \\(i_{r}\\)이라고 했을 때, \\(\\mathcal{S}_{r-1}=\\mathcal{S}_{r}\\backslash i_{r}\\), \\(\\mathcal{D}_{r-1}=\\mathcal{D}_{r}\\cup i_{r}\\)이다. 그러므로 웨이블릿 계수들이 얻어지는 순서는 \\(i_{n},i_{n-1},\\ldots, i_{r+1}\\)순이다. 제거되는 \\(i_{r}\\) 각각은 척도함수의 적분값의 size, 즉 가장 작은 적분을 갖는 척도함수를 먼저 제거하게 된다고 한다. 29.3.1 LOCAAT의 전방변환(forward transform in LOCAAT) 각 \\(i_{r}\\)에 대해 \\(n_{r}\\)개의 이웃이 존재하고 이들의 인덱스들은 \\(J_{r}\\)에 저장되어 있다고 하자. \\(c_{j}, j\\in J_{r}\\)은 \\(c_{i_{r}}\\)의 근사를 구성하기 위해 사용될 것이다. 제거될 점 \\(i_{r}\\) 각각은 길이 \\(|J_{r}|\\)인 두 벡터 \\(\\mathbf{a}^{i_{r}}, \\mathbf{b}^{i_{r}}\\)의 정의를 필요로 한다. (여기서 잠시 혼동을 막기 위해 \\(i_{r}\\)을 \\(i\\)로, \\(J_{r}\\)을 \\(J\\)로 표기하자. 그리고 \\(r\\)의 뜻은 다중해상도에서 \\(r\\)번째 단계라는 뜻이다.) Predict 상세계수 \\(d_{i}\\)는 제거될 점 \\(i\\)와 그 주변의 이웃들 \\(j\\in J\\)의 weighted sum과의 차이로 얻어진다. \\[\\begin{equation} d_{i}=c_{ri}-\\sum_{j\\in J}a_{j}c_{rj}. \\tag{28.2} \\end{equation}\\] 이 때 weight vector \\(\\mathbf{a}^{i}\\)는 어떤 리프팅 전략을 쓰느냐에 따라 달라진다. 이 말은 \\(i\\)와 \\(\\in J\\) 사이에 어떤 거리(ex. 유클리드 거리)를 정해놓고 이 거리가 클수록 weight를 적게 주는 것이다. \\[\\mathbf{a}^{i}=\\{ \\frac{1/\\text{dist}_{j}}{\\sum_{j\\in J}1/\\text{dist}_{j}}\\}, \\forall j\\in J.\\] 그리고(아마 당연하게도) \\(\\sum_{j\\in J} a_{j}=1\\)이다. Update 제거된 점 \\(i\\)에서 상셰계수를 얻은 후에 이웃들의 값은 다음과 값이 업데이트된다. \\[\\begin{equation} c_{rj}:=c_{rj}+d_{i}b_{j},\\forall j\\in J. \\tag{28.3} \\end{equation}\\] (이 때 \\(\\mathbf{b}^{i}\\)를 어떻게 정의할 지에 대해서는 생각해야 한다.) LOCAAT에서는 다음 레벨의 척도함수 계수는 다음과 같이 \\[c_{r-1,j}=c_{r,j},\\forall j \\in \\mathcal{S}_{r-1}\\] 로 쓸 수 있다. 예측 및 업데이트 단계는 재귀적으로 실행되며 더이상 제거할 점이 없을 때까지 진행한다. 예제에 따르면 웨이블릿 변환에 비해 sparsity는 좋지 않지만 fine scale에서 detail wavelet 계수들이 coarser scale에서의 detail wavelet coefficient들에 비에 덜 significant한 것들이 많음을 알 수 있다고 한다. 29.3.2 LOCAAT의 역변환(inverse transform in LOCAAT) 앞선 결과에 의해 \\[c_{rj}:=c_{rj}-d_{i}b_{j},\\] \\[c_{ri}:=d_{i}+\\sum_{j\\in J}a_{j}c_{rj}, j\\in J\\] 를 얻는다. 이 단계들은 역시 모든 \\(i\\in\\mathcal{D}_{r-1}\\)에 대해 재귀적으로 진행하여 완벽한 reconstruction을 얻는다. 29.3.3 LOCAAT의 예(example of LOCAAT) FIGURE 28.9: Toy network on which we assume the data [1,1,-1,-1] is observed. We also assume the nodes are separated by distance of 1 unit. 위 그림과 같이 \\(\\{1,1,-1,-1\\}\\)이라는 자료가 있다고 하자. LOCAAT 변환을 이 자료에 적용하려면 우선 네트워크를 디자인해야 한다. 1차원 자료기 때문에 위 그림과 같이 간단한 형태로 디자인하였다. 첫 번째로 제거되어야 할 점을 1번 노드라고 하자(참고로 어떤 점을 먼저 제거해야 할 지에 대한 논의는 (M. Jansen, Nason, and Silverman 2009)에 있다). 1번 노드의 이웃은 2번 노드밖에 없으며 inverse distance weight를 주었을 때 \\(a_{2}=1\\)이 된다. 그러면 식 ((28.2))에 넣어 \\(d_{2}=0\\)을 얻는다. 다음 단계는 척도계수를 업데이트 하는 것이다. 여기서는 2번 노드만 업데이트 하면 된다. LOCAAT 계수가 0이었기 때문에, ((28.3))에 의해 업데이트를 해도 2번 노드의 값은 변하지 않는다. 그러므로 결과적으로 첫번째 scale 후 다음 척도계수는 \\(c_{2}=\\{1,-1,-1\\}\\) 그리고 상세계수는 \\(d={0}\\)이 되는 것이다. 두 번째 scale에서는 \\(c_{2}=\\{1,-1,-1\\}\\)으로 시작한다. 여기서는 두 번째 제거되어야 할 점으로 4번 노드를 지정한다. 4번의 이웃 노드는 3밖에 없으므로 inverse distance weight가 \\(a_{3}=1\\)이 된다. 다시 ((28.2))을 사용해 LOCAAT coefficient \\(d_{4}=0\\)을 얻고, 3번 노드의 값을 ((28.3))을 이용해 업데이트한다. 두 번째 scale 후에는 \\(c_{1}=\\{ 1,-1 \\}\\)이 나오고 \\(d={0,0}\\)이 된다. 마지막 리프팅 스텝에서는 2번 노드를 제거하기로 하자. 여기서 주의해야 할 점은 2번 노드의 이웃은 3번 노드밖에 없다는 것이다. 왜냐하면 1번 노드는 앞선 스텝에 의해 제거되었기 때문이다. 그러면 ((28.2))에 의해 \\(d_{2}=2\\)이며 업데이트 스텝 ((28.3))을 거치고 나오는 척도계수는 \\(c_{0}=\\{0\\}\\)이 된다. 결과적으로 위 예제를 LOCAAT 분해하면 \\(c_{0}=\\{0\\}\\), \\(d=\\{ d_{2}, d_{4}, d_{1}\\}=\\{2,0,0\\}\\)이 된다. References "],
["29-4-variance-approximation.html", "29.4 Variance approximation", " 29.4 Variance approximation "],
["29-5-spatial-model.html", "29.5 Spatial model", " 29.5 Spatial model \\((k,j)\\)를 노드 \\(k\\)와 \\(j\\)의 엣지(edge)라고 하고 \\(\\delta_{kj}\\)를 노드 \\(k\\)와 \\(j\\)의 거리라고 하자. (M. Jansen, Nason, and Silverman 2009)는 tree-based network structure를 이용해 알고리즘으 구현하였다. 리프팅을 통해 제거할 때마다 minimum spanning tree (MST) 방법을 통해 트리를 업데이트한다. FIGURE 28.10: Simple network and its edge entries of spatial data. 위 그림은 일곱 개의 노드로 이루어진 공간 네트워크 예제이다. 각 노드 \\(k\\)마다 이웃의 수를 \\(n_{k}\\)로 놓는다. 각각의 노드는 다른 노드와 엣지를 통해 연결되어 있으며 점 \\(k\\)가 없어지면 같이 사라질 엣지들의 집합을 \\(J_{k}\\)라고 놓는다. (adjacency list) LOCAAT 알고리즘은 거리측도(distance measure)를 정해주어야 하는데, 여기서는 간단히 유클리드 거리 \\(\\delta_{kj}\\), 즉 \\[\\delta_{kj}=\\sqrt{(x_{k}-x_{j})^{2}+(y_{k}-y_{j})^{2}}\\] 를 고려한다. 여기서 \\((x_{k},y_{k})\\)는 노드 \\(k\\)의 좌표값이다. 여기서 관찰값에 대한 모델로는 \\[f_{k}=g_{k}+\\epsilon_{k}, k=1,\\ldots , n\\] 을 생각하며 \\(e_{k}\\)는 i.i.d 가우스 \\((0,\\sigma_{k}^{2})\\)을 따른다고 가정한다. 이것은 temporal correlation은 고려되지 않는 모형이다. References "],
["29-6-minimum-spanning-tree-mst-type-network.html", "29.6 Minimum spanning tree (MST) type network", " 29.6 Minimum spanning tree (MST) type network "],
["29-7-spatio-temporal-model.html", "29.7 Spatio-temporal model", " 29.7 Spatio-temporal model 시공간 모형은 temporal correlation 또한 고려하는 모형이다. 즉, \\[f_{t,k}=g_{t,k}=e_{t,k}, t=1,\\ldots, T, k=1,\\ldots , n,\\] 여기서 \\(f_{t,k}\\)는 노드 \\(k\\), 시간 \\(t\\)에서의 관찰값, \\(g_{t,k}\\)는 노드 \\(k\\), 시간 \\(t\\)에서의 알려지지 않은 진짜 함수이며 \\(e_{k}\\)는 i.i.d 가우스 \\((0,\\sigma^{2})\\)을 따른다고 가정한다. \\(T\\) 시간동안 데이터를 관찰한 것이다. 우리의 목표는 \\(g_{t,k}\\)를 (잘) 추정하는 것이다. 여기서 네트워크의 인덱싱을 세로 한다면 \\[\\mathcal{N}_{t}=\\{((t-1)n+k)| k \\in \\mathcal{N}_{1}\\}\\] 이라고 놓을 수 있다. 이와 같이 하면 전체 노드의 수는 \\(Tn\\)개가 된다. We consider distance along spatial dimension as Euclidean distance and the distance in the time dimension as the minimum distance in the spatial dimension multiplied by some temporal scale factor -&gt; 이것을 \\(l_{t}\\)라고 놓는다. 이 척도 factor는 시간 domain의 어떠한 irregularity라도 유지하기 위해서라고 한다. \\(\\delta^{min}\\)을 모든 노드에서의 최소 spatial edge distance, 즉 \\[\\delta^{min}=\\min \\{ (\\delta_{kj})_{j\\in J_{k}, k\\in \\mathcal{N}_{1}}\\}\\] 이라고 하자. 그리고 두 가지 경우의 시공간 네트워크를 고려하자. FIGURE 28.11: Two spatio-temporal network examples. 29.7.1 Case 1 첫번째 경우는 최초 시간에서의 엣지 구조가 시간이 지남에 따라 변하지 않고 계속 유지되는 경우다. FIGURE 28.12: Extending the spatial network to the spatio-temporal network. 이것은 위 그림과 같이 시간에 따라 순차적으로 계산함으로써 해결할 수 있다. 노드 \\((t-1)n+k\\)와 \\(tn+k\\)의 엣지 거리는 \\[\\delta_{(t-1)n+k,tn+k}=l_{t}\\delta^{min}\\] 으로 정의한다. 이웃 노드들의 집합은 다음과 같이 정의한다. \\[ J_{(t-1)n+k}= \\begin{cases} \\{ \\{ (j)_{j\\in J_{k}}\\} \\cup \\{ n+k \\} \\} &amp; \\text{if $t=1$}\\\\ \\{ \\{ ((t-1)n+j)_{j\\in J_{k}} \\} \\cup \\{ ((t-2)n+k) \\} \\cup \\{ (tn+k) \\} \\} &amp; \\text{if $1&lt;t&lt;T$}\\\\ \\{ \\{ ((t-1)n+j)_{j\\in J_{k}} \\} \\cup \\{ ((t-2)n+k) \\} \\} &amp; \\text{if $t=T$}. \\end{cases} \\] 29.7.2 Case 2 "],
["29-8-window-based-approach.html", "29.8 Window based approach", " 29.8 Window based approach 시공간 자료를 위 방법으로 분석시 모든 시간 point들을 함께 고려해야 하는데, 이것은 spatial-only method에 비해 일반적으로 좋은 결과를 가져오지는 못한다. 여기서는 시간축에 대한 윈도우 크기를 \\(M_{t}=3\\)으로 하여 실험을 하도록 한다. FIGURE 28.13: Window based approach. "],
["29-9-generalized-lifting-scheme.html", "29.9 일반화 리프팅 스킴(generalized lifting scheme)", " 29.9 일반화 리프팅 스킴(generalized lifting scheme) 다음은 일반화 리프팅 스킴의 흥미로운 특징들이다. 보는 관점에 따라 비선형 또는 적응적 필터를 사용하는 것으로 볼 수 있다. adaptive non-separable 2D 변환이 가능토록 한다. "],
["30-EMD.html", "Chapter 30 경험적 모드 분해", " Chapter 30 경험적 모드 분해 경험적 모드 분해(emprical mode decomposition, EMD)는 신호를 유한한 숫자의 기저함수들로 근사하고 싶을 때 사용할 수 있는 방법이다. 기존 방법으로는 Fourier-based spectral analysis, wavelet analysis 등이 있는데, 신호가 비정상적이고 nonlinear할때에는 잘 작동하지 않는다고 한다. (PCA 또한 empirical한 basis를 갖는다고 한다.) 시간에 따라 변하는 주파수는 Hilbert transform으로 정의할 수 있다고 한다. "],
["31-clustering.html", "Chapter 31 클러스터링 ", " Chapter 31 클러스터링 "],
["31-1-k-meodid-k-medoid-method.html", "31.1 k-meodid 방법(k-medoid method)", " 31.1 k-meodid 방법(k-medoid method) "],
["32-PCA.html", "Chapter 32 주성분분석", " Chapter 32 주성분분석 주성분분석(principal component analysis, PCA)란 차원 축소(dimension reduction)을 위해 많이 쓰이는 툴이다. 이 분야의 유명한 참고문헌으로는 (Jolliffe 2002)가 있다. 주성분분석은 차원 축소방법 중 변수를 직접적으로 변환하는 변수변환(feature transformation) 방법이다. 기상학에서는 empirical orthogonal functions라고 부른다. 여러 다변량 데이터셋이 갖는 문제들 중 하나는 변수가 너무 많다는 것이다. 너무 많은 변수들이 가질 수 있는 문제로는 차원의 저주(curse of dimensionality)가 알려져 있다. References "],
["32-1-curse-of-dimensionality.html", "32.1 차원의 저주(curse of dimensionality)", " 32.1 차원의 저주(curse of dimensionality) 이러한 문제로부터 데이터셋에 존재하는 원래의 변동(variation)을 가능한 한 많이 설명하면서 다변량 데이터의 차원을 줄이는 것을 주된 목적으로 하는 다변량 기법인 주성분분석이 만들어졌다. 이러한 목적은 원래 변수(original variable)들의 선형결합(linear combination) 형태로 새로운 변수 집합인 주성분(principal component)로 변환함으로써 얻을 수 있다. 주성분들은 서로 상관되지 않으며 순서화되어 처음 몇 개의 주성분이 원래 변수들의 변동(variation)을 대부분 설명하도록 한다. 주성분분석의 결과는 많은 원래 변수들의 대용(surrogate)으로서 사용될 수 있는 작은 개수의 새로운 변수를 만드는 것이다. "],
["32-2-basic-object-of-pca.html", "32.2 주성분분석의 기본 목적(basic object of PCA)", " 32.2 주성분분석의 기본 목적(basic object of PCA) 다음과 같이 \\(\\mathbf{x}_{i}\\in\\mathbb{R}^{d}, i=1,\\ldots, n\\)이라는 training pattern이 있다고 하자. 주성분은 \\(q &lt;d\\)의 직교정규 벡터의 집합이며 첫번째 주성분은 데이터를 한 개의 축으로 사상(projection)시켰을 때 그 분산이 가장 커지는 축이다. \\(\\mathbf{y}\\)를 subspace로의 projection이라고 하자. \\(\\mathbf{W}\\)를 column에 principal component를 포함하는 \\(d\\times q\\) 행렬이라고 하자. 그러면 \\[\\mathbf{y}=\\mathbf{W}^{T}\\mathbf{x}\\] 가 된다. 즉 \\(\\mathbf{y}\\)는 \\(\\mathbf{x}\\)의 dimension-reduced 표현이 되는 것이다. \\(\\hat{\\mathbf{x}}\\)를 \\(\\mathbf{y}\\)가 주어졌을 때 \\(\\mathbf{x}\\)의 reconstruction이라고 하자. \\[\\hat{\\mathbf{x}}=\\mathbf{W}^{T}\\mathbf{y}.\\] 그리면 PCA의 목표는 다음과 같은 \\[E_{rec}=\\frac{1}{n}\\sum_{i=1}^{n}\\| \\mathbf{x}_{i}-\\hat{\\mathbf{x}}_{i}\\|^{2}\\] \\(E_{rec}\\)을 minimize하도록 subspace를 set하는 것이다. "],
["32-3-population-principal-components.html", "32.3 모집단 주성분들(population principal components)", " 32.3 모집단 주성분들(population principal components) (Izenman 2009)를 참고하였다. 다음과 같은 무작위 \\(r\\)-벡터 \\[\\mathbf{X}=(X_{1},\\ldots, X_{t})^{T}\\] 가 평균이 \\(\\boldsymbol{\\mu}_{X}\\)이고 \\((r\\times r)\\) 공분산행렬 \\(\\boldsymbol{\\Sigma}_{XX}\\)를 갖는다고 가정하자. PCA는 \\(r\\)개의 correlated된 투입 변수들 \\(X_{1},\\ldots, X_{r}\\)로부터 \\(t (\\leq r)\\)개의 uncorrelated된 linear projection들 \\(\\xi_{1},\\ldots ,\\xi_{t}\\)을 얻고자 하는 것이다. 이 때, \\(\\xi_{j}\\)는 \\[\\begin{equation} \\xi_{j}=\\mathbf{b}_{j}^{T}\\mathbf{X}=b_{j1}X_{1}+\\ldots + b_{jr}X_{r},\\qquad{j=1,\\ldots , t} \\tag{32.1} \\end{equation}\\] 이다. 그리고 \\(\\xi\\)들을 정보를 최소화하는 방향으로 찾고자 한다. 이 식을 \\(\\mathbf{X}\\)의 처음 \\(t\\) principal components라고 알려져 있다. PCA에서 정보는 original input varible들의 total variation으로 설명할 수 있다. \\[\\sum_{j=1}^{r}\\text{var}(X_{j})=\\text{tr}(\\boldsymbol{\\Sigma}_{XX}).\\] 스펙트럼 분해 정리(1장 참조)에 의해 우리는 다음과 같이 쓸 수 있다. \\[\\boldsymbol{\\Sigma}_{XX}=\\mathbf{U}\\boldsymbol{\\Lambda}\\mathbf{U}^{T}, \\qquad{\\mathbf{U}^{T}\\mathbf{U}=\\mathbf{I}_{r}.}\\] 이 때 대각행렬 \\(\\boldsymbol{\\Lambda}\\)는 \\(\\boldsymbol{\\Sigma}\\)의 고유값들 \\(\\{\\lambda_{j}\\}\\)을 대각원소들로 갖는다. 그리고 \\(\\mathbf{U}\\)의 열들이 \\(\\boldsymbol{\\Sigma}_{XX}\\)의 고유치(eigenvector)가 된다. 그래서 총 variation은 \\(\\text{tr}(\\boldsymbol{\\Sigma}_{XX})=\\text{tr}(\\boldsymbol{\\Lambda})=\\sum_{j=1}^{r}\\lambda_{j}\\)가 된다. \\(j\\)번째 계수 벡터 \\(\\mathbf{b}_{j}=(b_{1j},\\ldots, b_{rj})^{T}\\)들은 다음과 같이 고른다. \\(\\mathbf{X}\\)의 처음 \\(t\\) 선형 사영 \\(\\xi_{j}, j=1,\\ldots, t\\)들은 그들의 분산 \\(\\{ \\text{var}\\{\\xi_{j} \\} \\}\\)들을 이용해 ${{1} } {{2} } {_{t} } $로 순위를 매겨 결정한다. \\(k&lt;j\\)일 경우 \\(\\xi_{j}\\)는 \\(\\xi_{k}\\)와 uncorrelated이다. PCA의 집합들을 유도하는 방법은 두 가지가 있다. Least-squares optimality criterion을 활용한다. Variance-maximizing technique을 활용한다. 32.3.1 최소제곱법으로 구하는 PCA \\(\\mathbf{B}=(\\mathbf{b}_{1},\\ldots, \\mathbf{b}_{t})^{T}\\)를 가중치의 \\((t\\times r)\\) \\((t\\leq r)\\) 행렬이라고 하자. 선형 사영식 (32.1)은 다음과 같이 \\(t\\)-벡터 \\[\\boldsymbol{\\xi}=\\mathbf{BX}\\] 로 쓸 수 있다. 여기서 \\(\\boldsymbol{\\xi}=(\\xi_{1},\\ldots , \\xi_{t})^{T}\\)이다. 우리는 \\(\\mathbf{X}\\approx\\boldsymbol{\\mu}+\\mathbf{A}\\boldsymbol{\\xi}\\)를 least-square 관점에서 만족시키는 \\(r\\)-벡터 \\(\\boldsymbol{\\mu}\\)와 \\((r\\times t)\\) 행렬 \\(\\mathbf{A}\\)를 찾고자 한다. 우리는 다음과 같은 최소자승 오차 조건 \\[\\begin{equation} E\\{ (\\mathbf{X}-\\boldsymbol{\\mu}-\\mathbf{A}\\boldsymbol{\\xi})^{T}(\\mathbf{X}-\\boldsymbol{\\mu}-\\mathbf{A}\\boldsymbol{\\xi}) \\} \\tag{32.2} \\end{equation}\\] 을 선형 사영 \\(\\boldsymbol{\\xi}\\)가 \\(\\mathbf{X}\\)를 얼마나 잘 재구성하는지에 대한 측도로 사용한다. 앞선 식 (32.2)을 \\(\\boldsymbol{\\xi}\\)를 \\(\\mathbf{BX}\\)로 바꿔 씀으로써 좀더 명백한 방법으로 표현할 수 있다. 그러면 평가기준은 \\((r\\times t)\\) 행렬 \\(\\mathbf{A}\\)와 \\((t\\times r)\\) 행렬 \\(\\mathbf{B}\\) (둘 다 full rank \\(t\\)를 갖는다), \\(r\\)-벡터 \\(\\boldsymbol{\\mu}\\)로 표현할 수 있다. \\[\\begin{equation} E\\{ (\\mathbf{X}-\\boldsymbol{\\mu}-\\mathbf{ABX})^{T}(\\mathbf{X}-\\boldsymbol{\\mu}-\\mathbf{ABX}) \\} \\tag{32.3} \\end{equation}\\] 만약 \\(t=1\\)일 경우 식 (32.3)는 최소자승 문제로 쓸 수 있다. \\[\\min_{\\boldsymbol{\\mu},\\mathbf{A},\\mathbf{B}}E\\sum_{j=1}^{r}(X_{j}-\\mu_{j}-a_{j1}\\mathbf{b}_{1}^{T}\\mathbf{X})^{2},\\] 여기서 \\(\\boldsymbol{\\mu}=(\\mu_{1},\\ldots, \\mu_{r})^{T}\\), \\(\\mathbf{A}=\\mathbf{a}_{1}=(a_{11},\\ldots, a_{r}1)^{T}\\), \\(\\mathbf{B}=\\mathbf{b}_{1}^{T}\\)이다. (최소화하는 방법 소개) 식 (32.3)는 reduced-rank rregression solution으로 최소화할 수 있고, 결과는 다음과 같다. \\[\\mathbf{A}^{(t)}=(\\mathbf{v}_{1},\\ldots, \\mathbf{v}_{t})=\\mathbf{B}^{(t)T},\\] \\[\\boldsymbol{\\mu}^{(t)}=(\\mathbf{I}_{r}-\\mathbf{A}^{(t)}\\mathbf{B}^{(t)})\\boldsymbol{\\mu}_{X},\\] 여기서 \\(\\mathbf{v}_{j}=\\mathbf{v}_{j}(\\boldsymbol{\\Sigma}_{XX})\\)는 \\(j\\)번째 큰 고유값에 대응되는 고유벡터들이다. 그러면 원래 자료의 가장 최고의 rank-\\(t\\) 근사는 다음과 같다. \\[\\hat{\\mathbf{X}}^{(t)}=\\boldsymbol{\\mu}^{(t)}+\\mathbf{C}^{(t)}\\mathbf{X}=\\boldsymbol{\\mu}_{X}+\\mathbf{C}^{(t)}(\\mathbf{X}-\\boldsymbol{\\mu}),\\] 여기서 \\[\\mathbf{C}^{(t)}=\\mathbf{A}^{(t)}\\mathbf{B}^{(t)}=\\sum_{j=1}^{t}\\mathbf{v}_{j}\\mathbf{v}_{j}^{T}\\] 는 rank \\(t\\) principal component case의 reduced-rank regression coefficient matrix이다. 식 (32.3)의 최소값은 \\(\\sum_{j=t+1}^{r}\\lambda_{j}\\)로 \\(\\boldsymbol{\\Sigma}_{XX}\\)의 가장 작은 \\(r-t\\) 고유값들의 합이 된다. 이러한 결과를 다음과 같이 생각하는 것이 도움이 될 수도 있다. \\(\\mathbf{V}=(\\mathbf{v}_{1},\\ldots, \\mathbf{v}_{r})\\)은 \\((r\\times r)\\) 행렬로 column들이 \\(\\boldsymbol{\\Sigma}_{XX}\\)의 ordered eigenvector들의 complete set을 만든다고 가정해보자. \\(\\mathbf{X}\\)의 가장 정밀한 rank-\\(t\\) 최소자승 reconstruction은 두개의 linear maps \\(L&#39;\\circ L\\)의 합성으로 얻을 수 있다. 첫 번째 맵 \\(L:\\mathbb{R}^{r} \\rightarrow \\mathbb{R}^{t}\\)는 \\(\\mathbf{V}\\)의 첫 \\(t\\) 개의 열들을 \\(\\mathbf{X}\\)의 \\(t\\) linear projection을 형성하는데 사용한다. 두 번째 맵 \\(L&#39;:\\mathbb{R}^{t}\\rightarrow \\mathbb{R}^{r}\\)은 같은 \\(\\mathbf{V}\\)의 첫 \\(t\\) 개의 열들을 \\(\\mathbf{X}\\)의 선형 재구성을 만드는 데 사용한다. \\(\\mathbf{X}\\)의 처음 \\(t\\) 주성분들은 (이것들을 또한 Karhunen-Lo\\(\\grave{e}\\)ve 변환으로 부르기도 함) \\(\\xi_{1},\\ldots, \\xi_{t}\\)의 선형 사영들로 주어지며, \\[\\xi_{j}=\\mathbf{v}_{k}^{T}\\mathbf{X}, \\qquad{j=1,\\ldots, t}\\] 이다. \\(\\xi_{i}\\)와 \\(\\xi_{j}\\) 사이의 공분산은 \\[\\text{cov}(\\xi_{i},\\xi_{j})=\\text{cov}(\\mathbf{v}_{i}^{T}\\mathbf{X}, \\mathbf{v}_{j}^{T}\\mathbf{X})=\\mathbf{v}_{i}^{T}\\boldsymbol{\\Sigma}_{XX}\\mathbf{v}_{j}=\\lambda_{j}\\mathbf{v}_{i}^{T}\\mathbf{v}_{j}=\\delta_{ij}\\lambda_{j}\\] 이고 \\(\\delta_{ij}\\)는 크로네커 델타이다. References "],
["32-4-pca-summary.html", "32.4 주성분 분석의 결과 정리(PCA summary)", " 32.4 주성분 분석의 결과 정리(PCA summary) 박창이 교수님 외 R을 이용한 데이터마이닝 책을 참고하였다. 주성분 분석의 간단한 결과 요약은 다음과 같다. 주성분은 원 변수들의 공분산행렬 또는 상관계수행렬의 고유벡터로부터 구해진다. 임의의 두 주성분간의 공분산은 항상 0이므로 주성분들 간에는 상관성이 존재하지 않는다. 원 자료의 변수들의 분산의 합은 주성분변수들의 분산의 합과 항상 일치한다. 주성분의 각 적재계수(loading coefficient)는 특정 변수가 주성분변수에 기여하는 정도를 나타낸다. "],
["32-5-principal-component-regression.html", "32.5 주성분 회귀분석(principal component regression)", " 32.5 주성분 회귀분석(principal component regression) (Jolliffe 2002)의 내용을 참고한다. 다음과 같은 standard 회귀모형이 있다고 하자. 즉 모형은 다음과 같다. \\[\\begin{equation} \\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon} \\tag{32.4} \\end{equation}\\] 이 때 \\(\\mathbf{y}\\)는 dependent variable의 평균에서 잰 \\(n\\)개 관찰값들의 벡터이고, \\(\\mathbf{X}\\)는 \\(n\\times p\\) predictor matrix, \\(\\boldsymbol{\\beta}\\)는 \\(p\\)개 회귀분석 계수들의 벡터, \\(\\boldsymbol{\\epsilon}\\)는 오차항들의 벡터이다. 이 때 \\(\\boldsymbol{\\epsilon}\\)의 원소들은 각각 독립이고, 분산은 \\(\\sigma^{2}\\)이다. 참고로 주성분 회귀분석에서는 자료들을 센터링(centering)하는 것이 좋다. FIGURE 32.1: 주성분분석에서 센터링을 해야 하는 이유. References "],
["32-6-pca-pca-for-multivariate-data.html", "32.6 다변량 자료에서의 PCA (PCA for multivariate data)", " 32.6 다변량 자료에서의 PCA (PCA for multivariate data) (Ramsay and Silverman 2005)의 8장을 참고하였다. 다변량 자료에서의 기초 컨셉은 다음과 같은 설명변수들의 선형 결합을 취하는 것이다. \\[f_{i}=\\sum_{j=1}^{p}\\beta_{j}x_{ij}, i=1,\\ldots, N.\\] 여기서 \\(\\beta_{j}\\)는 \\(j\\)번째 변수에 대한 \\(x_{ij}\\) 관련 가중 계수(weighting coefficient)이다. References "],
["32-7-pca-pca-for-functional-data.html", "32.7 함수자료에서의 PCA (PCA for functional data)", " 32.7 함수자료에서의 PCA (PCA for functional data) (Izenman 2009)에 있는 간단한 설명이다. 어떤 상황들에서는 우리는 함수나 또는 curve로 구성된 자료를 분석하려고 한다. 이러한 함수 자료는 종종 시간-의존적이지만 시간이 특별한 역할을 하지 않는다고 놓는다. 실제로, 다르고 독립적으로 얻어진 함수자료들은 다른 시간 point에서 기록될 것이므로 자료 자체가 equally spaced되지 않았을 가능성이 높다. 이런 경우에는 이산 점들에서 얻어진 자료들을 개별적인 함수 관찰값로 보는 것이 좋다. 함수 PCA에서는 각각의 관찰된 함수들이 같은 individual들의 반복된 관찰값이라고 본다. 그리고 우리는 그들을 가지고 함수의 main feature를 묘사하고자 한다. 이것을 할 수 있는 한 가지 방법은 functional PCA를 이용하는 것이다. 여기서는 각각의 값 대신 커브를 생각하기 때문에 벡터로 표시한 관찰값들 \\(\\mathbf{X}_{1},\\ldots , \\mathbf{X}_{n}\\)이 일변량 함수들 \\(X_{1}(t),\\ldots, X_{n}(t)\\)로 대체된다. 여기서 \\(t\\)는 일반적으로 시간을 의미하나 닫힌 구간 \\([0,T]\\)에서 연속인 어떤 값들로도 바뀔 수 있다. 함수적 PCA에서는 각 표본 커브들이 부드러운 평균함수 \\(E\\{X(t)\\}=\\mu(t)\\) 그리고 공분산 함수 \\[\\text{cov}\\{X(s),X(t)\\}=\\sigma(s,t)\\] 를 갖는 일변량 확률과정 \\(X(t)\\)의 독립적인 실현이라고 간주한다. 이것은 \\(X(t)\\)의 잘 알려진 Karhunen-Loeve expansion이다. 공분산 함수의 스펙트럼 분해를 통해 우리는 \\(\\sigma\\)를 고유값들 \\(\\{\\lambda_{j}\\}\\)와 그것에 대응되는 고유함수(eigenfunction)들 \\(\\{V_{j}(t)\\}\\)를 가지고 L2 관점에서 직교인 확장으로 표현할 수 있다. 즉 \\[\\sigma(s,t)=\\sum_{j=1}^{\\infty}\\lambda_{j}V_{j}(s)V_{j}(t)\\] 로 표현할 수 있다. 여기서 고유값들은 처음 몇 개들만을 제외하고는 빠르게 0으로 간다고 가정한다. 공분산 함수는 양정치이므로, 우리는 고유값들이 양수이며 \\(\\lambda_{1}\\geq \\lambda_{2} \\ldots \\geq 0\\)으로 정렬할 수 있다. 여기서의 목표는 \\(\\sigma(s,t)\\)에서 functional variation을 나타내는 처음 몇 개의 부분을 찾는 것으로, 고유치는 각각의 component들이 total variance를 얼마나 설명해주는지를 말해준다. 무작위 커브 \\(X(t)\\)는 다음과 같이 표현할 수 있다. \\[X(t)=\\mu(t) + \\sum_{j=1}^{\\infty}\\xi_{j}V_{j}(t).\\] 여기서 계수 \\(\\xi_{j}\\)는 다음과 같은 스칼라 확률변수이다.(j번째 functional PC score이다.) \\[\\begin{equation} \\xi_{j} =\\int [X(t)-\\mu(t)]V_{j}(t)dt. \\tag{32.5} \\end{equation}\\] 이 때 \\(E\\{xi_{j}\\}=0\\), \\(\\text{var}\\{\\xi_{j}\\}=\\lambda_{j}\\), \\(\\sum_{j}\\lambda_{j}&lt;\\infty\\) 그리고 \\(\\text{cov}\\{\\xi_{j},\\xi_{k}\\}=0,j\\neq k\\)이다. 고유함수들 \\(\\{V_{j}(t) \\}\\) (PC 함수라고도 부른다)은 다음을 만족한다. \\[\\int_{[0,T]} [V_{j}(t)]^{2}dt=1, \\qquad{\\int_{[0,T]} V_{j}(t)V_{k}(t)dt=0, j\\neq k. }\\] 여기서 적분은 \\([0,T]\\)에서 정의되며 periodic일 수 있다. 식 (32.5)은 \\(X(t)\\)에 대해 잘 알려진 Karhunen-Loeve expansion이다. 그래서 \\(X(t)-\\mu(t)\\)는 각각의 곡선들이 uncorrelated random amplitude를 갖는 직교 곡선들의 유한한 합으로 생각할 수 있다. 과학적으로는 함수 자료임이 알려졌다고 하더라도 실제로는 표본을 통해 유한한 양의 지식만을 알고 있다. 따라서 평균 곡선 \\(\\mu(t)\\)와 공분산 함수 \\(\\sigma\\)를 추정하는 것은 \\(n\\)개의 표본 곡선들의 collection들 \\(X_{1}(t),\\ldots, X_{n}(t)\\)로부터 기반한다. 이 때 \\(i\\)번째 곡선 \\(X_{i}(t)\\)는 \\(X_{i}(t)=\\mu(t)+\\sum_{j}\\xi_{ij}V_{j}(t)\\)이다. \\(i\\)번째 곡선의 \\(k\\)번째 점은 \\(X_{ik}=X_{i}(t_{k})\\)이다. 이러한 functional PCA를 적합하는 방법으로는 각각의 표본 곡선들을 spline이나 local-linear smoother로 부드럽게 만든 후 적합하게 되며 regularization을 사용하기도 한다. (Kokoszka and Reimherr 2017)에 따르면, 함수자료 PCA의 목적은 관찰된 자료 \\(X(t_{m})\\)을 추정 또는 예측된 주성분 점수 \\(\\{\\hat{\\xi}_{j} \\}\\) 또는 부드러운 경로로 대체하는 데에 그 목적이 있다. 또한 FPCA가 달성할 수 있는 것으로 다음의 네 가지를 적었다. irregular data are now on a “common scale” when working with scores, the scores are typically of a lower dimension (though not necessarily for very sparse data), the scores can be used in further multivariate statistical analyses, the scores and FPC’s can be used to reconstruct individual trajectories. 32.7.1 함수자료 PCA의 적합(estimation of functional PCA) (Ramsay and Silverman 2005) 책 8장에 FPCA에 대해 자세히 소개되어 있다. L2관점에서 fPCA를 하는 것은 eigneproblem을 푸는 것과 같다고 한다. FPCA를 하는 것에는 다음과 같은 방법들이 있다. Discretizing the functions: 가장 간단한 방법은 관찰된 함수 \\(x_{i}\\)을 이산화하는 것이다. equally spcaed grid point \\(t_{1},\\ldots , t_{m}\\)을 생각하고 covariance matrix \\(\\mathbf{V}^{*}\\)를 \\(\\mathbf{V}(t_{i},t_{j})\\)로 나타낸 다음 다변량 PCA를 \\(\\mathbf{V}^{*}\\)에 적합, smoothes PC를 얻기 위해 interpolation을 추가로 한다. 이를 이용하는 방법은 함수 prcomp로 할 수 있다. Basis expansion of the functions: \\(y_{i}(t)=\\sum_{j=1}^{K}c_{ij}\\phi_{k}(t)\\)라고 호자. \\(\\Phi\\)를 orthonormal basis의 집합이라고 하자. 그리고 \\(\\mathbf{C}\\)를 \\((n\\times K)\\) coefficient matrix라고 하자. 그러면 \\(\\mathbf{Y}=\\mathbf{C}\\Phi\\)이고 표본 공분산 행렬은 \\(\\mathbf{V}=\\frac{1}{n}\\Phi^{T}\\mathbf{C}^{T}\\mathbf{C}\\Phi\\)로 쓸 수 있다. 이를 이용하는 방법은 패키지 FDA에서 구현되어 있다. Smoothing the covariance kernel: 이 방법은 PACE 패키지에 구현되어있다. Regularized principal components References "],
["33-CCA.html", "Chapter 33 정준상관분석", " Chapter 33 정준상관분석 주성분분석은 변수 집합 내의 연관성을 고려한다. 그러나 연구자가 변수들의 두 개의 집합 사이의 관계를 평가하는 데 관심이 있을 수 있다. 예를 들면 한 지역 내의 \\(n\\)개의 장소 각각에서 식물의 산출량과 관련된 \\(q_{1}\\)개 변수(즉 키, 건조 중량, 잎의 개수)를 측정하였으며 동시에 그 지역의 날씨 상태와 관련된 \\(q_{2}\\)개 변수(즉 평균 일별 강수량, 습도, 일조시간)를 기록한 예이다. 따라서 전체 조사는 \\(n\\)개체에 대해 \\((q_{1}+q_{2})\\)개의 측정으로 구성되며 관심있는 문제는 수확량과 날씨 사이의 연관성 측정이다. 그러한 문제를 언급하는 한 가지 기법이 정준상관분석(canonical correlation analysis, CCA)이다. 이러한 분석으로부터의 결과에 대한 해석이 어렵기 때문에 비교적 덜 사용되는 측면이 있다. 정준상관분석을 보는 한 가지 방법은 다중 회귀분석의 확장인데, 왜냐하면 한 개의 변수(반응)가 여러 설명변수들과 관련되는 회귀 해가 반응과 가장 높게 상관된 설명변수들의 선형결합을 구하는 것이 다중 회귀분석의 목적이기 때문이다. 두 집합의 각각에 두 개 이상의 변수가 있는 정준상관분석에서는, 그 목적이 한 집합 내의 변수들의 선형함수와 최대로 상관된 다른 집합의 변수들의 선형함수를 발견하는 것이다. 요구되는 선형함수를 정의하는 계수의 추출은 주성분을 구하는 과정과 유사하다. 정준상관분석의 목적은 두 변수 집합 \\(\\mathbf{x}^{T}=(x_{1},\\ldots, x_{q})\\)와 \\(\\mathbf{y}^{T}=(y_{1},\\ldots, y_{q})\\) 사이에 독립으로 통계적 관계를 특징짓는 것이다. "],
["34-SSA.html", "Chapter 34 시간 변화도 분석", " Chapter 34 시간 변화도 분석 시계열분석에서 시간 변화도 분석(singular spectrum analysis, SSA)는 비모수 스펙트럼 추정 방법이다. 이 방법은 기존의 시계열분석과 다변량분석, 다변량기하학, 동역학계 및 신호처리 방법을 혼합한 것이다. SSA는 시계열을 component들의 sum으로 분해하는데 그 목적을 두는데, 의미있는 설명으로 가능하도록 의도한다. "],
["34-1-ssa-algorithms-and-methodology.html", "34.1 시간 변화도 분석 알고리즘과 방법론(SSA algorithms and methodology)", " 34.1 시간 변화도 분석 알고리즘과 방법론(SSA algorithms and methodology) 시간 변화도 분석의 목적을 다시 한 번 상기시키자면, 사전 정보 없이 관찰한 시계열 자료를 설명가능한 component들로 분해하는 것이다. 34.1.1 시간 변화도 분석 알고리즘 실수값을 갖는 길이 \\(N\\)인 시계열 \\(\\mathbf{x}_{N}\\)을 생각해보자. \\(L, 1&lt;L&lt;N\\)은 window length라 부르는 정수이며 \\(K=N-L+1\\)이다. (Decomposition step) (Reconstruction step) "],
["35-trees.html", "Chapter 35 의사결정나무", " Chapter 35 의사결정나무 이 장의 기본적인 설명은 박창이 교수님 외 R을 이용한 데이터마이닝 책을 참고하였다. 의사결정나무(decision tree)는 주어진 입력값에 대해 출력값을 예측하는 모형으로써 분류나무(classification trees)와 회귀나무(regression trees) 모형이 있다. 이 장에서는 회귀 의사결정나무에 중점을 두어 설명한다. "],
["35-1-construction-of-decision-trees.html", "35.1 의사결정나무의 형성(construction of decision trees)", " 35.1 의사결정나무의 형성(construction of decision trees) 의사결정나무의 형성과정은 크게 성장(growing), 가지치기(pruining), 타당성 평가, 해석 및 에측으로 이루어져 있다. 훈련자료를 \\((x_{i}, y_{i})\\)로 나타내자. \\(p \\in \\mathbb{N}_{+}\\)개의 설명변수가 있을 경우 \\(x_{i}=(x_{i1}, \\ldots, x_{ip})^{T}\\)이다. \\(\\mathcal{B}\\)를 \\(X\\)의 치역이라고 두자. 즉 \\(\\Omega \\rightarrow \\mathcal{B} \\subseteq \\mathbb{R}^{p}\\)이다. 이 전체의 영역 \\(\\mathbf{B}\\)를 \\(L\\)개의 부분공간 \\(R_{l}\\subseteq \\mathcal{B}\\)로 나누고 각 영역에서 상수값 \\(c_{l}\\)로 예측하는 다음과 같은 나무모형을 생각해 볼 수 있다. \\[f(x)=\\sum_{l=1}^{L}c_{l}I(x\\in R_{l}).\\] 이 때 우리는 \\(c_{l}\\)과 \\(R_{l}\\)의 값을 정해줘야 하는데, 불순도(impurity)라는 측도를 이용한다. 회귀나무에서는 흔히 오차제곱합 \\(Q_{l}(T)=\\sum_{i=1}^{n}(y_{i}-f(x_{i}))^{2}\\)을 그 측도로서 사용한다. 주어진 분리변수(split variable)가 \\(x_{j}\\)가 연속형인 경우 분리점을 \\(s\\)라 하면 두 영역 \\(R_{1}(j,s)=\\{ x: x_{j} \\leq s\\}\\)와 \\(R_{2}(j,s)=\\{ x: x_{j} &gt; s\\}\\)를 정의할 수 있다. 그러면 분리기준을 정하기 위해 다음 최적화 문제를 생각한다. \\[\\min_{j,s}(\\min_{c_{1}}\\sum_{x_{i}\\in R_{1}(j,s)}(y_{i}-c_{1})^{2} + \\min_{c_{2}}\\sum_{x_{i}\\in R_{2}(j,s)}(y_{i}-c_{2})^{2}).\\] 위 식에서 주어진 \\(j\\)와 \\(s\\)에 대해 최소값을 갖는 해는 \\(c_{1}\\), \\(x_{2}\\)로써 각기 \\(R_{1}(j,s)\\)와 \\(R_{2}(j,s)\\)에 속하는 자료의 \\(y_{i}\\)값들의 평균으로 주어진다. 35.1.1 가지치기(pruning) 너무 큰 나무모형은 자료를 과대적합하고 반대로 너무 작은 나무모형은 자료를 과소적합한다. 즉, 의사결정나무에서는 나무의 크기를 모형의 복잡도로 볼 수 있고 최적의 나무크기는 자료로부터 추정하게 된다. 일반적으로 사용되는 방법은 마디에 속하는 자료가 일정 수 이하일 때 분할을 정지하고 비용-복잡도 가지치기(cost-complexity pruning)을 이용하여 성장시킨 나무를 가지치기 하게 된다. "],
["35-2-random-forests.html", "35.2 랜덤 포레스트(random forests)", " 35.2 랜덤 포레스트(random forests) "],
["35-3-quantile-regression-forests.html", "35.3 분위수 회귀 포레스트(quantile regression forests)", " 35.3 분위수 회귀 포레스트(quantile regression forests) 분위수 회귀 포레스트는 (Meinshausen 2006)이 처음 발표했다. References "],
["35-4-generalized-random-forest.html", "35.4 일반화 랜덤 포레스트(generalized random forest)", " 35.4 일반화 랜덤 포레스트(generalized random forest) "],
["36-qr.html", "Chapter 36 분위수 회귀분석", " Chapter 36 분위수 회귀분석 모스텔러와 튜키는 다음과 같이 말했다. “회귀곡선은 \\(x\\)의 집합에 대응되는 분포의 평균에 대한 좋은 요약정보를 제공한다. 우리는 x의 집합에 대해 좀 더 정확한 정보를 제공하기 위해 평균 뿐 아니라 다양한 분위수에 대응되는 회귀곡선을 그려야 한다. 평균이 분포에 대해 불완전한 정보를 제공하는 것처럼, 회귀곡선 또한 분포들의 집합에 대해 불완전한 정보를 제공한다.” 분위수 회귀분석은 극단값 이론에 기반하는 것은 아니지만, 분위수를 조절함으로써 극단값 모델링을 할 수 있다. 이 장의 표기는 Roger Koenker의 강의노트를 따른다. "],
["36-1-quantile.html", "36.1 분위수 (quantile)", " 36.1 분위수 (quantile) Definition 36.1 (분위수) 실수값을 갖는 확률변수 \\(X\\)가 분포함수 \\(F\\)를 따른다고 할 때, \\(X\\)의 \\(\\tau\\)번째 분위수(quantile)는 \\[Q_{X}(\\tau)=F_{X}^{-1}(\\tau)=\\inf\\{x|F(x)\\geq \\tau\\}\\] 로 정의된다. FIGURE 36.1: Cummulative distribution function (left) and corresponding quantile plot (right). 참고로 \\(Q_{X}(\\tau)\\)는 감소하지 않는 함수이다. 즉 \\[Q_{X}(\\tau_{1}) \\leq Q_{X}(\\tau_{2}) \\qquad{ \\text{for } \\tau_{1} &lt; \\tau_{2}}\\] 이다. Definition 36.2 (조건부 분위수) \\(Y\\)를 반응변수, \\(\\mathbf{X}\\)를 \\(p\\)차원 예측변수라고 하자. 이 때 \\(\\mathbf{X}=\\mathbf{x}\\)로 주어졌을 때 \\(Y\\)의 조건부 누적분포함수는 \\(F_{Y}(y|\\mathbf{X}=\\mathbf{x})=P(Y\\leq y|\\mathbf{X}=\\mathbf{x})\\)라고 하자. 이 때 \\(Y\\)의 \\(\\tau\\)번째 조건부 분위수 (\\(\\tau\\)-th conditional quantile)는 \\[Q_{\\tau}(Y|\\mathbf{X}=\\mathbf{x})=\\inf\\{y:F_{Y}(y|\\mathbf{x})\\geq \\tau\\}\\] 로 정의된다. "],
["36-2-basics-of-quantile-regression.html", "36.2 분위수 회귀분석의 기초(basics of quantile regression)", " 36.2 분위수 회귀분석의 기초(basics of quantile regression) 36.2.1 선형 분위수 회귀분석(linear quantile regression) 분위수 회귀분석에서의 손실함수(loss function) \\(\\rho_{\\tau}(u)\\)를 다음과 같이 정의하자. \\[\\rho_{\\tau}(u)=u(\\tau -I(u&lt;0)).\\] 최소자승법으로 해를 구하는 일반적인 (평균에 관한) 회귀분석 모형을 생각해보자. \\[Y=\\mathbf{X}^{T}\\boldsymbol{\\beta}+U, E(U)=0.\\] 이 때 \\[E(Y|\\mathbf{X}=\\mathbf{x})=\\mathbf{x}^{T}\\boldsymbol{\\beta}\\] 이며 \\(\\boldsymbol{\\beta}\\)는 \\(\\mathbf{x}\\)의 주변 변화에 의한 \\(Y\\)의 평균의 주변 변화를 측정하는 역할을 한다. 이와 비슷하게 선형 분위수 회귀분석 모형(linear quantile regression model)은 \\[Q_{\\tau}(Y|\\mathbf{x})=\\mathbf{x}^{T}\\boldsymbol{\\beta}(\\tau), \\qquad{0&lt;\\tau &lt;1}\\] 이며 여기서 \\(\\boldsymbol{\\beta}(\\tau)=(\\beta_{1}(\\tau),\\ldots , \\beta_{p}(\\tau))^{T}\\)는 \\(\\tau\\)에 관련있는 분위수 계수(quantile coefficient)이다. 이 때 \\(\\mathbf{x}\\)의 첫 번째 원소가 절편에 대응된다고 하면 \\[Q_{\\tau}(Y|\\mathbf{x})=\\beta_{1}(\\tau)+x_{2}\\beta_{2}(\\tau)+\\ldots +x_{p}\\beta_{p}(\\tau)\\] 로 표현된다. \\(\\boldsymbol{\\beta}(\\tau)\\)는 \\(\\mathbf{x}\\)의 주변 변화에 의한 \\(\\tau\\)-분위수의 주변 변화를 측정하는 역할을 한다. 참고로 \\(Q_{\\tau}(Y|\\mathbf{x})\\)는 \\(\\mathbf{x}\\)가 주어졌을 때 \\(\\tau\\)에 대해 감소하지 않는 함수다. Example 36.1 (위치이동모델) 위치이동모델(location-scale shift model)은 다음과 같이 주어진다. \\[Y_{i}=\\alpha + \\mathbf{Z}_{i}^{T}\\boldsymbol{\\beta} + (1+\\mathbf{Z}_{i}^{T}\\boldsymbol{\\gamma})\\epsilon_{i}, \\qquad{\\epsilon_{i}\\stackrel{\\text{i.i.d}}{\\sim}F(\\cdot).}\\] 조건부 분위수 함수는 \\[Q_{\\tau}(Y|\\mathbf{X}_{i})=\\alpha(\\tau)+\\mathbf{Z}_{i}^{T}\\boldsymbol{\\beta}(\\tau)\\] 이다. 이 때 \\(\\alpha(\\tau)=\\alpha + F^{-1}(\\tau)\\): \\(\\tau\\)에 대한 감소하지 않는(nondecreasing) 함수 \\(\\boldsymbol{\\beta}(\\tau)=\\boldsymbol{\\beta}+\\boldsymbol{\\gamma}F^{-1}(\\tau)\\): \\(\\tau\\)에 의존할 수도 있는 함수. 즉 covariate들은 \\(Y\\)의 분포의 다양한 분위수에서 다른 효과를 줄 수도 있다. 만약 \\(\\boldsymbol{\\gamma}=0\\)일 때에는 \\(\\boldsymbol{\\beta}(\\tau)=\\boldsymbol{\\beta}\\)로 즉 quantile level에 따라 상수로 주어지는 모형이 된다. 36.2.2 분위수 처리 효과(quantile treatment effect) \\(X_{i}=0\\)은 control을, \\(X_{i}=1\\)은 treatment를 나타낸다고 하자. 그리고 control일 때와 treatment일 때의 조건부 분포를 다음과 같이 \\(Y_{i}|X_{i}=0\\sim F\\) (control distribution) \\(Y_{i}|X_{i}=1\\sim G\\) (treatment distribution) F, G로 둔다. 그러면 평균 처리 효과(mean treatment effect) \\(\\Delta\\)는 \\[\\Delta = E(Y_{i}|X_{i}=1) - E(Y_{i}|X_{i}=0)=\\int ydG(y) - \\int ydF(y)\\] 이고 분위수 처리 효과(quantile treatment effect) \\(\\delta(\\tau)\\)는 \\[\\delta(\\tau)=Q_{\\tau}(Y_{i}|X_{i}=1) -Q_{\\tau}(Y_{i}|X_{i}=0)=G^{-1}(\\tau)-F^{-1}(\\tau).\\] 따라서 평균 처리 효과와 분위수 처리 효과 사이의 관계는 다음과 같이 된다. \\[\\Delta=\\int_{0}^{1}G^{-1}(u)du - \\int_{0}^{1}F^{-1}(u)du = \\int_{0}^{1}\\delta(u)du.\\] 이에 대응되는 분위수 회귀 모델은 이변량 covariate를 갖는 모형으로 \\(\\delta(\\tau)\\)를 이용해 다음과 같이 쓸 수 있다. \\[Q_{\\tau}(Y|X)=\\alpha(\\tau)+\\delta(\\tau)X.\\] 세 가지 간단한 이동의 경우를 살펴본다. 위치 이동(location shift): \\(F(y)=G(y+\\delta) \\Rightarrow \\delta(\\tau)=\\Delta = \\delta\\). par(mfrow=c(1,2)) x &lt;- seq(-10,9,by=0.1) plot(x, dnorm(x), xlim=c(-7,7), type=&#39;l&#39;, xlab=&quot;y&quot;, ylab=&quot;Density&quot;) lines(x,dnorm(x,mean=2), lty=2, col=&quot;red&quot;) plot(seq(0.01, 0.99, 0.01), qnorm(p=seq(0.01, 0.99, 0.01),mean=2)- qnorm(p=seq(0.01, 0.99, 0.01),mean=0), xlim=c(0,1),ylim=c(1.9,2.1), type=&#39;l&#39;, xlab=expression(tau), ylab=expression(delta(tau))) FIGURE 36.2: Location shift model. 척도 이동(scale shift): \\(\\Delta = \\delta(0.5)=0\\)이지만 다른 분위수들에서는 \\(\\delta(\\tau)\\neq 0\\)이다. par(mfrow=c(1,2)) x &lt;- seq(-10,9,by=0.1) plot(x, dnorm(x), xlim=c(-7,7), type=&#39;l&#39;, xlab=&quot;y&quot;, ylab=&quot;Density&quot;) lines(x,dnorm(x,mean=0, sd=1.5), lty=2, col=&quot;red&quot;) plot(seq(0.01, 0.99, 0.01), qnorm(p=seq(0.01, 0.99, 0.01),mean=0,sd=1.5)- qnorm(p=seq(0.01, 0.99, 0.01),mean=0), xlim=c(0,1),ylim=c(-1.25,1.25), type=&#39;l&#39;, xlab=expression(tau), ylab=expression(delta(tau))) abline(h=0, col=&quot;blue&quot;, lty=2) FIGURE 36.3: Scale shift model. 위치-척도 이동(location-scale shift) par(mfrow=c(1,2)) x &lt;- seq(-10,9,by=0.1) plot(x, dnorm(x), xlim=c(-7,7), type=&#39;l&#39;, xlab=&quot;y&quot;, ylab=&quot;Density&quot;) lines(x,dnorm(x,mean=1, sd=1.5), lty=2, col=&quot;red&quot;) plot(seq(0.01, 0.99, 0.01), qnorm(p=seq(0.01, 0.99, 0.01),mean=1,sd=1.5)- qnorm(p=seq(0.01, 0.99, 0.01),mean=0), xlim=c(0,1),ylim=c(-0.25,2.25), type=&#39;l&#39;, xlab=expression(tau), ylab=expression(delta(tau))) abline(h=0, col=&quot;blue&quot;, lty=2) FIGURE 36.4: Location-scale shift model. 36.2.3 분위수 회귀분석의 장점들(advantages of quantile regression) 그렇다면 우리는 왜 분위수 회귀분석을 쓰는가? Xuming He는 강의노트에서 세 가지 이유를 들었다. 분위수 회귀분석은 반응함수의 각기 다른 분위수에서의 predictor의 영향력을 공부할 수 있게 해주고 \\(Y\\)와 \\(\\mathbf{X}\\) 사이의 관계를 완벽히 보여준다. \\(y\\)값에 이상치가 있을 때 로버스트하다. 분포에 자유롭게(distribution-free) 추정과 추론을 할 수 있다. 36.2.4 분위수와 분위수 회귀분석의 다른 성질들(other properties of quantiles and quantile regression) Basic equivariance properties: \\(A\\)를 \\(p\\times p\\) nonsigular matrix라고 하고 \\(\\boldsymbol{\\gamma}\\in\\mathbb{R}^{p}\\), \\(a&gt;0\\)은 상수라고 두자. \\(\\hat{\\boldsymbol{\\beta}}(\\tau;y,\\mathbf{X})\\)를 관찰값들 \\((y,\\mathbf{X})\\)에 기반한 \\(\\tau\\)-th 분위수 회귀분석의 추정량이라고 하자. 그러면 어떤 \\(\\tau\\in [0,1]\\)에 대해 \\(\\hat{\\boldsymbol{\\beta}}(\\tau; ay, \\mathbf{X})=a\\hat{\\boldsymbol{\\beta}}(\\tau;y,\\mathbf{X})\\) \\(\\hat{\\boldsymbol{\\beta}}(\\tau; -ay, \\mathbf{X})=-a\\hat{\\boldsymbol{\\beta}}(1-\\tau;y,\\mathbf{X})\\) \\(\\hat{\\boldsymbol{\\beta}}(\\tau;y+\\mathbf{X}\\gamma, \\mathbf{X})=\\hat{\\boldsymbol{\\beta}}(\\tau, y, \\mathbf{X})+\\gamma\\) \\(\\hat{\\boldsymbol{\\beta}}(\\tau;y,\\mathbf{X}A)=A^{-1}\\hat{\\boldsymbol{\\beta}}(\\tau;y,\\mathbf{X})\\). Equivariance property: 분위수는 monotone transformation에 대해 equivariant하다. \\(h(\\cdot)\\)이 \\(\\mathbb{R}\\)에서 증가함수라고 가정하자. 그러면 임의의 변수 \\(Y\\)에 대해 \\[Q_{h(Y)}(\\tau)=h\\{ Q_{\\tau}(Y) \\}\\] 이다. 즉 변환된 확률변수 \\(h(Y)\\)의 분위수는 단순히 오리지날 스케일에서의 분위수를 변환시킨 것이라는 뜻이다. Interpolation: 선형 분위수 회귀분석은 \\(p\\) observation들을 interpolate한다. 만약 design matrix의 첫 번째 열이 intercept에 대응된다면 대략 \\(p\\) zero, \\(n\\tau\\) negative, 그리고 \\(n(1-\\tau)\\) positive residual들 \\(y_{i}-\\mathbf{x}_{i}^{T}\\hat{\\boldsymbol{\\beta}}(\\tau)\\)가 존재한다. "],
["37-functionestimation.html", "Chapter 37 함수추정 ", " Chapter 37 함수추정 "],
["37-1-how-to-specify-basis-systems-for-building-functions.html", "37.1 함수를 만들 때 기저시스템을 어떻게 특정할 것인가(how to specify basis systems for building functions)", " 37.1 함수를 만들 때 기저시스템을 어떻게 특정할 것인가(how to specify basis systems for building functions) 우리는 어떤 함수 \\(x(t)\\)를 기저함수들(functional building blocks) \\(\\phi_{k}\\)들의 선형 결합으로 표현할 수 있다. 이를 basis function expansion이라고 부른다. \\[x(t)=\\sum_{k=1}^{K}c_{k}\\phi_{k}(t)=\\mathbf{c}&#39;\\phi(t).\\] 여기서 \\(c_{1},\\ldots, c_{K}\\)를 확장의 계수(coefficient)라고 부른다. 이 때 \\(\\phi\\)는 \\(K\\)개의 기저함수들을 갖고 있다. 만약 우리가 \\(N\\)개의 함수 표본을 갖고 있다면 위의 행렬 표현은 \\[\\mathbf{x}(t)=\\mathbf{C}\\phi(t)\\] 가 된다. 이 때 \\(\\mathbf{x}(t)\\)는 \\(x_{i}(t)\\)를 갖고있는 길이 \\(N\\)인 벡터고, 계수 행렬 \\(\\mathbf{C}\\)는 \\((N\\times K)\\) 행렬이다. 다항함수 기저(polynomial basis): 기속도 등을 모델링할 때 좋으나 함수 모양이 복잡할 경우 그 쓰임새가 제한된다. 스플라인 기저(splines basis) 푸리에 수열 기저(Fourier series basis) "],
["37-2-function-on-function-regression.html", "37.2 함수-함수 회귀분석(function-on-function regression)", " 37.2 함수-함수 회귀분석(function-on-function regression) 함수 다발과 함수 다발 사이에 회귀분석을 하는 것이다. "],
["38-spatial.html", "Chapter 38 공간통계학", " Chapter 38 공간통계학 이 장에서는 공간통계학과 관련된 내용을 다룬다. 주된 내용은 2015년 공간통계학 특강 수업 내용이다. 지도 그리기와 같은 작업을 R로 하는데 다음 튜토리얼 을 이용하면 좋을 것이다. "],
["38-1-classes-of-spatial-data.html", "38.1 공간자료의 종류(classes of spatial data)", " 38.1 공간자료의 종류(classes of spatial data) 결과적으로 공간 자료의 종류는 크게 세 가지로 나눌 수 있다. 연속자료(continuous data; 이것을 다루는 분야가 geostatistics) 이산자료(discrete data, lattice data, areal data) 점 패턴 데이터(point pattern data) Elevation data Davis (1972)는 geoR이라는 R 패키지를 만들었다. 이 안에 있는 자료 elevation은 52개 지역의 표면 높이(surface elevation)를 측정한 자료이다. 기본 distance unit은 50 feet이며, 높이의 기본 distance unit은 10 feet이다. 이러한 자료를 plot하기 위해서는 geodata로 바꿔줘야 한다. Rongelape Island data Diggle et al. (1998)이 만든 R geoRglm 패키지의 롱겔라프 환초 자료(Rongelape Island data, rongelap)은 1954년 미국이 수소탄 실험을 한 곳의 방사능을 측정한 자료이다. 이 자료는 공간 이산 자료(spatial discrete data)의 예이다. 이 자료는 다른 자료들과 달리 sampling design이 되어있는 자료이다. 즉 자료를 200m마다 하나씩 일정하게 뽑은 것이다. 추가로 4개의 지역에 대해서는 50m마다 subsampling을 하였다. 200m마다 측정한 자료로는 200m보다 작은 variation을 구할 수 없다. 그래서 microscale variation을 보기 위해 추가로 subsampling을 한 것이다. Scottish lip cancer data 다음 자료는 1975-1980 동안 스코틀랜드 지역 남성의 lip cancer case 숫자를 county별로 센 scotland 자료이다. 이 자료는 SpatialEpi 패키지에 있다. 이 자료는 spatial dependency가 clear해서 많이 쓰인다고 한다. 이 자료는 앞 자료들과 달리 point 자료가 아닌 지역별 자료이다. 이런 자료를 공간 집적 자료(areal aggregation data)라고 한다. 이런 경우의 자료 분석은 first neighbor, second neighbor에 어떤 자료가 있는지 살펴보는 것을 많이 한다. Inventory data of the Zurichberg Forest, Switzerland 이 자료는 spBayes에 있는 취리히 숲 자재 자료(Zurichberg forest inventory data, Zurich.dat)이다. 이 자료의 특징은 숲이 어디 생길지 모르기 때문에 위치 자체가 random이 된다는 것이다. 앞선 자료들의 위치가 고정되어 있었던 것과는 다른 상황이다. 나무의 size를 잴 때에는 사람 가슴 정도 높이의 trunk를 잰다고 한다. 산림학에서의 관심사는 나무와 나무 사이의 상호작용(interaction)이 있는지 보는 것이다. 나무의 종류에 따라 같이 자랄 수도 있고, 또는 한 나무만 살아남을 수도 있는데 이러한 현상에 관심을 갖는 것이다. Location 자체가 random인 자료들은 point process로 모델링한다. 여기서 \\[\\mathbf{x}=(x_{1}, \\cdots , x_{n})\\] 이라고 하면 \\(\\mathbf{x}\\)와 \\(n\\)이 모두 random이다. 또 mark라고 추가정보가 들어올 수도 있다고 한다. \\[M|\\mathbf{x}=(m_{x_{1}}, \\cdots , m_{x_{n}}).\\] "],
["39-spatialprocess.html", "Chapter 39 공간과정", " Chapter 39 공간과정 연속자료의 공간과정(spatial process)은 다음과 같이 나타낸다. \\[\\{Z (\\mathbf{s}), \\mathbf{s} \\in \\mathcal{D} \\subset \\mathbb{R}^{d} \\} .\\] 여기서 \\(\\mathbf{s}\\)는 위치(location)이며 \\(d\\)차원 자료이다. \\(d\\)는 2차원일 수도 있고 고도를 고려하면 3차원일 수도 있다. \\(Z(\\mathbf{s})\\)는 \\(\\mathbf{s}\\)에서의 확률변수를 나타낸다. 비슷한 방식으로 시공간 과정(또는 무작위장)을 정의할 수 있다. \\[\\{Z(\\mathbf{s},t), \\mathbf{s} \\in \\mathcal{D} \\subset \\mathbb{R}^{d}, t\\in\\mathbb{R}\\}.\\] 만약 이산자료라면 \\[\\{Z (\\mathbf{s}), \\mathbf{s} \\in \\mathcal{D} \\subset \\mathbb{Z}^{d} \\} \\] 로 바뀐다. 점 패턴 자료의 경우에는 굳이 표현하자면 \\[\\{ (\\mathbf{s}_{1},z(\\mathbf{s}_{1})), \\cdots , (\\mathbf{s}_{n},z(\\mathbf{s}_{n})) \\} \\] 으로 쓸 수 있으며 이 때 \\(s\\), \\(Z\\), \\(n\\) 모두 무작위라고 한다. 다음은 \\(Z(\\mathbf{s})\\)의 평균과 분산을 생각해보자. \\[\\text{mean function}:\\mu(\\mathbf{s})=E(z(\\mathbf{s}))\\] \\[\\text{covariance function}: C(\\mathbf{s}_{1},\\mathbf{s}_{2})=E(Z(\\mathbf{s}_{1}-\\mu(\\mathbf{s}_{1})))(Z(\\mathbf{s}_{2}-\\mu(\\mathbf{s}_{2}))).\\] 우리의 관심사는 \\(C(\\mathbf{s}_{1},\\mathbf{s}_{2})\\)이다(공간 변화 모델링, spatial variation modeling). 이것은 때때로 자기공분산(autocovariance)이라 불리우는데 만약 표본이 1이면 자기자신의 공분산이 되기 때문이다. 그렇다면 우리는 왜 이러한 공간 변화(sptaial variation)를 고려해야 하는가? 간단한 회귀분석의 예를 들면 \\[\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}, \\qquad{\\epsilon_{i} \\sim (0, \\sigma^{2}\\Sigma_{0})}\\] 으로 식을 쓸 수 있다. 그런데 여기서 오차항을 \\(\\epsilon_{i} \\stackrel{\\text{iid}}{\\sim} (0, \\sigma^{2})\\)이라고 놓고 모델링을 하면 일치성(consistency)은 만족하나 효율성(efficiency)이 깨지는 결과를 얻는다. 즉 추론(inference)를 하기 위해서 변동(variability)을 구할 때 이것이 커지므로 신뢰구간(confidence interval)도 커지고 부정확한 검정(test) 결과를 주는 것이다. "],
["39-1-stationary-in-spatial-data.html", "39.1 공간자료의 정상성(stationary in spatial data)", " 39.1 공간자료의 정상성(stationary in spatial data) 그렇다면 우리는 왜 정상성(stationary)을 고려하는가? 그 이유는 정상성이 아니면 점근(asymptotic) 결과가 거의 없어 모델링하기 어렵기 때문이다. 이론적 배경을 얘기해 줄 때 정상성이 필요한 것이다. 여기서는 세 가지 정상성 개념이 등장한다. 39.1.1 순정상성(strictly stationary) 이것은 \\[(Z(\\mathbf{s}_{1}), \\cdots , Z(\\mathbf{s}_{k})) \\stackrel{\\mathcal{D}}{=} (Z(\\mathbf{s}_{1}+\\mathbf{h}), \\cdots , Z(\\mathbf{s}_{k}+\\mathbf{h}))\\] 으로 \\(\\mathbf{h}\\)만큼 장소가 변해도 분포가 동일하다는 것이다. 즉 확률분포가 전이 불변(translation invariant)라는 것이다. 또한 \\(\\mathbf{s}_{1}, \\cdots , \\mathbf{s}_{k}, \\mathbf{s}_{1}+\\mathbf{h}, \\cdots , \\mathbf{s}_{k}+\\mathbf{h} \\in \\mathcal{D}\\) 라는 가정이 필요하다. 39.1.2 약정상성(second order stationary, weakly stationary) 이것은 \\[\\mu(\\mathbf{s})=\\mu \\text{ (mean function이 상수)}\\] \\[C(\\mathbf{s}_{1},\\mathbf{s}_{2})=C_{0}(\\mathbf{s}_{1}-\\mathbf{s}_{2})\\] 두 가지 조건을 만족하는 것이다. 두 번째 조건은 covariance function이 distribution에 depend하는 어떤 함수 \\(C_{0}\\)로 표현된다는 것이다. \\(C \\in \\mathbb{R}^{d}\\times \\mathbb{R}^{d}\\), \\(C_{0} \\in \\mathbb{R}^{d}\\)라는 점에서 두 함수는 다른 함수이다. 이 조건은 공분산이 전이 불변이라는 것이다. 이것을 만족하는 예는 가우스 과정(Gaussian process, GP), 가우스 임의장(Gaussian random field, GRF)이 있다. 보통 \\(\\mathbf{s}\\)가 1차원이면 주로 과정(process), 2차원이면 주로 장(field)이라고 부른다. 39.1.3 내재정상성(intrinsic stationary) 이것은 차이(difference)를 가지고 정의한다. \\[E(Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s}))=0, \\forall \\mathbf{h}\\] \\[\\text{Var}(Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s}))=2\\gamma(\\mathbf{h}), \\forall \\mathbf{h}\\] 여기서 \\(2\\gamma(\\mathbf{h})\\)를 변동도(variogram), \\(\\gamma(\\mathbf{h})\\)를 준변동도(semivariogram)라고 한다. "],
["39-2-relationship-between-stationarity.html", "39.2 정상성들 사이의 관계(relationship between stationarity)", " 39.2 정상성들 사이의 관계(relationship between stationarity) 일반적으로 순정상성이 가장 강한 조건이며 그 다음이 약정상성, 내재정상성이 가장 약한 조건을 가진다. 그러나 특별한 경우에는 역방향도 성립할 수 있다. 39.2.1 순정상성과 약정상성간의 관계(relationship between strong and weak stationary) \\(C(\\mathbf{h})=\\text{Cov}(Z(\\mathbf{s}+\\mathbf{h}), Z(\\mathbf{h}))\\)일 때, \\(C(\\mathbf{s},\\mathbf{s}) &lt; \\infty\\)인 경우에는 순정상성이면 무조건 약정상성이 된다. 한편 가우스 과정이나 가우스 임의장인 경우는 처음 두 적률(moment)만 알면 모든 정보를 알 수 있어 약정상성이면 순정상성 또한 성립한다고 한다(우리가 가우스 과정이나 가우스 임의장을 많이 쓰는 이유이기도 하다). 39.2.2 약정상성와 내재정상성간의 관계(relationship between weak and intrinsic stationary) \\[2\\gamma(\\mathbf{h})=2(C(\\mathbf{0})-c(\\mathbf{h}))\\] 관계식을 살펴보면, \\(C\\)가 주어지면 \\(\\gamma\\)를 정의할 수 있다. 그렇다는 얘기는 약정상성이면 내재정상성도 된다는 것이다. 그러나 \\(\\gamma(\\mathbf{h})\\)만 알 경우 \\(C(\\mathbf{0})\\)과 \\(C(\\mathbf{h})\\)를 동시에 specify하지 못한다. 일반적으로 \\(\\lim_{\\mathbf{h}\\rightarrow \\infty}\\gamma(\\mathbf{h})=C(\\mathbf{0})\\)로 정의하여 \\(C(\\mathbf{0})\\)과 \\(C(\\mathbf{h})\\)를 정의한다. 이 말인즉 거리가 멀면 \\(C(\\mathbf{h})\\)는 \\(\\mathbf{0}\\)이 될 것이라고 생각하는 것이다. 39.2.3 내재정상성이나 약정상성이 안 되는 예(counterexample of intrinsic stationary but not weak stationary) 내재정상성이나 약정상성이 안 되는 경우의 예로는 브라운 운동(Brownian motion)이 있다. 브라운 운동 \\(B(t)\\)는 어떤 과정(process)이며 \\(B(t)=0\\) when \\(t=0\\), \\(B(t)\\)는 almost surely continuous \\(B(t)\\) has independent increments with \\(B(t)-B(s) \\sim \\mathcal{N}(0,\\sigma^{2}(t-s)), t&gt;s\\) 를 만족시킨다고 한다. 이 때 \\(\\sigma^{2}\\)을 확산계수(diffusion coefficient)라고 한다. 편의상 1차원에서 생각하자. 그러면 \\(E(B(t+h)-B(t))=0\\), \\(\\text{Var}(B(t+h)-B(t))=2|h|\\)이므로 내재정상성이다. 그러나 \\(h &lt; 0\\)인 경우에 공분산을 계산하면 \\[\\begin{eqnarray} \\text{Cov}(B(t+h),B(t)) &amp;=&amp; E(B(t+h)B(t))\\nonumber\\\\ &amp;=&amp;E[B(t+h)\\{B(t)-B(t+h)+B(t+h)\\}]\\nonumber\\\\ &amp;=&amp;E[B^{2}(t+h)]+E[B(t+h)]E[B(t)-B(t+h)]\\nonumber\\\\ &amp;=&amp;\\sigma^{2}(t+h)+0=\\sigma^{2}(t+h). \\end{eqnarray}\\] 가 된다. 같은 방법으로 \\(h &gt; 0\\)인 경우도 증명할 수 있으며 결국 \\(Cov(B(t+h),B(t))=\\min (t+h,t)\\)가 된다. 이는 \\(h\\)의 함수가 아니고 차이로 표현 못한다는 뜻이므로 약정상성이 아니다. "],
["39-3-ergodic-process.html", "39.3 에르고딕 과정(ergodic process)", " 39.3 에르고딕 과정(ergodic process) \\[\\lim_{\\|\\mathbf{h}\\| \\rightarrow \\infty}C(\\mathbf{h}) \\rightarrow \\mathbf{0}\\] 인 과정(process)을 에르고딕 과정(ergodic process)이라고 한다. 이 성질은 충분히 긴 (정상상태)과정에서 앙상블평균(통계적평균)과 시간평균이 같다는 것이다. \\[\\bar{Z}_{n}:\\frac{1}{n}\\sum_{i=1}^{n}Z(t_{i}) \\rightarrow \\mu .\\] “앙상블 평균은 시간을 고정시켜 놓고 표본 함수를 무한 개로 하여 계산한 것이고 시간평균은 표본 함수를 고정시켜 놓고 시간을 무한대로 하여 계산한 것이다.” "],
["39-4-second-order-process.html", "39.4 2차 과정(second-order process)", " 39.4 2차 과정(second-order process) 여기서부터는 (Gaetan and Guyon 2009)를 따른다. Definition 39.1 (2차 과정) \\(S\\)를 set of site라고 하자. 그러면 모든 \\(s\\in S\\)에 대해 \\(E(X_{s})^{2}&lt;\\infty\\)인 확률변수 \\(X=\\{X_{s}, s\\in S\\}\\)를 2차 과정(second-order process)라구 한다. \\(X\\)의 평균은 \\(m:S\\rightarrow \\mathbb{R}\\)인 함수이며 \\(m(s)=E(X_{s})\\)이고, \\(X\\)의 공분산은 모든 \\(s,t\\)에 대해 \\(c: S\\times S \\rightarrow \\mathbb{R}\\)이며 \\(c(s,t)=Cov(X_{s},X_{t})\\)라고 쓴다. \\(X\\in L^{2}\\)는 \\(X\\)가 2차 과정이라는 뜻이다. References "],
["39-5-gaussian-process.html", "39.5 가우스 과정(Gaussian process)", " 39.5 가우스 과정(Gaussian process) 가우스 과정은 \\(L^{2}\\) 과정의 중요한 class이다. Definition 39.2 (가우스 과정) 모든 유한한 부분집합 \\(\\Lambda \\subset S\\)와 실수값을 갖는 수열 \\(a=(a_{s}, s\\in\\Lambda)\\)에 대해 \\(\\sum_{s\\in\\Lambda}a_{s}X_{s}\\)가 가우스 확률변수인 경우 \\(X\\)가 \\(S\\)에서의 가우스 과정이라고 한다. 가장 대표적인 가우스 과정이 브라운 운동(brownian motion)이다. "],
["40-covfct.html", "Chapter 40 공분산함수", " Chapter 40 공분산함수 공분산함수(covariance function) \\(C(\\mathbf{h})\\)는 \\[C(\\mathbf{h})=\\text{Cov}(Z(\\mathbf{s}+\\mathbf{h}), (Z(\\mathbf{s}), \\qquad{C(\\cdot); \\mathbb{R}^{d} \\rightarrow \\mathbb{R}}\\] 이다. 우리가 공분산함수를 고려할 때 생각해 볼 점은 공분산함수가 되기 위한 조건은 무엇이냐는 것이다. 공분산함수가 되려면 그 함수가 양정치함수(positive definite function)이어야 한다. 이것은 대응되는 행렬이 비음정치(non-negative definite) 또는 양반정치(positive semi-definite)이어야 한다는 것이다. 함수가 순양정치함수(strictly positive definite function)이어야 한다는 것은 대응되는 행렬이 양정치(positive definite)이어야 한다는 것이다. 그러나 저 둘을 보이는 것은 모든 유한한 표본에 대해 항상 성립해야 하는 것을 보여야하기 때문에 어렵다. 이를 좀 더 쉽게 보일 수 있는 방법으로 Bochner (1933, 1955)의 정리를 이용하는 것이다. "],
["40-1-spectral-representation-theorem.html", "40.1 스펙트럴 표현 정리(spectral representation theorem)", " 40.1 스펙트럴 표현 정리(spectral representation theorem) 스펙트럴 표현 정리(spectral representation theorem)는 다른 말로 Bochner의 정리(Bochner’s theorem)이라고 부른다. Theorem 40.1 (스펙트럴 표현 정리) 실수값을 갖는 연속 함수 \\(C\\)가 양정치함수라는 것은 그 함수가 symmetric nonnegative measure \\(F\\)로부터 \\(\\mathcal{R}^{d}\\)로 가는 Fourier transform인 경우이다. 즉 \\[\\begin{eqnarray} C(\\mathbf{h})&amp;=&amp;\\int_{\\mathbb{R}^{d}}\\exp(i\\mathbf{h}^{T}\\mathbf{x})dF(\\mathbf{x})\\nonumber\\\\ &amp;=&amp;\\int_{\\mathbb{R}^{d}}\\cos(\\mathbf{h}^{T}\\mathbf{x})dF(\\mathbf{x}) \\text{ (spectral representation)} \\end{eqnarray}\\] 인 경우이다. 여기서 \\(F\\)를 스펙트럼 측도(spectral measure)라고 한다. 만약 \\(F\\)가 좋은 성질을 갖고 있어서 (르베그) 밀도함수((Lebesgue) density function) \\(f\\)가 있으면, 즉 \\(F(\\mathbf{x})=f(\\mathbf{x})d\\mathbf{x}\\)이면 \\(f(\\mathbf{x})\\)를 스펙트럼 밀도(spectral density)라고 하며 이것의 스펙트럼 표현(spectral representation)은 \\[ C(\\mathbf{h})=\\int_{\\mathbb{R}^{d}}\\exp(i\\mathbf{h}^{T}\\mathbf{x})f(\\mathbf{x})d\\mathbf{x}=\\int_{\\mathbb{R}^{d}}\\cos(\\mathbf{h}^{T}\\mathbf{x})f(\\mathbf{x})d\\mathbf{x} \\] 로 쓸 수 있다. 이 정리를 쓰면 상대적으로 쉽게 어떤 함수가 양정치함수임을 보일 수 있다. 즉 \\[ C(\\mathbf{h}) =\\int_{\\mathbb{R}^{d}}\\exp(i\\mathbf{h}^{T}\\mathbf{x})dF(\\mathbf{x}) =\\int_{\\mathbb{R}^{d}}\\exp(i\\mathbf{h}^{T}\\mathbf{x})f(\\mathbf{x})d\\mathbf{x} \\] 임을 보이고 \\(f(\\mathbf{x})\\)가 양(positive)임을 보이기만 하면 된다. "],
["40-2-kolmogorovs-existence-theorem.html", "40.2 콜모고로프 존재 정리(Kolmogorov’s existence theorem)", " 40.2 콜모고로프 존재 정리(Kolmogorov’s existence theorem) 정상성이 아닌 경우에는 콜모고로프 존재 정리(Kolmogorov’s existence theorem)으로 해결할 수 있다고 한다. "],
["40-3-properties-of-covariance-functions.html", "40.3 공분산함수의 성질(properties of covariance functions)", " 40.3 공분산함수의 성질(properties of covariance functions) 여기서부터는 공분산함수(covariance function) \\(C(\\mathbf{h})\\)의 성질에 대해 다루겠다. 표본이 하나인 경우, 자기공분산을 추정하기 위해서는 공분산 구조에 약정상성이나 등방성 등과 같은 가정을 만들어야 한다. \\(C(\\mathbf{0}) \\geq 0\\) (분산이 음이 아님) \\(C(\\mathbf{-h})=C(\\mathbf{h})\\) \\(|C(\\mathbf{h})| \\leq C(\\mathbf{0})\\) (코쉬-슈바르츠 부등식) \\(C_{1}\\), \\(C_{2}\\)가 양정치함수이면 \\(a_{1}C_{1}+a_{2}C_{2}\\) 또한 양정치함수이다. (\\(a_{1}\\), \\(a_{2} \\geq 0\\)) 추가적으로 \\(C_{1}C_{2}\\) 또한 양정치함수이다. \\(C_{1}, C_{2}, \\ldots\\)가 양정치함수의 수열이고 이것의 극한 \\(\\lim_{n \\rightarrow \\infty}C_{n}\\)이 존재하면 이것 또한 양정치함수이다. 40.3.1 등방성(isotropy) \\(C(\\mathbf{h})=C_{0}(\\|\\mathbf{h}\\|)\\)인(or \\(\\gamma(\\mathbf{h})=\\gamma_{0}(\\|\\mathbf{h}\\|)\\)) \\(C_{0}\\)가 존재할 경우 이 공간과정이 \\(Z(\\mathbf{s})\\)를 등방성(isotropy)을 갖는다라고 한다. 이것은 \\(d\\)차원에서 정의한 \\(\\mathbf{h}\\) 1차원인 거리에만 의존하는 공분산함수로 표현 가능하다는 것이다. 40.3.1.1 약등방성(weakly isotropy) (전미경 교수님 강의노트) 어떤 임의장 \\(Z\\)가 유한한 이차 모멘트를 갖고, 평균함수가 상수이고 공분산 함수가 \\[Cov(Z(\\mathbf{s}_{1}), Z(\\mathbf{s}_{2}))=C(|\\mathbf{s}_{1},\\mathbf{s}_{2}|)\\] 인 경우 약등방성(weakly isotropy)를 갖는다고 한다. 즉 등방성은 공분산이 전이 불변, 회전 불변이라는 것을 의미한다. 만약 어떤 임의장이 등방성을 가지면 그것은 정상(stationary)이라고 한다. 40.3.2 동질성(homogeneous) (잘 쓰이지는 않지만) \\(Z(\\mathbf{s})\\)가 내재적(intrinsic)이고 등방성(isotrophic)인 경우 \\(Z(\\mathbf{s})\\)를 동질성(homogeneous)을 갖는다라고 한다. 40.3.3 이등방성(anisotropy) 이등방성(anisotropy)란 말 그대로 등방성이 아닌 경우를 얘기하지만 이런 경우가 너무 많아 범위를 나누어 생각한다. 40.3.4 z3 기하학적 이등방성(Geometric anisotropy) 이것은 \\[\\gamma(\\mathbf{h})=\\gamma_{0}(\\|A\\mathbf{h}\\|)\\] 즉 어떤 선형변환행렬(linear transfomation matrix) \\(A\\)를 통해 변환한 후 등방성인 경우를 얘기한다. 보통 \\(A\\)는 대칭인 양정치행렬(symmetric positive definite matrix)을 다루며 이 때 \\(\\|A\\mathbf{h}\\|\\)는 타원형 등고선(ellipse contour)이 된다. 40.3.4.1 띠모양 이등방성(zonal anisotropy) 이것은 기하학적 이등방성의 일반화된 버전이라고 생각하면 된다. \\[\\gamma(\\mathbf{h})=\\sum_{i=1}^{K}\\gamma_{0}(\\|A_{i}\\mathbf{h}\\|)\\] 로 \\(A\\) 대신 \\(A_{i}\\)들로 표현할 수 있는 경우를 얘기한다. 즉 \\(\\gamma(\\mathbf{h})\\)에 대응되는 공간과정을 \\(Z(\\mathbf{s})\\)라 할 때 각 변동도(variogram)에 해당하는 독립인 공간과정(independent spatial process)의 합으로 즉 \\[Z(\\mathbf{s})=Z_{1}(\\mathbf{s})+ \\cdots Z_{k}(\\mathbf{s})\\] 로 표현할 수 있다는 것이다. 여기서 각각은 변동도인데 이들의 합도 변동도인가?라는 궁금증을 가질 수 있다. 이것은 맞다고 한다. 앞서 ’공분산함수가 되려면 이 함수가 양정치함수이어야 한다’라는 것에 대해 배운 적이 있다. 변동도에 대해서도 똑같이 생각해 볼 수 있을 것이다. 유효한 변동도(valid variogram)이란 무엇인가? 이를 확인해 보기 위해 다음 정의를 살펴보자. \\(\\gamma(\\mathbf{h})=C(\\mathbf{0})-C(\\mathbf{h})\\)라고 하자. 이 때 \\(C(\\mathbf{h})\\)는 양정치함수이나 \\(C(\\mathbf{0})\\)의 존재로 \\(\\gamma(\\mathbf{h})\\)가 양정치함수라고 말할 수는 없다. 대신 \\(\\sum a_{i}=0\\)을 만족하는(\\(C(\\mathbf{0})\\) 때문에 붙는 조건이다) 임의의 \\(a_{1}, \\cdots a_{n}\\)에 대해 \\[\\sum_{i}\\sum_{j}a_{i}a_{j}\\gamma(\\mathbf{s}_{i},\\mathbf{s}_{j}) \\leq 0\\] 인 경우 \\(\\gamma(\\mathbf{h})\\)를 조건부 음정치(conditionally negative definite)라고 한다. 우리는 종속구조(dependent structure)를 모델링하기 위해 공분산 준변동도(covariance semivariogram)를 생각하고 있다. 그런데 공간 데이터를 가지고 있으면 이를 어떤 표면(surface)으로 표현 가능하고 이 과정이 부드러운(smooth)지, 즉 과정이 연속인지 또는 미분가능한지 체크해 보고 싶을 수 있다. 이를 공분산을 가지고 체크해 볼 수 있다고 한다. 즉 공분산은 종속구조를 측정하는 것 이외의 또 다른 기능을 갖고 있는 것이다. "],
["40-4-continuity-and-differentiabiliy-of-spatial-stochastic-process.html", "40.4 공간 확률과정의 연속성과 미분가능성(continuity and differentiabiliy of spatial stochastic process", " 40.4 공간 확률과정의 연속성과 미분가능성(continuity and differentiabiliy of spatial stochastic process 우선 연속성(continuity)과 미분가능성(differentiability)의 정의를 해야 한다. 여러 버전이 있으나 여기서는 두 가지만 소개하기로 한다. 40.4.1 경로연속(path-continuity) 또는 경로 미분가능성(path-differentiability) 어떤 확률과정 \\(Z(\\mathbf{s})\\)가 경로연속(path-continuity) (또는 K번 미분가능(K-times differentiability))하다는 것은 그것의 실현(realization)이 연속(K번 미분가능)한 것이다. 말은 쉬우나 보이기는 어렵다. \\(\\{ Z(\\mathbf{s}) , S \\in \\mathcal{D}\\}\\)를 확률변수의 모임(collection)이라고 할 때 \\((\\omega \\in \\Omega, \\mathcal{F}, P)\\)에서 \\(\\omega\\) 하나당 \\(\\{ Z(\\mathbf{s})\\}\\)가 나오고 이것을 실현한 것이다. 40.4.2 평균제곱연속(mean-square continuity) 또는 평균제곱 미분가능성(mean-square differentiability) 어떤 확률과정 \\(Z(\\mathbf{s})\\)가 \\(\\mathbf{s}\\)에서 평균제곱연속(mean-square continuity)이라는 것(다른 말로 \\(L_{2}\\)-수렴)은 \\[E[(Z(\\mathbf{s}+\\mathbf{h}))^{2}] \\stackrel{\\|\\mathbf{h}\\| \\rightarrow 0}{\\rightarrow} 0\\] 인 경우이다. 같은 방법으로 어떤 확률과정 \\(Z(\\mathbf{s})\\)가 미분계수 \\(Z&#39;(\\mathbf{s})\\)에 대해 평균제곱 미분가능(mean-square differentiable)이라는 것은 \\[E[(\\frac{Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s})}{h}-Z&#39;(\\mathbf{s}))^{2}] \\stackrel{\\|\\mathbf{h}\\| \\rightarrow 0}{\\rightarrow} 0\\] 인 경우이다. 사실 \\(\\frac{Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s})}{h}\\)의 극한으로 \\(Z&#39;(\\mathbf{s})\\)를 정의하는 것이다. 고차원의 경우도 반복적으로 정의가 가능하다. 이것의 생김새로 보아 변동도와 관련이 있을 것이다라는 생각도 해 볼 수 있을 것이다. 그렇다면 이 둘 사이에는 어떤 관계가 있을까? 안타깝께도 내재하는 관계는 없다. 즉 경로연속이나 평균제곱연속은 아닌 경우도 있고 그 반대도 있다. 한편 공분산과 평균제곱연속(또는 미분가능성)은 어떤 연관성이 있는 걸까? \\[E[(Z(\\mathbf{s}+\\mathbf{h}))^{2}] \\stackrel{\\|\\mathbf{h}\\| \\rightarrow 0}{\\rightarrow} 0\\] 으로부터 \\[2\\gamma(\\mathbf{h})=2(C(\\mathbf{0})-C(\\mathbf{h})) \\stackrel{\\|\\mathbf{h}\\| \\rightarrow 0}{\\rightarrow} 0\\] 즉 \\(C\\)라는 함수가 \\(\\mathbf{0}\\)에서 연속이라는 것을 알 수 있다. (약)정상성을 가정할 경우 (\\(\\mathbf{s} \\in \\mathbb{R}^{d}\\), \\(\\mathbf{s}\\)는 고정되어있지 않다) \\[ \\mathbf{s} \\text{에서 평균제곱연속} \\leftrightarrow C(\\cdot)\\text{이 } \\mathbf{0}\\text{에서 연속}\\] \\[C(\\cdot)\\text{이 } \\mathbf{0}\\text{에서 연속} \\rightarrow Z(\\mathbf{s})\\text{가 모든 지점에서 평균제곱연속}\\] 위 결과로부터, \\(Z(\\mathbf{s})\\)는 모든 지점에서 평균제곱연속이거나 어떠한 지점에서도 평균제곱연속하지 못함을 알 수 있다. (어떤 특정한 지역에서만 평균제곱연속할 수 없다) 또한 다음과 같은 사실도 알 수 있다. \\[C(\\cdot) \\text{가 원점에서 연속이면} \\rightarrow C(\\cdot) \\text{는 모든 지점에서 연속이다}.\\] 이것의 증명에 대해서는 각자 생각해보기로 한다. 40.4.3 Bartlett의 정리(Bartlett’s theorem) 이 정리는 다음 두 가지를 일컫는 말이다. Theorem 40.2 (Bartlett의 정리) 공분산함수 \\(\\rho(\\mathbf{u})\\)를 갖는 정상확률과정이 k-번 평균제곱 미분가능하다는 것은 \\(\\rho(\\mathbf{u})\\)가 원점에서 2k-번 미분가능하다는 것과 동치이다. (k=0일 경우 위에서 말했던 관계와 같다.) k번 미분가능한 평균제곱 미분계수(k-th mean-square derivative) \\(Z^{(k)}(\\mathbf{s})\\)의 공분산함수는 \\((-1)^{k}C^{(2k)}\\)이다. 위 설명 내용은 나중에 공분산 모형으로 체크해 볼 수 있다. 지수 공분산 모형(exponential covariance model)은 미분가능하지 않다. 한편 Matern 계급(class)을 이용할 경우 모수를 조절해서 어느 정도까지 공분산 모형이 미분가능할 지 조절할 수 있다. 한편 비모수적인 방법으로 경험적 변동도(empirical variogram)를 쓸 수 있는데, 이 방법으로는 공분산 모형이 몇 번 미분가능한지 구분할 수 없다. Example 40.1 (Bartlett의 정리의 예) (1-d인 경우) \\(Z_{h}(\\mathbf{s})=\\frac{Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s})}{h}\\)로 정의하고 이것의 공분산함수 \\(C_{h}(\\mathbf{t})\\)를 계산하면 \\[C_{h}(\\mathbf{t})=\\text{Cov}(Z_{h}(\\mathbf{s}+\\mathbf{t}),Z_{h}(\\mathbf{s}))=\\frac{1}{h^{2}}\\{2C(\\mathbf{t})-C(\\mathbf{t}+\\mathbf{h})-C(\\mathbf{t}-\\mathbf{h})\\}\\] 이다. 만약 \\(C(\\cdot)\\)이 두 번 미분가능하다면 \\[C_{h}(\\mathbf{t}) \\stackrel{\\|\\mathbf{h}\\| \\rightarrow 0}{\\rightarrow} -C^{&#39;&#39;}(\\mathbf{t})\\] 이다. 한편 평균제곱 연속성은 프랙탈 분석(fractal analysis) (표면의 부드러움 체크 관련), first index estimation 등과도 관련된다고 한다. 40.4.4 Kent의 경로연속을 위한 충분조건(Kent’s sufficient condition for path-continuity) (2-d ver) 평균제곱연속이나 경로연속이지 않은 경우(path-continuous 조건이 mean-square continuous조건보다 strong하다)는 것을 보이는 (Kent 1989)의 정리를 소개하였다. 여기서는 간단하게 2-d version으로 정리한다. Theorem 40.3 (Kent의 경로연속을 위한 충분조건) \\(\\rho(\\mathbf{u})\\)를 상관함수(correlation function)라고 하자. 이 함수를 테일러 전개로 \\[\\rho(\\mathbf{u})=\\rho_{m}(\\mathbf{u})+r_{m}(\\mathbf{u}), \\mathbf{u} \\in \\mathbb{R}^{2},\\] 여기서 \\(\\rho_{m}(\\mathbf{u})\\)는 \\(\\mathbf{u}=\\mathbf{0}\\)에서 전개한 테일러 급수의 m차 다항함수, \\(r_{m}(\\mathbf{u})\\)는 나머지(remainder)이다. 이 때, 경로연속이 성립할 충분조건은 \\(\\rho (\\cdot)\\)이 두번 연속 미분가능하고 \\(|r_{2}(\\mathbf{u})|\\)가 다음의 순서로 \\[|r_{2}(\\mathbf{u})|=O(\\frac{|\\mathbf{u}|^{2}}{(\\log |\\mathbf{u}|)^{3+\\gamma}}) \\text{ as } |u| \\rightarrow 0 \\text{ for some } \\gamma &gt;0\\] 0으로 가는 것이다. Corollary 40.1 정상 가우스 과정일 때 경로 연속에 대한 충분조건은 \\[\\rho(\\mathbf{0})-\\rho(\\mathbf{u})=O(\\frac{1}{(\\log |\\mathbf{u}|)^{1+\\epsilon}})=o(1) \\text{ as } |\\mathbf{u}| \\rightarrow 0 \\text{ for some } \\epsilon &gt; 0\\] 이다. 왼쪽의 \\(\\rho(\\mathbf{0})-\\rho(\\mathbf{u})\\)은 가우스 과정일 경우 나머지의 차수(order)가 아닌 상관(correlation)의 차수로 표현 가능하다는 뜻이다. 분산 1일 시 \\[\\rho(\\mathbf{0})-\\rho(\\mathbf{u})=\\gamma(\\mathbf{u}) \\stackrel{\\|\\mathbf{u}\\| \\rightarrow 0}{\\rightarrow} 0\\] 이며 이 화살표는 평균제곱 연속성의 정의와 같다. (\\(\\rho(\\mathbf{0})-\\rho(\\mathbf{u})=o(1)\\)) 한편 corollary의 차수보다 천천히 0으로 가면 평균제곱 연속은 되지만 경로연속이 되지는 않는다. References "],
["41-covmodel.html", "Chapter 41 공분산모형", " Chapter 41 공분산모형 이 장에서는 공분산모형에는 어떤 것들이 있는지 살펴볼 것이다. 여기에 등장하는 그림은 주로 (Montero, Fernández-Avilés, and Mateu 2015) 책에 있는 그림들을 가져온 것이다. References "],
["41-1-nugget-effect.html", "41.1 덩어리 효과(nugget effect)", " 41.1 덩어리 효과(nugget effect) 덩어리 효과(nugget effect)란 공간자료분석에서 흔히 나타나는 특징 중 하나이다. 일반적으로 공간자료 모델링은 다음과 같이 한다. \\[Y(\\mathbf{s})=\\mu(\\mathbf{s})+Z(\\mathbf{s})+\\epsilon(\\mathbf{s}).\\] 여기서 \\(Y(\\mathbf{s})\\)는 관측과정(observed process), \\(\\mu(\\mathbf{s})=E(Y(\\mathbf{s}))\\)는 결정적 평균 함수(deterministic mean function), \\(Z(\\mathbf{s})\\)는 순수 공간과정(spatial process), 마지막으로 \\(\\epsilon(\\mathbf{s})\\)는 나머지 설명되지 않은 항(remaining unexplained term)이다. 일종의 백색잡음(white noise)이라고 생각해도 좋다. 그리고 \\(Z(\\mathbf{s}) \\bot \\epsilon(\\mathbf{s})\\)이다. \\(\\epsilon(\\mathbf{s})\\)에 대해 공분산을 생각해보면, \\[ \\text{COV}(\\epsilon(\\mathbf{s}),\\epsilon(\\mathbf{s}+\\mathbf{h}))= \\left\\{ \\begin{array}{ll} \\sigma_{\\epsilon}^{2} &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ 0 &amp; \\textrm{o.w.} \\end{array} \\right. \\] 인데 여기서 \\(\\sigma_{\\epsilon}^{2}\\)을 덩어리(nugget)이라고 한다. 그리고 이러한 \\(\\epsilon(\\mathbf{s})\\)가 있는게 덩어리 효과(nugget effect)가 있다고 한다. 그렇다면 왜 이름이 덩어리인지 생각해 볼 필요가 있다. ‘Nugget’은 ’조그만 덩어리’ 라는 이름의 영어로, 금광 채굴 문제에서 유래했다고 한다. 유전 발굴과 같은 경우에는 변동성이 작아 어느 지점에서 유전이 발견되면 그 주변에서도 높은 확률로 유전이 발견되지만, 금광의 경우는 microscale variability가 있어 어느 지점에서 발견되었다 하더라도 주변에는 금광이 없을 수도 있다는 것이다. 또 다른 관점으로도 덩어리 효과를 표현할 수 있다. 극한값에서 생각을 해 보면 \\[C(\\mathbf{0})-C(\\mathbf{h})=\\gamma(\\mathbf{h})=\\frac{1}{2}\\text{Var}(Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s}))\\] 로 표현할 수 있는데, 덩어리 효가 존재할 경우 \\[\\lim_{\\mathbf{h}\\rightarrow \\mathbf{0}}\\gamma(\\mathbf{h})=\\gamma_{0} &gt;0\\] 일 수도 있다는 것이다. 이떄 이 \\(\\gamma_{0}\\)가 덩어리 효에 대응되는 것이다. 평균제곱과정(mean square process)인 경우 공분산이 \\(\\mathbf{h}=\\mathbf{0}\\)일 때 연속이어야 한다. 따라서 평균제곱이며 연속인 공간과정 \\(Z(\\mathbf{s})\\)의 경우 이러한 현상이 존재 할 수 없고 \\(\\epsilon(\\mathbf{s})\\)는 \\(\\mathbf{h}=\\mathbf{0}\\)일 때 불연속일 수 있고 \\(Z(\\mathbf{s}) \\bot \\epsilon(\\mathbf{s})\\)이므로 덩어리 효과가 존재할 수 있는 것이다. 그런데 앞서 또 다른 관점으로 설명할 때 \\(\\sigma_{\\epsilon}^{2}\\) 대신 \\(\\gamma_{0}\\)이라는 표기를 썼는데 그 이유는 측정 오류(measurement error)가 존재할 수도 있기 때문이다. 엄밀히 얘기하면 \\[\\sigma_{\\epsilon}^{2}=\\text{measurement error variance } + \\text{ 순수한 microscale error variance}\\] 로 표현할 수 있는데 공간자료의 경우 반복관찰이 없어 집합이 1개이므로 이 둘을 따로 구분해서 측정하는 것이 불가능하다. 여러 번 측정할 수 있으면 둘을 구분해서 추정할 수 있다고 한다. (독립인 자료의 경우) 그렇다면 언제 반복이 있느냐? 시공간 자료(spatio-temporal data)에서 시간(temporal) 정보를 다 빼냈을 경우 반복이 있는 자료라 생각할 수 있고 이 둘을 구분하여 추정할 수 있다고 한다. "],
["41-2-idealized-shape-of-variogram-isotropic-case.html", "41.2 이상적인 변동도의 모양(idealized Shape of Variogram (isotropic case))", " 41.2 이상적인 변동도의 모양(idealized Shape of Variogram (isotropic case)) 그렇다면 일반적으로 생각하는 변동도의 모양은 어떠한가? FIGURE 41.1: Variogram example. 새로 등장하는 용어인 문턱(sill)과 범위(range) 그리고 덩어리(nugget)의 의미를 꼭 알아두자. 변동도의 모양은 공분산이 얼마나 빨리 줄어드는지, 그 때 형태(shape)는 어떠한지에 따라 달라진다. 정상과정인 경우 \\[\\gamma(\\mathbf{h})=C(\\mathbf{0})-C(\\mathbf{h})\\] 가 성립한다. 그런데 \\(\\mathbf{h}\\)를 키우면 \\(C(\\mathbf{h})\\)가 줄어드므로 종속성(dependency)이 감소할 것이다. 그리고 정상과정인 경우 \\(C(\\mathbf{0})\\neq \\infty\\)이므로 \\(\\mathbf{h} \\rightarrow \\infty\\)일 때 \\(\\gamma(\\mathbf{h})\\)가 수렴할 것이다. (그렇지 않다면 비정상과정이다) "],
["41-3-effective-range.html", "41.3 유효 범위(effective range)", " 41.3 유효 범위(effective range) 앞서 말한 성질들에 variogram은 \\(\\mathbf{h} \\rightarrow \\infty\\)어떤 값으로 수렴한다. 그런데 어느정도 지난 \\(\\mathbf{h}\\)이후에 수렴값과 맞닿으면 range를 정의할 수 있으나 점근해서 수렴하는 경우는 range가 \\(\\infty\\)가 되는 문제가 발생한다. 이럴 때 대신 쓰는 정의로 유효 범위(effective range)라는 것이 있다. 이 것의 정의는 \\(\\gamma(\\mathbf{h})\\) 가 sill의 95% 접근하는 smallest \\(\\|\\mathbf{h}\\|\\) 이다. "],
["41-4-classical-parametric-isotropic-variogram-models.html", "41.4 대표적인 모수 등방성 변동도 모형들(classical parametric isotropic variogram models)", " 41.4 대표적인 모수 등방성 변동도 모형들(classical parametric isotropic variogram models) 여기서는 총 9가지의 변동도 모형을 소개한다. 그러나 실제로 널리 쓰이는 모델은 ‘exponential’과 ’matern’ 두 개이다. Linear \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}\\| \\mathbf{h}\\| &amp; \\textrm{if $\\mathbf{h}\\neq 0$}\\\\ \\end{array} \\right. \\] \\(\\lim_{\\|\\mathbf{h}\\| \\rightarrow \\mathbf{0}}\\gamma(\\mathbf{h}) \\rightarrow \\infty\\)이므로 이것은 비정상과정의 변동도라는 것을 알 수 있다. (대신 내재정상과정이다) Spherical \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}[\\frac{3}{2}(\\frac{\\| \\mathbf{h}\\|}{R})-\\frac{1}{2}(\\frac{\\| \\mathbf{h}\\|}{R})^{3}] &amp; \\textrm{if $0 \\leq \\|\\mathbf{h}\\|\\leq R$}\\\\ c_{0}+c_{1} &amp; \\textrm{if $\\|\\mathbf{h}\\|&gt;R$}\\\\ \\end{array} \\right. \\] 이것은 지구통계학(geostatstics)에서는 많이 쓰나 모형이 복잡해 분포 가정 후 우도 추정(likelihood estimation)을 할 때 어렵고 잘 안되므로 통계학자들은 잘 안 좋아하는 모형이라고 한다. 참고로 이 변동도는 \\(\\mathbf{h} \\in \\mathbb{R}^{d}, d=1,2,3\\)에서만 유효하다. 이것보다 더 큰 차원에서는 유효하지 않다. 이것 이외에 나머지 변동도의 예들은 다 모든 양수 \\(d\\)에서 유효한 변동도를 갖는다고 한다. Exponential \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}(1-e^{-\\frac{\\|\\mathbf{h}\\|}{R}}) &amp; \\textrm{if $\\mathbf{h}\\neq 0$}\\\\ \\end{array} \\right. \\] 이것은 평균제곱연속이나 평균제곱 미분 가능하지는 않다고 한다. 그리고 다른 애들보다 독립적인 편이라고(공분산이 약함) 한다. 특히 뒤에 나오는 가우스 변동도(Gaussian variogram)와 비교했을 때 덜 부드럽다. R 패키지 SpatialExtremes를 통해 공분산함수를 출력해 볼 수 있다. 여기서 \\(c_{1}\\)은 sill, \\(R\\)은 range로 조절할 수 있다. FIGURE 41.2: sill이 1일 때의 exponential covariance function. Gaussian \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}(1-e^{-(\\frac{\\|\\mathbf{h}\\|}{R})^{2}}) &amp; \\textrm{if $\\mathbf{h}\\neq 0$}\\\\ \\end{array} \\right. \\] 가우스분포랑은 관련이 없으며 2차항이 있기 때문에 이러한 이름이 붙은 것이다. 이것은 무한번 평균제곱 미분 가능(infinitely mean-square differentiable)하다. 그렇다는 얘기는 엄청 부드러운 데이터 모델링 시 사용할 수 있다는 것이다. 그러나 이런 경우는 드물므로 많이 보기는 힘들다. FIGURE 41.3: sill이 1일 때의 Gaussian covariance function. Exponential power \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}(1-e^{-(\\frac{\\|\\mathbf{h}\\|}{R})^{p}}) &amp; \\textrm{if $\\mathbf{h}\\neq 0$, $0 &lt; p \\leq 2$}\\\\ \\end{array} \\right. \\] 이것은 exponential과 Gaussian의 중간쯤 되는 변동도로 \\(p\\)를 추정하는 것이 어려워 보통 미리 정하고 사용한다고 한다. Rational quadratic \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}\\| \\mathbf{h}\\|^{2}/(1+\\frac{\\|R\\|^{2}}{R}) &amp; \\textrm{if $\\mathbf{h}\\neq 0$}\\\\ \\end{array} \\right. \\] Wave \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}(1-\\frac{R}{\\|\\mathbf{h}\\|}\\sin(\\frac{\\|\\mathbf{h}\\|}{R})) &amp; \\textrm{if $\\mathbf{h}\\neq 0$}\\\\ \\end{array} \\right. \\] Power-law \\[ \\gamma(\\mathbf{h})= \\left\\{ \\begin{array}{ll} 0 &amp; \\textrm{if $\\mathbf{h}$=0}\\\\ c_{0}+c_{1}\\| \\mathbf{h}\\|^{\\lambda} &amp; \\textrm{if $\\mathbf{h}\\neq 0$, $0\\leq \\lambda &lt; 2$}\\\\ \\end{array} \\right. \\] 이것은 선형모형(linear model)의 일반화(generalization)이며 \\(\\lambda=0\\)일 때에는 선형모형이다. 이것은 Local whittle model에서 감소율(decay rate) (\\(\\| \\mathbf{h} \\| \\rightarrow \\infty\\), \\(\\| \\mathbf{h} \\| \\rightarrow 0\\) 부근) 결정시 부분적으로 사용한다고 한다. (공분산을 일종의 준모수 모델링하는 것 같다) Matern (변동도가 복잡하므로 공분산 형태로 썼다) \\[C(\\mathbf{h})=\\sigma^{2}\\frac{2^{1-\\alpha}}{\\Gamma(\\alpha)}(\\frac{\\|\\mathbf{h}\\|}{\\phi})^{\\alpha}K_{\\alpha}(\\frac{\\|\\mathbf{h}\\|}{\\phi})\\] 참고로 \\[\\lim_{\\mathbf{h} \\rightarrow 0}C(\\mathbf{h}) = \\sigma^{2}\\] 이다. FIGURE 41.4: sigma와 alpha가 1일 때 Matern covariance function. 이 때 \\(K_{\\alpha}\\)는 차수 \\(\\alpha\\)를 갖는 변형된 이형(second kind) 베셀 함수(Bessel function)라고 한다. 그리고 \\((\\phi&gt;0,\\alpha&gt;0)\\)는 각각 척도모수(scale parameter), 평활모수(smoothness parameter) (shape parameter, random process의 smootheness와 연결)라고 부르는데, 이름으로 그 역할들을 짐작할 수 있을 것이다. Matern 공분산함수(Matern covariance function)는 두 개의 모수가 있으므로 다양한 형태의 변동도 모델링이 가능하다. 이들은 때때로 정의가 바뀌기도 하므로 R-package를 쓸 때 체크가 필요하다. Matern 공분산함수를 갖는 \\(Z(\\mathbf{s})\\)는 \\(\\lceil \\alpha \\rceil -1\\)번 평균제곱 미분가능하다. (\\(0&lt;\\alpha \\leq 1\\)인 경우에는 평균제곱연속) 이 말은 즉 \\(\\alpha\\)를 조절해 공분산 함수의 평활도(smoothness)를 조절할 수 있다는 뜻이다. \\(\\alpha=0.5\\)인 경우에는 지수모형(exponential model), \\(\\alpha \\rightarrow \\infty\\)인 경우에는 가우스모형(Gaussian model)이 된다. (\\(\\alpha\\)가 커질수록 differentiability 또한 올라간다) \\(\\alpha\\)가 half-integer인 경우 explicit form이 있다고 한다. Example 41.1 (Matern 공분산 함수의 예.) \\(\\phi=1\\)일 때 \\[ \\begin{array}{ll} \\alpha=0.5: &amp; e^{-\\|\\mathbf{h}\\|}\\\\ \\alpha=1.5: &amp; (1+\\|\\mathbf{h}\\|)e^{-\\|\\mathbf{h}\\|}\\\\ \\alpha=2.5: &amp; (1+\\|\\mathbf{h}\\| + \\frac{\\|\\mathbf{h}\\|^{2}}{3})e^{-\\|\\mathbf{h}\\|}\\\\ \\end{array} \\] 41.4.1 변형된 이형 베셀에 대한 보충 설명(addtional explanation for K_alpha) 변형 베셀 함수(modified Bessel function)은 변형 베셀 방정식(modified Bessel equation)의 해이다. 변형 베셀 방정식(modified Bessel equation)은 다음의 \\[x^{2}y&#39;&#39;+xy&#39;-(x^{2}+\\alpha^{2})y=0\\] 미분방정식의 해이다. (original은 \\(x^{2}+\\alpha^{2}\\) 부분이 다르다고 한다) 이 해는 두 개가 존재한다. \\[ \\begin{array}{ll} I_{\\alpha}(x): &amp; \\text{exponentially growing}\\\\ K_{\\alpha}(x): &amp; \\text{exponentially decaying}\\\\ \\end{array} \\] 우리는 감소하는 형태의 함수를 필요로 하므로 \\(K_{\\alpha}(x)\\)를 사용하는 것이다. 추가적으로 \\(x &gt;&gt; [\\alpha^{2}-\\frac{1}{4}]\\)이면 \\[K_{\\alpha}(x) \\sim \\sqrt{\\frac{\\pi}{2x}}e^{-x}\\] 가 되고, \\(0&lt;x&lt;&lt;1\\)이면 \\[ K_{\\alpha}(x) \\sim \\left\\{ \\begin{array}{ll} -\\log (\\frac{x}{2}) - c &amp; \\textrm{if $\\alpha$=0}\\\\ (\\frac{\\Gamma(\\alpha)}{2})(\\frac{2}{x})^{\\alpha} &amp; \\textrm{if $\\alpha$&gt;0}\\\\ \\end{array} \\right. \\] \\(\\alpha\\)를 추정하는 것은 쉽지 않다. 공간통계학에서는 보통 우도로 모수 추정을 하는데 이것을 하기 위해서는 공분산행렬의 역행렬 등을 계산해야 한다. 그런데 \\(\\alpha\\)가 클 경우 수치적 특이점(numerical singularity)이 많이 나와 \\(\\alpha\\) 추정이 어렵다. 그래서 보통 작은 숫자의 \\(\\alpha\\)를 고정한 후 많이 사용한다. "],
["41-5-variograms-in-other-situation.html", "41.5 기타 다른 상황에서의 변동도들(variograms in other situation)", " 41.5 기타 다른 상황에서의 변동도들(variograms in other situation) 지금까지는 일변량(univariate)이고 정상성을 가지며 시간 구조(temporal structure)는 고려 안한 변동도만 살펴보았다. 그러나 그렇지 않은 경우에는 어떻게 할 것인가? 다변량(multivariate)인 경우 한 장소에서의 관측값이 여러 개 일 수도 있다. 즉 한 지점에서 미세먼지 농도만 관측한 것이 아니라 강수량도 같이 관측한 경우도 있을 수 있다. 이런 경우의 변동도는 상호의존성(interdependence)을 고려해야 한다. 같은 장소와 다른 장소 사이의 dependence와 관측값 사이의 dependence 등도 고려해야 한다. 이런 경우의 변동도들을 공변동도(covariogram)이라고 부른다. 시공간자료(spatio-temporal data)인 경우 가장 간단한 모델은 분리가능한(separable) 모델이다. 이 모델은 시간과 공간 공분산이 독립이라는 것이다. \\[C(h,t;\\theta)=C_{s}(h)C_{t}(t).\\] 그러나 이 모델은 어느 위치에 있던지 시간 의존성이 같다는 매우 강한 가정을 갖는 것이다. 그렇지 않은 모형들을 분리 가능하지 않은(non-separable) 모델이라고 부른다. 스케일(scale)이 커지는 경우 전 지구적 수준의 데이터를 다룰 경우 구면좌표계를 사용할 필요가 있다. 구(sphere)나 다양체(manifold) 상에서 정의됨을 고려해야 하며 어떤 거리(distance)를 쓸 것인지에 대해서도 생각해 봐야 한다. "],
["42-variogramest.html", "Chapter 42 변동도의 추정", " Chapter 42 변동도의 추정 이 문서에서는 variogram을 어떻게 추정할 것인지에 대해 다룰 것이다. 크게 두 가지가 있다. Empirical model (nonparametric) Parametric fit 그리고 (Gelfand et al. 2010)의 33쪽부터, (N. A. C. Cressie 1993)의 69쪽부터 참고했다. References "],
["42-1-empirical-variogram.html", "42.1 경험변동도(empirical variogram)", " 42.1 경험변동도(empirical variogram) 이것은 변동도를 비모수 추정하는 것이다. 다시 한 번 변동도의 정의를 살펴보면 \\[2\\gamma(\\mathbf{h})=\\text{Var}(Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s}))\\] 으로 lag \\(\\mathbf(h)\\)에만 의존하는 함수이다. 그런데 내재정상성(instinsic stationary)에서는 평균이 0이므로 \\[2\\gamma(\\mathbf{h})=E[Z(\\mathbf{s}+\\mathbf{h})-Z(\\mathbf{s}))^{2}]\\] 이 된다. 다음은 추정량을 구하기 위한 방법들이다. 적률 추정(Metohd of moment (MoM) estimation (Matheron, 1962)) \\(E(Z(\\mathbf{s}))=\\mu\\)라는 상수 평균(constant mean) 가정하에 적률추정량(MoM estimator)은 \\[2\\hat{\\gamma}(\\mathbf{h})=\\frac{1}{|N(\\mathbf{h})|}\\sum_{(s_{i},s_{j})\\in N(\\mathbf{h})}(Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j}))^{2}, \\mathbf{h}\\in \\mathbb{R}^{d}\\] 이다. 여기서 \\(N(\\mathbf{h})\\)는 거리가 \\(\\mathbf{h}\\)가 되는 \\((\\mathbf{s}_{i},\\mathbf{s}_{j})\\)들의 집합이다. 즉 \\[N(\\mathbf{h})=\\{ (\\mathbf{s}_{i},\\mathbf{s}_{j}), \\mathbf{s}_{i}-\\mathbf{s}_{j}=\\mathbf{h} \\}\\] 이다. \\(N(\\mathbf{h}) \\neq N(\\mathbf{-h})\\)임에 주의하자. 이 추정량의 문제는 정규 격자(regular grid) 자료에만 잘 적용된다는 점이다. Irregular한 자료에서는 \\(\\mathbf{h}\\)에 대응되는 \\(N(\\mathbf{h})\\)가 공집합(empty set)일 수도 있다. 그런 상황을 해결하기 위해 \\(\\mathbf{h}\\)의 적당한 근방(neighborhood) \\(T(\\mathbf{h})\\)을 생각하여 \\(N(\\mathbf{h})\\)를 정의하기도 한다. \\[N(\\mathbf{h})=\\{ (\\mathbf{s}_{i},\\mathbf{s}_{j}), \\mathbf{s}_{i}-\\mathbf{s}_{j}=T(\\mathbf{h}) \\} .\\] 그렇다면 이 근방의 size는 어떻게 정해야 할 것인가라는 질문이 생길 수도 있다. 이것은 띠너비 선택(bandwidth selection) 문제와 유사하다. Practically하게 (Journel and Huijbregts 2003)는 \\(| \\cup \\{N(\\mathbf{h}): \\mathbf{h} \\in T(\\mathbf{h}) \\} |\\)에 들어가는 distinct pair들이 적어도 30개 이상이 되도록 잡는 것이 좋다고 하였다. 그러나 이 경우도 역시 데이터의 사이즈가 적을 경우 문제가 된다. 또한 \\(\\mathbf{h}\\)의 방향도 고려할 경우 자료가 더 부족해지고, \\(\\mathbf{h}\\)에 따라 pair 갯수 또한 차이가 난다. 그리고 자료로 인해 관측할 수 있는 \\(\\mathbf{h}\\)의 minimum과 maximum length가 존재한다. 역시 practically하게 \\(\\mathbf{h}\\)는 observation location들의 maximum length의 절반 정도를 고르도록 권장하고 있다. 마지막으로 이 추정량의 성질에 대해 알아보자. 우선 unbiased하다(특히 grid 자료인 경우). 그러나 outlier에 로버스트하지는 않다. \\(Z(\\mathbf{s})\\)가 Gaussian distribution이면 \\[(Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j}))^{2} \\sim 2 \\gamma(\\mathbf{h})\\chi_{1}^{2}\\] 이다. 그런데 카이제곱 분포는 매우 skewed된 분포인데 이 분포를 sample mean을 이용해 추정했으므로 finite sample 이용시 variation이 클 수 있다. 로버스트 추정량(robust estimator (Cressie and Howkins, 1980)) 이 문제를 해결하기 위해 Cressie와 Howkins는 robust한 통계량을 제시하였다. \\[2 \\bar{\\gamma}(\\mathbf{h})=\\frac{1}{0.457+\\frac{0.494}{|N(\\mathbf{h})|}}\\{\\frac{1}{|N(\\mathbf{h})|}\\sum_{(\\mathbf{s}_{i},\\mathbf{s}_{j} \\in N(\\mathbf{h}))} |Z(\\mathbf{s}_{i}-Z(\\mathbf{s}_{j})|^{\\frac{1}{2}}\\}^{4}.\\] 앞의 \\(\\frac{1}{0.457+\\frac{0.494}{|N(\\mathbf{h})|}}\\)는 bias correction term이다. 이 추정량의 아이디어는 다음과 같다. 어떤 확률변수 \\(X \\sim \\chi_{1}^{2}\\)때 \\(X^{\\frac{1}{4}}\\)는 거의 symmetric임을 보일 수 있다고 한다. 즉 \\(|Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j})|^{2}\\)보다는 \\(|Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j})|^{\\frac{1}{2}}\\)이 더 symmetric하게 행동할 수 있을 것이다. 따라서 이것을 이용하고자 하는 것이다. \\(\\mathbf{X}_{n}\\)을 \\(X_{n}\\equiv\\frac{1}{|N(\\mathbf{h})|}\\sum_{(\\mathbf{s}_{i},\\mathbf{s}_{j} \\in N(\\mathbf{h}))} |Z(\\mathbf{s}_{i}-Z(\\mathbf{s}_{j})|^{\\frac{1}{2}}\\) 이라고 하자. 다음은 \\(X \\sim \\chi_{1}^{2}\\)시 몇 가지 계산 결과이다. \\[E(X^{\\frac{1}{4}})=0.82216, \\text{Var}(X^{\\frac{1}{4}})=0.12192, E(X_{n})=0.82216 \\equiv \\nu\\] \\[\\text{Var}(X_{n})=\\frac{0.12192}{|N(\\mathbf{h}|)} \\text{(cross-covariance 무시할 경우)} .\\] 그 다음 \\(f(x)=x^{4}\\)에 대해 \\(\\nu\\) 근방에서 테일러 전개를 해보자. 그러면 \\[f(X_{n})\\circeq f(\\nu) +f&#39;(\\nu)(X_{n}-\\nu)+\\frac{1}{2}f&#39;&#39;(\\nu)(X_{n}-\\nu)^{2} .\\] 여기서 \\(X_{n}\\)만 random이다. 기댓값을 취하면 \\[ \\begin{aligned} E(X_{n})^{4}&amp;\\circeq f(\\nu) + f&#39;(\\nu)E(X_{n}-\\nu) +\\frac{1}{2}f&#39;&#39;(\\nu)E(X_{n}-\\nu)^{2}\\\\ &amp;\\circeq 0.457 + 0 +\\frac{0.494}{|N(\\mathbf{h})|} \\text{(second order까지 bias correction)}\\\\ \\end{aligned} \\] 따라서 robust estimator 앞에 bias correction을 위한 숫자항이 붙는 것이다. 또 다른 로버스트 추정량(another robust estimator) 특별한 이름은 없으며 앞 estimator에서 약간 변형한 형태이다. \\[ \\begin{aligned} 2\\tilde{\\gamma}(\\mathbf{h})&amp;=\\frac{1}{0.457}\\text{Median}\\{ |Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j})|^{2} , (\\mathbf{s}_{i},\\mathbf{s}_{j})\\in N(\\mathbf{h}) \\}\\\\ &amp;=\\frac{1}{0.457}\\{\\text{Median} \\{ |Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j})|^{\\frac{1}{2}} \\}^{4} \\} \\end{aligned} \\] Median을 쓸 경우 제곱근을 한 다음 네제곱을 하거나 그냥 제곱을 하거나 차이가 없다고 한다. References "],
["42-2-fitting-parametric-models-to-empirical-variogram.html", "42.2 경험변동도를 이용한 모수적 모형 추정(fitting parametric models to empirical variogram)", " 42.2 경험변동도를 이용한 모수적 모형 추정(fitting parametric models to empirical variogram) 경험변동도(empirical variogram) 자료들을 가지고 왜 또 모수적(parametric)인 적합(fitting)을 하려고 할까? 지구통계학(geostatistics)에서는 종속구조(dependence structure) \\(\\boldsymbol{\\sigma}\\)를 이용한 예측(prediction)에 관심이 있다. 그런데 예측을 하려면 \\(\\boldsymbol{\\sigma}^{-1}\\)이 필요하다. 그런데 경험변동도로 하면 \\(\\boldsymbol{\\sigma}\\)가 비음정치(non-negative definite)가 아니거나 수치적 특이성(numerical singularity)이 생긴다. 일반적으로 다음과 같은 모수 모델 \\[\\hat{\\boldsymbol{\\gamma}}(h;\\hat{\\boldsymbol{\\theta}})\\] 는 양정치함수(positive definite function)임을 보장한다(물론 numerical singular한 경우도 있을 수는 있다). 이러한 이유로 공간통계학에서는 모수를 이용한 모델링을 선호하는 것이다. 다음과 같이 \\(\\hat{\\gamma}(\\mathbf{h}_{1}), \\cdots , \\hat{\\gamma}(h_{m})\\)이 available하다고 하자(이들을 새로운 자료로 생각해도 좋다). 여기서 \\(m\\)은 고정시킨다. 우리의 목표는 \\(\\boldsymbol{\\gamma}(h;\\boldsymbol{\\theta})\\)가 true model일 때 \\(\\hat{\\boldsymbol{\\gamma}}(h;\\hat{\\boldsymbol{\\theta}})\\)를 만들고자 한다. 추정 방법은 크게 세 가지가 있다. 42.2.1 LS method \\[ \\begin{aligned} \\hat{\\boldsymbol{\\theta}}_{LS}&amp;=\\text{argmin}_{\\boldsymbol{\\theta}}\\sum_{j=1}^{m}\\{ \\hat{\\gamma}(h_{j})-\\gamma(h_{j};\\boldsymbol{\\theta})\\}^{2}\\\\ &amp;=\\text{argmin}_{\\boldsymbol{\\theta}}(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))^{T}(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))\\\\ \\end{aligned} \\] 이 방법은 \\(\\hat{\\gamma}(\\mathbf{h}_{i})\\)들의 종속성(dependency)을 무시한다. 42.2.2 GLS method 최소자승법의 약점을 보완하기 위한 방법이다. \\[\\hat{\\boldsymbol{\\theta}}_{GLS}=\\text{argmin}_{\\boldsymbol{\\theta}}(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))^{T}V^{-1}(\\boldsymbol{\\theta})(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))\\] 여기서 \\(V^{-1}(\\boldsymbol{\\theta})=\\text{Var}(\\hat{\\boldsymbol{\\gamma}})\\)이다. 일반적인 GLS는 \\((\\hat{y}-X\\beta)^{T}V^{-1}(\\theta)(\\hat{y}-X\\beta)\\)꼴처럼 \\(\\beta\\)와 \\(\\theta\\)가 다르지만, 이 경우는 두 개가 \\(\\theta\\)로 같다. 42.2.3 WLS method \\[\\hat{\\boldsymbol{\\theta}}_{GLS}=\\text{argmin}_{\\boldsymbol{\\theta}}(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))^{T}W(\\boldsymbol{\\theta})(\\boldsymbol{\\theta})(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))\\] 여기서 \\(W(\\boldsymbol{\\theta})=\\text{diag}(V(\\boldsymbol{\\theta}))\\)이다. 이것은 highly nonlinear한 object function이라 \\(\\boldsymbol{\\theta}\\)가 많을수록 적합이 어려워진다. GLS처럼 \\(\\beta\\)와 \\(\\theta\\)가 같으므로 two-stage iteration을 통해 적합한다. Iteration procedure는 다음과 같다. \\[\\hat{\\boldsymbol{\\theta}}^{(k+1)}=\\text{argmin}_{\\boldsymbol{\\theta}}(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))^{T}V^{-1}(\\hat{\\boldsymbol{\\theta}}^{(k)})(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))\\] OLS로 \\(\\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\) 부분을 먼저 고정시키고 iteration을 돌린다는 것 같다. 42.2.4 근사 WLS (approximated WLS) (N. Cressie 1985)는 WLS의 계산의 어려움을 피하기 위해 다음과 같은 근사 WLS 방법을 쓰기도 한다. \\[\\hat{\\boldsymbol{\\theta}}=\\text{argmin}_{\\boldsymbol{\\theta}}\\sum_{j}\\frac{|N(\\mathbf{h}_{j})}{\\gamma^{2}(\\mathbf{h}_{j};\\boldsymbol{\\theta})}\\{ \\hat{\\gamma}(\\mathbf{h}_{j})-\\gamma(\\mathbf{h}_{j};\\boldsymbol{\\theta}) \\}^{2}\\] 이 근사가 가능한 이유는 \\(\\text{Var}(\\hat{\\gamma(\\mathbf{h}_{j})}) \\cong \\frac{8 \\gamma^{2}(\\mathbf{h}_{j}l\\boldsymbol{\\theta})}{|N(\\mathbf{h}_{j})|}\\)이기 때문이다(8은 상수라 무시해도 수렴함). 그러나 여전히 두 군데에 \\(\\boldsymbol{\\theta}\\)가 있어 two-stage iteration을 해야 한다. 이렇게 계산한 AWLS 추정량이 (어떤 조건 하에) asymptotic normal이 됨을 보일 수 있다고 한다. 그런데 이런 경우에도 \\(\\hat{\\gamma}(\\mathbf{h}_{j}) \\stackrel{n \\rightarrow}{\\rightarrow} \\gamma(\\mathbf{h};\\boldsymbol{\\theta})\\)를 따로 보여야 한다고 한다. 몇 가지 기본 가정들은 다음과 같다. \\(\\mathbf{\\gamma}(\\mathbf{h}_{1}), \\cdots , \\mathbf{\\gamma}(\\mathbf{h}_{m})\\) 이 \\(\\mathbf{h}_{1}, \\cdots , \\mathbf{h}_{m}\\)에서 계산되어있다. 여기서 \\(m\\)은 고정되어 있다고 가정한다. \\(|N(\\mathbf{h}_{j})|=O(n)\\). 좀 더 자세하게는 \\(N(\\mathbf{h}_{j})=n\\cdot \\phi_{j,n}\\)이고 \\(\\lim_{n \\rightarrow \\infty}\\phi_{j,n}=\\phi_{j} &lt; \\infty\\)이다(그렇지 않으면 \\(O(n)\\)의 order가 올라갈 것이다). 말로 설명하자면 데이터가 커질 때마다 밀도가 일정해야 하므로 region도 커져야 한다는 것이다. 참고로 (N. Cressie 1985)에서는 다음과 같이 적혀 있다. “\\(|N(\\mathbf{h}_{j})| \\rightarrow \\infty\\) for each \\(j=1, \\cdots, k\\) as \\(N \\rightarrow \\infty\\) as \\(|D| \\rightarrow \\infty\\) such that \\(N/|D|\\), the sampling rate per unit area is constant.” 그리고 data가 evenly spaced 되어야 이 방법이 잘 맞는다고 한다. \\(\\text{Cov}(\\hat{\\gamma}(\\mathbf{h}_{j}), \\hat{\\gamma}(\\mathbf{h}_{k}))=O(\\frac{1}{n})\\). 여기서 \\(\\text{Cov}(\\hat{\\gamma}(\\mathbf{h}_{j}), \\hat{\\gamma}(\\mathbf{h}_{k})) \\sim \\frac{U_{jk}(\\boldsymbol{\\theta})}{n}\\)을 만족하는 \\(m \\times m\\) 행렬 \\(U(\\boldsymbol{\\theta})\\)가 존재한다. Decay 속도가 충분히 빠른 variogram model들 (ex. exponential)이 이 조건을 만족한다고 한다. 이 세 가지 조건을 만족할 경우 \\[\\sqrt{n}(\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta})) \\stackrel{\\mathcal{D}}{\\rightarrow} \\mathcal{N}(\\mathbf{0}, U(\\boldsymbol{\\theta}))\\] \\(m\\)이 커지면 \\((\\hat{\\boldsymbol{\\gamma}}-\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))\\)의 dimension 또한 커져 복잡한 문제가 되므로 \\(m\\)을 고정하는 것이다. \\[\\sqrt{n}(\\hat{\\boldsymbol{\\theta}}-\\boldsymbol{\\theta}) \\stackrel{\\mathcal{D}}{\\rightarrow} \\mathcal{N}(\\mathbf{0}, H^{-1}R^{T}URH^{-1})\\] 여기서 \\(R\\)은 \\(m \\times p\\) (p: number of parameter) 행렬인데 \\[R_{ij}=\\frac{2\\phi_{i}}{\\gamma^{2}(\\mathbf{h}_{i};\\boldsymbol{\\theta})}\\cdot \\frac{2\\gamma}{2\\boldsymbol{\\theta}_{j}}(\\mathbf{h}_{j};\\boldsymbol{\\theta})\\] 가 성립한다. 한편 \\(H\\)는 목적함수 \\(S_{n}(\\boldsymbol{\\theta}*)\\)의 헤시안의 확률수렴 값이다. \\[H:\\frac{\\nabla^{2}S_{n}(\\boldsymbol{\\theta}*)}{n} \\stackrel{P}{\\rightarrow} H(\\boldsymbol{\\theta})\\] 이다. 참고로 목적함수의 asymptotic은 보통 다음과 같이 한다. Consistency는 따로 보이고 이것을 만족하면 그 다음 테일러 전개로 \\[S_{n}&#39;(\\boldsymbol{\\theta})=S_{n}&#39;(\\hat{\\boldsymbol{\\theta}})+S_{n}&#39;&#39;(\\boldsymbol{\\theta}*)(\\hat{\\boldsymbol{\\theta}}-\\boldsymbol{\\theta})\\] 를 만든다 (mean value theorem에 의해 등호 성립). 이때 \\(S_{n}&#39;(\\hat{\\boldsymbol{\\theta}})\\)은 minimization 문제이므로 0이 된다. \\(S_{n}&#39;&#39;(\\boldsymbol{\\theta}*)\\)는 \\(H\\)에 해당된다. 따라서 \\(S_{n}&#39;(\\boldsymbol{\\theta})\\)의 분포만 알아내면 되는 것이다. 이러한 방법을 “Sandwich method”라고 한다. 자세한 내용은 (Fuentes, 2007) 강좌의 4장을 보면 된다. References "],
["42-3-directional-variogram.html", "42.3 비등방성 자료의 변동도(directional variogram)", " 42.3 비등방성 자료의 변동도(directional variogram) 몇몇 비등방성 자료에 대해서는 방향에 따라 다른 변동도를 주는 경우가 있다. 만약 \\(Z\\)가 기하학적 비등방성을 갖는다고 가정해보자. 즉, 어떤 행렬 \\(V\\)가 존재해 \\(Z(V\\mathbf{x})\\)가 비등방성 자료가 되는 것이다. "],
["42-4-r-r-variogramest.html", "42.4 R 예제(R-variogramest)", " 42.4 R 예제(R-variogramest) 이제 실제 R 예제에 대해 살펴보자. data(s100) s100.v1 &lt;- variog(s100, option=&quot;cloud&quot;) &gt; variog: computing omnidirectional variogram s100.v2 &lt;- variog(s100, max.dist=1, estimator.type=&quot;classical&quot;) &gt; variog: computing omnidirectional variogram s100.v3 &lt;- variog(s100, max.dist=1, estimator.type=&quot;modulus&quot;) &gt; variog: computing omnidirectional variogram par(mfrow=c(2,2)) plot(s100$coords[,1], s100$coords[,2], pch=&quot;x&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;locations&quot;) plot(s100.v1, main=&quot;Variogram cloud&quot;) plot(s100.v2, main=&quot;MoM estimator&quot;) plot(s100.v3, main=&quot;Robust estimator&quot;) FIGURE 42.1: Various variogram estimation methods. true &lt;- 1-matern(seq(0,1,0.1),0.3,0.5) ols &lt;- variofit(s100.v2, ini=c(0.9,0.2), cov.model=&quot;mat&quot;, fix.kappa=F, kap=1.5, nug=0.2, weights=&quot;equal&quot;) &gt; variofit: covariance model used is matern &gt; variofit: weights used: equal &gt; variofit: minimisation function used: optim wls &lt;- variofit(s100.v2, ini=c(0.9,0.2), cov.model=&quot;mat&quot;, fix.kappa=F, kap=1.5, nug=0.2, weights=&quot;cressie&quot;) &gt; variofit: covariance model used is matern &gt; variofit: weights used: cressie &gt; variofit: minimisation function used: optim par(mfrow=c(1,1)) plot(s100.v2, main=&quot;&quot;,col=&quot;blue&quot;, lwd=2) lines(seq(0,1,0.1), true, col=&quot;red&quot;) lines(ols, lwd=1.5) lines(wls, lty=2, lwd=1.5) legend(&quot;bottomright&quot;, c(&quot;true&quot;, &quot;ols&quot;, &quot;wls&quot;), col=c(&quot;red&quot;, &quot;black&quot;, &quot;black&quot;), lty=c(1,1)) FIGURE 42.2: Comparison of variogram estimation methods. "],
["43-spatlikelihood.html", "Chapter 43 공간자료에서의 가능도 기반 방법들", " Chapter 43 공간자료에서의 가능도 기반 방법들 앞 장에서는 지구통계 모형의 모수 추정을 적률 추정 또는 최소자승법에 기반한 추정으로 하는 방법들을 고려했다. 이러한 방법들을 흔히 고전 지구통계학(classical geostatistics)라고 부른다. 이 장에서는 가능도 기반 방법론들에 대해 살펴본다. (Gelfand et al. 2010)의 45쪽부터의 내용을 참고하였다. 보통 coordinate를 가지고 least square로 mean trend 제거 후(\\(\\hat{\\beta}\\) 모델링) 잔차를 이용해 variogram을 fitting한다. 그리고 variogram 모델링을 통해 \\(\\hat{\\Sigma}\\)를 구한 후 이것을 \\(\\hat{\\beta}=(X^{T}\\Sigma^{-1}X)^{-1}X^{T}\\Sigma^{-1}Z\\)에 넣어 \\(\\hat{beta}\\)를 업데이트 한다. 이것을 가지고 다시 \\(\\hat{\\Sigma}\\)를 업데이트 하는 등 iterative한 방법으로 업데이트를 많이 한다. 그러나 가능도를 사용하면 first-order-structure와 second-order-structure를 동시에 업데이트 할 수 있다고 한다. 그렇지만 우도 방법을 쓰려면 데이터의 분포 가정을 해야 한다. Empirical variogram을 사용할 때에는 데이터에 대한 분포 가정이 필요치 않다. References "],
["43-1-likelihood-based-methods.html", "43.1 가능도 기반 방법론들(likelihood-based methods)", " 43.1 가능도 기반 방법론들(likelihood-based methods) 몇 가지 가정을 먼저 하자. 먼저 \\[Z(\\mathbf{s})=\\mathbf{x}^{T}(\\mathbf{s})\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}(\\mathbf{s}), \\qquad{\\boldsymbol{\\epsilon}(\\mathbf{s}) \\sim \\text{GP}(0, C(\\cdot, \\boldsymbol{\\theta}))}\\] 와 같이 mean-structure는 선형이라고 가정한다. \\(\\epsilon(\\mathbf{s})\\)는 가우스 과정(Gaussian process)이다. 그리고 \\(\\mathbf{s}_{1}, \\cdots , \\mathbf{s}_{n}\\)에서 정의된 \\(Z(\\mathbf{s}_{1}), \\cdots , Z(\\mathbf{s}_{n})\\)에 대해 \\[\\mathbf{Z}=\\mathbf{X}^{T}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\sigma^{2}V(\\boldsymbol{\\rho}))\\] 라고 가정한다. 여기서 \\(\\boldsymbol{\\theta}=(\\sigma^{2}, \\boldsymbol{\\rho})\\)로 놓는다. \\(\\boldsymbol{\\rho}\\)는 벡터일 수도 있다. Exponential variogram model with nugget인 경우 covariance function은 (일반적인 정의와 다른 것 같으니 체크 필요) \\[ C(\\mathbf{h})= \\begin{cases} c_{0}+\\sigma^{2} &amp; \\text{if $\\mathbf{h}$=0}\\\\ \\sigma^{2}(e^{-\\frac{\\|\\mathbf{h}\\|}{R}}) &amp; \\text{if $\\mathbf{h}\\neq 0$}\\\\ \\end{cases} \\] 여기서 \\(\\sigma^{2}\\)이 \\(c_{1}\\)에 해당한다. 이 때 \\(\\boldsymbol{\\rho}=(c_{0},R)\\)이다. Covariance matrix를 계산하면 \\[ \\begin{bmatrix} c_{0}+\\sigma^{2} &amp; &amp; \\\\ \\sigma^{2}e^{-\\frac{1}{R}} &amp; \\ddots &amp; \\\\ &amp; &amp; c_{0}+\\sigma^{2}\\\\ \\end{bmatrix} \\] 식으로 나오는데, nugget 때문에 nice한 convex가 아는 wiggle한 형태가 된다. 이러한 문제를 해결하기 위해 재모수화(reparametrization)를 한다. "],
["43-2-reparametrization.html", "43.2 재모수화(reparametrization)", " 43.2 재모수화(reparametrization) 위 문제를 해결하기 위해 다음과 같이 재모수화을 한다. \\[\\phi=\\frac{c_{0}}{c_{0}+\\sigma^{2}}: \\text{ ratio of nugget to sill (일종의 parameter stabilization)}\\] 이것은 parameter들 \\(\\boldsymbol{\\theta}\\)를 \\[\\boldsymbol{\\theta}=(\\sigma^{2}, c_{0}, R) \\rightarrow (\\sigma^{2}, \\phi , R)\\] 다음과 같이 one-to-one mapping하는 것이다. 재모수화 후의 공분산 행렬은 \\[ \\sigma^{2}V(\\boldsymbol{\\theta}) = \\sigma^{2} \\begin{bmatrix} \\frac{1}{1-\\rho} &amp; &amp; \\\\ e^{-\\frac{d_{ij}}{R}} &amp; \\ddots &amp; \\\\ &amp; &amp; \\frac{1}{1-\\rho}\\\\ \\end{bmatrix} \\] 와 같이 모델링한다. 여기서 \\(d_{ij}=\\|\\mathbf{s}_{i}-\\mathbf{s}_{j}\\|\\)이다. \\(\\sigma^{2}\\)이 밖으로 빠져나와 MLE 계산이 쉽다. Exponential variogram model 뿐만 아니라 다른 모델들도 nugget이 있는 경우 재모수화를 많이 한다. "],
["43-3-mle-in-spatial-data.html", "43.3 공간자료에서의 최대가능도추정(MLE in spatial data)", " 43.3 공간자료에서의 최대가능도추정(MLE in spatial data) MLE 추정 방법의 기본 골자는 다음과 같다. \\[ \\begin{aligned} l(\\boldsymbol{\\beta},\\sigma^{2}, \\boldsymbol{\\rho})=&amp;\\log f(\\mathbf{Z};\\boldsymbol{\\beta},\\sigma^{2},\\boldsymbol{\\rho})\\\\ &amp;\\varpropto -\\frac{1}{2}\\log |\\sigma^{2}V(\\boldsymbol{\\rho})| -\\frac{1}{2\\sigma^{2}}(\\mathbf{Z}-\\mathbf{X}\\boldsymbol{\\beta})^{T}V^{-1}(\\boldsymbol{\\rho})(\\mathbf{Z}-\\mathbf{X}\\boldsymbol{\\beta})\\\\ \\end{aligned} \\] 위 식에서 각 모수들에 대해 미분을 하자. \\[\\frac{\\partial l}{\\partial \\boldsymbol{\\beta}}=0 \\rightarrow \\hat{\\boldsymbol{\\beta}}=(\\mathbf{X}^{T}V^{-1}(\\boldsymbol{\\rho})\\mathbf{X})^{-1}\\mathbf{X}^{T}V^{-1}(\\boldsymbol{\\rho})\\mathbf{Z}\\] \\[\\frac{\\partial l}{\\partial \\sigma^{2}}=0 \\rightarrow \\frac{1}{n}(\\mathbf{Z}-\\mathbf{X}^{T}\\hat{\\boldsymbol{\\beta}})^{T}V^{-1}(\\boldsymbol{\\rho})(\\mathbf{Z}-\\mathbf{X}^{T}\\hat{\\boldsymbol{\\beta}})\\] \\[\\frac{\\partial l}{\\partial f}=0\\] 또는 profile likelihood를 정의하여 문제를 풀 수도 있다. Profile likelihood의 idea를 어떤 parameter를 다른 parameter의 함수로 표현하여 모수를 줄여 푸는 것이다. \\[l*(f)=f(\\hat{\\beta}(\\boldsymbol{\\rho}), \\hat{\\sigma}^{2}(\\boldsymbol{\\rho}),\\boldsymbol{\\rho}).\\] Profile likelihood와 그냥 likelihood의 차이는 무엇일까? Likelihood인 경우 joint density, joint probability로 나타낼 수 있지만, profile likelihood인 경우 true likelihood가 아닐 수도 있다. 그 얘기는 즉 joint density, joint probability로 표현하지 못할 수도 있다는 뜻이다. 이 경우 추정에는 문제가 없으나 inference, 특히 test시 문제가 된다. 일반적으로 likelihood 사용시 쓰는 test는 LRT test이다. Profile likelihood를 사용할 경우 \\[2(l*(\\hat{\\boldsymbol{\\theta}})-l*(\\boldsymbol{\\theta_{0}})) \\sim \\chi^{2}\\] 이 식에서 \\(\\chi^{2}\\)로 점근적으로 가는 속도가 그냥 likelihood를 쓸 때보다 느려진다고 한다. 또한 bias가 생기는 문제도 있다. 이를 해결하기 위해 Bartlett Correction이라는 것을 사용한다고 한다. (BarndorfF-Nielsen 1983)이나 (Cox and Reid 1987) 등은 modified profile likelihood를 제안하기도 하였다. 더 자세한 내용을 알려면 mixed model thoery나 likelihood inference쪽 reference를 찾아보기 바란다. References "],
["43-4-restricted-mle.html", "43.4 제한된 최대가능도추정(restricted MLE)", " 43.4 제한된 최대가능도추정(restricted MLE) 다음과 같은 모델 \\[\\mathbf{Z}=\\mathbf{X}^{T}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon} \\rightarrow \\mathcal{N}(\\mathbf{X}^{T}\\boldsymbol{\\beta}, \\sigma^{2}V(\\boldsymbol{\\rho}))\\] 을 생각해보자. Restricted MLE는 mean part가 0이 되도록 변환을 해 주는 것이다. 즉 \\[w=\\mathbf{A}^{T}\\mathbf{Z}=\\mathbf{A}^{T}\\mathbf{X}^{T}\\boldsymbol{\\beta}+\\mathbf{A}\\boldsymbol{\\epsilon} \\rightarrow \\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{A}^{T}V(\\boldsymbol{\\rho})\\mathbf{A})\\] 이 likelihood를 가지고 estimation을 하는 것이다. 그렇다면 \\(\\mathbf{A}\\)를 어떻게 찾을 것인가? Harville (1974)는 \\[ \\left(\\begin{array}{l} \\mathbf{A}\\mathbf{A}^{T}=\\mathbf{I}-\\mathbf{X}(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\\\ \\mathbf{A}^{T}\\mathbf{A}=\\mathbf{I} \\end{array} \\right\\} \\text{ 이면 } \\mathbf{A}^{T}\\mathbf{X}^{T}\\boldsymbol{\\beta}=\\mathbf{0} \\] 임을 보였다. 즉 projection matrix의 linear independent한 column을 뽑아내면 된다. 또 다른 방법으로는 QR 분해를 하는 것이 있다. \\[ \\mathbf{X}_{n\\times p}=\\mathbf{Q}\\mathbf{P}=[\\mathbf{Q}_{1}, \\mathbf{Q}_{2}]_{n\\times n} \\begin{bmatrix} &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\\\ \\end{bmatrix} \\] 여기서 \\(\\mathbf{Q}\\)는 orthogonal matrix, \\(\\mathbf{R}\\)는 upper triangular matrix이다. 이 때 \\(\\mathbf{Q}_{2}=\\mathbf{A}\\)라고 한다. RMLE을 쓸 경우 \\(\\sigma^{2}=\\frac{1}{n-p}( \\cdots )\\)가 되어 불편추정량이 된다고 한다. "],
["43-5-asymptotics-of-mle-of-spatial-data.html", "43.5 공간자료 최대우도추정의 점근성(asymptotics of MLE of spatial data)", " 43.5 공간자료 최대우도추정의 점근성(asymptotics of MLE of spatial data) 공간자료에서는 크게 세 가지 asymptotic framework가 있다. Increasing domain asymptotics 가장 클래식하고 많이 쓰는 방법이다. 이 방법의 가정은 관찰 location 사이의 minimum distance가 sample size가 \\(\\rightarrow \\infty\\)이더라도 계속 \\(&gt;0\\)일 것이라는 가정이다. 즉 이 방법은 sample을 계속 뽑을수록 dist \\(&gt;0\\)이어야 하므로 domain도 같이 늘어나야 한다. 이 방법은 time series의 asymptotic과 비슷한다. Daily 시계열 자료를 생각해보면 날짜가 계속 늘어날 수 있을 것이다. 그러나 시계열에서는 한쪽방향으로만 증가할 수 있다. 즉 domain의 direction이 존재한다. 시계열 자료의 asymptotic에 주로 쓰는 마팅게일은 방향이 있는 자료밖에 못쓴다고 한다. 그래서 시계열과 비슷하더라도 같은 asymptotic을 쓰지 못한다. Fixed domain asymptotics (infill asymptotics) 이 방법은 domain이 무한정 증가하는 게 말이 안된다고 생각해서 나온 것이다. Sample size가 \\(\\rightarrow \\infty\\)일 때 minimum distance는 \\(\\rightarrow 0\\)이며 domain은 고정되어 있다고 본다. 즉 observation의 갯수가 \\(n\\)일 때, sample size 사이의 거리는 \\(O(\\frac{1}{n})\\)이라고 생각하는 것이다. 이 방법은 time series나 nonparametric setting에서 많이 쓰인다. 그러나 다른 방법들보다 보이는 것이 어려워 잘 쓰이지는 않는다. Mixed domain asymptotics (shrinking asymptotics) 이 방법은 앞 두 방법을 섞은 것이라고 생각하면 된다. Domain은 늘어나고 sample 사이의 distance는 줄어든다. 즉 observation의 갯수가 \\(n\\)일 때, sample size 사이의 거리는 \\(O(\\frac{1}{n^{\\alpha}}), 0 &lt;\\alpha &lt;1\\)이라고 생각하는 것이다. 교수님께서는 MLE에서는 보지 못했으나 MLE말고 다른 asymptotic에서는 종종 쓰인다고 하였다. 43.5.1 몇 가지 결과들(sum results about asymptotics of MLE of spatial data) Increasing domain asymptotics하의 결과들 Mardia and Marshall (1984)는 linear regression, dependence가 있는 Gaussian distribution을 따르는 모형에서의 MLE asymptotic (weak consistence, asymptotic normal)을 보였다고 한다. General한 결과는 stationary 가정도 필요없다고 한다. 이들의 결과는 Sweeting (1980)의 general CLT 결과를 이용한 것이다. Cressie and Lahiri (1993, 1996)은 REML에서의 asymptotics를 보였다고 한다. Fixed domain asymptotics (infill asymptotics)하의 결과들 이 방법은로는 general한 결과는 없고 매우 specific한 경우의 결과들만 있다. Ying (1991)은 Gaussian이고 exponential covariance model \\((\\sigma^{2}e^{-\\theta h})\\)이고 \\(d=1\\)인 경우에 \\(\\sigma^{2}\\)과 \\(\\theta\\)를 따로 estimate 할 수 없음을 보였다고 한다(MLE 포함 모든 방법이 다 안된다. Increasing domain asymptotics인 경우에는 따로 estimate하는 것이 가능하다고 한다). 그러나 곱한 경우, \\(\\sigma^{2}\\theta\\)는 MLE가 consistent함을 보였다고 한다. Ying (1993)은 \\(d \\geq 2\\)인 multiplicative covariance model (두 exponential covariance model을 곱한 것, \\(d=2\\)일 때 \\(\\sigma^{2}e^{-\\theta_{1} h_{1}-\\theta_{2}h_{2}}=\\sigma^{2}e^{-\\theta_{1}h_{1}}e^{-\\theta_{2}h_{2}})\\)이다. Anisotropic model 중 하나지만 computation이 쉬운 편이다.)로 확장하여 \\(\\sigma^{2}, \\theta_{1}, \\theta_{2}\\)를 따로 consistently하게 estimate할 수 있음을 보였다고 한다. 참고로 multiplicative covariance model은 공학에서 Gaussian process의 covariance model로 많이 쓴다고 한다. Zhang (2004)는 \\(d \\leq 3\\)인 Matern covariance model에 대하여 \\((\\sigma^{2}, \\phi, \\alpha)\\)가 따로 consistently estimated 될 수 없음을 보였다고 한다. 다만 가능한 경우는 \\(\\alpha\\)의 경우 true를 안다고 가정하고 \\(\\phi\\)는 true를 모르지만 \\(\\phi=\\phi_{1}\\)와 같이 고정할 경우 \\[\\hat{\\sigma}^{2}\\phi_{1}^{2\\alpha} \\stackrel{a.s.}{\\rightarrow} \\sigma^{2}\\phi^{2\\alpha}\\] 가 된다고 한다(consistency만 되고 asymptotic normality는 안된다). Du et al. (2009) 는 Gaussian distribution, Matern covariance, \\(d=1\\)인 경우에 (maybe consistency와) asymptotic normality를 보였다. 또한 MLE의 tapered version에 대해서도 asymptotic normality가 성립함을 보였다. Tapering에 대해서는 뒤에 다시 설명하겠다. 기타 Loh (2005, 2011), Kaufman et al (2008) 등이 있다. 이제 다음과 같은 질문을 해 볼 수 있다. Increasing domain asymptotics와 fixed domain asymptotics (infill asymptotics) 중에 어떤 방법이 더 better한 방법인가? 그리고 왜 increasing domain asymptotics는 잘 되는데 fixed domain asymptotics는 어려울까? 우선 뒤의 질문부터 답하면 모수가 microergodic parameter일 경우 추정이 잘 되나 그렇지 않으면 잘 안된다고 한다. 이것은 spatial prediction part에서 다시 설명할 것이다. 첫번째 질문에 대한 답은 Zhang and Zimmerman (2005)가 Guassian distribution을 따르는 MLE 추정에 대해서 해 본적이 있다. 방법은 asymptotic distribution 중 어떤 것이 finite sample distribution (Monte-carlo로 계산)에 가까운가이다. Exponential covariance model인 경우 \\((\\sigma^{2}e^{-\\theta h})\\) parameter가 두 framework에서 다 잘 estimated될 경우에는 둘 다 performance가 좋았으나 parameter가 not estimable할 경우에는 infill asymptotics 근사 결과가 좀 더 좋았다고 한다. "],
["43-6-computational-issues-in-spatial-statistics.html", "43.6 공간통계에서의 계산 문제들(computational issues in spatial statistics)", " 43.6 공간통계에서의 계산 문제들(computational issues in spatial statistics) 공간통계에서는 주로 \\(|\\Sigma|\\) (determinant)와 \\(\\Sigma^{-1} \\sim O(n^{3})\\), (symmetric이고 positive definite한 경우에는 order를 낮출 수 있다고 한다)을 계산해야 하는 경우가 많다. 그런데 \\(|\\Sigma|\\)나 \\(\\Sigma^{-1}\\)이 block diagonal이나 nice한 모양이 아니므로 computation이 문제되는 경우에 있다. 이는 데이터가 커지고 있는 최근에 더 문제가 된다. MLE에서의 computational issue들은 다음과 같은 것들이 있다. Inverse, determinant 계산 문제 Parameter가 많아 likelihood surface가 smooth (nice)하지 않아 어려운 경우 (보통 re-parametrization을 쓸 수 있다고 한다) 최근에는 아예 MLE가 아닌 다른 inverse-free approach를 찾는 연구 또한 활발하다고 한다. 43.6.1 공간통계에서의 계산 문제들의 해결책들(solutions about computational issues in spatial statistics) Classical Cholesky decomposition \\[\\Sigma=LL^{T}, \\text{ L은 lower triangular matrix}\\] 를 쓰는 방법이 있다. Lower triangular matrix로 바꿀 경우 linear하게 inverse를 계산할 수 있어 앞서 말했던 계산의 order가 \\(O(n)\\)으로 줄어드는 효과가 있다고 한다. 그리고 \\[|\\Sigma | = \\prod_{i=1}^{n}l_{ii}^{2}\\] 이 된다고 한다. 여기서 \\(l_{ii}\\)는 diagonal entry이다. Tapering Tapering의 의미는 ’잘라내다’라는 뜻으로, 공대나 time series 등에서 많이 사용된다고 한다. Tapering을 지칭하는 경우는 data에 tapering을 하는 경우와 covariance에 tapering을 하는 경우 두 가지가 있는데, 여기서는 covariance matrix에 tapering을 하는 것을 의미한다. 큰 자료를 다룰 때, 공분산 행렬 또한 매우 커지므로 역행렬을 계산하기 힘들어진다. 그래서 공분산 행렬의 각 원소에 compactly supported된 공분산 함수를 곱해 공분산함수를 좀 더 sparse하게 만드는 데 tapering의 목적이 있다. 그러나 sparse하게 변경된 공분산 행렬은 positive definiteness를 유지해야 한다. \\(C_{T}(h)\\)가 compact support (compact support가 아니면 곱해줘도 0이 안되어 computational gain이 없다)를 갖는 isotropic correlation function이라고 하자. Tapered covariance function \\(\\tilde{C}(h)\\)는 \\[\\tilde{C}(h)=C(h)\\cdot C_{T}(h)\\] 로 정의된다. 여기서 곱은 elementwise product (Hadamard, Schur) 인 것 같다(전미경 교수님 노트 참고). Tapered covariance matrix는 block-diagonal 형태가 되며 이런 행렬의 경우 inverse나 determinant를 더 빨리 계산하는 알고리즘들이 이미 있다고 한다. 물론 \\(\\tilde{C}(h)\\) 또한 nonnegative definite covariance인지와 같은 thoery를 justify해야 한다. 그러나 거의 일반적으로 tapering해도 nonnegative definite covariance가 그대로 유지된다고 한다. 한편 tapering을 쓰면 surface가 original보다 좀 더 wiggle해짐이 알려져 있다(sol 찾을 시 조심해야). 공분산을 국소 이웃들에만 제한하는 것은 새로운 방법은 아니다. 이런 테이퍼링 개념은 수치적 날씨 예측에도 사용되어졌고 앙상블 칼만 필터링에도 사용되어졌다고 한다. 이것과 관련된 수학적 테크닉은 (Kaufman, Schervish, and Nychka 2008)을 참고하기 바란다. References "],
["43-7-approximate-likelihood.html", "43.7 근사 가능도(approximate Likelihood)", " 43.7 근사 가능도(approximate Likelihood) 마지막으로 기타 다른 방법들에 대해서 소개한다. Vecchina (1988)은 approximate likelihood라는 것을 소개했다. \\(\\beta\\)를 회귀모수, \\(\\theta\\)를 covariance parameter, \\(\\mathbf{z}=(z_{1}, \\cdots , z_{n})\\)를 data라고 하자. 그러면 원래 likelihood를 conditional density argument를 통해 decompose할 수 있다는 아이디어에서 비롯되었다. \\[\\begin{eqnarray*} L(\\beta, \\sigma, \\mathbf{z}) &amp;=&amp; f(\\mathbf{z}, \\beta, \\sigma)\\\\ &amp;=&amp;f(\\mathbf{z}, \\beta, \\sigma) \\prod_{i=2}^{n}f(z_{i}|z_{j}, 1 \\leq j \\leq i-1, \\beta, \\theta)\\\\ \\end{eqnarray*}\\] 그 후에 적당한 subset \\(z_{im}\\)을 잡는 것이다. 즉 \\[\\begin{eqnarray*} P(X,Y)&amp;=&amp;P(X)P(Y|X)\\\\ &amp;\\approx&amp; f(\\mathbf{z},\\beta, \\theta)\\prod_{i=2}^{n}f(z_{i}|z_{j}; z_{im}\\text{은 subset of }z_{1}, \\cdots ,z_{i-1})\\\\ \\end{eqnarray*}\\] 그렇다면 얼마나 자를 것인가? 가까운 애들만 남기면 된다. Empirically, \\(n=100\\)일 때 \\(m \\approx 10\\) 정도를 쓴다고 한다. Vecchina는 theory를 안했다고 한다. 물론 80년대라서 이럴 수 있었다고 한다. Stein et al (2004)는 Vecchina의 접근을 REML에서 시도하였다. 특히 subset을 찾기 위한 몇 가지 시도들을 했고, 근사값을 계산하기 위한 방법을 제공했다. 또한 강한 spatial dependence가 있는 경우, 멀리 있는 observation 또한 고려할 필요가 있음을 보였다. "],
["43-8-pseudo-likelihood-and-composite-likelihood.html", "43.8 유사가능도와 복합가능도(pseudo-Likelihood and composite Likelihood)", " 43.8 유사가능도와 복합가능도(pseudo-Likelihood and composite Likelihood) Pseudo-likelihood의 기본적인 아이디어는 dependent data를 마치 independent data처럼 쪼개서 생각한다는 것이다. Lattice model의 conditional AR model에서도 다시 등장한다. Pseudo-likelihood는 Besag (1975)에 의해 처음 소개되었다. 그리고 Gurriero and Lele (1999)sms variogram에 대해 pseudo-likelihood를 사용하였다. \\(\\gamma(h;\\sigma)\\)를 semivariogram이라고 하자. 그리고 \\[v_{ij}\\equiv Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j})\\] 라고 하자. \\(Z\\)는 instrinsic stationary이며 normal로 assume한다. 여기서 \\(\\mathbf{s}_{i}-\\mathbf{s}_{j}=\\mathbf{h}\\)이다. 그러면 \\[v_{ij} \\sim \\mathcal{N}(0, 2\\gamma(\\mathbf{h};\\theta))\\] 이다. 만약 다른 index \\(k\\)가 존재해 \\(\\mathbf{s}_{i}-\\mathbf{s}_{k}=\\mathbf{h}\\)를 만족한다면 \\(v_{ij}\\)와 \\(v_{ik}\\)는 dependent하다. 그러나 pseudo approach에서는 independent인 것처럼 모델링한다(Handbook of sptaial statistics 52쪽). \\[f(v_{ij})=\\frac{1}{2\\pi\\sqrt{2\\gamma(\\mathbf{h};\\theta)}}\\rho^{-\\frac{1}{2}v_{ij}^{2}/2\\gamma(\\mathbf{h};\\theta)]}\\] 이며 log-likelihood는 \\[\\text{CL}(\\theta)=-\\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j&gt;i}\\{ \\frac{(Z(\\mathbf{s}_{i})-Z(\\mathbf{s}_{j}))^{2}}{2\\gamma(\\mathbf{s}_{i}-\\mathbf{s}_{j};\\theta)}+\\log \\gamma(\\mathbf{s}_{i}-\\mathbf{s}_{j};\\theta) \\}\\] 이다(수식 찾아서 확인해 볼 필요 있음). 이것의 장점은 matrix inverse나 determinant 계산이 필요가 없고 consistent estimator를 준다는 것이다. 그리고 MLE는 원래 분포가정과 실제 분포가 다를 때 misspecification이 일어나는데 여기서는 joint/bivariate distribution assumption을 안했으므로 이것에 대해 robust하다는 것 또한 장점이다. 그러나 dependency를 고려하지 않기 때문에 efficiency가 떨어진다. 비슷한 개념으로 quasi-likelihood가 있는데, GLM이나 GLMM에서 등장한다(찾아보기). Pseudo-likelihood는 generalized mixed effect model에 등장한다. 이것으로 지금까지 geostatstics에서 nonparametric/parameteric/MLE 추정에 대해 간략히 살펴보았다. "],
["44-kriging.html", "Chapter 44 크리깅", " Chapter 44 크리깅 이 문서에서는 지금까지 다뤘던 추정 방법들을 가지고 공간 예측(spatial prediction)을 하는 방법들에 대해 다루겠다. 공간 예측을 다른 말로 크리깅(Kriging)이라 부른다. 어떤 정사각형 공간에 공간적 상관관계를 가지는 자료들이 놓여있다고 가정해보자. 몇 개의 장소가 관측되어있지 않다고 했을 때, 그 결측된 장소에 대한 가장 최선의 추축은 무엇인가? 이러한 물음이 크리깅 컨셉을 생각하게 한다. 크리깅은 다른 말로 최소 선형 불편 예측(best linear unbiased prediction, BLUP)라고도 하는데, 그 장소에서 예측한 값들은 다른 장소에서 예측한 값들의 선형 결합이 된다. 이런 선형 결합의 계수를 결정하기 위해서 공분산이 중요한 역할을 하게 된다. "],
["44-1-spatial-prediction.html", "44.1 공간 예측(spatial prediction)", " 44.1 공간 예측(spatial prediction) \\(Z(\\mathbf{s})\\)를 spatial process라고 하자. 목표는 \\(n\\)개의 관측값(data) \\(\\{ Z(\\mathbf{s}_{1}), \\cdots Z(\\mathbf{s}_{n}) \\}\\)을 이용해 관측되어지지 않은 장소 \\(\\mathbf{s}_{0}\\)의 \\(Z(\\mathbf{s}_{0})\\)을 predict하는 것이다. 그런데 문제는 \\(Z(\\mathbf{s}_{0})\\)또한 확률변수라는 것이다(그래서 predict라는 말을 쓴다고 한다). 그렇다면 어떤 기준을 가지고 prediction할 것인가? 가장 일반적인 기준으로는 mean-square prediction error (MSPE)를 계산하는 것이다. 우선 몇 가지 notation들을 정리해보자. \\[\\mathbf{Z}=(Z(\\mathbf{s}_{1}), \\cdots , Z(\\mathbf{s}_{n}))^{T}: \\text{ data vector}\\] \\[Z_{0}\\equiv Z(\\mathbf{s}_{0}) \\text{ (간단히 쓰기 위함)}\\] \\[T=Z_{0}: \\text{ predict하고싶은 것}\\] \\[\\hat{T}=\\hat{Z}_{0}: \\text{ &quot;prediction&quot;}=t(\\mathbf{Z}) \\text{ ( 데이터들에 대한 함수)}\\] Prediction error를 \\((T-\\hat{T})^{2}\\)이라고 하면 MSPE는 \\(E(T-\\hat{T})^{2}\\)라고 하며 \\[\\hat{T}=\\text{argmin}_{\\tilde{T}\\in t(\\mathbf{Z})}E(T-\\tilde{T})^{2}\\] 을 만족하는 \\(\\hat{T}\\)를 best predictior (BP)라 부른다. Restriction을 걸어 다른 predction을 할 수도 있다. 예를 들면 best linear predictor (BLP), best linear unbiased predictor (BLUP)등이다. BLUP를 많이 쓴다고 한다. Random effect에서 등장하는 개념과 똑같으나 계산할 때만 spatial covariance로 넣어 계산하는 것이라고 생각할 수도 있다. 여기서 말하는 결론: \\(\\hat{T}=E(Z_{0}|\\mathbf{Z})\\) Geostatistics에서 spation prediction은 1950년대 남아공 마이닝 엔지니어 D.G. Krige의 이름을 따 크리깅(Kriging)이라 부른다. 이 크리깅의 종류는 여러가지가 있다. "],
["44-2-universal-kriging.html", "44.2 일반 크리깅(universal Kriging)", " 44.2 일반 크리깅(universal Kriging) \\[\\text{Model: } \\mathbf{Z}(\\mathbf{s})=\\mathbf{x}^{T}(\\mathbf{s})\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}(\\mathbf{s}) \\text{ (spatial dependence는 } \\boldsymbol{\\epsilon}(\\mathbf{s})\\text{에서 나온다)}\\] \\[\\text{Data: } \\mathbf{Z}=(Z(\\mathbf{s}_{1}), \\cdots , Z(\\mathbf{s}_{n}))^{T}\\] \\[\\text{Want to predict } Z_{0}=Z(\\mathbf{s}_{0})=\\mathbf{x}^{T}(\\mathbf{s}_{0})\\boldsymbol{\\beta}+\\mathbf+\\boldsymbol{\\epsilon}(\\mathbf{s}_{0})\\stackrel{let}{=}\\mathbf{x}_{0}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}_{0}\\] 일단 covariance structure가 필요하다. \\[ \\text{Cov}\\left[\\begin{array} {r} \\mathbf{Z}\\\\ Z_{0}\\\\ \\end{array}\\right] = \\left[\\begin{array} {rr} \\boldsymbol{\\Sigma}_{n\\times n} &amp; \\mathbf{T}_{n \\times 1}\\\\ \\mathbf{T}_{1\\times n}^{T} &amp; \\sigma_{0}^{2}\\\\ \\end{array}\\right] \\] 로 놓는다. 여기서 \\(\\boldsymbol{\\Sigma}=\\text{Cov}(\\mathbf{Z})\\), \\(\\mathbf{T}_{j}=\\text{Cov}(Z(\\mathbf{s}_{j}), Z_{0})\\), \\(\\sigma_{0}^{2}=\\text{Var}(Z_{0})\\)이다. 지금부터 MSPE를 minimize하는 predictor들을 찾는 방법을 다룰 것이다. 이 방법들은 공간통계에 국한된 것이 아니고 mixed effect model 등에도 해당되는 것이다. 44.2.1 라그랑즈 승수 접근법(Lagrange multiplier approach) Linear unbiased predictor \\[\\hat{Z}_{0}=\\sum_{i=1}^{n}\\lambda_{i}z_{i}=\\boldsymbol{\\lambda}^{T}\\mathbf{Z} \\text{ and } E(\\hat{Z}_{0}-Z_{0})\\] 를 가정하자. 여기서 주의하여야 할 점은 \\(Z_{0}\\)자체도 random이므로 \\(E(\\hat{Z}_{0})=Z_{0}\\)라 할 수 없다는 것이다. \\(\\mathbf{Z}=\\boldsymbol{X}^{T}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}\\)을 이용하면 \\[\\begin{eqnarray*} E(\\hat{Z}_{0})&amp;=&amp;E(\\boldsymbol{\\lambda}^{T}\\mathbf{Z})\\\\ &amp;\\Longrightarrow&amp; E(\\boldsymbol{\\lambda}^{T}(\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}))=\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}\\\\ &amp;\\Longleftrightarrow&amp; \\boldsymbol{\\lambda}^{T}\\mathbf{X}\\boldsymbol{\\beta}=\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}\\\\ &amp;\\Longleftrightarrow&amp; \\boldsymbol{\\lambda}^{T}\\mathbf{X}\\mathbf{x}_{0}^{T} \\textbf{ (unbiasedness 조건)}\\\\ \\end{eqnarray*}\\] 마지막 줄이 성립하는 이유는 \\(\\boldsymbol{\\lambda}^{T}\\mathbf{X}\\), \\(\\mathbf{x}_{0}^{T}\\)는 행렬이 아닌 벡터지만 임의의 \\(\\boldsymbol{\\beta}\\)에 대해 세번째 줄 식이 모두 만족해야 하기 때문이다. \\(E(\\hat{Z}_{0}-Z_{0})^{2}\\)을 minimize하기 위해 우선 \\[\\begin{eqnarray*} \\hat{Z}_{0}-Z_{0} &amp;=&amp; \\boldsymbol{\\lambda}^{T}(\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}-(\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}+\\epsilon_{0}))\\\\ &amp;=&amp;\\boldsymbol{\\lambda}^{T}\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}-\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}-\\epsilon_{0}\\\\ &amp;=&amp;\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}+\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}-\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}-\\epsilon_{0}\\text{ (unbiased constraint를 쓴다)}\\\\ &amp;=&amp;\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}-\\epsilon_{0} \\end{eqnarray*}\\] 마지막 식을 보면, unbiasedness 조건을 줬더니 놀랍게도 \\(\\boldsymbol{\\beta}\\)가 없어졌음을 알 수 있다. 이는 \\(\\boldsymbol{\\beta}\\)를 뭘 쓸지 고민할 필요 없이 prediction이 가능하다는 의미라고 한다. 그러면 \\(E(\\hat{Z}_{0}-Z_{0})^{2}\\)의 계산은 \\[\\begin{eqnarray*} E(\\hat{Z}_{0}-Z_{0})^{2}&amp;=&amp;E(\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}-\\epsilon_{0})^{2}\\\\ &amp;=&amp;E((\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon})^{2})+E(\\epsilon_{0}^{2})-2E(\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}-\\epsilon_{0})\\\\ &amp;=&amp;\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\Sigma}\\boldsymbol{\\lambda}+\\sigma_{0}^{2}-2\\boldsymbol{\\lambda}^{T}\\mathbf{T} \\end{eqnarray*}\\] \\(E((\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon})^{2})\\)를 계산하기 위해 \\(\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}\\)이 스칼라라는 것을 이용, \\((\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon})(\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon})^{T}=\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^{T}\\boldsymbol{\\lambda}\\)임를 이용하였다. 이제 \\(\\boldsymbol{\\lambda}^{T}\\mathbf{X}\\mathbf{x}_{0}^{T}\\) 제한이 걸린 (\\(\\star\\))를 최소화하는 문제 (constraint optimization problem)을 풀기 위해 Lagrange multiplier를 쓰도록 하자. 참고로 나중에 추정을 해야 하지만 지금은 \\(\\boldsymbol{\\Sigma}, \\sigma_{0}^{2}\\)을 안다고 가정한다. 다음 \\[ L(\\boldsymbol{\\lambda},\\boldsymbol{\\nu})=\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\Sigma}\\boldsymbol{\\lambda}-2\\boldsymbol{\\lambda}^{T}\\mathbf{T}+\\sigma_{0}^{2}-2(\\boldsymbol{\\lambda}^{T}\\mathbf{X}-\\mathbf{x}_{0}^{T})\\boldsymbol{\\nu} \\text{ (계산을 편하게 하기 위해 constraint에 2를 곱합)} \\] 식을 미분하면 minimizer를 구할 수 있다. \\[\\frac{\\partial L(\\boldsymbol{\\lambda},\\boldsymbol{\\nu})}{\\partial \\boldsymbol{\\lambda}}=2\\boldsymbol{\\lambda}^{T}\\boldsymbol{\\Sigma}-2\\mathbf{T}-2\\mathbf{X}\\boldsymbol{\\nu}=\\mathbf{0}\\] \\[\\frac{\\partial L(\\boldsymbol{\\lambda},\\boldsymbol{\\nu})}{\\partial \\boldsymbol{\\nu}}=-2(\\mathbf{x}_{0}^{T}-\\boldsymbol{\\lambda}^{T}\\mathbf{X})=0 \\] 우선 첫 번째 식으로부터 \\[\\hat{\\boldsymbol{\\lambda}}=\\boldsymbol{\\Sigma}^{-1}(\\mathbf{T}+\\mathbf{X}\\boldsymbol{\\nu})\\] 를 얻는다. 이것을 두 번째 식에 집어넣으면 \\[ \\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{T}+\\mathbf{X}\\boldsymbol{\\nu})=\\mathbf{x}_{0}\\\\ \\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{T}+\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{X}\\boldsymbol{\\nu}=\\mathbf{x}_{0}\\\\ \\therefore \\hat{\\boldsymbol{\\nu}}=(\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{X})^{-1}(\\mathbf{x}_{0}-\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{T})\\\\ \\] 가 된다. 이 식을 다시 첫 번째 식에 집어넣는다. 그러면 \\[\\hat{\\boldsymbol{\\lambda}}=\\boldsymbol{\\Sigma}^{-1}(\\mathbf{T}+\\mathbf{X}(\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{X})^{-1}(\\mathbf{x}_{0}-\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{T}))\\] 이고 \\[\\begin{eqnarray*} \\hat{Z_{0}}&amp;=&amp;\\hat{\\boldsymbol{\\lambda}}^{T}\\mathbf{Z}=(\\mathbf{T}+\\mathbf{X}(\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{X})^{-1}(\\mathbf{x}_{0}-\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{T}))^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{Z}\\\\ &amp;=&amp;\\mathbf{T}^{2}\\boldsymbol{\\Sigma}^{-1}\\mathbf{Z}+(\\mathbf{x}_{0}-\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{T})^{T}(\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{Z}\\\\ &amp;=&amp;\\mathbf{x}_{0}\\hat{\\boldsymbol{\\beta}}_{\\text{GLS}}+\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{Z}-\\mathbf{X}^{T}\\hat{\\boldsymbol{\\beta}}_{\\text{GLS}})\\\\ \\end{eqnarray*}\\] 이다. 마지막 식을 살펴보면 \\((\\mathbf{Z}-\\mathbf{X}^{T}\\hat{\\boldsymbol{\\beta}}_{\\text{GLS}})\\)는 일종의 residual로 생각할 수 있고 \\(\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1}\\)은 대응되는 적당한 weight라고 생각할 수 있다. 여기서 \\[\\hat{\\boldsymbol{\\beta}}_{\\text{GLS}}=(\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{Z}\\] 이다. 44.2.2 조건부분포 방법(conditional distribution approach) 이 방법은 라그랑지 승수법을 이용한 방법과 달리 다변량 분포의 정규성 가정이 필요하다. 즉 \\[ \\begin{pmatrix} \\mathbf{Z}\\\\ Z_{0}\\\\ \\end{pmatrix} \\sim \\mathcal{N} \\begin{bmatrix} \\begin{pmatrix} \\mathbf{X}\\boldsymbol{\\beta}\\\\ \\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}\\\\ \\end{pmatrix}, \\begin{pmatrix} \\boldsymbol{\\Sigma} &amp; \\mathbf{T}\\\\ \\mathbf{T}^{T} &amp; \\sigma_{0}^{2}\\\\ \\end{pmatrix} \\end{bmatrix} \\] 으로 가정한다. 그러면 \\(Z_{0}|\\mathbf{Z}\\)의 분포는 \\[Z_{0}|\\mathbf{Z} \\sim \\mathcal{N}(\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}+\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{Z}-\\mathbf{X}\\boldsymbol{\\beta}), \\sigma_{0}^{2}-\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{T})\\] 가 된다. 조건부 기댓값을 구하는 공식에 의해 \\(\\hat{Z}_{0}\\)을 정할 수 있다. \\[\\hat{Z}_{0}=E(Z_{0}|\\mathbf{Z})=\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}+\\mathbf{T}^{T}\\Sigma^{-1}(\\mathbf{Z}-\\mathbf{X}\\boldsymbol{\\beta}).\\] 그런데 이 추정량은 알려지지 않은 \\(\\boldsymbol{\\beta}\\)가 들어있어 문제가 된다. 그래서 실제 문제에서 이대로 쓰지 못한다. 따라서 \\[\\hat{Z}_{0}\\Longrightarrow \\mathbf{x}_{0}^{T}\\hat{\\boldsymbol{\\beta}}+\\mathbf{T}^{T}\\Sigma^{-1}(\\mathbf{Z}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}})\\] 로 바꿔 사용한다(참고로 normal 가정시 BP=BLP=BLUP라고 한다). 44.2.3 베이지안 방법(Bayesian approach) 여기서도 조건부 분포 방법과 마찬가지로 다변량 분포의 정규성 가정이 필요하다. \\[ \\begin{pmatrix} \\mathbf{Z}\\\\ Z_{0}\\\\ \\end{pmatrix} \\sim \\mathcal{N} \\begin{bmatrix} \\begin{pmatrix} \\mathbf{X}\\boldsymbol{\\beta}\\\\ \\mathbf{x}_{0}^{T}\\boldsymbol{\\beta}\\\\ \\end{pmatrix}, \\begin{pmatrix} \\boldsymbol{\\Sigma} &amp; \\mathbf{T}\\\\ \\mathbf{T}^{T} &amp; \\sigma_{0}^{2}\\\\ \\end{pmatrix} \\end{bmatrix} \\] 이때 \\[\\Sigma=\\sigma^{2}V(\\theta), \\mathbf{T}=\\sigma^{2}W(\\theta), \\sigma_{0}^{2}=\\sigma^{2}\\] 으로 놓는다. 그 다음에는 \\(\\boldsymbol{\\beta}, \\sigma^{2}, \\theta\\)(보통 1,2차원이라 가정한다)에 대한 사전분포를 만들어야 한다. 일반적으로 이 사전분포는 \\[\\propto \\pi(\\theta)\\cdot \\frac{1}{\\sigma^{2}}\\] 로 준다. \\(\\boldsymbol{\\beta}\\)는 flat prior를 주며 \\(\\pi(\\theta)\\)는 parameter에 따라 바뀐다. 가능하면 사전분포의 contribution을 없애고 싶기 때문에 이렇게 놓는다고 한다. Bayesian setting에서는 \\(Z_{0}|\\mathbf{Z}\\)에 \\(Z_{0}|\\mathbf{Z}, \\boldsymbol{\\beta}, \\sigma^{2}, \\theta\\)(이 분포는 알고 있는 분포이다)가 숨어있는 꼴이라고 한다. \\(\\pi(Z_{0}|\\mathbf{Z})\\)를 만들려면 \\(\\boldsymbol{\\beta}, \\sigma^{2}, \\theta\\)에 대해 적분해야 한다. 먼저 \\(\\boldsymbol{\\beta}\\)에 대해 decompose를 이용해 적분하면 \\[\\begin{eqnarray*} \\pi(Z_{0}|\\mathbf{Z},\\sigma^{2},\\theta)&amp;=&amp;\\int \\pi(Z_{0},\\boldsymbol{\\beta}|\\mathbf{Z},\\sigma^{2},\\theta)d\\mathbf{\\beta}\\\\ &amp;=&amp; \\int \\pi(Z_{0}|\\mathbf{Z},\\boldsymbol{\\beta},\\sigma^{2},\\theta)\\pi(\\boldsymbol{\\beta}|\\mathbf{Z},\\sigma^{2},\\theta)d\\mathbf{\\beta}\\\\ \\end{eqnarray*}\\] 으로 구할 수 있다. 같은 방법으로 \\(\\sigma^{2}\\)에 대해서도 적분하면 \\[\\pi(Z_{0}|\\mathbf{Z},\\theta)=\\int \\pi(Z_{0},\\sigma^{2}|\\mathbf{Z},\\theta)d\\sigma^{2}\\] 으로 구할 수 있다. 여기까지는 explicit form이 잘 나온다고 한다. 그리고 \\(\\theta\\)에 대해서도 마찬가지로 적분할 수 있는데 \\[\\begin{eqnarray*} \\pi(Z_{0}|\\mathbf{Z})&amp;=&amp;\\int\\pi(Z_{0},\\theta |\\mathbf{Z})d\\theta\\\\ &amp;=&amp;\\int\\pi(Z_{0}|\\mathbf{Z}, \\theta )\\cdot\\pi(\\theta)d\\theta\\\\ \\end{eqnarray*}\\] 이다. 그런데 여기서는 explicit form이 잘 안나와 보통 numerical integration을 한다고 한다. 이 방법의 장점은 앞선 두 방법들과 달리 \\(\\Sigma\\), \\(\\sigma_{0}^{2}\\)을 알 필요가 없다는 것이다. 라그랑지 승수법과 조건부 분포를 이용한 방법은 \\(\\hat{\\Sigma}\\), \\(\\hat{\\sigma}_{0}^{2}\\)를 통해 uncertainty가 늘어나는데 이 방법은 그렇지 않다. 그리고 \\(\\hat{\\phi}=(\\hat{\\boldsymbol{\\beta}}, \\hat{\\sigma}^{2}, \\hat{theta})\\)로 parameterization했을 때에도 unbiased한지 optimal한지 체크해야 하는데, 어떠한 조건이 주어질 경우 된다고 한다. 44.2.4 덩어리 효과가 있는 모형의 크리깅(Kriging for the model with a nugget effect) 지금까지 크리깅은 nugget 효과가 없다는 가정에서 진행하였다. 그렇다면 nugget이 있는 경우에는 어떻게 되는가? \\(Z(\\mathbf{s})\\)에 대해 다음과 같은 decomposition을 할 수 있다. \\[Z(\\mathbf{s})=x(\\mathbf{s})^{T}\\boldsymbol{\\beta}+\\eta(\\mathbf{s})+\\epsilon(\\mathbf{s}).\\] 이것에 대한 자세한 내용은 Cressie 책 112쪽을 참고하기 바란다. 그러면 \\(\\boldsymbol{\\Sigma}\\)가 \\(\\boldsymbol{\\Gamma}\\)로 대체된다. \\[\\boldsymbol{\\Gamma}=\\boldsymbol{\\Sigma}+C_{0}\\mathbf{I}\\] 여기서 \\(\\boldsymbol{\\Sigma}\\)는 \\(\\eta(\\mathbf{s})\\)의 covariance structure, \\(C_{0}\\mathbf{I}\\)는 \\(\\epsilon(\\mathbf{s})\\)에 대한 covariance structure이다. 어쨌든 결론은 nugget이 커지면 prediction 결과도 spread out (퍼짐)한다는 것이다. "],
["44-3-prediction-error-in-kriging.html", "44.3 크리깅의 예측오차(prediction error in Kriging)", " 44.3 크리깅의 예측오차(prediction error in Kriging) 크리깅에 대해서 다시 살펴보면, 관측하지 않은 \\(\\mathbf{s}_{0}\\)지점을 \\[\\hat{Z}_{0}\\equiv \\hat{Z}(S_{0})\\] 으로 예측하는 것이다. 그러나 실제로 \\(\\hat{Z}_{0}=\\hat{Z}_{0}(\\boldsymbol{\\psi})\\), \\(\\boldsymbol{\\psi}\\)는 covariance parameter들의 set인데 이 parameter들을 모르므로 \\(\\hat{Z}_{0}(\\hat{\\boldsymbol{\\psi}})\\) (이것을 추정하는 것, OLS, WLS, MLE, REML, empirically 하는 것이 저번시간에 했던 내용들)로 해야한다. 즉 \\(\\boldsymbol{\\psi} \\rightarrow \\hat{\\boldsymbol{\\psi}}\\)로 할 때 추가 error가 발생하는 것이다. 다시 말하면 \\(\\hat{Z}_{0}(\\hat{\\boldsymbol{\\psi}})\\)는 MSPE를 overestimate하는 것이다. 그래서 다음과 같은 correction을 한다. \\[ \\begin{aligned} \\hat{m}(\\boldsymbol{\\psi})=E(Z_{0}(\\hat{\\boldsymbol{\\psi}})-Z_{0})^{2}&amp;=E(Z_{0}(\\hat{\\boldsymbol{\\psi}})-Z_{0}(\\boldsymbol{\\psi})+Z_{0}(\\boldsymbol{\\psi})-Z_{0})^2\\\\ &amp;=E(Z_{0}(\\hat{\\boldsymbol{\\psi}})-Z_{0}(\\boldsymbol{\\psi}))^{2}+E(Z_{0}(\\boldsymbol{\\psi})-Z_{0})^2\\\\ &amp;\\geq E(Z_{0}(\\boldsymbol{\\psi})-Z_{0})^2 \\end{aligned} \\] 여기서 \\(E(Z_{0}(\\hat{\\boldsymbol{\\psi}})-Z_{0}(\\boldsymbol{\\psi}))^{2}=m&#39;(\\boldsymbol{\\psi})\\)라 하고 \\(E(Z_{0}(\\boldsymbol{\\psi})-Z_{0})^2=m(\\boldsymbol{\\psi})\\)라 하면 \\(\\hat{m}(\\boldsymbol{\\psi})\\)에서 \\(m&#39;(\\boldsymbol{\\psi})\\)를 빼내어 \\(m(\\boldsymbol{\\psi})\\)에 가깝게 만든다고 한다(correction). 사실 application이 굉장히 많고 공간통계학 뿐만 아니라 random effect prediction에서도 생기는 문제라고 한다. 그런데 공간통계학자들은 이 예측오차를 무시하고 그냥 할 때가 많고 random effect쪽은 자료가 독립이라 간단하게 된다고 한다. 이 문제를 깊게 다루는 분야는 small area estimation이니 관심있으면 찾아보는 것이 좋다. 또한 Bayesian 입장에서는 \\(\\boldsymbol{\\psi}\\)를 integrated out하므로 \\(\\pi(Z_{0]|\\mathbf{Z}})\\)하는 것이 큰 문제가 되지 않는다. 그러나 numerical integration이 문제가 된다. "],
["44-4-other-krigings.html", "44.4 다른 크리깅들(other Krigings)", " 44.4 다른 크리깅들(other Krigings) Universal kriging 이외에 다른 방법들은 간단히 소개만 하고 넘어갈 것이다. Simple kriging: \\(\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta} \\rightarrow \\boldsymbol{\\mu}\\) \\[\\hat{Z}_{0}=\\hat{\\boldsymbol{\\mu}}+\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{Z}-\\hat{\\boldsymbol{\\mu}}\\cdot \\mathbf{1}), \\hat{\\mathbf{\\mu}}=\\bar{\\mathbf{Z}}.\\] 여전히 covariance parameter들은 안다고 가정한다. 특히 평균은 알려져 있다고 가정하거나 0이라고 놓는다. Ordinary kriging: \\(\\mathbf{x}_{0}^{T}\\boldsymbol{\\beta} \\rightarrow \\boldsymbol{\\mu}\\) \\[\\hat{Z}_{0}=\\tilde{\\boldsymbol{\\mu}}+\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{Z}-\\tilde{\\boldsymbol{\\mu}}\\cdot \\mathbf{1}), \\tilde{\\boldsymbol{\\mu}}=(\\mathbf{1}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{1})^{-1}\\mathbf{1}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{Z}.\\] 여기서 \\(\\tilde{\\boldsymbol{\\mu}}\\)는 \\(\\boldsymbol{\\mu}\\)의 GLS solution이며 ordinary kriging은 universal kriging의 special case이다. 만약 \\(\\hat{Z}_{0}\\)를 prediction weight (\\(\\boldsymbol{\\psi}\\)의 함수) \\(\\lambda_{i}\\)와 \\(Z(\\mathbf{s}_{i})\\)의 linaer combination으로 생각한다면 \\(\\hat{Z}_{0}=\\sum_{i=1}^{n}\\lambda_{i}Z(\\mathbf{s}_{i})\\)로 쓸 수 있다. Simple kriging의 경우는 \\[\\begin{eqnarray*} \\hat{Z}_{0}&amp;=&amp;(1-\\sigma_{i}\\lambda_{i})\\boldsymbol{\\mu}+\\boldsymbol{\\lambda}^{T}\\mathbf{Z} \\qquad(\\boldsymbol{\\lambda}=\\mathbf{T}^{T}\\boldsymbol{\\Sigma}^{-1})\\\\ &amp;=&amp;(1-\\sigma_{i}\\lambda_{i})\\boldsymbol{\\mu}+\\sum_{i}\\lambda_{i}Z(\\mathbf{s}_{i})\\\\ &amp;=&amp;\\text{global mean + data로부터 나오는 mean}\\\\ \\end{eqnarray*}\\] 으로 \\(\\hat{\\boldsymbol{\\mu}}=\\bar{\\mathbf{Z}}\\)로 했기 때문에 global mean이 없어지지 않고 남는다. 한편 ordinary kriging의 경우는 \\(\\sum_{i}\\lambda_{i}=1\\)이라는 제약조건 하에 \\(\\hat{Z}_{0}=\\sum_{i}\\lambda_{i}Z(\\mathbf{s}_{i})\\)로 표현 가능하다. 참고로 universal kriging인 경우에 constraint는 \\(\\boldsymbol{\\lambda}^{T}\\mathbf{x}=x_{0}\\)이라는 제약조건이 있다. 참고로 크리깅 자체는 stationary 가정이 필요 없다. 다만 나중에 \\(\\Sigma\\) 추정시 문제가 될 수 있다고 한다. "],
["44-5-more-krigings.html", "44.5 추가적인 크리깅들(more Krigings)", " 44.5 추가적인 크리깅들(more Krigings) Co-kriging (kriging의 multivariate case) 예를 들면 weather station에 있는 기온, 습도, 풍속 데이터 등을 크리깅할 경우가 이에 해당한다. 한 장소에 \\(p\\)개의 데이터 \\[\\mathbf{Z}(\\mathbf{s})=(Z_{1}(\\mathbf{s}), \\ldots, Z_{p}(\\mathbf{s}_{n}))\\] 이 있다고 하자. 여기서 \\(Z_{1}(\\mathbf{s}_{0})\\)을 예측하고 싶다고 하자. 추가로 \\(E(\\mathbf{Z}(\\mathbf{s}))=\\boldsymbol{\\mu}=(\\mu_{1}, \\ldots , \\mu_{n})^{T}\\), \\[ \\text{Cov}(\\mathbf{Z}(\\mathbf{s}),\\mathbf{Z}(\\mathbf{t}))=C(\\mathbf{s},\\mathbf{t})= \\begin{bmatrix} C_{11}(\\mathbf{s},\\mathbf{t}) &amp; \\ldots &amp; C_{1p}(\\mathbf{s},\\mathbf{t}) \\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ C_{p1}(\\mathbf{s},\\mathbf{t}) &amp; \\ldots &amp; C_{pp}(\\mathbf{s},\\mathbf{t}) \\end{bmatrix} \\] 이다\\((p\\times p\\) matrix). Cross-covariance에 대한 모델링이 추가로 필요하다. 다음과 같은 linear unbiased predictior \\(\\hat{Z}_{1}(\\mathbf{s}_{0})=\\sum_{i}^{n}\\sum_{j}^{p}\\lambda_{ji}Z_{j}(\\mathbf{s}_{i})\\)를 생각하보자. unbiasedness에 의해 constraint가 나온다. \\[E(\\hat{Z}_{1}(\\mathbf{s}_{0})-Z_{1}(\\mathbf{s}_{0}))=0 \\rightarrow \\sum_{i}^{n}\\lambda_{ji}=1, \\sum_{i=1}^{n}\\lambda_{ji}=0 \\qquad \\text{for } j=2,\\ldots, p (unbiased constraints).\\] 그러면 \\[\\text{MSPE}=E(Z_{1}(\\mathbf{s}_{0})-\\sum_{i=1}^{n}\\sum_{j=1}^{p}\\lambda_{ji}Z_{j}(\\mathbf{s}_{i})) \\qquad{\\text{under some constraints.}}\\] 로 크리깅을 할 수 있다. 복잡하지만 라그랑지 승수법으로 계산 가능하다고 한다. Trans-Gaussian Kriging 이 방법은 자료가 가우시안이 아닐 경우 어떡할 것인가로부터 시작했다. \\(\\mathbf{Z}(\\mathbf{s})\\)가 가우시안이 아니라고 하자. 만약 변환을 통해 만들어진 \\(\\mathbf{Y}(\\mathbf{s})\\) \\[\\mathbf{Y}(\\mathbf{s})=h(\\mathbf{Z}(\\mathbf{s}))\\] 가 가우시안일 경우 모델링 할 수 있다는 것이다. 여기서 잠시 자료가 가우시안인지 아닌지 어떻게 검정할 것인가라는 문제가 있는데, 자료가 독립일 경우 Q-Q plot 또는 Kolmogorov-Sminov 검정 등을 한다고 한다. 공간통계학자들의 경우 검정보다는 그냥 모델링에 관심을 갖는다. \\(\\mathbf{Z}(\\mathbf{s_{0}})\\)으로부터 \\(E(\\mathbf{Z}(\\mathbf{s_{0}})|\\mathbf{Z})\\)를 예측하고 싶어한다. 이 때 가우시안 가정은 필요치 않으나 가우시안이 아닐 경우 이 predictor가 optimal이 아닐 수도 있다고 한다. 실제로 \\(E(\\mathbf{Z}(\\mathbf{s_{0}})|\\mathbf{Z})\\)의 추정량 \\(\\hat{E}(\\mathbf{Z}(\\mathbf{s_{0}})|\\mathbf{Y})\\)을 구할 수 있는 \\(h\\)는 몇 개 없다고 한다. 구할 수 있는 가장 대표적인 \\(h\\)는 log-normal로, 이 때의 \\(Z\\)를 log-normal process라고 부른다. Indicator Kriging 지금까지는 조건부 기댓값을 예측했지만, 이번에는 확률을 예측하고 싶어한다. 예를 들면, \\(Z(s_{1}), \\ldots , Z(s_{n})\\)이라는 자료를 사용 가능할 때 \\(s_{0}\\)라는 장소의 비가 \\(c\\) 이상 올 확률에 대해 알고 싶어한다고 하자. 즉, \\[P(Z(s_{0})&gt;c |\\mathbf{Z})=E(I(Z(s_{0})&gt;c)|\\mathbf{Z})=P(Y(s_{0})|\\mathbf{Z})\\] 에 대해 알고싶어한다. 한 가지 방법은 indicator observation \\((0,1)\\)로 크리깅하는 것이다. Ordinary kriging에 의해 \\[\\hat{P}(Z(s_{0})&gt;c|\\mathbf{Z})=\\hat{mu}_{Y}+\\mathcal{T}_{Y}^{T}\\Sigma_{Y}^{-1}(\\mathbf{Y}-\\hat{\\mu}_{Y}\\mathbf{1})\\] 식이 성립한다. \\(\\hat{\\mathcal{T}}_{Y}\\), \\(\\hat{\\Sigma}_{Y}\\) 대신 \\(\\hat{\\mathcal{T}}_{Z}\\), \\(\\hat{\\Sigma}_{Z}\\)와의 관게를 이용해 바꿔넣기도 한다고 한다. 그리고 \\(c\\)는 보통 분위수를 threshold로 잡게끔 한다고 한다. 또한 예를 들면 \\(P(Z(s_{0})&gt;0.1)&gt;P(Z(s_{0})&gt;0.2)\\)가 안되거나 음의 확률이 나올 수 있어 잘 correction을 해 주어야 한다. 더불어 extreme quantile에 대해 잘 작동하지 않으므로 따로 모델링하거나 아예 다른 방법(분위수 회귀분석 등)을 쓰기도 한다고 한다. Indicator kriging은 image segmentation 시 clustering 대용으로 쓸 수 있다고 한다. Disjunctive kriging 이 방법은 trans-Gaussian과 비슷하게 Gaussian이 아닐 시 쓰는 방법이라고 한다. 지금까지의 결과로 best predictor는 conditional mean임을 안다. 그런데 특히 Gaussian일 때에는 이 predictor가 선형이면서 간단하게 된다. 그러나 그렇지 않을 경우에는 어떻게 할 것인가? Disjuntive kriging에서는 좀 더 일반화시켜 문제를 풀려고 하는 것이다. \\(E(Z(s_{0})|Z(s_{1}),\\ldots , Z(s_{n}))\\)을 \\(Z(s_{1}), \\ldots, Z(s_{n})\\)에 의해 span되는 공간(기댓값을 노름으로 생각하는 공간)으로의 orthogonal projection이라고 하자. 그리고 다음과 같은 가법모형을 고려하는 것이다. \\[\\hat{Z}(s_{0})=\\sum_{i=1}^{n}f_{i}(Z(s_{i})).\\] 물론 이 방법은 당연히 좀 더 일반화된 방법이나 \\(\\hat{f}_{i}\\)을 찾는게 어렵다는 문제점이 있다. 이 방법은 \\[E(Z(s_{0})|Z(s_{j}))=\\sum_{i=1}^{n}E(f_{i}(Z(s_{i}))|Z(s_{j})), \\qquad{j=1,\\ldots, n}\\] 을 만족하는 \\(f_{i}\\)들을 찾는 것이다. Best predictor \\(E(Z(s_{0})|Z(s_{1}),\\ldots ,Z(s_{n}))\\)은 \\((Z(s_{1}),\\ldots ,Z(s_{n}))\\)의 결합분포를 계산하여야 한다. 그러나 \\(E(Z(s_{0})|Z(s_{j}))\\)는 이변량 구조만 알면 되므로 좀 더 간단해지는 장점이 있다고 한다. \\(f_{i}\\)의 후보가 너무 많은 문제의 한 가지 해결책을 Hermite polynomial을 기저로 하는 애들로 \\(f_{i}\\)를 표현하는 방법이 있다. 이 방법을 쓰면 Hermite polynomial의 계수만 찾으면 된다. "],
["45-simGaussian.html", "Chapter 45 가우스과정의 시뮬레이션", " Chapter 45 가우스과정의 시뮬레이션 여기서는 \\(\\mathbf{Z}\\sim \\mathcal{N}(0,\\Sigma)\\)를 따르는 \\(Z(s_{1}),\\ldots, Z(s_{n})^{T}\\)를 생성하는 방법에 대해 다룬다. "],
["45-1-direct-method-exact.html", "45.1 Direct method (Exact)", " 45.1 Direct method (Exact) 이 방법은 근사 방법들이 아니다. Cholesky decomposition: \\(\\Sigma\\)가 symmetric이고 positive definite matrix이므로 \\[\\boldsymbol{\\Sigma} =LL^{T}\\] 로 쓸 수 있다. 여기서 \\(L\\): lower triangular matrix이며 standard normal을 생성할 수 있다는 가정 하에 다음과 같이 얻을 수 있다. \\[\\mathbf{Z}=\\mathbf{LW}, \\mathbf{W}\\sim\\mathcal{N}(0,\\mathbf{I}), \\text{var}(\\mathbf{Z})=\\mathbf{L}\\text{var}(\\mathbf{w})\\mathbf{L}^{T}=\\boldsymbol{\\Sigma}\\] SVD: symmetric이고 positive deifinite인 행렬 \\(\\boldsymbol{\\Sigma}\\)에 대해 \\[\\boldsymbol{\\Sigma}=\\mathbf{UAU}^{T}\\] 임을 안다. 이 때 \\(\\mathbf{A}\\)는 eigenvalue들의 diagonal matrix이며 \\(\\mathbf{U}\\mathbf{U}^{T}=\\mathbf{I}\\), \\(\\mathbf{U}^{T}\\mathbf{U}=\\mathbf{I}\\)이고 \\(\\mathbf{U}\\)의 column이 normalized eigenvector들로 구성된다. 좀 더 일반적으로 \\[\\mathbf{Z}=\\mathbf{U}\\boldsymbol{\\Lambda}^{T}\\mathbf{W}\\] 이고 \\(\\text{var}(\\mathbf{Z})=\\mathbf{U}\\boldsymbol{\\Lambda}^{\\frac{1}{2}}\\text{var}(\\mathbf{W})(\\mathbf{U}\\boldsymbol{\\Lambda}^{\\frac{1}{2}})^{T}=\\boldsymbol{\\Sigma}\\)이다. 그러나 일반적으로 Cholesky와 SVD는 \\(n\\)이 커지면 계산 시간이 오래 걸리게 된다. 이를 해결하기 위해 몇가지 방법들을 소개한다. "],
["45-2-circulant-embedding-methods.html", "45.2 Circulant embedding methods", " 45.2 Circulant embedding methods (G. Chan and Wood 1997)은 regular lattice 자료인 경우 circulant matrix를 사용하는 방법을 제안했다. 원하는 행렬보다 더 큰 행렬을 만들고(closed-form 가능한 것으로) 그 후에 sub-sampling을 하는 것이다. \\(d=1\\)일 때에는 exact, \\(d&gt;1\\)일 때에는 근사 방법이다. \\(d=1\\)인 경우 \\((Z(s_{0}), Z(\\frac{1}{n}),\\ldots, Z(\\frac{n-1}{n}))\\sim\\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma})\\)를 생성하고 싶다고 하자. 특별히 \\(\\Sigma=C(u)\\)라고 하자. 그러면 \\[ \\boldsymbol{\\Sigma}= \\begin{bmatrix} C(0) &amp; C(\\frac{1}{n}) &amp; C(\\frac{2}{n}) &amp; &amp; \\\\ C(\\frac{1}{n}) &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\\\ &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; C(\\frac{2}{n}) \\\\ &amp; &amp; \\ddots &amp; \\ddots &amp; C(\\frac{1}{n}) \\\\ &amp; &amp; &amp; C(\\frac{1}{n}) &amp; C(0) \\\\ \\end{bmatrix} \\] 와 같이 Toeplitz 행렬을 만들 수 있다. \\(\\boldsymbol{\\Sigma}\\)으로 \\(m\\times m (&gt;n)\\) circulant covariance matrix (이것은 FFT로 closed form expression이 있음) \\(\\mathbf{G}\\)를 만든다. (\\(m\\)은 dyadic이고 \\(m \\geq 2(n-1)\\)이다.) \\[ \\mathbf{G}= \\begin{bmatrix} g_{0} &amp; g_{1} &amp; \\cdots &amp; g_{n-1}\\\\ g_{n-1} &amp; g_{0} &amp; \\cdots &amp; g_{n-2}\\\\ &amp; \\ddots &amp; \\ddots &amp; \\vdots\\\\ &amp; &amp; \\cdots &amp; g_{0}\\\\ \\end{bmatrix} \\] 이고 \\(g_{j}\\)는 다음과 같다. \\[ g_{j}= \\begin{cases} C(\\frac{j}{n}) &amp; \\text{if } 0 \\leq j \\leq \\frac{m}{2} \\\\ C(\\frac{m-j}{n}) &amp; \\text{if } x \\frac{m}{2} \\leq j \\leq m-1 \\end{cases}. \\] 이 방법은 1차원일 경우 항상 유효한 공분산 행렬(nonnegative definite)을 보장해 주지만, 차원이 1보다 클 경우 nonnegative definite를 만들기 위해 추가적인 근사가 들어간다. 이것은 추후에 설명하기로 한다. FFT를 써서 \\[\\mathbf{G}=\\mathbf{Q}\\boldsymbol{\\Lambda}\\mathbf{Q}^{*}, \\mathbf{Q}\\mathbf{Q}^{*}=\\mathbf{I}=\\mathbf{Q}^{*}\\mathbf{Q} \\qquad{\\text{unitary}}\\] 를 만족하는 \\(\\mathbf{Q}\\)와 \\(\\boldsymbol{\\Lambda}\\)를 찾는다. 이 때 \\(\\boldsymbol{\\Lambda}=\\{\\lambda_{1},\\ldots,\\lambda_{m} \\}\\)이다. Circulant이면 \\(\\mathbf{Q}, \\boldsymbol{\\lambda}\\)를 쉽게 찾을 수 있다고 한다. 추가적으로 \\(\\lambda_{k}=\\sum_{j=0}^{m-1}g_{j}\\exp\\{ -\\frac{2\\pi i j k}{m} \\}\\), \\(\\mathbf{Q}=\\{Q_{j,k}\\}\\), \\(Q_{j,k}=\\frac{1}{\\sqrt{m}}\\exp\\{-\\frac{\\pi i j k}{m}\\}\\)이라고 한다. 여기서 \\(i\\)는 모두 복소수이다. \\(\\mathbf{Z}_{j}=\\mathbf{Q}\\boldsymbol{\\Lambda}^{\\frac{1}{2}}\\mathbf{Q}^{*}\\mathbf{W}, \\mathbf{W}\\sim\\mathcal{N}(\\mathbf{0}, \\mathbf{I}), \\text{var}(\\mathbf{Z}_{0})=\\mathbf{G}\\)로 얻을 수 있다. 여기서 \\(\\mathbf{Z}_{0}\\)중 처음 \\(n\\)개의 표본을, \\(\\mathbf{G}\\)에서는 처음 \\(n\\times n\\)행렬을 취하면 된다. 그러면 1차원이 아닐 때의 대처 방법에 대해 알아보자. 이때는 block circulant matrix를 \\(\\boldsymbol{\\Sigma}\\)를 얻기 위한 공분산 행렬로 사용한다. 이것은 periodic random field의 공분산으로 볼 수 있다. 둘레를 \\(\\mathbf{R}\\)이라고 하면 \\(\\mathbf{Z}(\\mathbf{s})=\\mathbf{Z}(\\mathbf{s+R})\\)이 된다고 한다. 즉 2차원에서 이것은 torus 위에서 정의되는 임의장이 된다. Block circulant matrix 또한 푸리에 변환을 통해 쉽게 \\(\\mathbf{Q}\\boldsymbol{\\Lambda}\\mathbf{Q}^{*}\\) 식의 변환이 가능하다고 한다. 그러나 (G. Chan and Wood 1997)의 방법은 \\(m\\)이 매우 크지 않은 이상 \\(\\mathbf{G}\\)의 non-negative definiteness를 보장해 주지 못한다. non-negative definiteness를 다루는 방법 중 하나로 다음과 같은 방법이 있다. \\[\\mathbf{G}=\\mathbf{Q}\\boldsymbol{\\Lambda}\\mathbf{Q}^{*}=\\mathbf{Q}(\\boldsymbol{\\Lambda}_{+}-\\boldsymbol{\\Lambda}_{-})\\mathbf{Q}^{*}\\] 라고 할 때 근사를 더 좋게 하는 scaling factor \\(\\rho\\)를 이용해 \\[\\tilde{\\mathbf{G}}=\\rho^{2}\\mathbf{Q}\\boldsymbol{\\Lambda}_{+}\\mathbf{Q}^{*}\\] 로 놓는 것이다. 이 때 \\(\\rho\\)의 선택으로는 \\(\\rho_{1}=\\frac{\\text{tr}(\\boldsymbol{\\Lambda})}{\\text{tr}(\\boldsymbol{\\Lambda})_{+}}\\) (\\(\\boldsymbol{\\Lambda}_{-}\\)를 무시함으로써 생기는 distributional error를 최소화 하는 것), \\(\\rho_{1}=(\\frac{\\text{tr}(\\boldsymbol{\\Lambda})}{\\text{tr}(\\boldsymbol{\\Lambda})_{+}})^{\\frac{1}{2}}\\) (1차원 marginal variance가 같도록 하는 것) 등이 있다. References "],
["45-3-simulation-of-fractional-browninan-surfaces.html", "45.3 Simulation of Fractional Browninan Surfaces", " 45.3 Simulation of Fractional Browninan Surfaces 앞선 circulant embedding methods의 방법은 stationary Gaussian인 lattice model에서만 된다는 문제점이 있다. 그렇다면 nonstationary이면서 size가 큰 경우(작으면 direct 방법을 쓰면 됨)에는 어떤 방법을 쓸 수 있을까? 그에 대한 해결책 중의 하나로 (M. L. Stein 2002)가 제안한 방법이 있다. Fractional Brownian surfaces는 \\(\\text{var}(\\mathbf{Z}(\\mathbf{X})-\\mathbf{Z}(\\mathbf{Y})) \\propto |\\mathbf{X}-\\mathbf{Y}|^{\\alpha} \\propto \\in (0,2)\\)인 class들로 intrinsic stationary하다. 이 fractional Brownian surfaces는 time series의 long memory, fractal dimension (\\(d+1-\\frac{\\alpha}{2}\\))와 관련이 있다고 한다. 예를 들면 $((),())||^{} + ||^{} - ||^{} $인 것이 이 클래스에 속하게 된다. 아이디어는 다음과 같다. \\(\\mathbb{R}\\)에서 연속이고 isotropic covariance (positive definite를 의미) functions의 클래스인 \\(\\mathcal{D}_{d}\\)의 원소 \\(K\\in\\mathcal{D}_{d}\\)를 찾고자 하는 것이다. 예를 들면, 다음과 같은 \\(K\\) \\[ K(r)= \\begin{cases} c_{0}-r^{\\alpha}+c_{2}r^{2} &amp; 0 \\leq r \\leq 1 \\\\ K_{1}(r) &amp; 1 &lt; r \\leq R \\\\ 0 &amp; r &gt; R \\end{cases} \\] 가 있으면, \\(K\\in \\mathcal{D}_{d}\\)인 \\(c_{0}, c_{2}, K, r\\)만 찾으면 되는 것이다. 이 때 \\(R\\geq 1, c_{2}\\geq 0, K\\)는 \\(K\\in\\mathcal{D}_{d}\\)을 만들 때 아무런 제약이 없다. \\(\\rho_{R}^{d}K\\)를 \\(\\rho_{R}^{d}K(x)=K(|x|)\\) for \\(x\\in [-R,R]^{d}\\)로 정의하고 \\(\\rho_{R}^{d}K(x)\\)는 각 좌표에서 \\(2R\\)의 주기를 갖는다고 하자. 그러면 \\(\\rho_{R}^{d}K\\)는 공분산 함수가 된다. 그러나 이런 방식으로 \\(\\mathbf{Z}(\\mathbf{x})\\)를 생성할 경우 \\(\\mathbf{X},\\mathbf{Y}\\)가 unit ball의 원소일 때, \\[\\frac{1}{2}\\text{var}(\\mathbf{Z}(\\mathbf{x})-\\mathbf{Z}(\\mathbf{y}))=|\\mathbf{X-Y}|^{\\alpha}-c_{2}|\\mathbf{X-Y}|^{2}\\] 이 되어 원치 않는 \\(-c_{2}|\\mathbf{X-Y}|^{2}\\)가 포함된다. 이 문제를 해결하기 위해 \\(\\mathbf{Z}\\)를 아주 살짝 바꾼 \\(\\mathbf{Z}^{*}(\\mathbf{X})=\\mathbf{Z}(\\mathbf{X})+\\sum_{i=1}^{d}x_{i}X_{i}\\)로 정의해 \\(\\mathbf{Z}^{*}\\)를 사용한다. 이 때 \\(X_{1},\\ldots, X_{d}\\stackrel{iid}{\\sim}\\mathcal{N}(\\mathbf{0}, 2c_{2})\\), \\(\\mathbf{x}=(x_{1},\\ldots, x_{d})\\)이고 따라서 \\[\\frac{1}{2}\\text{var}(\\mathbf{Z}^{*}(\\mathbf{x})-\\mathbf{Z}^{*}(\\mathbf{y}))=|\\mathbf{X-Y}|^{\\alpha}\\] 가 된다. References "],
["46-spatialspectral.html", "Chapter 46 공간통계학에서의 스펙트럼 방법들", " Chapter 46 공간통계학에서의 스펙트럼 방법들 주파수 영역(frequency domain)은 주기(sine, cosine 등)를 따라 과정(process)을 분해하는 것이다. "],
["46-1-complex-valued-random-variables.html", "46.1 복소 확률 변수들(complex-valued random variables)", " 46.1 복소 확률 변수들(complex-valued random variables) \\(Z=U+iV\\), \\(U ,V\\)는 실수값을 갖는 확률변수라고 하자. 그러면 \\(Z\\)는 복소 확률 변수(complex-valued random variable)이 된다. \\(E(Z)=E(U)+iE(V)\\), \\(\\text{var}(Z)=E((Z-E(Z))(\\overline{Z-E(Z)}))\\), \\(\\text{cov}(Z,W)=E((Z-E(Z))(\\overline{(W-E(W))}))\\)이다. 46.1.1 복소 정규분포(complex normal distribution) 어떤 복소 확률 변수가 복소 정규분포(complex normal distribution)를 따른다는 것을 기호로는 \\(X\\sim \\mathcal{N}^{c}(\\mu,\\Sigma)\\)로 쓰며 \\(\\mathbf{x}=(x_{1},\\ldots, x_{n})^{T}\\)라고 할 때 \\[ \\begin{pmatrix} \\text{Re}(X) \\\\ \\text{Im}(X) \\end{pmatrix} \\sim \\mathcal{N}_{2n} \\Bigg( \\begin{pmatrix} \\text{Re}(\\mu) \\\\ \\text{Im}(\\mu) \\end{pmatrix}, \\frac{1}{2} \\begin{pmatrix} \\text{Re}(\\Sigma) &amp; -\\text{Im}(\\Sigma) \\\\ \\text{Im}(\\Sigma) &amp; \\text{Re}(\\Sigma) \\end{pmatrix} \\Bigg) \\] 를 만족할 때 복소 정규분포가 된다. 복소 정규분포의 성질은 다음과 같다. \\(E(X)=\\mu\\), \\(E((X-\\mu)(\\overline{X-\\mu})^{T})\\), \\(E((X-\\mu)(X-\\mu)^{T})=0\\)이다. 만약 \\(\\Sigma\\)가 대각행렬이면 \\(X_{1},\\ldots , X_{n}\\)은 독립이다. 그리고 \\(n=1\\)일 때에는 \\(\\text{Re}(X)\\sim \\mathcal{N}(\\text{Re}(\\mu), \\frac{1}{2}\\sigma^{2})\\), \\(\\text{Im}(X)\\sim \\mathcal{N}(\\text{Im}(\\mu), \\frac{1}{2}\\sigma^{2})\\) 이며 \\(\\text{Re}(X) \\perp \\text{Im}(X)\\)이다. 46.1.2 복소값을 갖는 공간과정(complex-values spatial process) 복소값을 갖는 공간과정(complex-values spatial process)는 \\(Z(s)=U(x)+iV(s)\\)이며 \\(U,V\\)는 실수값을 갖는 공간과정이다. 만약 \\(U\\)와 \\(V\\)가 joint stationary(각각이 stationary이고 joint의 covariance도 stationary를 만족하는 경우)이고 \\(\\text{cov}(U(s),V(t))=C_{0}(s-t)\\)로 표현이 되면 \\(Z(s)\\)는 약정상성(weakly stationary)을 갖는다고 말한다. 정상성을 갖는 공분산 함수는 \\(C(h)=\\text{cov}(Z(s+h),Z(s))\\)가 되고 \\(C(-h)=\\overline{C(h)}\\)가 되며 \\(C(h)\\)는 \\(\\sum_{j}\\sum_{k}c_{j}\\overline{c}_{k}C(s_{j}-s_{k})\\geq 0\\) (real, positive definiteness)를 만족한다. "],
["46-2-spectral-representation-of-a-spatial-process.html", "46.2 공간과정의 스펙트럼 표현(spectral representation of a spatial process)", " 46.2 공간과정의 스펙트럼 표현(spectral representation of a spatial process) \\(Z_{1}, \\ldots, Z_{n}\\)은 평균이 0인 복소 확률변수이며 \\(j\\neq k\\)일 경우 \\(E(Z_{j}\\overline{Z}_{k})=0\\)가 되며 \\(E|Z_{j}|^{2}=f_{j}\\)이다. 그러면 \\[Z(\\mathbf{s})=\\sum_{k=1}^{n}Z_{k}e^{i\\boldsymbol{\\omega}_{k}^{T}\\mathbf{s}},\\qquad{\\boldsymbol{\\omega}_{1},\\ldots, \\boldsymbol{\\omega}_{n}\\in\\mathbb{R}^{d}, \\mathbf{s}\\in\\mathbb{R}^{d}}\\] 로 표현할 수 있다. 여기서 \\(\\sum\\)은 decomposition을 나타낸다. \\(Z_{k}\\)는 weight amplitude contribution \\(e^{i\\boldsymbol{\\omega}_{k}^{T}\\mathbf{s}}=\\cos(\\boldsymbol{\\omega}_{k}^{T}\\mathbf{s})+i\\sin (\\boldsymbol{\\omega}_{k}}^{T}\\mathbf{s})\\) \\(\\boldsymbol{\\omega}_{k}\\)들이 frequency에 해당한다. 그러면 이에 대응되는 covariance function은 \\(C(\\mathbf{h})=\\sum_{k=1}^{n}f_{k}e^{i\\boldsymbol{\\omega}_{k}^{T}\\mathbf{h}}\\)가 된다. 이것들은 뒤에 나올 정리의 근사에 해당된다. 46.2.1 약정상과정의 스펙트럼 표현 정리(spectral representation theorem for weakly stationary process) 모든 mean-square continuous weakly stationary process \\(Z(\\mathbf{s})\\)에 대해 orthogonal increments를 갖는 어떤 프로세스 \\(Y(\\boldsymbol{\\omega})\\)가 존재해 \\[Z(\\mathbf{s})=\\int e^{i\\boldsymbol{\\omega}_{k}^{T}\\mathbf{s}}dY(\\boldsymbol{\\omega})\\] 로 쓸 수 있고 orthogonal increment들이 존재해 \\(j\\neq k \\neq l \\neq m\\)일 때 \\[\\text{Cov}(Y(\\boldsymbol{\\omega}_{j})-Y(\\boldsymbol{\\omega}_{k}), Y(\\boldsymbol{\\omega}_{l})-Y(\\boldsymbol{\\omega}_{m}))=0\\] 이 된다. 즉 차이들 \\(Y(\\boldsymbol{\\omega}_{j})-Y(\\boldsymbol{\\omega}_{k})\\)와 \\(Y(\\boldsymbol{\\omega}_{l})-Y(\\boldsymbol{\\omega}_{m})\\)이 uncorrelated 되어있는 것이다. 우리가 만약 \\(F\\)를 \\[E[|dY(\\boldsymbol{\\omega})|^{2} ]=F(d\\boldsymbol{\\omega}),\\] \\(|F(d\\boldsymbol{\\omega})|&lt;\\infty, \\forall \\boldsymbol{\\omega}\\)로 정의하고 positive finite measure라고 하자. 만약 \\(F\\)가 르베그 측도에 대해 밀도 \\(f\\)를 갖게 된다면, 이 \\(f\\)를 스펙트럼 밀도(spectral density)라고 부르게 된다. 스펙트럼 밀도가 존재할 때, 만약 공분산 함수 \\(C\\)가 연속 함수이면 다음의 푸리에 inversion 식을 갖는다. \\[f(\\boldsymbol{\\omega}=\\frac{1}{(2\\pi)^{d}}\\int_{\\mathbb{R}^{d}}\\exp(-i\\boldsymbol{\\omega}^{t}\\mathbf{s})C(\\mathbf{s})d\\mathbf{s}.\\] 그리고 분산 \\[C(\\mathbf{0})=\\int f(\\boldsymbol{\\omega})d\\boldsymbol{\\omega} \\] 은 total power에 해당한다. \\(C(\\mathbf{0})\\)은 스케일링을 해줘야만 1이 된다. "],
["46-3-some-spectral-densities-of-covariance-functions.html", "46.3 공분산 함수들의 스펙트럼 분포(some spectral densities of covariance functions)", " 46.3 공분산 함수들의 스펙트럼 분포(some spectral densities of covariance functions) 우리가 앞서 배운 공분산 함수들은 스펙트럼 버전이 존재한다. Matern model \\[C(\\mathbf{h})=\\frac{\\sigma^{2}2^{1-\\alpha}}{\\Gamma(\\alpha)}(\\frac{\\|\\mathbf{h}\\|}{\\phi})^{\\alpha}K_{\\alpha}(\\frac{\\|\\mathbf{h}\\|}{\\phi})\\] 로 정의된 Matern covariance 함수의 스펙트럼 버전은 \\[f(\\boldsymbol{\\omega})=\\frac{\\sigma^{2}\\Gamma(\\alpha+\\frac{d}{2})}{\\Gamma(\\alpha)\\pi^{\\frac{d}{2}}}(\\frac{1}{\\phi})^{2\\alpha}(\\frac{1}{\\phi})^{2}+|\\boldsymbol{\\omega}|^{2})^{-(\\alpha+\\frac{d}{2})}\\] 로 나타낼 수 있다고 한다. Parametrization을 어떻게 하느냐에 따라 결과가 달라진다. 다른 spectral version을 확인해보려면(Gelfand et al. 2010)의 5장을 참고하길 바란다. References "],
["46-4-aliasing.html", "46.4 깨진 패턴(aliasing)", " 46.4 깨진 패턴(aliasing) 신호 처리에서 에일리어싱(aliasing)은 표본화를 하는 가운데 각기 다른 신호를 구분해내지 못하는 현상을 가리킨다. 차원 \\(d=1\\)이고 \\(Z(\\mathbf{s})\\)가 공분산 함수 \\(C_{Z}(\\cdot)\\)을 가지는 약정상과정이고 이것의 스펙트럼 함수를 \\(f_{Z}(\\cdot)\\)이라고 하자. 그러면 \\(C_{Z}:\\mathbb{R}\\rightarrow\\mathbb{R}_{+}\\), \\(f_{Z}:\\mathbb{R}\\rightarrow\\mathbb{R}_{+}\\)가 된다. \\(Z(\\mathbf{s})\\)가 등간격 \\(\\delta\\)만큼 떨어진 거리에서 관찰되었다고 하자. 그리고 격자 과정 \\(Y_{j}\\equiv (\\delta_{j}),j=0\\pm 1, \\pm2 \\ldots\\)를 정의한다. 그러면 \\(Y_{j}\\)의 공분산함수는 \\[C_{Y}(k)=\\text{Cov}(Y_{j+k},Y_{j}=\\text{Cov}(Z(\\delta(j+k)), Z(\\delta(j)))= C_{Z}(\\delta_{k})\\] 가 된다. 또한 \\(C_{Z}:\\mathbb{Z}\\rightarrow\\mathbb{R}_{+}\\)이다. 이때 \\(f_{Y}(\\omega)\\)과 \\(f_{Z}(\\omega)\\)와의 관계는 어떻게 되는가? 그 관계를 살펴보기 전에 \\(\\{g_{k}\\}, k=0,\\pm 1, \\ldots\\)에 이산 푸리에 변환을 적용해본다. 그러면 다음을 얻는다. \\[\\hat{g}(\\omega)=\\frac{1}{2\\pi}\\sum_{k=-\\infty}^{\\infty}g_{k}e^{-i\\omega k}, \\qquad{\\omega \\in [-\\pi, \\pi].}\\] 이때 \\(g_{k}=\\int_{-\\pi}^{\\pi}e^{i\\omega k }\\hat{g}(\\omega)d\\omega\\)가 된다. 그리고 \\(g_{k}\\)를 \\(C_{Y}(k)\\)로 대체한다면 inversion formula를 통해 \\[f_{Y}(\\omega)=\\frac{1}{2\\pi}\\sum_{k=\\infty}^{\\infty}C_{Y}(k)e^{-i\\omega k}, \\qquad{\\omega \\in [-\\pi, \\pi]},\\] lattice process의 공분산 함수는 \\[C_{Y}(k)=\\int_{-\\pi}^{\\pi}e^{i\\omega k}f_{Y}(\\omega)d\\omega\\] 가 되고 \\[f_{Z}(\\omega)=\\frac{1}{(2\\pi)^{d}}\\int e^{-i\\boldsymbol{\\omega}^{T}\\mathbf{s}}C(\\mathbf{s})d\\mathbf{s}\\] 인데 편의상 \\(d=1\\)일 경우 연속 과정의 공분산함수는 \\[C_{Z}(\\mathbf{s})=\\int_{\\mathbb{R}}e^{i\\mathbf{s}\\omega}f(\\omega)d\\omega \\] 가 된다. 한편 1차원에서 \\[f_{Y}(\\omega)=\\frac{1}{\\delta}\\sum_{j=-\\infty}^{\\infty}f_{Z}(\\frac{\\omega + 2\\pi j }{\\delta}), \\qquad{\\omega \\in [-\\pi, \\pi]}\\] 이고 일반적인 \\(d\\)차원에서는 \\[f_{Y}(\\omega)=\\frac{1}{\\delta^{d}}\\sum_{J\\in\\mathbb{Z}^{d}}f_{Z}(\\frac{\\omega + 2\\pi J}{\\delta})\\] 임을 보일 수 있다고 한다. 즉 \\(f_{Y}(\\omega)\\)는 \\(f_{Z}(\\omega)\\)와 \\(\\frac{\\omega}{\\delta}=0\\) (즉 \\(j=0\\))에서 뿐만 아니라 다음의 주파수들 \\[(\\frac{\\omega}{\\delta}\\pm \\frac{2\\pi}{\\delta}, \\ldots , \\frac{\\omega}{\\delta}\\pm 2\\cdot\\frac{2\\pi}{\\delta},\\ldots)\\] 에 대해 모두 의존하게 된다. 따라서 우리는 \\(\\frac{\\omega}{\\delta}\\)를 \\(\\{\\frac{\\omega}{\\delta}+ \\frac{2\\pi j}{\\delta} \\}_{j\\neq 0}\\)과 깨진 패턴을 이룬다고 말한다. 즉 \\(\\{\\frac{\\omega}{\\delta}+ \\frac{2\\pi j}{\\delta} \\}_{j\\neq 0}\\)를 \\(\\frac{\\omega}{\\delta}\\)와 같은 것으로 본다는 것이다. 이 때 lower frequency와 alias를 이루지 않는 가장 높은 주파수를 Nyquist frequency라고 한다. 앞선 예에서 Nyquist frequency는 \\(\\frac{\\pi}{\\delta}\\)가 된다. 즉 이것보다 큰 주파수 정보는 잡지 못하는 것이다. 참고로 공간자료에서 lag가 큰 것은 frequency domain에서 frequency가 작은 것, lag가 작은 것은 frequency domain에서 frequency가 큰 것에 대응된다고 한다. 그리고 irregular할 때 스펙트럼 domain은 잘 고려되지 않는다고 한다. "],
["46-5-estimation-of-spectral-density.html", "46.5 스펙트럼 밀도의 추정(estimation of spectral density)", " 46.5 스펙트럼 밀도의 추정(estimation of spectral density) 46.5.1 이산 푸리에 변환(discrete Fourier transform in spatial statistics) 다음과 같이 사용 가능한 자료 \\(\\{Z(\\mathbf{J}) \\}_{\\mathbf{J}\\in T_{n}}\\), \\(T_{n}=\\{ 1,2,\\ldots, n\\}^{d}\\) \\((\\delta=1)\\)이 있다고 하자. 이것의 공분산 함수는 \\(\\text{Cov}(h)=E(Z(s+h)-\\mu)(Z(s)-\\mu)\\)이고 추정량은 \\(\\hat{C}(h)=\\Sigma(Z(s+h)-\\bar{Z})(Z(s)-\\bar{Z})\\)이다. 이 때 이 자료의 이산 푸리에 변환(discrete Fourier transform, DFT)는 \\[D(\\omega)=\\sum_{\\mathbf{J}\\in T_{n}}Z(\\mathbf{J})e^{-i\\boldsymbol{\\omega}^{T}\\mathbf{J}}, \\qquad{\\boldsymbol{\\omega}\\in[-\\pi,\\pi]^{d}}\\] 이다. 이 때 \\(\\omega = \\frac{2\\pi k}{n}, K\\in \\{ -\\lfloor\\frac{(n+1)}{2}\\rfloor,\\ldots, 0,\\ldots, n-\\lfloor\\frac{n}{2}\\rfloor \\}^{d}\\)를 푸리에 주파수(Fourier frequency)라고 부른다. (대충 \\([-\\pi,\\pi]^{d}\\)안에 들어가게 하기 위함) 이 푸리에 주파수를 더 빨리 계산할 수 있도록 하는 방법으로 FFT라는 것이 있다. 46.5.2 비모수적 방법-피리오도그램(nonparametric estimate - periodogram) \\(Y(\\mathbf{J})\\equiv Z(\\delta \\mathbf{J})\\)라고 할 때 (관찰값이 discrete일 경우) lattice process \\(f_{Y}(\\boldsymbol{\\omega})\\)의 비모수적 추정(periodogram)은 다음과 같다. Definition 46.1 (공간통계에서의 피리오도그램) 공간통계에서의 피리오도그램(periodogram)의 정의는 다음과 같다. \\[I(\\boldsymbol{\\omega})=\\frac{1}{(2\\pi n)^{-d}}|D(\\boldsymbol{\\omega})|^{2}=D(\\boldsymbol{\\omega}D(\\boldsymbol{\\omega})), \\qquad{\\boldsymbol{\\omega}\\in[-\\pi,\\pi]^{d}}.\\] 피리오도그램은 \\(f_{Y}(\\boldsymbol{\\omega})\\)에 대한 특별한 형태 가정을 하지 않고 있다. \\((\\boldsymbol{\\omega})\\)가 유용한 추정량인지 보려면, 불편성(unbiased), 일치성(consistency), 이것의 점근 분포 등을 살펴보아야 한다. 실제로 \\((\\boldsymbol{\\omega})\\)는 일치추정량은 아니다. "],
["46-6-increasing-domain-assumptions-properties-of-periodograms-unber-increasing-domain-assumptions.html", "46.6 Increasing domain assumptions에서의 피리오도그램의 성질(properties of periodograms unber increasing domain assumptions)", " 46.6 Increasing domain assumptions에서의 피리오도그램의 성질(properties of periodograms unber increasing domain assumptions) 자료가 늘어남에 따라 자료 사이의 거리가 늘어나는 것이 아닌, 자료 사이의 거리는 고정되어있고 정의역이 늘어난다는 가정을 increasing domain assumptions라고 한다. 이러한 가정의 장점으로는 시계열분석의 연구를 가져올 수 있다는 점이 있다. \\(Y(\\mathbf{J})\\equiv Z(\\delta \\mathbf{J})=Z(\\mathbf{J})\\)가 lattice process라고 하자. 이 때 \\(Z\\)는 공분산함수 \\(C_{Z}(\\mathbf{u}), u\\in \\mathbb{R}^{d}\\), 스펙트럼 함수 \\(f_{Z}(\\boldsymbol{\\omega}), \\boldsymbol{\\omega}\\in\\mathbb{R}^{d}\\)를 갖는다. 마찬가지로 \\(Y(\\mathbf{J})\\)또한 공분산함수 \\(C_{Z}(\\mathbf{u}), \\mathbf{u}\\in\\mathbb{Z}^{d}\\), 스펙트럼 밀도 \\(f_{Y}(\\boldsymbol{\\omega}), \\boldsymbol{\\omega}\\in (-\\pi,\\pi]^{d}\\)를 갖는다고 하자. 그러면 \\[f_{Y}(\\boldsymbol{\\omega}) = \\frac{1}{\\delta^{d}}\\sum_{\\mathbf{J}\\in \\mathbb{Z}^{d}}f_{Z}(\\frac{\\boldsymbol{\\omega}+2\\pi \\mathbf{J}}{\\delta})\\] 로 표현할 수 있다고 한다. \\(\\mathbf{J}\\)가 커질 때 밀도함수는 0으로 수렴하므로 위의 식의 유한한 항만 고려해도 된다. \\(d=1\\)인 경우 정확히 시계열 분석과 같아진다. \\(d=1\\)이라고 해보자. 그리고 \\((Z(1),\\ldots , Z(n))=(Y(1),\\ldots , Y(n))\\)은 다변량 가우스 분포를 따른다고 하자. 추가적으로 평균은 0이라고 해보자. 그러면 이 때 \\(D(\\omega)\\)는 복소 정규분포를 따르고 \\(E(D(\\omega))=0\\), \\(\\text{Var}(D(\\omega))=\\int_{-\\pi}^{\\pi}\\frac{\\sin^{2}(\\frac{(\\alpha-\\omega)n}{2})}{\\sin^{2}(\\frac{\\alpha-\\omega}{2})}f_{Y}(\\alpha)d\\alpha\\)를 따른다. 이 때 \\(\\alpha\\)는 \\(\\omega\\)가 제일 높은 값으로, Fejer kernel에 해당한다고 한다. 이를 점근 분포로 나타내면 \\[D(\\omega) \\sim \\mathcal{N}^{C}(0,2\\pi n f_{Y}(\\omega)), \\qquad{\\omega\\neq 0}\\] \\[\\text{Var}(D(\\omega))\\sim 2\\pi n f_{Y}(\\omega), \\qquad{\\omega\\neq 0}\\] 이 된다. 사실 \\(n\\)이 있기 때문에 엄밀한 의미의 점근 분포는 아니다. 그리고 \\(n\\rightarrow \\infty\\)일 때 \\(\\omega_{k}=\\frac{2\\pi k}{n}, \\omega_{k&#39;}=\\frac{2\\pi k&#39;}{n}\\)이 다른 주파수인 경우 \\(\\{ D(\\frac{2\\pi k}{n})\\}\\)은 asymptotically independent라고 한다. 피리오도그램이 \\(I(\\boldsymbol{\\omega})=\\frac{1}{(2\\pi n)^{-d}}|D(\\boldsymbol{\\omega})|^{2}, \\qquad{\\boldsymbol{\\omega}\\in[-\\pi,\\pi]^{d}}\\)으로 정의되는 이유는 \\(d=1\\)일 때 생각해보면 \\(E(I_{n}(\\omega))=\\frac{1}{2\\pi n}E|D(\\omega)|^{2}= \\frac{1}{2\\pi n}\\text{Var}|D(\\omega)|^{2} \\sim f_{Y}(\\omega)\\)이므로 피리오도그램은 스펙트럼 밀도에 대한 점근적 불편추정량이 된다. 확률변수가 독립이면 확률변수의 함수도 독립이므로, \\[\\text{Var}(I_{n}(\\omega)) = f_{Y}(\\omega)^{2} + \\mathcal{o}(1), \\qquad{\\omega_{k}=\\frac{2\\pi k}{n}, \\omega_{k}\\neq 0}\\] \\[\\text{Cov}(I_{n}(\\omega_{k}),I_{n}(\\omega_{k&#39;}))=\\mathcal{o}(1)\\] 이 되어 피리오도그램 또한 asymptotically independent이다. (\\(\\omega=0\\)일 때에는 따로 증명해줘야 한다.) 앞서 말했듯이 피리오도그램은 일치추정량이 아니다. 일치추정량이 되려면 \\(\\text{Var}(I_{n}(u))\\stackrel{n\\rightarrow\\infty}{\\rightarrow}0\\)이어야 한다. 그런데 왜 피리오도그램을 쓰는가? 그 이유는 피리오도그램을 가지고 일치추정량을 만들 수 있고 피리오도그램이 갖고 있는 좋은 성질들을 활용하기 위함 이라고 한다. 실제로 피리오도그램은 wiggly하게 나오는 경우가 많아 Nadayara-Watson kernel smoother로 스므딩을 한 smoothed periodogram을 쓰기도 한다. \\[\\hat{I}(\\omega_{k})=\\sum K_{h}(\\omega_{J},\\omega_{k})I_{n}(\\omega_{J}).\\] 이는 일치추정량이 된다고 한다. 46.6.1 피리오도그램과 표본 공분산과의 관계(relationship between periodogram and sample covariance) 피리오도그램을 공분산의 푸리에 주파수로 볼 수도 있다. \\(Y\\)의 스펙트럼 밀도에 대해 다시 복습해보자. \\[f_{Y}(\\omega)=\\frac{1}{2\\pi}\\sum_{-\\infty}^{\\infty}e^{-i\\omega u}C_{Y}(u).\\] 이것의 truncated version은 다음과 같다. \\[\\hat{f}_{Y}(\\omega)=\\frac{1}{2\\pi}\\sum_{-n}^{n}e^{-i\\omega u}\\hat{C}_{Y}(u).\\] 이 때 \\(\\hat{C}_{Y}(u)\\)는 평균 0이고 lag \\(u\\)인 공분산의 표본 버전으로 다음과 같다. \\[\\hat{C}_{Y}(u)=\\frac{1}{n}\\sum_{1\\leq k, k+u\\leq n}Y(u+k)Y(k).\\] 이 때 \\(I_{n}(\\omega)=\\frac{1}{2\\pi n}|\\sum_{j=1}^{n}Y(j)e^{-i\\omega j}|^{2}\\)으로 피리오드그램은 스펙트럼 밀도의 추정값이다. 46.6.2 가중 최소자승을 이용한 스펙트럼 밀도의 추정(estimation of spectral density with weighted least squares) 이제부터는 스펙트럼 밀도 모수 모형과 그 추정에 대해 살펴보기로 하자. 스펙트럼 밀도를 추정하는 것은 스펙트럼 밀도를 이용해 공분산 모수들을 추정하는 것과 동치이다. 즉 \\(I_{n}(\\omega_{k})\\) \\((\\omega_{k}\\)는 푸리에 주파수)와 \\(f_{Y}(\\omega, \\theta)\\)를 매칭시켜서 \\(\\theta\\)를 계산하는 것이다. 가중 최소자승법은 \\(\\text{Var}I_{n}(\\omega_{k})\\sim f_{Y}^{2}(\\omega_{k})+\\mathcal{o}(1)\\)을 이용해 \\[\\hat{\\theta}=\\text{argmin}_{\\theta}\\sum\\frac{1}{f(\\omega_{k};\\theta)}(I_{n}(\\omega_{k})-f(\\omega_{k};\\theta))^{2}\\] 으로 추정하는 것이다. 그러나 분포에도 \\(\\theta\\)가 있어 비선형 최적화 문제가 되므로 이 방법은 많이 안쓰고 대신 다음에 나올 가능도 기반 방법을 이용한 스펙트럼 밀도 추정 방법을 주로 이용한다. 46.6.3 가능도 기반 방법을 이용한 스펙트럼 밀도의 추정(estimation of spectral density with likelihood-based methods) (P. 1954)는 가우스 과정의 negative log-likelihood의 근사로서 Whittle-likelihood를 제안하였다. Whittle-likelihood의 기본적인 아이디어는 \\(f\\)가 lattice process라고 할 때 적분을 다음과 같이 근사하는 것이다. \\[\\begin{align*} -l(\\theta) &amp;\\approx \\int_{-\\pi}^{\\pi}(\\log f_{Y}(\\omega; \\theta) + \\frac{I_{n}(\\omega)}{f_{Y}(\\omega;\\theta)})d\\omega \\\\ &amp;\\approx \\sum_{k}(\\log f_{Y}(\\frac{2\\pi k}{n};\\theta) + \\frac{I_{n}(\\omega)}{f_{Y}(\\frac{2\\pi k}{n};\\theta)}) \\end{align*}\\] 그러면 이 때의 추정량은 위의 -log likelihood를 최소화하여 얻을 수 있다. \\[\\hat{\\theta}=\\text{argmin}_{\\theta}\\sum_{k}(\\log f(\\frac{2\\pi k}{n};\\theta)+ \\frac{I_{n}(\\omega)}{f_{Y}(\\frac{2\\pi k}{n};\\theta)})\\] 이것은 consistent하고 점근적 분포를 갖고 있음이 알려져 있다. 그러나 공분산 행렬의 고유치가 nice하게 움직이는(well-defined) 특별한 class의 f에서만 이것이 성립한다고 한다. References "],
["46-7-properties-of-periodogram-under-infill-asymptotics.html", "46.7 인필 점근 하에서의 피리오도그램의 성질들(properties of periodogram under infill asymptotics)", " 46.7 인필 점근 하에서의 피리오도그램의 성질들(properties of periodogram under infill asymptotics) 이 경우에는 \\(\\delta\\)부터 다시 정의하고 스펙트럼 밀도의 정의도 조금 바꿔야 한다. 다음과 같은 lattice process \\(Y_{\\delta}(\\mathbf{J})\\equiv Z(\\delta \\mathbf{J}), \\mathbf{J}\\in \\mathbb{Z}^{d}\\)를 생각하보자. 관찰값들은 다음과 같은 격자 \\(\\delta \\mathbf{J}\\in [0,1]^{d}\\) 위에서 관찰한다고 하자. \\(n\\)을 각각의 방향에서 grid point들의 갯수라고 하자. \\(\\delta = \\frac{1}{n}\\)이므로 \\(n\\rightarrow \\infty\\)일 시에 \\(\\delta \\rightarrow 0\\)이다. \\(f_{Y}(\\omega)=\\frac{1}{\\delta^{d}}\\sum_{\\mathbf{J}\\in\\mathbb{Z}^{d}}f_{Z}(\\frac{1}{\\delta}(\\omega+2\\pi\\mathbf{J}))\\)였음을 상기하자. 그리고 \\(|\\omega|\\rightarrow\\infty\\)일 때 \\(f_{Z}(\\omega )\\sim c|\\omega|^{-\\alpha}\\)라고 하자. 만약 \\(d\\)가 \\(\\alpha\\)보다 작을 경우 분산 \\(C(0)=\\int f(\\omega)d\\omega\\)가 not integrable이므로 분산이 blow-up해서 무한한 모멘트들을 가진 것들만 보려면 \\(\\alpha &gt;d\\)임을 가정한다. 적분가능성을 보장하기 위해 \\[\\delta^{d-\\alpha}f_{Y}(\\omega)\\stackrel{\\delta\\rightarrow 0}{\\rightarrow}c\\sum_{\\mathbf{J}\\in\\mathbb{Z}^{d}}|\\omega + 2\\pi \\mathbf{J}|^{-\\alpha}\\] "],
["47-spatiotemporal.html", "Chapter 47 시공간 통계학", " Chapter 47 시공간 통계학 이 장의 전체적인 내용 및 수학 기호 표시는 (N. A. C. Cressie and Wikle 2015)를 따라가려고 한다. R-code로 참고할 만한 논문은 (S. A. Padoan and Bevilacqua 2015)가 있다. 또 다른 참고할 만한 책으로는 (Montero, Fernández-Avilés, and Mateu 2015)로, 이 책의 5장부터 내용을 참고했다. References "],
["47-1-gaussian-random-fields.html", "47.1 가우스 확률장(Gaussian random fields)", " 47.1 가우스 확률장(Gaussian random fields) Definition 47.1 (가우스 확률장) 시공간 확률장 \\(Y(\\mathbf{s},t)\\)가 임의의 \\(\\{(\\mathbf{s}_{1},t_{1}),\\ldots , (\\mathbf{s}_{n},t_{n})\\}\\)에 대해 무작위 벡터 \\(\\mathbf{Y}=(Y(\\mathbf{s}_{1},t_{1}),\\ldots , Y(\\mathbf{s}_{n},t_{n}) )&#39;\\)가 다변량 가우스 분포(multivariate Gaussian distribution)를 따를 때, 이 확률장을 가우스 확률장(Gaussian random fields)이라고 한다. \\(\\{ Y(\\mathbf{s},t), (\\mathbf{s},t) \\in \\mathcal{I}\\}\\)를 \\(\\mathcal{I}\\)에서 정의된 실수값을 갖는 확률과정(random process)이라고 하자. 이 때 \\(\\mathcal{I}=\\mathcal{S}\\times\\mathcal{T}, \\mathcal{S}\\subseteq \\mathbb{R}^{d}, \\mathcal{T}\\subseteq \\mathbb{R}\\)이다. \\(\\mathcal{I}=\\mathcal{S}\\)이면 \\(Y(\\mathbf{s})\\equiv Y(\\mathbf{s},t_{0})\\)이면 공간 확률장(spatial random field)이 된다. 마찬가지로 \\(\\mathcal{I}=\\mathcal{T}\\)이면 \\(Y(\\mathbf{t})\\equiv Y(\\mathbf{s}_{0},t)\\)은 시간 확률장(temporal random field)이 된다. \\(I:=\\{1,\\ldots , l\\}\\)과 \\(J:\\{ 1, \\ldots, k \\}\\)를 index set이라고 놓고 이들의 데카르트 곱(Cartesian product)을 \\(I^{*}=I\\times J\\)라고 놓자. 그리고 이것의 카디널리티를 \\(m=k\\cdot l\\)이라고 놓자. 간단히 하기 위해 \\(Y(\\mathbf{s},t)\\)가 약정상성(second-roder stationary)을 따르는 시공간 가우스 확률장이라고 놓자. 이 뜻은 \\[\\forall (\\mathbf{s},t)\\in\\mathcal{I}, E[Y(\\mathbf{s},t)]=\\mu, \\qquad{\\text{Var}[Y(\\mathbf{s},t)]=\\omega{2}}\\] \\[\\forall (\\mathbf{s},t), (\\mathbf{s}&#39;,t)\\in\\mathcal{I}, \\text{cov}[Y(\\mathbf{s},t), Y(\\mathbf{s}&#39;,t)]=E[Y(\\mathbf{s},t), Y(\\mathbf{s}&#39;,t)]-\\mu^{2}\\] 이다. 마지막 공분산과 관련된 조건은 \\(C(\\mathbf{h}, u)\\)가 이동불변성(translation invariant)을 갖는다고 볼 수 있다. \\(C(\\cdot, \\cdot)\\)는 양의 정부호 함수(positive definite function)로 \\(\\mathbf{h}=\\mathbf{s}&#39;-\\mathbf{s}\\)와 \\(u=t&#39;-t\\)에만 의존하는 함수다. 이럴 경우에 \\(Y\\)는 시간 및 공간에 대해 정상 공분산함수(stationary covariance function)를 갖는다고 말한다. 그러면 \\(Y\\)의 분산은 시간 또는 공간의 위치의 영향을 받지 않게되며 \\[V(Y(\\mathbf{s},t))=C(\\mathbf{0},0)=\\sigma^{2}, \\forall (\\mathbf{s},t)\\in\\mathbb{R}^{d}\\times\\mathbb{R}\\] 과 같이 표현할 수 있다. 이 때 \\(C(\\mathbf{0},0)\\)은 무작위장의 사전분산(priori variance)이라 불린다. \\(Y\\)의 상관관계 함수는(correlation function) \\[\\rho (\\mathbf{h}, u )=\\frac{C(\\mathbf{h}, u )}{C (\\mathbf{0}, 0 )}\\] 가 된다. Definition 47.2 (분리가능) 시공간 확률장 \\(Y(\\mathbf{s},t)\\)의 공분산함수가 임의의 시공간 장소 \\((\\mathbf{s}_{i}, t_{i}),(\\mathbf{s}_{j}, t_{j})\\in\\mathbb{R}^{d}\\times \\mathbb{R}\\)에 대해 다음과 같이 \\[C((\\mathbf{s}_{i}, t_{i}), (\\mathbf{s}_{j}, t_{j}))=C_{s}(\\mathbf{s}_{i},\\mathbf{s}_{j})C_{t}(t_{i},t_{j})\\] 시간에 대한 공분산함수 \\(C_{s}\\)와 공간에 대한 공분산함수 \\(C_{t}\\)로 분해될 때, 이 공분산함수 \\(C\\)가 분리가능(separable)하다고 한다. Definition 47.3 (시공간 변동도) 시공간 확률장 \\(Y(\\mathbf{s},t)\\)의 시공간 변동도(spatio-temporal variogram)는 \\[2\\gamma((\\mathbf{s}_{i},t_{i}), (\\mathbf{s}_{j},t_{j}))=V(Y(\\mathbf{s}_{i},t_{i})-Y(\\mathbf{s}_{j},t_{j}))\\] 로 정의된다. 이것의 절반을 시공간 준변동도(spatio-temporal semivariogram)으로 정의한다. 만약 상수 평균값을 갖는 시공간 확률장이라면, \\[\\gamma((\\mathbf{s}_{i},t_{i}), (\\mathbf{s}_{j},t_{j}))=\\frac{1}{2}E(Y(\\mathbf{s}_{i},t_{i})-Y(\\mathbf{s}_{j},t_{j}))^{2}\\] 이 된다. 47.1.1 시공간 공분산함수(spatio-temporal covariance) 이 절의 내용은 (N. A. C. Cressie and Wikle 2015)의 6장 1절을 참고한다. (S. A. Padoan and Bevilacqua 2015)에서는 실제 현상의 국소 변동성을 묘사하기 위해 시공간 확률장을 \\[Y(\\mathbf{s}, t)=Y_{0}(\\mathbf{s},t) +\\epsilon (\\mathbf{s},t),\\] 으로 놓는다. 여기서 \\(\\epsilon(\\mathbf{s},t)\\sin\\mathcal(0,\\tau^{2})\\)은 \\(Y_{0}\\)와 독립인 백색잡읍이다. 이것의 공분산함수는 \\[C(\\mathbf{h},u)=\\tau^{2}I_{\\{\\mathbf{0},0\\}}((\\mathbf{h},u))+\\sigma^{2}\\rho_{0}(\\mathbf{h},u), \\qquad{(\\mathbf{h},u)\\in\\mathbb{R}^{d}\\times \\mathbb{R}}\\] 로 정의한다. \\(\\sigma^{2}&gt;0\\)과 \\(\\rho_{0}\\)은 임의장의 일반적인 분산 및 상관계수이며, \\(\\tau^{2}&gt;0\\)은 덩어리 효과(nugget effect)를 표현하기 위한 국소 분산(local variance)이다. 그러면 시공간 확률장 \\(Y(\\mathbf{s},t)\\)의 분산은 \\[\\omega^{2}=\\tau^{2}+\\sigma^{2}\\] 이고 공분산함수는 \\(\\sigma^{2}\\rho_{0}(\\mathbf{h},u)\\)가 된다. 만약 \\(Y(\\mathbf{s},t)\\)의 내재정상성을 가정한다면 이것의 변동도는 \\[2\\gamma(\\mathbf{h},u)=V\\{ Y(\\mathbf{s}+\\mathbf{h}, t+u\\}\\] 로 나타낼 수 있다. 이것은 약정상성 아래서는 \\[\\gamma(\\mathbf{h},u)=C(\\mathbf{0},0) - C(\\mathbf{h}, u)\\] 가 된다. 47.1.2 시공간 공분산함수와 준변동도의 성질(properties of the spatio-temporal covariance and semivariogram) (Montero, Fernández-Avilés, and Mateu 2015) 5장 4절을 참고한다. References "],
["48-stcovmodel.html", "Chapter 48 시공간 공분산모형", " Chapter 48 시공간 공분산모형 R package CompRandFld에 있는 시공간 공분산모형들을 정리하였다. "],
["48-1-spatio-temporal-correlation-models.html", "48.1 시공간 상관관계 모형(Spatio-temporal correlation models)", " 48.1 시공간 상관관계 모형(Spatio-temporal correlation models) 48.1.1 Non-Separable models geniting (non-separable space-time model): (Gneiting 2002)에 등장한 시공간 상관관계 함수로, (Montero, Fernández-Avilés, and Mateu 2015) 7장 10절에 나온 정보에 따르면 기존 (N. Cressie and Huang 1999)의 방법은 파워풀하나 \\(d\\)-variate 푸리에 적분이 알려진 닫힌 형태의 해가 존재하는 매우 작은 함수 class에서만 사용할 수 있다는 단점이 있었다. (Gneiting 2002)는 (N. Cressie and Huang 1999)와 같은 방법을 적용하되, 앞에서 언급한 한계를 피하고 일반적으로 유효한 시공간 상관관계 모형을 제공하고자 했다. 그래서 그는 푸리에 변환을 쓰지 않고 시공간 공분산함수의 모수 구성을 시공간 정의역에서 바로 하는 방법을 생각하였다. gneiting_GC (non-separable space-time model with great circle distances) iacocesare (non-separable space-time model) porcu (non-separable space-time model) porcu2 (non-separable space-time model) 48.1.2 Separable models 분리가능한 시공간 상관관계 모형들은 \\[R(h,u)=R(h)R(u)\\] 꼴로 나타낼 수 있는 모형들이다. exp-exp: spatial exponential model and temporal exponential model exp-cauchy: spatial exponential model and temporal cauchy model matern_cauchy: spatial matern model and temporal cauchy model stable_stable spatial stabel model and temporal stable model (note that some models are nested) References "],
["49-stkriging.html", "Chapter 49 시공간 크리깅", " Chapter 49 시공간 크리깅 점 시공간 크리깅(spatio-temporal kriging)은 관측되지 않은 점 \\((\\mathcal{s}_{0},t_{0})\\)의 \\(Z(\\mathcal{s}_{0},t_{0})\\)을 예측하는 것을 목표로 한다. \\(\\{ Z(\\mathcal{s}, t): \\mathcal{s}\\in D, t\\in T\\}, D \\subset \\mathbb{R}^{2}, T\\mathbb{R}\\)을 시공간 확률장(spatio-temporal random field)라 하고 이 장을 통틀어서 확률장에서 \\(n\\)개의 시공간 확률장 관측값 \\(\\{ Z(\\mathcal{s}_{1}, t_{1}), \\ldots , Z(\\mathcal{s}_{n}, t_{n}\\}\\)을 관찰한다고 가정한다. 관측되지 않은 점 \\((\\mathcal{s}_{0},t_{0})\\)의 값 예측을 하기 위해 다음과 같은 선형 에측변수(linear predictor) \\[Z^{*}(\\mathcal{s}_{0},t_{0})=\\sum+{i=1}^{n}\\lambda_{i}Z(\\mathcal{s}_{i}, t_{i})\\] 고려한다. 우리는 이것이 BLUP이 되길 원한다. "],
["49-1-spatio-temporal-kriging-equations.html", "49.1 시공간 크리깅 공식들(spatio-temporal kriging equations)", " 49.1 시공간 크리깅 공식들(spatio-temporal kriging equations) "],
["50-pointpattern.html", "Chapter 50 공간점과정", " Chapter 50 공간점과정 이 절에서는 공간점과정(spatial point process)에 대한 소개를 한다. 공간점과정은 1차원(주로 시계열 상의 자료) 및 3차원(지구상의 태풍, 화산 자료)에서도 고려 가능하나 주로 다루는 차원은 2차원이다. "],
["50-1-examples-of-spatial-point-patterns.html", "50.1 공간점패턴 자료의 예(examples of spatial point patterns)", " 50.1 공간점패턴 자료의 예(examples of spatial point patterns) 공간점패턴(spatial point patterns) 자료란 어떤 관찰값 또는 사건의 관찰지역 내의 장소들을 모아놓은 자료라고 볼 수 있다. 주된 예로는 나무의 위치, 동물의 거주지역, 범죄 장소, 은하의 위치 등을 들 수 있다. 다음은 공간점패턴 자료의 예들이다. 이 자료들은 R 패키지 spatstat에 있다. Japanese pine trees data 일본소나무자료는 Numata (1961)가 모은 자료로 spatstat에서 japanesepine이라는 이름으로 들어있다. 공간점자료를 받았을 때 처음 할 일은 이 자료가 어떤 패턴을 가지고 있는지 확인해 보는 것이다. 그림을 그려 본 결과 이 자료는 특별한 패턴이 보이지 않으며 완비 무작위성을 띤다고 볼 수 있다. FIGURE 50.1: Japanese pine trees data. Califonia Redwoods 레드우드는 세계에서 제일 키가 큰 나무 종류 중 하나라고 한다. 이 자료는 Ripley (1977)이 62그루의 캘리포니아 레드우드 모종(seeding)과 묘목(sapling)의 위치를 모아놓은 자료이다. redwood라는 이름으로 들어있다. 묘목 사이에 군집(cluster)이 형성되어 있음을 확인할 수 있다. FIGURE 50.2: Califonia Redwoods data. Biological cells Crick and Ripley (1977)은 광학현미경으로 관찰한 42개의 생물학적 세포의 중심들을 자료로 만들었다. cell라는 이름에 들어있다. 이 자료의 특징은 세포의 크기 때문에 모든 점들이 일정 거리 이상 떨어져 분포하고 있다는 것이다. FIGURE 50.3: Biological cells data. Amacrine cells Diggle (1986)은 토끼의 망막에 있는 94개의 무축삭 세포(Amacrine cell) 자료를 분석했다. 이 세포들 중 152개는 빛이 들어오면 뇌에 정보를 전송하고 나머지들은 정보를 전송하지 않는다고 한다. amacrine이라는 이름으로 들어있다. FIGURE 50.4: Amacrine cells data. 여기서는 각자의 특징이 있는지, 두 그룹 사이에 관련성이 있는지에 대해 분석하게 된다. 마지막으로 marked point pocess라는 것도 있는데 이것은 점에 추가로 정보가 붙어있는 자료들을 의미한다. 무축삭 세포 자료가 이에 해당될 것이다. "],
["51-csr.html", "Chapter 51 완전공간임의성", " Chapter 51 완전공간임의성 공간점패턴 자료를 받으면 제일 처음으로 이 자료가 완전공간임의성(complete spatial randomness, CSR)을 따르는지 체크하게 되는데, 그 이유는 이것을 따르면 모델링이 단순해지기 때문이다. Definition 51.1 (동질적 포아송 점과정) 완전공간임의성 가정은 다음 두 조건 면적이 \\(|A|\\)인 관찰 지역 \\(A\\) 안의 사건의 숫자가 \\(\\text{Poisson}(\\lambda |A|), \\lambda &gt;0, |A| &gt;0\\)을 따른다. \\(n\\)개의 사건이 주어졌을 때, 각각의 사건들 \\(x_{i}, i=1,\\ldots , n\\)은 \\(A\\) 위에서 균등분포(uniform distribution)를 따르는 독립인 무작위 표본들이다. 을 만족하는 것이다. 이를 만족하는 점과정을 특별히 동질적 포아송 점과정(homogeneous Poisson point process)이라고 부른다. \\(\\lambda\\)는 강도(intensity)로 단위 면적 당 사건 발생의 기대값을 결정하는 값이다. \\(\\lambda\\)가 위치에 관계 없는 상수값이라는 것은 사건의 발생횟수가 위치에 따라 변하지 않는다는 의미이다. 또한 CSR 가정은 사건들 사이에 어떤 상호작용도 존재하지 않음을 의미한다. 우리는 어떤 자료가 정규분포를 따르는지 알아보기 위해 평균, 분산, 왜도, 첨도 등을 체크하고 Q-Q plot 등을 그리기도 한다. 그렇다면 CSR의 특징은 무엇인가? 이를 알면 어떤 자료가 CSR을 따르는지 체크 가능할 것이다. "],
["51-1-general-monte-carlo-methods-for-csr-test.html", "51.1 완전공간임의성 검정을 위한 일반적인 몬테카를로 방법 (general Monte Carlo methods for CSR test)", " 51.1 완전공간임의성 검정을 위한 일반적인 몬테카를로 방법 (general Monte Carlo methods for CSR test) \\(u_{1}\\)을 통계량 \\(U\\) (아마 확률번수인 듯)를 따르는 관찰값이라고 하자. 그리고 \\(u_{i}, i =2,\\ldots, s\\)를 어떤 단순한 가정(\\(H_{0}\\)) 하의 \\(U\\)의 분포에서 뽑힌 독립 표본들의 값이라고 하자. \\(u_{(j)}\\)를 \\(u_{i}, i=1,\\ldots , s\\) 중 \\(j\\)번째로 큰 순서통계량이라고 하자. 그러면 \\[P(u_{i}=u_{(j)})=\\frac{1}{s} \\qquad{\\text{under } H_{0}},\\] \\[P(u_{i}\\geq u_{(j)})=\\frac{k}{s}=\\text{(test의) size} \\qquad{\\text{(one-sided test)}}\\] 가 된다. 이 때 \\(U\\)는 동률이 없는 연속인 경우를 일단 생각한다. 만약 \\(U\\)가 이산이라면 동률이 생겨 rank 계산에 문제가 생길 것이다. 이 때는 less extreme rank(?)를 하는게 보수적인 판단이라고 한다. 갑자기 몬테카를로 검정을 이야기 한 이유는 어떤 자료가 CSR인지 테스트를 할 때 사용할 수 있기 때문이다. 관찰값들이 있으면 이들의 상호 떨어지 거리(inter-event distance)를 이용하는 것이다. \\(T\\)를 지역 \\(A\\) 안에서 독립인 균등분포로 뽑힌 두 사건의 거리들이라고 하자. 관찰 지역이 원이나 정사각형인 경우 \\(T\\)의 분포의 명시적 형태가 존재한다. 이 때 명시적 형태는 다음과 같다. 단위 정사각형의 경우, 분포함수 \\(H(t)\\)는 \\[ H(t)=P(T\\leq t) = \\begin{cases} \\pi t^{2}-\\frac{8}{3}t^{3}+\\frac{1}{2}t^{4} &amp; \\text{if $0 \\leq t \\leq 1$}\\\\ \\frac{1}{3} -2t^{2} + \\frac{1}{2}t^{4} + 4(t^{2}-1)^{\\frac{1}{2}}(2t^{2}+1)/3\\\\ + 2t^{2}\\sin^{-1}(2t^{-2}-1) &amp; \\text{if $1\\leq t \\leq \\sqrt{2}$} \\end{cases} \\] 이다. 식이 복잡해 보이는데 \\(a_{1}=(x_{1},y_{1})\\), \\(a_{2}=(x_{2},y_{2})\\)일 때 \\(x_{1}, x_{2}, y_{1}, y_{2}\\)가 모두 독립이고 이 때 \\(T=\\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}\\)의 CDF를 구한 듯 하다. 단위 원 경우에는 극 좌표계로 변환하여 계산하며 \\[H(t)=1+\\pi^{-1}\\{2(t^{2}-1)\\cos^{-1}(\\frac{t}{2})-t(1+\\frac{t^{2}}{2})\\sqrt{1-t^{2}/4}\\}, \\qquad{0\\leq t \\leq 2}\\] 가 된다. 위 사각형 예제에서, H(t)의 경험적 분포함수(empirical distribution function) \\(\\hat{H}(t)\\)는 \\[\\hat{H}(t)=\\frac{2}{n(n-1)}\\sum_{i,j}^{i\\neq j}I_{(t_{ij}\\leq t)}\\] 이며 이 때 empirical distribution function (EDF) 그림은 q-q plot과 비슷하게 그려진다. 한편, EDF에 봉투(envelope)들(마치 함수의 상한, 하한과 같다) \\(U(t)\\), \\(L(t)\\)을 다음과 같이 정의한다. \\[U(t)=\\max_{2\\leq i \\leq s}\\{\\hat{H}_{i}(t)\\} \\text{ and } U(t)=\\min_{2\\leq i \\leq s}\\{\\hat{H}_{i}(t)\\}.\\] 이 EDF 말고 통계량을 이용해 검정할 수는 없을까? 그러기 위해서는 우선 \\(\\hat{H}(t)\\)의 분포를 알아야 한다. 그러나 이를 구하는 것은 쉽지 않다. 따라서 공간점과정에서는 몬테칼로 방법(Monte Carlo method)을 많이 사용한다고 한다. 일반적인 절차는 CSR 가정 하에 지역 \\(A\\) 안에서 \\(n\\)개의 사건을 생성한다. 간단히 하기 위해 먼저 \\(t\\)를 고정시킨 다음, \\(\\hat{H}_{1}(t)\\) 는 데이터로부터 생성된 경험적 분포함수로, \\(\\hat{H}_{i}(t), i=2,\\ldots, s\\) (\\(s\\): 몬테칼로 반복 횟수)는 몬테칼로 방법으로 생성된 경험적 분포함수라고 놓는다. 그러면 \\(t\\)를 고정했을 때 CSR 하에서 다음이 성립한다. \\[P(\\hat{H}_{1}(t)&gt;U(t))=P(\\hat{H}_{1}(t)&lt;L(t))=\\frac{1}{s}\\] 51.1.1 경험적 분포함수를 이용한 몬테칼로 검정 방법들(MC tests using EDF) 크게 두 가지 방법이 있다. \\(t_{0}\\)를 고른 다음, \\(u_{1}=\\hat{H}_{1}(t_{0})\\)를 검정통계량으로 쓰는 것이다. 그러면 CSR 가정 하에 \\(P(U_{(j)}=u_{1})=\\frac{1}{s}\\)가 된다. \\(t_{0}\\)가 너무 주관적인 선택이므로 이를 해결하기 위해 \\(u_{i}=\\int (\\hat{H}_{i}(t)-H(t) )^{2}dt\\)를 사용하고 나머지는 앞의 방법과 동일하게 할 수도 있다. Corollary 51.1 1. Aggregate pattern이 의심될 경우: 작은 \\(t_{0}\\)를 선택하는 것이 좋다. 두 번째 검정은 검정력(power)이 첫 번째 검정에 비해 약하다. 실제 데이터의 분포 지역이 정사각형 또는 원이 아닌 경우 \\(H(t)\\)의 명시적 형태를 모른다. 이처럼 \\(H(t)\\)를 모르는 경우 \\(\\hat{H}_{i}, i=2,\\ldots, s\\)를 이용해 \\(H(t)\\)의 추정량 \\(\\bar{H}(t)\\)를 만들어 사용하는 것이다. \\[\\bar{H}_{i}(t)=\\frac{1}{s-1}\\sum_{j\\neq i}\\hat{H}_{j}(t)\\] 이며 \\(\\bar{H}_{1}(t)\\)를 \\(H(t)\\)의 추정량으로 주로 쓴다. "],
["51-2-methods-based-on-nearest-neighbor-distance.html", "51.2 최근접이웃거리 기반 방법들(methods based on nearest neighbor distance)", " 51.2 최근접이웃거리 기반 방법들(methods based on nearest neighbor distance) \\(Y\\)를 CSR 가정 하에 \\(A\\) 안에 \\(n\\) (\\(n\\)은 고정)개의 사건이 있다고 할 때 최근접이웃거리(nearest neighbor distance)라고 하자. 그러면 \\[\\begin{eqnarray*} G(y)=P(Y\\leq y)&amp;\\approx &amp; 1-(1-\\pi y^{2}|A|^{-1})^{n-1}\\\\ &amp;\\approx&amp; 1-e^{-\\lambda \\pi y^{2}}, \\qquad{y \\geq 0, \\lambda =\\frac{n}{|A|}} \\end{eqnarray*}\\] 가 된다. 이제 우리는 \\(G(y)\\)와 비교할 empirical한 것을 데이터로부터 찾아야 한다. \\(y_{i}\\)를 \\(i\\)번째 사건과 그 사건으로부터 가장 가까운 다른 사건 사이의 거리라고 하자. 그러면 \\(\\hat{G}_{1}(y)=\\frac{1}{n}\\sum I(y_{i} \\leq y)\\)가 되며 이를 이용해 EDF 그림을 그려보거나 몬테칼로 검정을 할 수 있다. 51.2.1 최근접이웃거리 기반 몬테칼로 검정 방법들(MC tests based on nearest neighbor distance) 다음의 방법들이 있다. \\(u_{i}=\\int (\\hat{G}_{c}(y)-G(y))^{2}dy\\)를 이용하는 것이다. 이 때 \\(G\\) 대신 \\(\\bar{G}\\)를 넣어도 된다. (Clark and Evans 1954) \\(\\bar{y}=\\frac{1}{n}\\sum y_{i}\\)로 놓는다. 이 경우에 \\(\\bar{y}\\)는 근사적으로 정규분포를 따르며 \\[E(\\bar{y})=0.5(n^{-1}|A|)^{\\frac{1}{2}} + (0.051 + 0.042 n^{-\\frac{1}{2}})n^{-1}P\\] \\[\\text{Var}(\\bar{y})=0.070n^{-2}|A| + 0.037(n^{-5}|A|)^{\\frac{1}{2}}P\\] 이다. 이 때 \\(P\\)는 \\(A\\)의 둘레의 길이다. (Point-to-nearest event distance) \\(X\\)를 \\(A\\) 안에 있는 어떤 점에서 \\(n\\)개의 사건들 중 가장 가까운 사건과의 거리라고 하자. 또 \\(x_{i}, i=1,\\ldots ,m\\)을 \\(A\\)의 \\(i\\)번째 점에서 \\(n\\)개의 사건들 중 가장 가까운 사건과의 거리라고 하자. 그러면 \\[F(x)=P(X\\leq x) \\approx 1 - e^{-\\lambda \\pi x^{2}}, \\qquad{x \\geq 0, \\lambda = \\frac{n}{|A|}}\\] \\[\\hat{F}_{1}(x)=\\frac{1}{m}\\sum I(x_{i}\\leq x)\\] 그 다음에는 앞게 비슷하게 EDF 그림을 그려보거나 \\(u_{1}=\\int (\\hat{F}_{1}(x)-\\bar{F}_{1}(x))^{2}dx\\)등으로 검정 가능하다. 정방구역 계산(quadrat count) FIGURE 51.1: Examples of rectangle area. 정방구역(quadrat)이란 어떤 관찰구역 \\(A\\)를 \\(m\\)개의 같은 크기의 소구역으로 나눴을 때 그 구역 하나 하나를 일컫는 말이다. 위 그림에서 셀 하나 하나를 정방구역이라고 부른다. CSR 가정 아래서는 같은 분포를 \\(m\\)번 반복하여 관찰하는 것으로 볼 수 있고 \\(n_{i}\\)는 \\[n_{i} \\sim \\text{Poisson}(\\lambda |B|),\\qquad{i=1,\\ldots, m}\\] 을 따른다. 여기서 \\(B\\)는 어떤 지역이다. 이 때의 검정통계량으로는 카이제공통계량을 쓴다. CSR 가정 아래서 \\[X^{2}=\\sum_{n=1}^{m}\\frac{(n_{i}-\\bar{n})^{2}}{\\bar{n}} \\sim \\chi_{m-1}^{2}\\] 이다. 이 때 \\(\\bar{n}=\\frac{n}{m}=\\frac{\\sum n_{i}}{m}\\)이다. References "],
["51-3-r-r-edf.html", "51.3 R 예제(R-edf)", " 51.3 R 예제(R-edf) # Define points x &lt;- c(3.4, 7.3, 6.3, 7.7, 5.2, 0.3, 6.8, 7.5, 5.4, 6.1, 5.9, 3.1, 5.2, 1.4, 5.6, 0.3) y &lt;- c(2.2, 0.4, 0.8, 6.6, 5.6, 2.5, 7.6, 0.3, 3.5, 3.1, 6.1, 6.4, 1.5, 3.9, 3.6, 5.2) # Store the coordinates as a matrix coords &lt;- as.matrix(cbind(x, y)) # Store the points as two-dimensional point pattern (ppp) object (ranging from 0 to 8 on both axis) coords.ppp &lt;- as.ppp(coords, c(0, 8, 0, 8)) # Number of points n &lt;- coords.ppp$n # We want to generate completely spatially random point patterns to compare against the observed ex &lt;- expression( runifpoint( n , win = owin(c(0,8),c(0,8)))) # Reproducible simulation set.seed(1) # Compute a simulation envelope using Gest, which estimates the nearest neighbour distance distribution function G(r) EDF &lt;- envelope( coords.ppp , Gest , nsim = 99, simulate = ex ,verbose = FALSE, savefuns = TRUE ) # Plot plot(EDF) FIGURE 51.2: EDF plot. "],
["52-sparsesampling.html", "Chapter 52 희박한 샘플링 분석", " Chapter 52 희박한 샘플링 분석 지금까지는 사건의 point의 각각의 location을 미리 안다고 가정하고 또 사건의 갯수인 \\(n\\) 또한 미리 안다고 가정한 상태에서 분석을 하였다. 한편, 지역이 엄청 크거나 사건의 point들이 너무 많을 경우 정보를 collect하는 데 시간이 오래 걸릴 것이다. 특히 기술이 발달하지 않은 옛날에는 특히 어려웠기 때문에 사람들은 관찰 지역 안에서 일부 정보를 뽑아 사용했다고 한다. 자료는 정방구역 계산(quadrat count) 및 \\(m\\)개의 표본추출 점들(sampling points)의 최근접이웃거리 기반 방법 으로 모은다. \\(m\\)을 조절할 수 있기 때문에 실제로 2의 방법으로 모으는 것이 더 쉽다고 한다. 희박한 샘플링 분석에서의 관심사는 CSR도 있지만 알려지지 않은 전채 갯수 \\(n\\)에 더 관심을 갖는다고 한다. 강도(intensity) \\(\\lambda\\)를 알면 \\(n\\)을 알 수 있지 않을까? 결국 \\(n\\) 또는 \\(\\lambda\\)의 분포를 알아야 하므로 CSR인지 먼저 체크하게 된다. "],
["52-1-quadrat-counts-for-sparse-sampled-data.html", "52.1 희박한 샘플링 자료를 위한 정방구역 계산(quadrat counts for sparse sampled data)", " 52.1 희박한 샘플링 자료를 위한 정방구역 계산(quadrat counts for sparse sampled data) \\(I\\)를 산포(dispersion)의 지수(index)라고 하자. 그러면 \\(I\\)는 \\[I=\\frac{\\sum_{i=1}^{m}(n_{i}-\\bar{n})^{2}}{\\bar{n}(m-1)},\\] 즉 표본분산(\\(\\frac{\\sum_{i=1}^{m}(n_{i}-\\bar{n})^{2}}{(m-1)}\\))과 표본평균(\\(\\bar{n}=\\frac{1}{m}\\sum n_{i}\\))의 비로 나타낸다. CSR하에서 \\(n_{1}, \\ldots, n_{m}\\)은 포아송 분포를 따르고 표본분산과 표본평균은 같다, 즉 \\(I \\approx 1\\)이길 기대하는 것이다. 검정은 \\((m-1)I \\sim \\chi_{m-1}^{2}\\) 사실을 이용하며 \\(I &gt;&gt; 1\\)인 경우에는 집적(aggregate)된 자료(\\(n_{1}, \\ldots, n_{m}\\)의 variation이 크므로 표본분산이 커짐)이며 \\(I &lt;&lt; 1\\)인 경우에는 정칙(regular)성을 띈 자료가 된다. (P. J. Diggle 1979)는 이 검정이 집적된 자료를 찾는데에는 강력(powerful)하나 정칙성을 띈 자료를 찾는 데에는 좋지 않다는 사실을 밝혔다. 한편 강도 \\(\\lambda\\)의 추정량 \\(\\hat{\\lambda}\\)는 \\[\\hat{\\lambda}=\\sum_{i=1}^{m}\\frac{n_{i}}{m|B|}\\] 와 같이 계산을 할 수 있다. References "],
["52-2-distance-methods-for-sparsely-sampled-data.html", "52.2 희박한 샘플링 자료를 위한 거리 방법들(distance methods for sparsely sampled data)", " 52.2 희박한 샘플링 자료를 위한 거리 방법들(distance methods for sparsely sampled data) \\(X\\)를 임의의 점(point, 사건이 아님)으로부터 가장 가까운 사건(event)까지의 거리라고 하자. 그러면 CSR 가정 하에서 \\[F(x)=P(X\\leq x)\\approx 1-e^{-\\pi\\lambda x^{2}}, \\qquad{x&gt;0\\text{ under CSR}}\\] 이다. 즉 \\(\\pi X^{2} \\sim \\text{Exp}(\\lambda)\\)이며 변수변환을 통해 \\(2\\pi \\lambda X^{2} \\sim \\chi_{2}^{2}\\)으로 바뀌며 \\(P(X&gt;x)\\sim e^{-\\pi\\lambda x^{2}}\\)이 된다. 이 때 CSR 검정을 하는 방법으로는 두 가지 방법이 있다. (Hopkins and Skellam 1954)는 뒤에 나올 \\(h\\)를 이용한 검정 방법을 제안했다. 임의로 \\(m\\)개의 점을 골랐을 때 각 점들마다 가장 가까운 사건 사이의 거리를 \\(\\{X_{1}, \\ldots, X_{m}\\}\\)이라고 놓자. 그리고 임의로 사건을 하나 골랐을 때 그 사건과 가장 가까운 다른 사건 사이의 거리를 \\(\\{Y_{1}, \\ldots, Y_{m}\\}\\)이라고 놓자. 그러면 \\[2\\pi\\lambda X_{i}^{2} \\stackrel{ind}{\\sim} \\chi_{2}^{2} \\bot \\sum 2\\pi\\lambda Y_{i}^{2} \\sim \\chi_{2}^{2},\\] \\[\\sum 2\\pi X_{i}^{2} \\stackrel{ind}{\\sim} \\chi_{2m}^{2} \\bot \\sum 2\\pi Y_{i}^{2} \\sim \\chi_{2m}^{2}\\] 이며 \\[h=\\frac{\\sum X_{i}^{2}}{\\sum Y_{i}^{2}} \\sim F_{2m,2m} \\qquad{\\text{under CSR.}}\\] 이다. 즉 임의 점에서 계산한 nearest distance나 무작위로 선택된 사건들로부터 계산된 nearest distance들이나 같아야 한다는 아이디어에서 출발한 것이다. 만약 CSR이 아닌 경우에는 \\(h\\)가 커지거나 작아지는데, \\(h\\)가 커진다는 것은 \\(\\sum Y_{i}^{2}\\)들이 작아지므로 집적된 자료이고, \\(h\\)가 작아질 때에는 \\(\\sum Y_{i}^{2}\\) 일정한 값들을 갖기 때문에 정칙성을 갖는 자료라고 한다. Besag and Gleaves (1973)은 T-square sampling procedure라는 것을 제안했다. FIGURE 52.1: Example of T-square sampling. 그림에 대한 설명은 다음과 같다. 사건(event)가 아닌 점(point) \\(O\\)를 생각한다. \\(O\\)에서 가장 가까운 사건이 \\(P\\)이고 이들 사이의 거리가 \\(x\\)이다. 그 다음에는 \\(P\\)에서 \\(O\\)를 중심으로 하고 반지름의 길이가 \\(x\\)인 원에 대한 접선을 그어 접선 바깥쪽에서 \\(P\\)와 가장 가까운 사건을 찾고 이들 사이의 거리를 \\(z\\)라고 놓는 것이다. 이 때, CSR 가정 하에서 \\[X_{1}, \\ldots, X_{m}: 2\\pi\\lambda X_{i}^{2} \\sim \\chi_{2}^{2},\\] \\[Z_{1}, \\ldots Z_{m} \\sim \\text{Poisson}(\\lambda \\frac{\\pi z^{2}}{2})\\] 이다. 이 때 \\(\\frac{\\pi z^{2}}{2}\\)는 반원의 면적이다. 이는 \\[\\begin{eqnarray*} P(Z&gt;z|X=x)&amp;=&amp; P(\\text{number of events in half circle}=0)\\\\ &amp;=&amp; 1-e^{-\\lambda \\frac{\\pi z^{2}}{2}}, \\qquad{X \\text{ and } Z \\text{ are independent}} \\end{eqnarray*}\\] 로 부터 나온 것이다. 즉 \\[2\\pi\\lambda X_{i}^{2} \\stackrel{ind}{\\sim} \\chi_{2}^{2} \\bot \\sum \\pi\\lambda Z_{i}^{2} \\sim \\chi_{2}^{2}\\] 이다. 검정통계량은 \\(t_{N}\\)과 \\(t_{F}\\)를 쓴다. \\[t_{N}=\\frac{1}{m}\\sum_{i=1}^{m}\\frac{x_{i}^{2}}{x_{i}^{2} + z_{i}^{2}/2} \\stackrel{\\text{approx}}{\\sim}\\mathcal{N}(\\frac{1}{2}, \\frac{1}{12m})\\] \\[t_{F}=\\frac{2\\sum x_{i}^{2}}{\\sum z_{i}^2} \\stackrel{\\text{approx}}{\\sim} F_{2m,2m}\\] References "],
["53-pointprocess.html", "Chapter 53 점과정", " Chapter 53 점과정 자료가 CSR에 해당되면 \\(\\lambda\\)를 잘 묘사하는 것으로 끝나지만 만약 자료가 CSR이 아니라면 점과정(point process)으로 모델링하게 된다. "],
["53-1-definition-of-point-processes.html", "53.1 점과정의 정의(definition of point processes)", " 53.1 점과정의 정의(definition of point processes) 점과정을 정의하기 위해 몇 가지 개념들을 정리한다. \\(X\\)를 공간(space) \\(S\\) 안에 있는 점들의 점과정 \\(S\\)는 \\(d(\\cdot, \\cdot)\\)이라는 거리(metric)를 갖는 거리 공간(metric space). 일반적으로는 \\(S\\subseteq \\mathbb{R}^{d}\\)인 공간을 생각한다. \\(x\\): \\(X\\)의 실현(realization, finite), \\(x=\\{\\zeta, \\eta, \\delta, \\ldots \\}\\). \\(x_{B}=x\\cap B, B\\subseteq S \\qquad{\\text{B 안에 있는 점들만 보겠다}}\\) \\(n(x_{B})=\\sharp \\text{ of } x, x\\cap B\\) \\(N(B)\\): count 함수 = \\(n(X_{B})\\) (확률변수임) \\(x\\cup \\xi \\Longleftarrow x \\cup \\{ \\xi\\}\\) (괄호생략, \\(\\xi\\)는 어떤 pt) \\(x \\backslash \\xi \\Longleftarrow x \\backslash \\{\\xi\\}\\) (괄호생략) \\(N_{lf}=\\{ x\\subseteq S: n(x_{B})&lt;\\infty, B \\stackrel{\\text{bdd}}{\\subset}S\\}\\): locally finite point configuration 점과정을 정의하기 전에 먼저 확률변수의 정의를 다시 생각해보자. 확률변수를 한 마디로 말하면 가측함수(measurable function)이다. \\(X\\)가 확률변수라면 \\[X: \\Omega \\longrightarrow \\mathbb{R}\\] 이며 이때 \\(\\Omega\\)는 \\((\\Omega, \\mathcal{F}, P)\\)인 확률공간이며 \\(\\mathbb{R}\\) 또한 보렐 시그마-체 \\(\\mathcal{B}\\)를 갖는다\\((\\mathbb{R}, \\mathcal{B})\\). \\(\\mathbb{R}\\)의 가측 집합을 \\(X\\)를 통해 \\(\\Omega\\)쪽으로 보내도 가측이어야 한다. 그러면 이제 점과정 \\(X\\)를 정의해보자. \\(X\\)는 \\[X: \\Omega \\longrightarrow N_{lf}\\] 로 확률공간은 \\((\\Omega, \\mathcal{F}, P)\\)이며 \\(N_{lf}\\) 또한 보렐 시그마-체 \\(\\mathcal{N}_{lf}\\)를 갖아 \\((N_{lf}, \\mathcal{N}_{lf})\\)가 된다. \\(\\mathcal{N}_{lf}\\)은 \\(S\\)에서의 시그마-체이며 \\[\\mathcal{N}_{lf}=\\sigma (\\{ \\{ x \\in N_{lf}, n(x_{B})=m \\{ m \\in \\mathbb{N}_{0}, B\\in\\mathcal{B}_{0}\\} \\} \\})\\] 로 정의되며 \\(\\mathbb{N}_{0}\\)는 set of nonnegative integer, \\(\\mathcal{B}_{0}\\)는 class of bounded Borel sets in \\(S\\)이다. 마지막으로 \\(X\\)의 분포함수 \\(P_{X}\\)는 \\[P_{X}(F)=P(\\{ \\omega \\in l : X(\\omega) \\in \\mathcal{F}\\}) \\qquad{\\text{where } \\mathcal{F} \\in \\mathcal{N}_{lf}}\\] 이다. Corollary 53.1 1. \\(X\\)의 가측성(measurability) \\(\\Longleftrightarrow\\) \\(N(B)\\)가 모든 \\(B\\in\\mathcal{B}_{0}\\)에서 확률변수 인 것(확률론에 의해 \\(\\mathcal{B}_{0}\\)을 \\(\\mathcal{B}\\)로 확장할 수 있다) \\(X\\)의 분포는 가산함수(count function)들의 유한한 분포 \\((N(B_{1}), \\ldots , N(B_{m}))\\)로 결정된다. 즉 가산함수들만 잘 알면 \\(X\\)의 정보를 모두 알 수 있다. \\(\\mathcal{N}_{lf}^{0}\\equiv\\{ \\{ x\\in N_{lf}, n(x_{B})=0 \\} ; B \\in \\mathcal{B}_{0}\\}\\) 빈 확률(void probability): 빈 확률 \\(v(B)\\)는 \\[v(B)=P(N(B)=0), B\\in\\mathcal{B}_{0}\\] 으로 정의된다. 빈 확률과 관련된 가장 중요한 성질은 점과정은 그것의 빈 확률로 유일하게 정의된다(분포가 같다는 의미). 포아송 점과정일 경우 \\(N(B)\\)는 결국 포아송분포(Poisson distribution)가 된다. 생성범함수(generating functional) \\(G_{X}(u)\\)는 \\[G_{X}(u)=E[\\prod_{\\xi \\in X}u(\\xi)]\\] 로 정의되면 여기서 함수 \\(u\\)는 \\(u:S\\longrightarrow [0,1]\\)이며 \\(\\xi\\)는 \\(\\{ \\xi \\in S, u(\\xi)\\leq 1 \\}\\)로 유계(bounded)이다. 생성범함수는 \\(X\\)의 분포를 유일하게 결정한다. 예를 들어 \\(u(\\xi)=t^{I_{\\{\\xi \\in B\\} }}\\)이고 \\(B\\in \\mathcal{B}_{0}, 0 \\leq t \\leq 1\\)이면 \\(G_{X}(u)=E t^{N(B)}\\)다. 53.1.1 표시된 점과정(marked point process) 때로는 각 지점의 장소 정보 이외에 추가된 정보가 있는 자료들이 있다. 예를 들면 나무의 사이즈 등이 같이 첨부된 자료 등이 있다. 이러한 자료들을 나타내는 점과정을 표시된 점과정(marked point process)라고 한다. \\[X=\\{ (\\xi, m_{\\xi}), \\xi \\in Y \\},\\] 여기서 \\(Y\\)는 \\(T\\)(보통 \\(\\mathbb{R}^{d}\\))에 있는 점과정이다. \\(m_{\\xi}\\)는 표시(mark)로 \\(m_{\\xi}\\in M\\)이다. \\(M\\)은 표시된 공간(mark space)으로 보통 정수집합이지만 실수집합이 될 수도 있다. 또는 \\(T\\times M=S\\)로 놓고 \\(X=\\{ (\\xi, m_{\\xi}\\}\\)를 차원이 하나 늘어난 점과정으로 보기도 한다. 그러나 \\(M\\)이 실수집합이 아닌 경우 구분하여 보는 것이 편리하다. "],
["53-2-poisson-point-process.html", "53.2 포아송 점과정(Poisson point process)", " 53.2 포아송 점과정(Poisson point process) 가장 기본적인 점과정으로 포아송 점과정(Poisson point process)이 있으며, 이것의 특별한 경우가 CSR이다. 포아송 점과정을 정의하기 위해서는 먼저 이항 점과정(binomial point process)에 대해 알아야 한다. Definition 53.1 (이항 점과정) \\(f\\)가 \\(B\\subseteq S\\) 위에서의 밀도함수(density function)라고 하자. B 위에서 밀도 \\(f\\)를 갖는 \\(n\\)개의 i.i.d. 점들로 구성된 점과정 \\(X\\)를 이항 점과정(binomial point process)이라고 하며 \\(X\\sim \\text{binomial}(B,n,f)\\)라고 쓴다. 포아송 점과정과는 달리 \\(n\\)이 고정되어 있으며 이 \\(n\\)는 균등(uniform)이 아닌 \\(f\\)에 의해 i.i.d로 뽑인다. CSR은 \\(f=\\frac{1}{|B|}\\)인 경우다. Definition 53.2 (포아송 점과정) \\(S\\) 위에서 강도함수(intensity function) \\(\\rho\\)를 갖는 점과정 \\(X\\)가 \\(\\mu (B)=\\int_{B} \\rho (\\xi) d\\xi &lt;\\infty\\)를 갖는 어떤 \\(B\\subset S\\)에 대해 \\(N(B)=n(X_{B}) ~ \\text{Poisson}(\\mu(B))\\) (만약 \\(\\mu(B)=0\\)이면 \\(N(B)=0\\)이다) 이고 \\(0 &lt; \\mu(B) &lt;\\infty\\)인 어떤 \\(n\\in\\mathbb{N}\\), \\(B\\subseteq S\\)에 대해 \\(N(B)=n\\)인 조건부에서 \\(X_{B}\\sim \\text{binomial}(B,n,f)\\)이고 \\(f(\\xi)=\\rho(\\xi)/\\mu(B)\\)를 따를 때 \\(X \\sim \\text{Poisson}(S,\\rho)\\)를 포아송 점과정(Poisson point process)이라 부른다. Corollary 53.2 - \\(E N(B)=\\mu(B)\\) for \\(\\mu(B) &lt;\\infty\\) \\(\\rho(\\xi)d\\xi\\): heuristically probability of a point in a small neighborhood of \\(\\xi\\) \\(P(X=\\xi)=0\\) Definition 53.3 (포아송 점과정과 관련된 정의들) \\(\\rho(\\cdot)=\\rho\\)인 포아송 점과정을 동질적 포아송 점과정(homogeneous Poisson point process), \\(\\rho(\\cdot)\\neq\\rho\\)인 포아송 점과정을 비동질적 포아송 점과정(inhomogeneous Poisson point process)이라고 부른다. 한편, 점과정에서도 정상성을 정의할 수 있는데, 임의의 점 \\(s\\in \\mathbb{R}^{d}\\)에 대해 이동불변성(translation invariant) \\[X+s =\\{\\xi + s xi\\in X\\} \\stackrel{\\mathcal{D}}{=} X\\] 을 갖는 \\(X\\)를 정상 점과정(stationray point process)라고 한다. 등방성(isotropy)에 대해서도 정의할 수 있는데, \\(\\mathbb{R}^{d}\\)상의 원점에 대해 회전불변성(rortation invariant) \\[\\mathcal{O}X=\\{ \\mathcal{O}\\xi, \\xi \\in X\\} \\stackrel{\\mathcal{D}}{=} X\\] 을 갖는 \\(X\\)를 등방 점과정(isotropic point process)라고 한다. \\(\\mathcal{O}\\)은 일종의 회전연산자이다. 53.2.1 포아송 점과정의 성질들(properties of Poisson point process) 이 절의 내용은 (Moller and Waagepetersen 2003)의 3장에 있는 포아송 점과정의 성질들을 언급한다. 증명은 생략하니 참고문헌을 참조하길 바란다. \\(S\\)는 기본적으로 유계일 필요는 없으며, \\(\\rho\\)는 기본적으로 국소 적분가능(locally integrable)이다. Proposition 53.1 (포아송 점과정과 관련된 성질들) 1. \\(X \\in \\text{Poisson}(S, \\rho)\\)인 것은 \\(\\mu(B)=\\int_{S}\\rho(\\xi)d\\xi &lt;\\infty\\)인 모든 \\(B \\subseteq S\\)와 모든 \\(F \\subseteq N_{lf}\\)에 대해 \\[P(X_{B}\\in F)=\\sum_{n=0}^{\\infty}\\frac{e^{-\\mu(B)}}{n!}\\int_{B}\\cdots\\int_{B}I_{[\\{x_{1},\\ldots, x_{n}\\}\\in F]}\\prod_{i=1}^{n}\\rho(x_{i})dx_{1}\\cdots dx_{n}\\] 과 동치이다. \\(X \\in \\text{Poisson}(S, \\rho)\\)이면 함수 \\(h:N_{lf}\\rightarrow [0,\\infty )\\)와 \\(\\mu(B) &lt; \\infty\\)인 \\(B\\subseteq S\\)에 대해 \\[E[h(X_{B})]=\\sum_{n=0}^{\\infty}\\frac{e^{-\\mu(B)}}{n!}\\int_{B}\\cdots\\int_{B}h(\\{x_{1},\\ldots, x_{n}\\})\\prod_{i=1}^{n}\\rho(x_{i})dx_{1}\\cdots dx_{n}\\] 이다. 다음 정리는 포아송 점과정에 해당하는 빈 확률(void probability)은 무엇일까에 관한 것이다. Proposition 53.2 (포아송 점과정에 해당하는 빈 확률) \\(X \\in \\text{Poisson}(S, \\rho)\\)는 빈 확률 \\[v(B)=e^{-\\mu(B)}, \\qquad{\\text{bounded } B\\subseteq S}\\] 에 의해 유일하게 결정된다. 다음 명제는 disjoint한 지역에서의 포아송 점과정들은 서로 독립이라는 것을 말하고 있다. Proposition 53.3 (disjoint한 지역에서의 포아송 점과정들은 서로 독립) 점과정 \\(X\\)가 포아송 점과정 \\(X \\in \\text{Poisson}(S, \\rho)\\)이면, \\(X_{B_{1}}, X_{B_{2}}, \\ldots\\)는 disjoint set들 \\(B_{1},B_{2},\\ldots \\subseteq S\\)에 대해 독립이다. 다음 명제는 포아송 점과정의 생성범함수에 관한 것이다. Proposition 53.4 (포아송 점과정의 생성범함수) 점과정 \\(X\\)가 포아송 점과정 \\(X \\in \\text{Poisson}(S, \\rho)\\)이면 \\[G_{X}(u)=E[ \\prod_{\\xi \\in X}u(\\xi)] \\stackrel{\\text{PPP}}{=}e^{-\\int_{S}(1-u(\\xi))\\rho(\\xi)d\\xi}\\] 이다. 이 때 \\(u:S\\rightarrow [0,1]\\)이다. 다음 명제는 (정상) 포아송 점과정을 어떻게 생성할 것인가에 대한 것이다. 여기서는 극좌표(polar coordinate)를 응용한다. Proposition 53.5 (극좌표를 활용한 포아송 점과정의 생성) \\(S_{1}, U_{1}, S_{2}, U_{2}, \\ldots\\)가 \\(U_{i}\\)는 \\(\\{u \\in \\mathbb{R}^{d}: \\| u\\| =1 \\}\\)에서 균등하게 분포되어 있고 \\(S_{i} \\sim \\text{Exp}(\\rho \\omega_{d})\\)가 평균 \\(1/(\\rho \\omega_{d})\\) \\((\\omega_{d}\\text{: volume of d-dimension unit ball})\\)로 지수 분포되어있다고 하자. \\(R_{0}=0, R_{i}^{d}=R_{i-1}^{d}+S_{i}, i=1,2,\\ldots\\)로 정의되었다고 할 때 \\[X=\\{R_{1}U_{1}, R_{2}U_{2},\\ldots\\}\\sim \\text{Poisson}(\\mathbb{R}^{d},\\rho)\\] 이다. Theorem 53.1 ((Slivnyak-Mecke’s theorem)) \\(X \\in \\text{Poisson}(S, \\rho)\\)일 때 함수 \\(h:S\\times N_{lf} \\rightarrow [0,\\infty])\\)에 대해 \\[E[\\sum_{\\xi\\in X}h(\\xi,X\\backslash \\xi)]=\\int_{S}[E[h(\\xi,X)]]\\rho(\\xi)d\\xi.\\] Theorem 53.2 ((Extended Slivnyak-Mecke’s theorem)) \\(X \\in \\text{Poisson}(S, \\rho)\\)일 때 함수 \\(h:S^{n}\\times N_{lf} \\rightarrow [0,\\infty])\\)에 대해 \\[\\begin{eqnarray*} &amp; &amp;E[\\sum_{\\xi_{1},\\ldots ,\\xi_{n}\\in X}^{\\neq}h(\\xi_{1},\\ldots,\\xi_{n},X\\backslash \\{\\xi_{1},\\ldots,\\xi_{n}\\})]\\\\ &amp;=&amp;\\int_{S}\\cdots\\int_{S}[E[h(\\xi_{1},\\ldots,\\xi_{n},X)]]\\prod_{i=1}^{n}\\rho(\\xi_{i})d\\xi_{1}\\cdots d\\xi_{n}.\\\\ \\end{eqnarray*}\\] 53.2.2 중첩과 세선화(superpositioning and thinning) 중첩(superposition)과 세선화(thnning)는 점과정의 기본적인 연산자들이다. Definition 53.4 (중첩) 포아송 점과정들 \\(X_{1},X_{2},\\ldots\\)의 배반 합집합 \\(\\cup_{i=1}^{\\infty}X_{i}\\)를 중첩(superposition)이라고 한다. Definition 53.5 (세선화) \\(p:S\\rightarrow [0,1]\\)이 함수이고 \\(X\\)가 \\(S\\)에서의 점과정이라고 하자. 점과정 \\(X_{thin}\\subseteq X\\)는 \\(\\xi \\in X\\)를 \\(X_{thin}\\)에 확률 \\(p(\\xi)\\)로 포함하는 점과정으로 정의한다. 이때 각 점들은 독립적으로 포함될지 안될지를 결정한다고 하자. 그러면 \\(X_{thin}\\)은 보유확률(retention probability) \\(p(\\xi)\\)를 갖는 \\(X\\)의 독립 세선화(independent thinning)으로 정의한다. 보통 \\(X_{thin}=\\{ \\xi \\in X: R(\\xi) \\leq p(\\xi) \\}\\) 로 놓으며 이 때 \\(R(\\xi) \\sim \\text{Uniform}[0,1]\\), \\(\\xi\\in S\\)는 \\(X\\)에서 뽑힌 상호독립 점들이다. \\(X_{i}\\)들이 독립인 포아송 점과정일 때에는 중첩을 하거나, 세선화 한 것, 그리고 세선화하면서 버려진 점과정들 또한 포아송 점과정이 된다. 다음 명제들은 이 사실에 관한 것들이다. Proposition 53.6 (포아송 점과정의 중첩과 세선화) \\(X_{i}\\sim \\text{Poisson}(S,\\rho_{i}), i=1,2,\\ldots\\)가 상호 독립이고 \\(\\rho=\\sum\\rho_{i}\\)가 확률 1로 국소 적분가능하면, 배반 합집합 \\(X=\\cup_{i=1}^{\\infty}X_{i}\\sim\\text{Poisson}(S,\\rho)\\)이다. Proposition 53.7 (독립 세선화) \\(X \\sim \\text{Poisson}(S,\\rho)\\)가 보유확률 \\(p(\\xi), xi\\in S\\)를 갖는 독립 세선화 \\(X_{thin}\\)을 갖는다고 하고 \\[\\rho_{thin}(\\xi)=p(\\xi)\\rho(\\xi), \\xi\\in S\\] 일 때, \\(X_{thin}\\)과 \\(X\\backslash X_{thin}\\)은 모두 독립 포아송 과정이며 이것의 강도함수는 각각 \\(\\rho_{thin}\\)과 \\(\\rho-\\rho_{thin}\\)이다. 다음 따름정리를 이용하면 비동질적 포아송 점과정 또한 생성 가능하다고 한다. Corollary 53.3 \\(X \\sim \\text{Poisson}(\\mathbb{R}^{d}, \\rho)\\)이며 강도함수 \\(\\rho\\)는 상수 \\(c\\)에 의해 유계이다. 그러면 \\(X\\)는 보유확률 \\(p(\\xi)=\\frac{\\rho(\\xi)}{c}\\)를 갖는 \\(\\text{Poisson}(\\mathbb{R}^{d},c)\\)의 독립 세선화로 간주할 수 있다. 53.2.3 포아송과정의 시뮬레이션(simulation of Poisson processes) \\(X \\sim \\text{Poisson}(\\mathbb{R}^{d},\\rho)\\)라고 하고 우리는 유계인 \\(B\\)에서 \\(X\\)를 생성하고 싶어 한다. (여기서 \\(\\rho\\)는 homogeneous이다.) 만약 \\(B=b(0,r)\\)과 같은 ball 형태라면 앞선 명제를 이용하여, \\[S_{1},\\ldots , S_{m} \\stackrel{\\text{i.i.d}}{\\sim} \\text{Exp}(\\rho\\omega_{d}), U_{1},\\ldots, U_{m-1} \\sim \\text{unif}(u, \\| u||=1)\\] 을 만든다. 여기서 \\(m\\)은 \\(R_{m-1}&lt;r&lt;R_{m}\\)이고 \\(R_{i}^{d}=R_{i-1}^{d}+S_{i}\\)이다.마지막으로 \\[X_{B}=\\{ R_{1}U_{1},\\ldots , R_{m-1}U_{m-1} \\}\\] 만약 \\(B=[0,a_{1}]\\times \\cdots \\times [0,a_{d}]\\), 즉 사각형 형태라면 given \\(N(B)=n\\) i.i.d. points uniformly on \\(B\\)일 때 \\(N(B) \\sim \\text{Poisson}(\\rho\\cdot\\prod_{i=1}^{d}a_{i})\\)를 생성하고 이를 바탕으로 포아송과정을 만든다. 마지막으로 일반적인 모양일 경우 독립 세선화를 이용해 \\(B\\)을 포함하는 더 큰 ball이나 사각형 \\(B_{0}\\)를 만들어 여기서 포아송과정을 생성한 다음 \\(B_{0}\\backslash B\\)인 점들을 버린다. \\(X\\)가 비동질적(inhomogeneous)인 경우, 즉 포아송 점과정의 밀도함수 \\(\\rho\\)가 \\(\\rho=\\rho(\\xi)\\)이고 \\(\\rho_{0}&gt;0\\)에 의해 유계인 경우, \\(Y\\sim \\text{Poisson}(B,\\rho_{0})\\)을 만들고 \\(X_{B}\\)는 독립세선화를 이용해 보유확률을 \\(\\rho(\\xi)/\\rho_{0}\\)으로 하여 만들 수 있다고 한다. 53.2.4 포아송 점과정의 밀도(density of Poisson point processes) \\(X_{1}\\), \\(X_{2}\\)가 \\(S\\)위에서의 두 개의 점과정이라고 하자. 그리고 \\(F\\subset\\mathcal{N}_{lf}\\)일 때 \\(X_{1}\\), \\(X_{2}\\)가 절대연속(absolutely continuous)라고 하자. 그러면 라돈-니코딤 정리(Radon-Nykodim theorem)에 의해 \\[P(X_{1}\\in F) = E[ I_{\\{X_{2}\\in F\\}}f(X_{2}) ], F\\subseteq \\mathcal{N}_{lf}\\] 를 만족하는 함수 \\(f: \\mathcal{N}_{lf} \\rightarrow [0,\\infty ]\\)가 존재한다. 이 때 \\(f\\)를 \\(X_{2}\\)와 관련한 \\(X_{1}\\)의 밀도(density)라고 한다. 포아송과정은 일반적으로 절대연속은 아니나 \\(S\\)가 유계일 경우에는 항상 절대연속이 된다고 한다. Proposition 53.8 (포아송 점과정의 절대연속) 1. 임의의 숫자 \\(\\rho_{1}, \\rho_{2} &gt;0\\)에 대해 \\(\\text{Poisson}(\\mathbb{R}^{d},\\rho_{1})\\)이 \\(\\text{Poisson}(\\mathbb{R}^{d},\\rho_{2})\\)에 대해 절대연속이라는 것은 \\(\\rho_{1}=\\rho_{2}\\)라는 것과 동치다. \\(i=1,2\\)일 때 \\(\\rho_{i}:S\\rightarrow [0,\\infty)\\)가 존재하여 \\(\\mu_{i}=\\int_{S}\\rho_{i}(\\xi)d\\xi\\)가 유한하다고 하자. 그리고 \\(\\rho_{1}&gt;0\\)일 때 항상 \\(\\rho_{2}&gt;0\\)이라고 하자. 그러면 \\(\\text{Poisson}(S,\\rho_{1})\\)은 \\(\\text{Poisson}(S,\\rho_{2})\\)에 대해 절대연속이며 밀도는 \\[f(x)=e^{\\mu_{2}(S)-\\mu_{1}S}\\prod_{\\xi\\in x}\\frac{\\rho_{1}(\\xi)}{\\rho_{2}(\\xi)}\\] 가 된다. \\((x\\subset S)\\) Proof. 1의 증명: (\\(\\Leftarrow\\)) 만약 \\(\\rho_{1}\\neq \\rho_{2}\\)라고 가정해보자. \\(F=\\{x: \\lim_{m}\\sum_{i=1}^{m}\\frac{n(x\\cap A_{i})}{m} =\\rho_{i} \\}\\) with \\(|A_{i}|=1\\)이라고 해보자. 그러면 \\(P(X_{1}\\in F)=1\\)이나 \\(P(X_{2}\\in F)=0\\)이다. 2의 증명: [포아송 점과정과 관련된 성질들]로부터 바로 유도된다고 한다. References "],
["53-3-marked-poisson-process.html", "53.3 표시된 포아송과정(marked Poisson process)", " 53.3 표시된 포아송과정(marked Poisson process) \\(X=\\{ (\\xi, m_{\\xi}), \\xi \\in Y \\}\\)라고 하자. Definition 53.6 (표시된 포아송과정) \\(Y \\sim \\text{Poisson}(T,\\phi)\\), \\(phi\\)는 \\(Y\\)가 conditioned 되어있을 때 locally integrable intensity function이라고 하자. 그리고 marks \\(\\{m_{\\xi}, \\xi\\in Y\\}\\)가 상호독립이라고 하자. 그러면 \\(X\\)는 표시된 포아송과정(marked Poisson process)라고 부른다. 만약 marks가 identically distributed with a common distribution \\(Q\\)일 경우 \\(Q\\)는 표시 분포(mark distribution)이라고 부른다. Proposition 53.9 (표시된 포아송과정의 성질) \\(X\\) 가 \\(M\\subset \\mathbb{R}^{p}\\)인 표시된 포아송 과정이고 \\(Y\\sim \\text{Poisson}(T,\\phi)\\)라고 하자. \\(Y\\)에 대해 conditioned 되었을 때, 각각의 mark \\(m_{\\xi}\\)는 이산 또는 연속 밀도 \\(p_{\\xi}\\)를 갖고 이것은 \\(Y\\backslash\\xi\\)에 의존하지 않는다. \\(\\rho(\\xi, m)=\\phi(\\xi)p_{\\xi}(m)\\)이라고 하자. 그러면 \\(X\\sim \\text{Poisson}(T\\times M, rho)\\). 만약 \\(M\\)에서의 밀도가 \\(\\kappa(m)=\\int_{T}\\rho(\\xi, m)d\\xi\\)로 정의되고 이것이 locally integrable하면, \\(\\{m_{\\xi}:\\xi \\in Y \\}\\sim \\text{Poisson}(M,\\kappa)\\)이다. 53.3.1 포아송과정의 점의 무작위 독립 이동(random independent displacements of the points in a Poisson process) 여기서 말하는 내용은 새로운 point process를 만들어 기존 point process 내용에 뭔가를 추가하고자 하는 것이다. \\(Y^{*}=\\{\\xi + m_{\\xi}: \\xi \\in Y\\}\\)를 무작위 독립 이동(random independent displacements)로 얻어졌다고 가정해보자. 이 때 \\(Y\\sim \\text{Poisson}(\\mathbb{R}^{d}, \\rho)\\)이고 \\(Y\\)에 대해 conditioned되었을 때 \\(m_{\\xi}\\)는 독립이고 각각의 분포 \\(\\rho_{\\xi}\\)는 \\(Y\\backslash\\xi\\)에 의존하지 않는다고 해보자. \\(X^{*}\\)를 표시된 점 \\((\\xi, \\xi+m_{\\xi})\\)를 갖는 표시된 점과정이라고 해보자. 그러면 \\(\\rho^{*}\\)가 locally integrable일 때 \\(Y^{*}\\)는 포아송 점과정이고 그것의 intensity function은 \\[\\rho^{*}(\\eta)=\\int\\rho(\\xi)p_{\\xi}(\\eta-\\xi)d\\xi\\] 이다. "],
["54-summaryPP.html", "Chapter 54 점과정의 요약통계", " Chapter 54 점과정의 요약통계 이 절에서는 나중에 추정에 유용하게 쓰일 공간점과정의 요약통계량들에 대해 다룬다. "],
["54-1-1-2-first-and-second-order-properties-of-a-point-process.html", "54.1 점과정의 1차 및 2차 성질들(first and second order properties of a point process)", " 54.1 점과정의 1차 및 2차 성질들(first and second order properties of a point process) \\(X\\)를 \\(S=\\mathbb{R}^{d}\\)에서의 점과정이라고 하자. \\(N(B)\\)가 \\(B\\subset S\\)에서 무작위 셀 수 있는 변수들의 1차 및 2차 성질들은 강도측도(intensity measure)와 이차계승적률측도(second order moment factorial moment measure)라고 부른다. Definition 54.1 (강도측도) \\(\\mathbb{R}^{d}\\)에서의 강도측도(intensity measure) \\(\\mu\\)는 \\[\\mu(B)=E[N(B)], B\\subset \\mathbb{R}^{d}\\] 로 정의하고 \\(\\mathbb{R}^{d}\\times \\mathbb{R}^{d}\\) 이차계승적률측도(second order moment factorial moment measure) \\(\\alpha^{(2)}\\)는 \\[\\alpha^{(2)}(C)=E \\sum_{\\xi, \\eta \\in X}^{\\neq} I_{[(\\xi, \\eta)\\in C]}, C\\subseteq \\mathbb{R}^{d}\\times \\mathbb{R}^{d}\\] 로 정의한다. 일반적인 집합 \\(S\\)에 대해 측도는 \\[E(N(B_{1})N(B_{2}))=\\alpha^{(2)}(B_{1}\\times B_{2}) + \\mu (B_{1} \\int B_{2}), B_{1}, B_{2}\\subseteq \\mathbb{R}^{d}\\] 와 같이 정의된다고 한다. Definition 54.2 (강도함수) \\(\\rho\\)가 존재하여 \\[\\mu(B)=\\int_{B}\\rho(\\xi)d\\xi\\] 를 만족한다면, \\(\\rho\\)를 강도함수(intensity function)라고 한다. 즉 \\(\\rho(\\xi)d\\xi\\)는 중심 \\(\\xi\\)에서 \\(d\\xi\\)만큼 볼륨을 가지는 지역에서 point가 존재할 확률이다. Definition 54.3 (2차 곱 밀도) 만약 2차 팩토리얼 모멘트 측도 \\(\\alpha^{(2)}\\)가 \\[\\alpha^{(2)}(C)=\\int \\int \\mathbf{1}[(\\xi,\\eta)\\in C]\\rho^{(2)}(\\xi,\\eta)d\\xi d\\eta, \\qquad{C\\subset \\mathbb{R}^{d}\\times\\mathbb{R}^{d}}\\] 로 쓸 수 있을 때 \\(\\rho^{(2)}\\)는 음이 아닌 함수이며 2차 곱 밀도(second order product density)라고 부른다. 직관적으로 \\(\\rho^{(2)}(\\xi, \\eta)d\\xi d\\eta\\)는 \\(X\\)로부터 얻어진 두 개의 점들이 동시에 두 개의 작은 지역에 떨어질 확률(일종의 interaction)을 나타낸다. \\(\\rho\\)가 상수함수이면 homogeneous, 상수가 아닐 경우 inhomogeneous라고 부른다. Definition 54.4 (짝 상관계수 함수) 만약 \\(\\rho\\), \\(\\rho^{(2)}\\)가 존재할 때, 짝 상관계수 함수(pair correlation function)은 \\[g(\\xi,\\eta)=\\frac{\\rho^{(2)}(\\xi,\\eta)}{\\rho(\\xi)\\rho(\\eta)}\\] 로 정의된다. Remark. 1. Poisson일 경우에는 \\(g(\\xi,\\eta)=1\\)이다. 즉 점들이 생기는 사건이 대략 독립이다. \\(g(\\xi,\\eta)&gt;1\\)인 경우는 각각 나올 확률보다 동시에 나올 확률이 높은 것이다. \\(g(\\xi,\\eta)&lt;1\\)는 2와 반대다. \\(X\\)가 정상(stationary)이면 \\(g\\)는 translation invariant이다. 즉 \\(g(\\xi, \\eta)=g(\\xi-\\eta)\\)인 것이다. 그러나 \\(g\\)가 translaton invariant라고 해서 \\(X\\)가 stationary인 것은 아닌데, 이에 대한 예로 log Gaussian Cox Process가 있다. Proposition 54.1 \\(h_{1}:\\mathbb{R}^{d}\\rightarrow [0,\\infty)\\), \\(h_{2}:\\mathbb{R}^{d}\\times \\mathbb{R}^{d}\\rightarrow [0,\\infty)\\)라고 하자. \\(X\\)는 intensity function \\(\\rho\\)를 갖고 second order density \\(\\rho^{(2)}\\)를 갖는다고 하자. 그러면 \\[E\\sum_{\\xi\\in X}h_{1}(\\xi)=\\int h_{1}(\\xi)\\rho(\\xi)d\\xi,\\] \\[E\\sum_{\\xi,\\eta\\in X}^{\\neq}h_{2}(\\xi,\\eta)=\\int\\int h_{1}(\\xi,\\eta)\\rho^{(2)}(\\xi,\\eta)d\\xi d\\eta\\] 이다. Proposition 54.2 \\(X\\)는 intensity function \\(\\rho\\)를 갖고 second order density \\(\\rho^{(2)}\\)를 갖는다고 하자. \\(X_{\\text{thin}}\\)은 \\(X\\)의 retention probability \\(p(\\xi)\\)에 대한 independent thinning이라고 하자. 그러면 \\(\\rho_{\\text{thin}}(\\xi)=p(\\xi)\\rho(\\xi)\\), \\(\\rho_{\\text{thin}}^{(2)}(\\xi,\\eta)=p(\\xi)p(\\eta)p^{(2)}(\\xi,\\eta)\\)가 되며 \\(g_{\\text{thin}}=g\\)이다. "],
["55-uGEVtheory.html", "Chapter 55 일변량 극단값 이론", " Chapter 55 일변량 극단값 이론 통계학자 존 튜키(John Tukey)는 이렇게 말했다. “나는 모든 지구물리학자들이 실제 오차나 변동성의 분포들이 가우스(Gauss)나 라플라스(Laplace)가 만든 매끄러운 종 모양의 분포보다 훨씬 더 극단값 분포에 가까운 모양을 갖고 있음을 알고 있다고 확신한다.” 이 장은 일변량 극단값 분포 이론과 모델링에 관한 내용을 담고 있다. 특히 부분 최댓값 \\[M_{n}=\\max\\{X_{1},\\ldots,X_{n}\\}\\] 의 통계적 움직임에 초점을 맞출 것이다. 여기서 \\(X_{1},\\ldots,X_{n}\\)은 \\(F\\)라는 분포함수를 갖는 독립 확률변수의 수열이다. 일반적으로 \\(X_{i}\\)는 일정한 시간 스케일(예: 시간별, 일별, 월별 등)을 갖고 측정된 어떤 (확률)과정의 값들을 나타낸다. 정리하면 \\(M_{n}\\)은 \\(n\\) 시간 단위의 관측값 중 최대값을 나타낸다. Definition 55.1 (극단값의 예) \\(n\\)이 일년동한 관찰한 관측값 수라고 할 경우, \\(M_{n}\\)은 월 최대값에 대응된다. \\(X_{i}\\)들이 독립이라고 가정하였으므로 \\(M_{n}\\)의 분포는 \\[ \\begin{align*} P\\{M_{n} \\leq z \\} &amp;= P\\{X_{1}\\leq z, \\ldots, X_{n} \\leq z\\}\\\\ &amp;=P\\{X_{1}\\leq z\\}\\times \\cdots \\times P\\{X_{n}z\\}\\\\ &amp;=\\{F(z)\\}^{n}. \\end{align*} \\] 가 된다. 그러나 이 식은 실제 도움이 되지 않는다. 왜냐하면 \\(F\\)의 진짜 분포가 어떤지를 모르기 때문이다. 여기서 우리는 관찰 데이터를 통해 \\(F\\)를 어떤 통계적 방법을 이용해 추정하고 그것으로 \\(F\\)를 대체할 가능성이 있는지 고민해볼 수 있다. 그렇지만 \\(F\\)의 변화가 아주 작더라도 \\(F^{n}\\)은 매우 많이 변하게 된다. 또 다른 접근방법으로는 \\(F\\)가 알려져 있지 않다는 것에 동의하고 극단값 자료만 가지고 \\(F^{n}\\)에 적합한 근사 모형이 있는지 찾아보는 방법이 있다. 이것은 표본 평균을 중심극한정리(central limit theorem)를 가지고 정규분포로 근사하는 것과 같은 방법이다. 즉 우리는 극단값 자료 분석에서도 중심극한정리와 같은 것이 있는지 살펴볼 필요가 있다. \\(n \\rightarrow \\infty\\)일 때 \\(F^{n}\\)의 움직임에 대해 살펴보자. 논리 전개를 위해 다음과 같은 논리가 추가로 더 필요하다. \\(z_{+}\\)를 \\(F(z)=1\\)로 만드는 가장 작은 값이라고 생각하자. 그러면 모든 \\(z &lt; z_{+}\\)에 대해 \\(n \\rightarrow \\infty\\)일 때 \\(F^{n}(z) \\rightarrow 0\\)이다. 결국 \\(M_{n}\\)은 \\(z_{+}\\)에서 점질량(point mass)을 갖는 퇴화분포(degenearte distribution)를 따르게 된다. 퇴화분포는 다루기 어렵기 때문에 다음과 같이 \\(M_{n}\\)에 대해 재정규화(re-normalization)를 한다. \\[M_{n}^{*}=\\frac{M_{n}-b_{n}}{a_{n}}.\\] 여기서 \\(\\{a_{n} &gt;0\\}\\)과 \\(\\{b_{n}\\}\\)은 적당한 상수열이다. \\(\\{a_{n}\\}\\)과 \\(\\{b_{n}\\}\\)은 \\(n\\)이 커짐에 따라 \\(M_{n}^{*}\\)의 위치(location)와 척도(scale)을 안정화시킬 수 있도록 잘 잡아준다. Theorem 55.1 (일반화 극단값 분포 정리) 만약 앞서 말한 상수열 \\(\\{a_{n} &gt;0\\}\\)과 \\(\\{b_{n}\\}\\)이 존재해 \\[P\\{(M_{n}-b_{n})/a_{n}\\leq z\\} \\rightarrow G(z), \\qquad{n \\rightarrow \\infty}\\] 가 성립한다고 가정하자. 여기서 \\(G\\)는 퇴화분포가 아닌 어떤 분포함수이다. 이 때, \\(G\\)다음 세 개의 족(family) 중 하나를 따른다. \\[\\textbf{(Gumbel): }G(z)=\\exp\\{\\exp[-(\\frac{z-b}{a})\\}, \\qquad{-\\infty &lt; z &lt; \\infty}.\\] \\[\\textbf{(Frechet): }G(z)= \\begin{cases} 0, &amp; \\text{z $\\leq$ b}\\\\ \\exp\\{-(\\frac{z-b}{a})^{-\\alpha}\\}, &amp; \\text{z &gt; b} \\end{cases}\\] \\[\\textbf{(Weibull): }G(z)= \\begin{cases} \\exp\\{-[-(\\frac{z-b}{a})^{-\\alpha}]\\}, &amp; \\text{z &lt; b}\\\\ 1, &amp; \\text{z $\\geq$ b} \\end{cases}\\] 이 때 \\(a&gt;0\\), \\(b\\)는 모수들이고 \\(\\alpha &gt;0\\)이다. 앞선 정리의 증명 스케치는 (Coles 2001) 50쪽에 잘 나와있다. 또한 증명을 위해 (Leadbetter 1983)을 참고하면 좋다. 증명을 위해서 다음과 같이 최대안정성(max-stablity)을 정의한다. Definition 55.2 (최대안정성) 모든 \\(n=2,3,\\ldots,\\)에서 상수들 \\(\\alpha_{n}&gt;0\\), \\(\\beta_{n}\\)이 존재해 \\[G^{n}(\\alpha_{n}z+\\beta_{n})=G(z)\\] 일 경우 분포 G를 최대안정(max-stable)하다고 부른다. 즉 \\(G\\)에 거듭제곱을 하는 것은 단지 위치모수와 척도모수의 변화만 야기한다는 것이다. 최대안정성과 일반화 극단값 분포 사이에는 다음과 같은 정리가 있다. Corollary 55.1 어떤 분포가 최대안정한 것은 분포가 일반화 극단값 분포임과 동치이다. (Coles 2001) Proof. (Coles 2001)에 따르면 GEV가 정말로 최대안정임을 보이는 것은 simple algebra로 가능하다고 한다. 그러나 역을 위해서는 함수해석 지식을 요구로 한다. 최대안정성의 패러다임은 다음과 같다. 유한한 \\(n\\)개의 블록 최댓값을 모델하고 그것의 최대안정 (극한) 분포를 사용하고, 자료의 temporal scale을 넘는 곳까지 외삽할 수 있게 한다. FIGURE 55.1: Plot of three GEV distributions. 위 정리는 재정규화 시킨 표본 최대값들 \\(M_{n}^{*}=\\frac{M_{n}-b_{n}}{a_{n}}.\\)이 세 가지 분포족 중 하나로 분포수렴할 것임을 알려주고 있다. \\(M_{n}^{*}\\)의 극한 분포는 놀랍게도 \\(F\\)에 상관없이 항상 저 세가지 분포족 중 하나로 수렴한다. 세 가지 분포의 이름은 앞으로 자주 등장할 것이므로 기억해두자. 참고로 이 적당한 \\(a_{n}\\), \\(b_{n}\\)은 존재하지 않을 수도 있다. (예: 포아송 분포) Example 55.1 (굼벨분포) \\(X_{1}, X_{2}, \\ldots\\)가 정규지수분포\\((=\\text{Exp}(1))\\)에서 추출된 확률변수의 수열이라고 하자. 참고로 \\(F(x)=1-\\exp^{x}\\) (\\(x&gt;0\\))이다. 이때 \\(a_{n}=1\\), \\(b_{n}=\\log n\\)이라고 하면 \\(n\\rightarrow \\infty\\)일 때 고정된 \\(z\\in\\mathbb{R}\\)에 대해 \\[\\begin{eqnarray} P\\{(M_{n}-b_{n})/a_{n} \\leq z \\} &amp;=&amp; F^{n}(z+\\log n) \\nonumber\\\\ &amp;=&amp;[1-e^{-(z+\\log n)}]^{n} \\nonumber\\\\ &amp;=&amp;[1-n^{-1}e^{-z}]^{n} \\nonumber\\\\ &amp;\\rightarrow&amp; \\exp(-e^{-z}) \\end{eqnarray}\\] 이다. 즉 \\(a_{n}\\)과 \\(b_{n}\\)을 위와 같이 선택하였을 때 \\(M_{n}\\)의 극한분포는 굼벨분포가 된다. Example 55.2 (굼벨분포로의 수렴속도) \\(X_{1}, X_{2}, \\ldots\\)가 표준정규분포에서 추출된 확률변수의 수열이라고 하자. 이때 \\[a_{n}=(2\\log n)^{-0.5}, b_{n}=(2\\log n)^{0.5}-0.5(2\\log n)^{-0.5}(\\log\\log n +log 4\\pi)\\] 로 놓을 경우 재정규화된 \\(M_{n}\\) 또한 굼벨분포로 수렴함이 알려져 있다. 그러나 앞 예제와 비교하였을 때 수렴 속도는 현저히 느리다. \\(M_{n}\\)의 수렴속도를 체크하는 것은 중요한 일이다. 왜냐면 우리는 일반화 극단값 분포를 유한개의 표본 최대값들의 점근 분포로 생각하고 사용할 것이기 때문이다. 결국 일반화 극단값 분포를 사용하기 위해 얼마나 많은 데이터가 필요할 것인가라는 문제는 \\(M_{n}\\)의 수렴속도와 관계된다. References "],
["55-1-domain-of-attraction.html", "55.1 흡인영역(domain of attraction)", " 55.1 흡인영역(domain of attraction) 이 부분은 (Huser 2013)을 참고하였다. Extremal types 정리는 i.i.d 확률변소의 renormalized maxima의 가능한 세 개의 극한 법칙을 구분해준다. 더 나아가, 만약 수열 \\(a_{n}&gt;0\\), \\(b_{n}\\in\\mathbb{R}\\)이 존재해 \\((M_{n}-b_{n})/a_{n}\\)이 non-degenerate 분포함수 G에 수렴한다면, G는 affine 변환(아핀 변환은 직선을 보존하며, 나아가 직선 위의 점들의 내분비, 외분비를 보존한다. 예를 들어 선분과 그의 중점은 변환 후 여전히 선분과 중점이다.)에 의해 유일하게 정의된다. 다시 말하면, 만약 다음과 같은 수열 \\(a_{n}&#39;&gt;0\\), \\(b_{n&#39;}\\in\\mathbb{R}\\)이 존재해 \\((M_{n}-b_{n}&#39;)/a_{n}&#39;\\stackrel{D}{\\rightarrow}G&#39;\\)라면 \\(G\\)와 \\(G&#39;\\)는 항상 같은 타입이어야 한다는 것이다. 따라서 우리는 어떤 분포의 최대값이 특별한 극한 법칙으로 흡인되는지에 따라 분포의 class들을 흡인영역(domain of attraction, MDA)으로 정의할 수 있다. Definition 55.3 (흡인영역) 확률변수 \\(Y\\)에 대해 다음과 같은 상수 \\(a_{n}&gt;0\\), \\(b_{n}\\in\\mathbb{R}\\)가 존재해 \\((M_{n}-b_{n})/a_{n}\\stackrel{D}{\\rightarrow}G\\)가 될 경우 우리는 \\(Y\\)가 극단값 분포 \\(G\\)의 흡인영역(domain of attraction, MDA)에 속한다고 하고 \\(Y\\in\\text{MDA}(G)\\)라고 쓴다. 이 흡인영역을 묘사하는 것에 대해서는 그동안 많은 연구가 진행되어왔다. tail-equivalent distributions라는 개념은 세 가지 타입의 극단값 분포의 MDA를 묘사하기 전에 먼제 설명하는 것이 필요하다. Definition 55.4 (Tail equivalence) 두 분포함수 \\(F_{1}\\), \\(F_{2}\\)가 같은 right endpoint \\(y_{F_{1}}=y_{F_{2}}=y_{F}\\)를 갖고 어떤 양의 상수 \\(0&lt;c&lt;\\infty\\)에 대해 \\[\\lim_{y\\rightarrow y_{F}}\\frac{1-F_{1}(y)}{1-F_{2}(y)}=c\\] 를 만족할 경우 두 분포함수는 tail-equivalent하다고 한다. 각각의 MDA은 tail-equivalence에 대해 닫혀있다. 즉 \\(F_{1}\\), \\(F_{2}\\)가 tail-equivalent이면 \\(F_{1}\\in \\text{MDA}(G)\\)는 \\(F_{2}\\in \\text{MDA}(G)\\)와 동치다. 즉 MDA는 riaght tail이 right end point에서 같은비율로 감소하는 분포들로 구성된다. Theorem 55.2 (MDA의 chracterization) \\(F\\)가 upper endpoint \\(y_{F}\\)를 갖는 분포함수라고 하자. 그리고 \\(\\sim\\)을 asymptotic equivalence를 나타내는 기호라고 하자. 그러면 어떤 \\(\\alpha &gt;0\\)과 \\(K\\in\\mathbb{R}\\)에 대해 다음 설정들은 참이 된다. \\(F\\in\\text{MDA}(\\Phi_{\\alpha})\\)는 \\(y\\rightarrow y_{F}=\\infty\\)임에 따라 \\(1-F(y)\\sim Ky^{-\\alpha}\\)임과 동치다. \\(F\\in\\text{MDA}(\\Psi_{\\alpha})\\)는 \\(y\\rightarrow y_{F}&lt;\\infty\\)임에 따라 \\(1-F(y)\\sim K(y_{F}-y)^{-\\alpha}\\)임과 동치다. \\(F\\in\\text{MDA}(\\Lambda)\\)는 \\(F(y)\\)가 \\(1-F(y)=c(y)\\exp[-\\int_{z}^{y}\\{1/a(t)\\}dt], z&lt;y&lt;y_{F}\\)를 만족하는 표현을 갖도록 하는 어떤 \\(z&lt;y_{F}\\leq \\infty\\)가 존재함과 동치다. 여기서 \\(c\\)는 가측함수이며 \\(y\\rightarrow y_{F}\\)일 때 \\(c(y)\\rightarrow c&gt;0\\)이고, \\(a(y)\\)는 양의 값을 갖는 (르베그 측도에 대해) absolutely continubous functions이고 density \\(a&#39;(y)\\)가 \\(\\lim_{y\\rightarrow y_{F}}a&#39;(y)=0\\)이다. Right endpoint에서 충분해 부드러운 분포의 경우에는 von Mises가 \\((M_{n}-b_{n})/a_{n}\\rightarrow Z \\sim \\text{GEV}(0,1,\\xi)\\)로 수렴하는 충분조건들을 발표했다. 이것은 극한 분포의 타입과 normalizing 상수들 \\(a_{n}&gt;0\\), \\(b_{n}\\)을 결정하는 데 큰 도움을 준다. 이러한 조건들은 알려진 분포들을 다른 MDA로 분류하는 데 사용된다. Proposition 55.1 (von Mises conditions) \\(F\\)가 right endpoint \\(y_{F}\\)를 갖는 분포함수고 \\(z&lt;y_{F}\\)가 존재해 \\(F\\)가 \\((z,y_{F})\\)에서 두번 미분가능하다고 가정하자. \\(f=F&#39;\\)가 \\((z,y_{F})\\)에서 \\(F\\)의 밀도라고 하자. 실수들의 수열 $b_{n}=F^{}(1-1/n)과 \\(a_{n}=r(b_{n})\\)을 정의하자. 이 때 \\(r(y)=\\{1-F(y)\\}/f(y)\\)가 \\(F\\)의 reciprocal harzard function이다. 더 나아가 \\(\\xi=\\lim_{y\\rightarrow y_{F}}r&#39;(y)\\)라고 하자. 그러면 \\((M_{n}-b_{n})/a_{n}\\stackrel{D}{\\rightarrow} Z\\sim \\text{GEV}(0,1,\\xi)\\)이다. 즉 \\(\\xi&gt;0\\)이면 \\(F\\in \\text{MDA}(\\Phi_{1/\\xi})\\)이고 \\(\\xi&lt;0\\)이면 \\(F\\in MDA(\\Psi_{-1/\\xi})\\)이고 \\(\\xi\\rightarrow 0\\)이면 \\(F\\in \\text{MDA}(\\Lambda)\\)이다. 다음은 (Huser 2013)에 있는 흡인영역에 따른 분포들의 분류다. \\(F\\in\\text{MDA}(\\Phi_{\\alpha})\\): 이들은 Fr'{e}chet 분포의 MDA이며 Fr'{e}chet, Pareto, Cauchy, Log0gamma, Student-t 분포 등이 속한다. \\(F\\in\\text{MDA}(\\Psi_{\\alpha})\\): 이들은 reversed Weibull 분포의 MDA이며 Uniform, Beta 그리고 \\(y_{F}&lt;\\infty\\)에서 power-law behavior를 갖는 모든 분포들이 속한다. \\(F\\in\\text{MDA}(\\Lambda)\\): 이들은 Gumbel 분포의 MDA이며 Normal, Gamma, Log-normal, Weibull, Exponential 그리고 모든 tail-equivalent distn들이 속한다. 그러나 maxima의 non-degenerate limiting distribution으로 이끄는 affine normalization이 항상 존재하지 않을 수도 있음을 항상 생각해야한다. 즉 어느 흡인영역에도 속하지 않는 분포가 존재한다는 것이다. 포아송, Geometric, negative binomial 분포 등이 대표적이다. 이러한 분포들은 right tail에서 not well-behaved하는 분포라고 생각하면 된다. 다음에 나오는 결과들은 non-degenerate 분포로의 maxima의 convergence는 right endpoint에서 어떤 continuity condition을 갖을 때에만 일어날 수 있으며, 이런 조건은 앞서 언급한 이산분포에서는 만족하지 못하는 것들이다. Proposition 55.2 \\(u_{n}\\)이 실수들의 수열이라고 하자. 그러면 모든 \\(0\\leq \\lambda \\leq \\infty\\)에 대해 두 가정이 동치이다. \\(n\\{1-F(u_{n}) \\}\\rightarrow \\lambda\\). \\(P(M_{n}\\leq u_{n}) \\rightarrow \\exp(-\\lambda).\\) Theorem 55.3 (Right endpoint에서의 continuity) \\(0&lt;\\lambda &lt;\\infty\\)라고 하자. 그러면 \\(n\\{1-F(u_{n})\\}\\rightarrow\\lambda\\)와 \\[\\lim_{y\\rightarrow y_{F}}\\frac{\\{1-F(y)\\}}{(1-F_{y_{\\cdot}})}=1\\] 을 동치로 만드는 수열 \\(u_{n}\\)이 존재한다. 이 때 \\(F_{y_{\\cdot}}=\\lim_{x\\uparrow y }F(x)\\)이다. \\(\\mathbb{Z}\\)에서 정의된 무한대의 rightendpoint를 갖는 분포에 대해 조건 \\(\\lim_{y\\rightarrow y_{F}}\\frac{\\{1-F(y)\\}}{(1-F_{y_{\\cdot}})}=1\\)은 \\(k\\rightarrow \\infty\\)일 때 \\(\\frac{1-F(k)}{1-F(k-1)}\\rightarrow 1\\)로 바꿀 수 있다. 포아송 분포의 경우에는 이 극한이 0이되며, maxima가 수렴하는 것을 막게 된다. Non-degenerate limit distribution for maxima가 존재하지 않는 또 다른 예로 super-heavy-tailed 분포가 있다. 예를 들어 분포함수 \\(F(y)=1-1/\\log(y), y&gt;e\\)는 매우 천천히 감소하여 적당한 linear normalizing constants \\(a_{n}&gt;0\\), \\(b_{n}\\)을 찾을 수 없을지도 모른다. References "],
["55-2-generalized-extreme-value-distribution.html", "55.2 일반화 극단값 분포(generalized extreme value distribution)", " 55.2 일반화 극단값 분포(generalized extreme value distribution) 앞서 말한 \\(G\\)의 극한값에서의 행동은 분포에 따라 달라진다. 예를 들면, 굼벨분포와 프레셰분포는 \\(z_{+}=\\infty\\)이나 와이블분포는 \\(z_{+}&lt;\\infty\\)이다. 그리고 굼벨분포에서는 \\(G\\)의 분포가 지수적으로 감소(exponentially decay)하나 프레셰분포에서는 다항식 차수로 감소(polynomially decay)한다. 즉 족이 달라지면 극단값의 움직임 또한 다르게 표현될 것임을 알려준다. 그런데 이렇게 족 별로 따로 나누어 분석하는 것은 두 가지 문제점을 지닌다. 첫째, 데이터를 보고 어떤 족으로 분석하는 것이 적절한지 미리 정해야 한다. 둘째, 이러한 결정 후에는 이 결정이 맞다는 전제 하에 추론이 진행되고 이 선택이 가지는 불확실성을 배제하게 된다. 따라서 일반적으로는 앞 정리에 나왔던 식을 재구성하여 다음과 같이 하나의 함수로 표현하여 분석하게 된다. \\[G(z)=\\exp\\{-[1+\\xi(\\frac{z-\\mu}{\\sigma})]^{-1/\\xi}\\}.\\] 이 때 \\(\\{z: 1+\\xi(z-\\mu)/sigma &gt;0\\}\\)이며 \\(-\\infty &lt; \\mu &lt; \\infty\\), \\(\\sigma &gt;0\\) 그리고 \\(-\\infty &lt;\\xi &lt;\\infty\\)를 만족한다. 이 분포를 일반화 극단값 분포(generalized extreme value distribution)이라고 부른다. 여기서 \\(\\mu\\)는 위치모수(location parameter), \\(\\sigma\\)는 척도모수(scale parameter), 그리고 \\(\\xi\\)는 형태모수(shape parameter)라고 한다. 특히 \\(\\xi\\)는 이 분포가 굼벨족(\\(\\xi=0\\)), 프레셰족(\\(\\xi&gt;0\\)) 또는 와이블족(\\(\\xi&lt;0\\))이 될지 결정하는 역할을 한다. "],
["55-3-return-level.html", "55.3 복귀 수준(return level)", " 55.3 복귀 수준(return level) 앞서 극단값 분석은 극단적인 사건들을 모델링하고 적합한 위험 평가를 해 줄 수 있는 통계적 방법을 제공한다고 설명하였다. 그렇다면 우리는 어떤 방법을 통해 이 위험(risk)를 측정할 수 있을까? 한 가지 방법으로 복귀 수준(return level)이라는 것이 있다. n-복귀 수준은 우리가 매 \\(n\\)년마다 한 번꼴로 초과될 것으로 기대되는 값이다. 다시 말하면 어떤 특정한 해에 그런 강도의 사건을 마주칠 확률이 \\(\\frac{1}{n}\\) 정도 될 때 \\(n\\)-복귀 수준이 된다. 분위수(quantile)로 봤을 때에는 \\(1-\\frac{1}{n}\\)분위수에 대응되는 사건이다. Example 55.3 (복귀 수준) 20년 복귀 수준은 매 20년마다 최대 수준이 한 번꼴로 초과할 것으로 기대되는 수준에 대응된다. 이것은 매 년 \\(\\frac{1}{20}=0.05\\)의 확률로 그러한 사건이 마주칠 것으로 기대되며 \\(1-\\frac{1}{20}=0.95\\)의 분위수에 대응된다. 일반적으로 많이 쓰이는 복귀 수준은 \\(20, 50, 100\\)년 정도이다. 이 복귀 수준이라는 개념은 통계학에서 말하는 분위수와 일맥상통한다. \\(0&lt;p&lt;1\\)이라 할 때, 일반화 극단값 분포의 분위수 \\(x_{p}\\)는 \\[x_{p}=\\mu-\\frac{\\sigma}{\\xi}[1-\\{-\\log(1-p)\\}^{-\\xi}]\\] 가 된다. 이것은 \\(G(x_{p})=1-p\\)라 놓고 \\(x_{p}\\)에 대해 풀어 얻을 수 있다. 이 때 \\(x_{p}\\)를 \\(1/p\\) 복귀 주기(return period)에 대응되는 복귀 수준이라 부른다. "],
["55-4-inference-in-extreme-value-statistics.html", "55.4 극단값 분포에서의 추론(inference in extreme value statistics)", " 55.4 극단값 분포에서의 추론(inference in extreme value statistics) \\(k\\)개의 연 최대값 \\(X_{1}, \\ldots , X_{k}\\)들이 주어져 있을 때, 일반화 극단값 분포의 모수들 \\((\\mu, \\sigma, \\xi)\\)을 추론하는 문제를 생각해보자. 가능한 추론 방법들은 다음과 같다. 그래프 기반 방법: 전통적으로 중요했고, 지금도 기본적인 모형 파악에 유용하다. 적률 기반(moment-based) 추정량: 적률이 존재하지 않을 가능성이 있어 극단값 분석에 유용하지 않은 경우가 많다. 확률 가중 적률: 수문학(hydrology)에서 많이 쓰이나 복잡한 자료로 확장하기 어렵다. 가능도(likelihood) 기반 방법: 통계학에서 가장 많이 이용하는 방법이다. 복잡한 자료에 적용할 수 있고 일반적인 점근적 추정과 검정이론을 적용할 수 있다. 또한 베이지안 방법을 적용할 수도 있다. 일반화 극단값 분포를 가능도 기반 방법으로 분석할 때 정칙 조건(regularity condition)을 만족하는지 항상 확인해야 한다. 일반화 극단값 분포의 모수들로 표현된 값 \\(\\mu-\\sigma/\\xi\\)이 \\(\\xi\\neq 0\\)일때 분포의 끝점(end point)이 되기 때문에 정칙 조건을 만족하지 않을 수도 있다.(Smith 1985) 한편 형태모수 값과 최대가능도추정량의 존재 사이의 관계에 대해 다음과 같은 사실이 알려져 있다. \\(\\xi &gt; -0.5\\)인 경우 최대가능도추정량은 정칙조건을 만족하며 일반적인 점근적 성질을 갖는다. \\(-1 &lt; \\xi &lt; -0.5\\)인 경우 최대가능도추정량을 얻을 수는 있으나 일반적인 점근적 성질을 갖지는 않는다. \\(\\xi &lt; -1\\)인 경우 최대가능도추정량을 얻지 못할 가능성이 높다. References "],
["55-5-mle-in-extreme-value-statistics.html", "55.5 극단값 분포에서의 최대가능도추정(mle in extreme value statistics)", " 55.5 극단값 분포에서의 최대가능도추정(mle in extreme value statistics) 일반화 극단값 분포에 최대가능도추정을 적용하기 전에 일반적인 가능도 관련 이론에 대해 정리해보자. Definition 55.5 (가능도와 최대가능도추정량) \\(y\\)가 자료이고 이 자료가 다음과 같은 모수 \\(\\theta\\)로 정의되는 확률변수 \\(Y \\sim f(y;\\theta)\\)의 실현(realization)이라고 하자. 이때 가능도(likelihood, 우도)와 로그 가능도는 \\[L(\\theta)=L(\\theta;y)=f_{Y}(y;\\theta), l(\\theta)=\\log L(\\theta), \\theta \\in \\Omega_{\\theta}\\] 로 정의된다. 최대가능도추정량(maximum likelihood estimate, MLE)은 \\[l(\\hat{\\theta})\\geq l(\\theta), \\forall \\theta \\in \\Omega_{\\theta}\\] 을 만족시키는 \\(\\hat{\\theta}\\)이다. 많은 경우 \\(\\hat{\\theta}\\)는 유일하며 다음과 같은 점수방정식(score equation, 또는 가능도방정식) \\[\\frac{\\partial l(\\theta)}{\\partial \\theta}=0\\] 을 만족한다. 만약 \\(\\theta\\)가 \\(p \\times 1\\) 벡터라면 점수방정식 또한 \\(p \\times 1\\) 벡터가 된다. 관측정보행렬(observed information matrix)는 점수방정식을 한 번 더 미분한 것이다. \\[J(\\theta)=-\\frac{\\partial^{2}l(\\theta)}{\\partial \\theta \\partial \\theta^{T}}.\\] 만약 \\(\\theta\\)가 \\(p \\times 1\\) 벡터라면 \\(J(\\theta)\\)는 \\(p \\times p\\) 행렬이 된다. 가능도 통계량(likelihood ratio statistic, 윌크스의 통계량)은 \\[W(\\theta)=2\\{l(\\hat{\\theta})-l(\\theta)\\}\\geq 0\\] 이다. 가능도 근사(likelihood approximation)은 \\(n\\)이 클때, 데이터가 \\(f(y,\\theta^{0})\\)에서 생성되었다고 가정하면 \\[\\hat{\\theta} \\stackrel{\\cdot}{\\sim} \\mathcal{N}_{p}(\\theta^{0}, J(\\hat{\\theta})^{-1})\\] 로 근사하는 것이다. 이때 \\(\\hat{\\theta}\\), \\(J(\\hat{\\theta})\\)는 보통 수치적으로 계산하게 된다. 그리고 검정통계량은 \\(n\\)이 작을지라도 \\[W(\\theta^{0}) \\stackrel{\\cdot}{\\sim} \\xi_{p}^{2}\\] 근사를 이용한다. 실제로는 \\(\\theta\\)를 흥미있는 모수들(interest parameters) \\(\\psi_{q\\times 1}\\)와 장애모수들(nuisance parameters) \\(\\lambda_{p-q\\times 1}\\)로 나누어 분석하게 된다. \\(\\hat{\\lambda}_{\\psi}\\)를 \\(\\psi\\)가 고정되어 있을 때 \\(\\lambda\\)의 최대가능도추정량이라고 하자. 그러면 일반화가능도통계량(generalized likelihood ratio statistic)을 \\[W_{p}(\\psi)=2\\{l(\\hat{\\psi},\\hat{\\lambda})-l(\\psi,\\hat{\\lambda}_{\\psi})\\}=2\\{l(\\hat{\\theta})-l(\\hat{\\theta}_{\\psi})\\}\\] 로 정의한다. 이 때 다음과 같은 통계량을 정의할 수 있다. Definition 55.6 (일반화가능도통계량) 일반화가능도통계량(generalized likelihood ratio statistic)은 \\[W_{p}(\\psi)=2\\{l(\\hat{\\psi},\\hat{\\lambda})-l(\\psi,\\hat{\\lambda}_{\\psi})\\}=2\\{l(\\hat{\\theta})-l(\\hat{\\theta}_{\\psi})\\}\\] 이다. 만약 \\(\\psi^{0}\\)이 정칙모형(regular model)의 자료로부터 얻은 \\(\\psi\\)값이라고 하면 앞선 정의에 의해 \\[W_{p}(\\psi) \\stackrel{\\cdot}{\\sim} \\xi_{q}^{2}, \\qquad{for large n}\\] 이 된다. \\(\\psi^{0}\\)에 대한 신뢰구간(confidence interval)과 검정은 이것에 기초해서 만들게 된다. "],
["55-6-profile-likelihood-in-extreme-value-statistics.html", "55.6 극단값 분포에서의 프로파일 가능도(profile likelihood in extreme value statistics)", " 55.6 극단값 분포에서의 프로파일 가능도(profile likelihood in extreme value statistics) 앞선 상황처럼 알려지지 않은 모수를 흥미있는 모수들과 장애모수들로 나눌 수 있고 이 둘을 모두 추정해야 하나 흥미있는 모수들에만 관심이 있을 경우 사용할 수 있는 것 중의 하나가 프로파일 가능도(profile likelihood)이다. Definition 55.7 (프로파일 가능도) \\(\\theta\\)를 모수 벡터라 하고 \\(\\theta_{i}\\)를 제외한 모든 \\(\\theta\\)의 원소들의 모임을 \\(\\theta_{-i}\\)라고 했을 때 \\(\\theta_{i}\\)에 대한 프로파일 로그 가능도(profile log-likelihood)는 \\[l_{p}(\\theta_{i})=\\max_{\\theta_{-i}}l(\\theta_{i},\\theta_{-i})\\] 이다. Definition 55.8 (프로파일 로그 가능도) \\(\\theta\\)를 모수 벡터라 하고 이것을 \\((\\theta^{(1)}, \\theta^{(2)})\\)로 분할할 수 있다고 하자. 여기서 \\(\\theta^{(1)}\\)은 \\(k\\)차원 흥미있는 모수들의 벡터이며 \\(\\theta^{(2)}\\)는 나머지들의 \\((d-k)\\)차원 벡터이다. 이때 \\(\\theta^{(1)}\\)에 대한 프로파일 로그 가능도(profile log-likelihood)는 \\[l_{p}(\\theta^{1})=\\max_{\\theta^{(2)}}l(\\theta^{(1)},\\theta^{(2)})\\] 이다. 정칙 조건 하에서 프로파일 로그 가능도를 이용한 통계량은 다음과 같은 점근분포를 갖음이 알려져 있다.(Coles 2001) Theorem 55.4 (프로파일 로그 가능도를 이용한 통계량의 점근분포) \\(x_{1}, \\ldots , x_{n}\\)을 모수분포 \\(\\mathcal{F}\\) 안에 있는 어떤 분포의 독립적인 실현이라고 하자. \\(\\hat{\\theta}_{0}\\)을 \\(d\\)차원 모수벡터 \\(\\theta_{0}=(\\theta^{(1)},\\theta^{(2)})\\)의 최대가능도추정량이라고 하자. 이때 \\(\\theta^{(1)}\\)의 길이를 \\(k\\)라고 하자. 그러면 정칙 조건 하에서 \\(n\\)이 클 때 \\[D_{p}(\\theta^{(1)})=2\\{l(\\hat{\\theta}_{0})-l_{p}(\\theta^{(1)}) \\} \\stackrel{\\cdot}{\\sim} \\chi_{k}^{2}\\] 이다. 위 정리는 크게 두 가지 상황에서 쓰인다. 첫째, 길이 1의 모수 \\(\\theta_{i}\\)에 대해 \\((1-\\alpha)\\) 신뢰구간 \\(C_{\\alpha}=\\{\\theta_{i}: D_{p}(\\theta_{i})\\leq c_{\\alpha}\\}\\)를 계산할 때 쓴다. 여기서 \\(c_{\\alpha}\\)는 \\(\\xi_{1}^{2}\\) 분포의 \\((1-\\alpha)\\) 분위수를 뜻한다. 두 번째 응용은 모형 선택이다. References "],
["55-7-l-probability-weighted-moments-or-l-moments.html", "55.7 확률가중적률 또는 L-적률 (probability weighted moments or L-moments)", " 55.7 확률가중적률 또는 L-적률 (probability weighted moments or L-moments) (Dey and Yan 2015)의 1장을 참고하였다. 분포함수 \\(F\\)를 갖는 확률변수 \\(X\\)의 확률가중적률(probability weighted moment)는 다음과 같이 정의된다. \\[M_{p,r,s}=E\\{ X^{p}F^{r}(X)[1-F(X)]^{s} \\}.\\] 여기서 \\(p,r,s\\)는 실수이다. 이러한 양은 \\(F\\)의 분위수 함수 \\(Q\\)가 closed form을 갖을 때 잘 계산된다. \\[M_{p,r,s} = \\int_{0}^{1}Q^{p}(u)u^{r}(1-u)^{s}du.\\] \\(M_{p,0,0}\\)은 \\(X\\)의 \\(p\\)차 적률이며 \\(\\xi &lt; 1/\\xi\\)일 때에만 존재한다. 이러한 제한은 GEV 모수 추정에서 method of moment를 사용하는 것이 매력적이지 않게 한다. (Hosking, Wallis, and Wood 1985)는 양 \\(\\beta_{r}=M_{1,r,0},r=0,1,2,\\ldots,\\)을 조사하였고 이들이 평균만 존재하면(즉 \\(\\xi&lt;1\\)) 모수를 추정하는데 이들의 표본을 사용할 수 있다는 것을 밝혔다. Closed-form quantile function이 존재할 때, (Hosking, Wallis, and Wood 1985)에서의 \\(\\beta_{r}\\)은 다음과 같다. \\[\\beta_{r}=\\frac{1}{r+1}\\Big[ \\mu-\\frac{\\sigma}{\\xi}\\{ 1-(r+1)^{\\xi}\\Gamma(1-\\xi) \\} \\Big],\\qquad{\\xi &lt; 1}.\\] \\(r\\in\\{0,1,2\\}\\)일 때 이것은 또한 다음들을 유도한다. \\[\\begin{equation} \\beta_{0}=\\mu -\\frac{\\sigma}{\\xi}(1-\\Gamma(1-\\xi)) \\tag{55.1} \\end{equation}\\] \\[\\begin{equation} 2\\beta_{1}-\\beta_{0}=\\frac{\\sigma}{\\xi}(1-\\xi)(2^{\\xi}-1) \\tag{55.2} \\end{equation}\\] \\[\\begin{equation} \\frac{3\\beta_{2}-\\beta_{0}}{2\\beta_{1}-\\beta_{0}}=\\frac{3^{\\xi}-1}{2^{\\xi}-1}. \\tag{55.3} \\end{equation}\\] \\(\\beta_{r}\\)의 추정은 순서통계량 \\(Y_{1:m},\\ldots, Y_{m:m}\\)에 기반하여 편리하게 계산할 수 있다. \\(\\beta_{r}\\)의 불편추정량은 다음과 같다. \\[b_{r}=\\frac{1}{m}\\sum_{j=1}^{m}\\Big(\\prod_{l=1}^{r}\\frac{(j-l)}{(m-l)}\\Big)Y_{j:m}.\\] 확률가중적률 추정량(probability weighted moment estimator)는 식 (55.1), (55.2), (55.3)에 있는 \\(\\beta_{r}\\)을 \\(b_{r}\\) 또는 \\(\\hat{\\beta}_{r}\\)로 대체한 것이다. References "],
["56-pot.html", "Chapter 56 분계점 방법들", " Chapter 56 분계점 방법들 지금까지는 블록 최대값으로 모델링하는 방법에 대해 생각해보았다. 그러나 이 방법은 데이터를 낭비한다고도 볼 수 있고, 모든 최대값이 진짜로 극단값인지에 대한 의문이 들게 된다. 즉 어떤 블록의 최대값이 아닌 값들이 다른 블록들의 최대값보다 훨씬 크지만 극단값으로 뽑히지 않는 상황이 발생하게 된다. 만약 시간별 또는 일별 관측값과 같은 상세한 시계열 자료를 얻을 수 있다면 블록화 하는 방법 이외에 다른 방법들 또한 고려해 볼 수 있을 것이다. 일반적으로 임계화를 하는 방법은 좀 더 효율적이지만, 시간 상관관계에 대한 좀 더 상세한 모델링을 필요로 한다. 분계점 방법들에 대한 간단한 리뷰로 (Scarrott and MacDonald 2012)를 참고하길 바란다. References "],
["56-1-generalized-pareto-distribution.html", "56.1 일반화 파레토 분포(generalized pareto distribution)", " 56.1 일반화 파레토 분포(generalized pareto distribution) \\(X_{1},X_{2},\\ldots\\)를 독립적이며 같은 분포를 따르며 분포함수 \\(F\\)를 갖는 확률변수들의 수열이라고 하자. 여기서 분계 \\(u\\)를 초과하는 \\(X_{i}\\)값들을 극단 사건(extreme event)라고 생각할 수 있다. \\(F\\)가 알려져 있는 분포라고 한다면 \\[P\\{X&gt;u+y|X&gt;u\\}=\\frac{1-F(x+y)}{1-F(u)}, y&gt;0\\] 이 성립한다. 주된 결과는 다음 정리에 포함되어 있다. Theorem 56.1 (일반화 파레토 분포) \\(X_{1},X_{2},\\ldots\\)이 분포함수 \\(F\\)를 갖는 독립인 확률변수의 수열이라고 하자. 그리고 \\[M_{n}=\\max\\{X_{1},\\ldots,X_{n}\\}\\] 을 정의한다. \\(F\\)가 극단 종류 정리를 만족한다면 충분히 큰 \\(n\\)에 대해 \\[P\\{M_{n}\\leq z\\}\\approx G(z)\\] 이 성립한다. 이때 \\[G(z)=\\exp\\{-[1+\\xi(\\frac{z-\\mu}{\\sigma})]^{-1/\\xi}\\}\\] 이며 여기서 \\(\\mu, \\sigma&gt;0\\)이다. 그리고 충분히 큰 \\(u\\)에 대해 \\(X&gt;u\\)일 때 \\((X-u)\\)의 분포함수는 \\[ H(y)=1-(1+\\frac{\\xi y}{\\tilde{\\sigma}})^{-1/\\xi} \\] 로 근사할 수 있다. 이 때 \\(\\{ y: y &gt; 0 \\text{ and } (1+\\xi y / \\tilde{\\sigma}) &gt;0 \\}\\)이며 \\[ \\tilde{\\sigma}=\\sigma + \\xi (x-\\mu) \\] 이다. 앞선 정리는 \\(H(y)\\)를 \\(u\\)가 증가함에 따라 수렴하는 극한 분포라고 생각하여 간간히 할 수 있다. \\(H(y)\\)로 정의되는 족(family)들을 일반화 파레토 족(generalized Pareto family)이라고 부른다. 앞선 정리는 블록 최댓값이 근사 분포 \\(G\\)를 갖으면, 임계 초과들은 일반화 파레토 족에서 근사하는 분포를 찾을 수 있다는 것이다. 더 나아가 , GPD의 모수들은 그것과 연관된 GEV 분포에 의해 유일하게 결정된다. 예를 들면, 앞선 정리에서 나오는 \\(\\xi\\)는 대응되는 GEV 분포에서의 \\(\\xi\\)와 정확하게 같다. 한 가지 다른 점이 있다면 GEV 분포의 모수와는 다르게 block size에 invariant하다는 것이다. 이런 GEV 분포와 GPD 사이의 duality는 GEV 분포에서처럼 모수 \\(\\xi\\)가 GPD의 질적인 행동을 결정하는 데 가장 큰 역할을 한다는 것을 말해준다. \\(\\xi&lt;0\\)이면 초과의 분포는 \\(u-\\tilde{\\sigma}/\\xi\\)의 upper bound를 갖는다. 만약 \\(\\xi=0\\)이면 분포는 unbounded이고 \\(H(y)\\)에서 \\(\\xi \\rightarrow 0\\)인 극한을 취해 다음의 식을 얻는다. \\[ H(y)=1-\\exp(-\\frac{y}{\\tilde{\\sigma}}), y &gt; 0. \\] 이 식은 모수가 \\(1/\\tilde{\\sigma}\\)인 지수 분포에 대응된다. "],
["56-2-modeling-threshold-excesses.html", "56.2 분계 초과의 모델링(modeling threshold excesses)", " 56.2 분계 초과의 모델링(modeling threshold excesses) 56.2.1 분계점 선택(threshold selection) 원래 자료가 i.i.d measurement \\(x_{1}, \\ldots, x_{n}\\)으로 구성되어 있다고 하자. 극단 사건들은 high threshold \\(u\\)로 정의된다. 즉 \\(\\{x_{i}: x_{i}&gt;u\\}\\)로 구성된 임과 초과들로 정의된다. 이러한 초과값들을 \\(x_{(1)}, \\ldots , x_{(k)}\\)라고 이름붙이고 threshold excesses를 \\(y_{j}=x_{(j)}-u, j=1,\\ldots, k\\)라고 정의하자. 앞선 GPD 정리에 따라 \\(y_{j}\\)는 분포를 GP족의 한 멤버로 근사할 수 있는 random variable의 independent realization으로 간주할 수 있다. 추론은 관찰된 임계 초과의 GP족의 적합, 모델 적합과 외삽으로 구성된다. GPD에서 threshold를 선택하는 문제는 block maxima 접근에서 block size를 고르는 문제와 유사한다. 이 경우에는 임계가 너무 낮으면 모형의 asymptotic bias를 위반할 수 있다. 너무 높으면 초과되는 값이 적어져 추정시 큰 분산을 만들게 된다. 일반적으로는 limit model이 reasonable approximation을 할 수 있도록 가능한 한 낮은 임계를 잡아주는 것이 좋다고 한다. 이러한 목적으로 두 가지 방법이 가능하다. 모형 추정 전에 탐색적 기법들을 사용한다. 모델을 다른 임계점들에 대해 적합해보고 추정된 모수의 안정성을 평가해 본다. 첫 번째 방법은 GPD의 평균에 기반한 방법이다. \\(Y\\)가 모수 \\(\\sigma, xi\\)인 GPD 분포를 따른다면 \\[\\begin{equation} E(Y)=\\frac{\\sigma}{1-\\xi}, \\xi&lt;1 \\tag{56.1} \\begin{equation} 이 된다. 만약 $\\xi\\leq 1$이면 평균은 무한대다. GPD가 수열 $X_{1},\\ldots, X_{n}$으로부터 생성되고 임계가 $u_{0}$인 초과의 모델로서 유효하다고 가정해보자. 그러면 \\@ref(eq:meanGPD)에 의해 $$ E(X-u_{0}|X &gt;u_{0})=\\frac{\\sigma_{u_{0}}}{1-\\xi}, \\xi &lt; 1 $$ 을 얻을 수 있다. 그런데 GPD가 $u_{0}$보다 큰 임계에 대해서도 유효해야 GPD가 유효하다고 볼 수 있으므로, 모든 $u&gt;u_{0}$에 대해 $\\sigma_{u_{0}}$또한 적절히 변해야 한다. 따라서, $u&gt;u_{0}$일 떄 $\\tilde{\\sigma}=\\sigma + \\xi (x-\\mu)$ 관계에 의해 $$ \\begin{align*} E(X-u|X&gt;u)&amp;= \\frac{\\sigma_{u}}{1-\\xi}\\\\ &amp;=\\frac{\\sigma_{u_{0}}+\\xi u}{1-\\xi} \\end{align*} $$ 를 얻는다. 따라서 $u&gt;u_{0}$일 때 $E(X-u|X&gt;u)$는 $u$에 대한 선형 함수여야 한다. 즉 $u$에 따라 선형으로 변하는 추정들은 GP 모형에서 적당하다고 생각할 수 있다. $$(u,\\frac{1}{n_{u}}\\sum_{i=1}^{n_{u}}(x_{(i)}-u) : u &lt; x_{\\text{max}}),$$ 이 때 $x_{(1)},\\ldots, x_{(n_{u})}$는 $u$를 초과하는 $n_{u}$개의 관찰값들이고 $x_{\\text{max}}$가 $X_{i}$들 중 가장 큰 값이라고 할 때, 이것을 **mean residual plot**이라고 부른다. &lt;!--chapter:end:92-pot.Rmd--&gt; # 극단값이론에서의 점과정 {#ppextremes} Poisson-GPD 모형은 GPD에 the number of exceedances를 Poisson 분포로 하여 모델링 한 것이다. 보통 Poisson 분포의 평균을 $\\lambda$ (per time)로 하여 모델링한다. &lt;!--chapter:end:93-ppextremes.Rmd--&gt; # 다변량 극단값 이론 {#mevtheory} 이 부분은 [@Dey2015]의 2장을 참고하였다. ## 코퓰라(copula) 이변량 또는 다변량 분포를 만들 수 있는 방법으로 **코퓰라(copula)**라는 것이 있다. 이것은 보험학, 금융, 경제 모델링, 생존분석, 극단값, 환경 모델링, 시계열과 생물통계 등에서 최근에 주목을 받고 있다. 이 부분은 [@Mikosch2006]를 참고하였다. 연속 분포 $F$를 갖고 그것의 support에서 역 $F^{-1}$을 갖는 실변수 확률변수 $X$를 생각해보자. 만약 $U$가 $(0,1)$에서 정의된 균등분포일 때 $X\\stackrel{d}{=}F^{-1}(U)$와 $F(X)\\stackrel{d}{=}U$임을 쉽게 체크할 수 있다. 이제 respective marginal distribution functions $F_{i}$ (assumed to be continous and have inverse on the support of $X_{i}$)를 갖는 $\\mathbb{R}^{d}$차원 무작위벡터 $\\mathbf{X}=(X_{1},\\ldots, X_{d})$를 생각하보자. 1차원일 때와 같은 방법으로 다음의 결과를 얻을 수 있다. $$ \\begin{align*} P(X_{1}\\leq F_{1}^{-1}(x_{1}),\\ldots, X_{d}\\leq F_{d}^{-1}(x_{d})) &amp;= P(F_{1}(X_{1})\\leq x_{1}, \\ldots, F_{d}(X_{d})\\leq x_{d}) \\\\ &amp;= C(x_{1},\\ldots, x_{d}). \\end{align*} $$ 식의 오른쪽에서 $d$차원 분포함수 $C$는 support $[0,1]^{d}$를 갖고 uniform marginal distribution functions를 갖는다. 이 때 이 분포함수 $C$를 벡터 $\\mathbf{X}$의 **코퓰라(copula)**라고 부른다. 한편 $\\mathbf{X}$의 copula $C$가 주어졌을 때 우리는 분포함수들 $F_{i}$들을 이용해 $\\mathbf{X}$의 distribution function을 재구성할 수 있다. $$ \\begin{align*} P(X_{1}\\leq y_{1}, \\ldots, X_{d}\\leq y_{d}) &amp;= P(F_{1}(X_{1})\\leq F_{1}(y_{1}), \\ldots, F_{d}(X_{d})\\leq F_{d}(y_{d})) \\\\ &amp;= C(F_{1}(y_{1}),\\ldots,F_{d}(y_{d})). \\end{align*} $$ 좀 더 넓은 의미로 $[0,1]^{d}$에서 support를 갖고 uniform marginal을 갖는 분포함수들을 코퓰라라고 부른다. 주변 분포 함수들 $F_{i}$에 대한 가정이 주어졌다면, 코퓰라 $C$와 $\\mathbf{X}$의 분포 사이에는 일대일 대응관계가 존재한다. 즉, $X_{1},\\ldots, X_{d}$의 상관관계 구조는 코퓰라와 주변분포 $F_{i}$로 재구성될 수 있다는 것이다. 그러나 코퓰라 $C$를 갖는 벡터 $\\mathbf{X}=(X_{1},\\ldots, X_{d})$와 분포함수 $C$를 갖는 $\\mathbf{Y}=(F_{1}(X_{1}), \\ldots, F_{d}(X_{d}))$의 dependence structure가 같다고 얘기하는 것은 아니다. 예를 들어, 벡터 $\\mathbf{X}$의 상관관계가 정의될 경우, 그것은 보통 $\\mathbf{Y}$의 상관관계 구조와 다르다. $X_{1},\\ldots, X_{d}$가 zero autocorrelation들을 갖는 seond order stationary process에서 얻은 표본들이라고 하자. 이것에 대응되는 $F_{1}(X_{1}), \\ldots, F_{d}(X_{d})$들을 매우 correlated되어 있고 따라서 일반적으로 second order stationary가 아닐 것이다. 마찬가지로 spectral measure도 $\\mathbf{X}$ with unbounded support에서 make sense한 $\\mathbf{Y}$에서는 그렇지 않다. \\BeginKnitrBlock{theorem}\\iffalse{-91-45572-51201-32-48516-54252-32-54632-49688-50752-32-53076-54512-46972-93-}\\fi{}&lt;div class=&quot;theorem&quot;&gt;&lt;span class=&quot;theorem&quot; id=&quot;thm:unnamed-chunk-409&quot;&gt;&lt;strong&gt;(\\#thm:unnamed-chunk-409) \\iffalse (누적 분포 함수와 코퓰라) \\fi{} &lt;/strong&gt;&lt;/span&gt;Sklar (1959)의 정리는 코퓰라 이론의 시작점을 제시하였다. [@Yee2015] $F$가 무작위 벡터 $(Y_{1}, Y_{2})$의 CDF이고 marginal이 $F_{1}$, $F_{2}$일 때, 대응되는 copula $C$가 존재해 다음을 만족한다. $$F(y_{1}, y_{2})=C(F_{1}(y_{1}), F_{2}(y_{2});\\boldsymbol{\\alpha})=C(u_{1},u_{2};\\boldsymbol{\\alpha}).$$ 모든 $(y_{1}, y_{2})\\in\\mathbb{R}^{2}$에 대해 $F_{j}$가 연속이라면 $C$는 unique하다고 할 수 있다. &lt;/div&gt;\\EndKnitrBlock{theorem} 우리는 $C$를 dependency parameter $\\boldsymbol{\\alpha}$를 통해 $F$의 dependence structure 정보를 담고 있는 것으로 볼 수 있다. 보통 $\\boldsymbol{\\alpha}$는 1차원 또는 2차원이다. \\BeginKnitrBlock{example}\\iffalse{-91-51060-48320-47049-32-44032-50864-49828-32-53076-54512-46972-93-}\\fi{}&lt;div class=&quot;example&quot;&gt;&lt;span class=&quot;example&quot; id=&quot;exm:unnamed-chunk-410&quot;&gt;&lt;strong&gt;(\\#exm:unnamed-chunk-410) \\iffalse (이변량 가우스 코퓰라) \\fi{} &lt;/strong&gt;&lt;/span&gt;$\\boldsymbol{\\alpha}=\\rho$일 때 **이변량 가우스 코퓰라(bivariate Gaussian copula)**는 $$C(u_{1}, u_{2}, \\rho)=\\Phi_{2}(\\Phi^{-1}(u_{1}), \\Phi^{-1}(u_{2});\\rho), -1&lt;\\rho &lt; 1, 0\\leq u_{j} \\leq 1$$ 이다. &lt;/div&gt;\\EndKnitrBlock{example} [@Yee2015]는 이변량 코퓰라들의 흥미로운 성질들을 적어놓았다. 1. $C(u_{1}, u_{2})=0$ if $u_{1}=0$ and/or $u_{2}=0$ 2. $C(u_{1}, 1) =u_{1}$ and $C(1,u_{2})=u_{2}$ 3. For $j=1,2$, $C(u_{1}, u_{2})$ is nondecreasing as $u_{j}$ increases, keeping the other agument fixed. 4. $F$로부터 random variates를 생성하기 위한 방법으로 다음의 방법을 사용한다. 그 전에 $u_{j}$가 증가함에 따라 $C(u_{1}, u_{2})$또한 증가한다는 강한 가정이 필요하다. - $U_{1}$, $U_{2}$를 standard uniform distribution으로부터 독립적으로 만든다. - $Z_{2}=C_{U_{2}|U_{1}}^{-1}(u_{2})$ where $C_{U_{2}|U_{1}}(u_{2})=\\partial C(u_{1}, u_{2})/\\partial u_{1}= P(U_{2}\\leq u_{2}|U_{1}=u_{1})$ is the conditional for $U_{2}$ given $U_{1}=u_{1}$. - Then $(U_{1}, Z_{2})\\sim F$. 5. 연속 확률 변수 $(Y_{1}, Y_{2})\\in\\mathbb{R}^{2}$에 대응되는 unique copula는 $Y_{1}$ and/or $Y_{2}$에 continuous monotonic transform을 적용해도 변하지 않는다. ## 극단 정규화(limiting standardization) $d$차원 **다변량 극단값 분포(multivariate extreme value distribution, MEVD)**은 $d$차원 다변량 분포에서의 random sample의 componentwise maxima의 limiting distribution을 고려하는 데에서 부터 시작하였다. $\\{\\mathbf{X}_{i}=(X_{i,1},\\ldots, X_{i,d}): i=1,\\ldots, n \\}$을 결합 분포 함수 $F$를 갖고 주변 분포 함수 $F_{1}, \\ldots, F_{d}$를 갖는 $d$차원 무작위 벡터의 무작위 표본이라고 하자. &lt;!--chapter:end:94-mevtheory.Rmd--&gt; # 정상시계열에서의 극단값들 {#timeextremes} 시계열 자료에서의 극단값은 독립적인 수열에서의 극단값과 많이 다른다. Serial dependence는 극단값의 양 뿐만 아니라 행동의 질에도 영향을 미친다. 이러한 점들은 극단값을 분석하기 위해 사용했던 기존 방법들의 변경과 새로운 특징을 개발하도록 하는 필요성을 만든다. 여기서는 [@Beirlant2004]의 10장을 참고하였다. mixing: [@Beirlant2004]의 372쪽 참고 [@Huser2013] 논문에서는 시공간 상관성을 고려하기 위해 temporally $\\alpha$-mixing이라는 개념을 도입했는데, mixing coefficients $\\alpha(n)$이 decay하는 것은 $n\\rightarrow \\infty$임에 따라 correlation이 사라지도록 하는 것이다. \\BeginKnitrBlock{definition}\\iffalse{-91-97-108-112-104-97-45-109-105-120-105-110-103-93-}\\fi{}&lt;div class=&quot;definition&quot;&gt;&lt;span class=&quot;definition&quot; id=&quot;def:unnamed-chunk-411&quot;&gt;&lt;strong&gt;(\\#def:unnamed-chunk-411) \\iffalse (alpha-mixing) \\fi{} &lt;/strong&gt;&lt;/span&gt;어떤 시계열 $Z_{t}, t\\in\\mathbb{Z}$가 계수 $\\alpha(n)$에 대해 $\\alpha$-mixing (또는 strongly-mixing)은 $$\\alpha(n)=\\sup | P(A\\cap B) - P(A)P(B) | \\rightarrow 0, \\qquad{n\\rightarrow\\infty}$$ 을 만족하는 것이다. &lt;/div&gt;\\EndKnitrBlock{definition} &lt;!--chapter:end:96-timeextremes.Rmd--&gt; # 공간 극단값 이론과 최대안정과정 {#spatextremes} 이 절은 **최대안정과정(max-stable process)** 및 이것의 **공간 극단값(spatial extremes)**이론으로의 응용에 초점을 맞춰 서술한다. 이 절의 서술 내용은 [@Coles2001]과 [@Dey2015]를 참고하였다. 그림은 R 패키지 `SpatialExtremes`를 이용하였다. ## 최대안정과정(max-stable process) 최대안정과정은 GEV 분포와 같은 극단값 분포를 공간 상황에서 설명할 수 있게끔 하는 역할을 한다. 앞서 나왔던 **최대안정(max-stable)**의 정의를 다시 살펴보자. 이번엔 [@Dey2015] 버전이다. \\BeginKnitrBlock{definition}\\iffalse{-91-52572-45824-50504-51221-44284-51221-51032-32-45796-47480-32-51221-51032-93-}\\fi{}&lt;div class=&quot;definition&quot;&gt;&lt;span class=&quot;definition&quot; id=&quot;def:unnamed-chunk-413&quot;&gt;&lt;strong&gt;(\\#def:unnamed-chunk-413) \\iffalse (최대안정과정의 다른 정의) \\fi{} &lt;/strong&gt;&lt;/span&gt;$Z_{1}, Z_{2},\\ldots$를 확률과정 $\\{Z(x):x\\in\\mathcal{X} \\}$의 독립인 copy들의 수열이라고 하자. 만약 각각의 $n, (n\\geq 1)$에 대해 다음과 같은 $a_{n}&gt;0$, $b_{n}\\in\\mathbb{R}$이 존재해 다음 $$ \\begin{equation} \\frac{\\max_{i=1,\\ldots ,n}Z_{i}-b_{n}}{a_{n}}\\stackrel{d}{=}Z \\end{equation}\\] $$ 을 만족한다면 \\(\\{Z(x):x\\in\\mathcal{X} \\}\\)를 최대안정(max-stable)하다고 말한다. 다음은 (De Haan 1984)에 나오는 정리이다. Theorem 56.2 (최대안정과정 관련 정리) \\(Y_{1}, Y_{2},\\ldots\\)를 continuous sample path를 갖는 \\(\\{Y(x):x\\in\\mathcal{X} \\}\\)의 독립인 copy들의 수열이라고 하자. 만약 연속함수 \\(c_{n}&gt;0, d_{n}\\in\\mathbb{R}\\)이 존재해 극한과정(limiting process) \\(\\{Z(x): x\\in\\mathcal{X}\\}\\)에 수렴한다면, 즉 \\[ \\begin{equation} \\frac{\\max_{i=1,\\ldots, n}Y_{i}(x)-d_{n}(x)}{c_{n}(x)}\\rightarrow Z(x), x\\in\\mathcal{X}, n\\rightarrow \\infty \\end{equation} \\] 이고 \\(Z(x)\\)가 non-degenerate라면 \\(\\{Z(x):x\\in\\mathcal{X} \\}\\) 최대안정과정(max-stable process)이어야 한다. 위 식의 수렴은 \\(\\mathcal{X}\\)의 연속함수 공간에서의 약수렴(weak convergence)을 의미한다. 이 정리의 의미는 다음과 같다. 일변량 극단값 이론과 연관성을 생각해보면 \\(\\{Z(x):x\\in\\mathcal{X} \\}\\)는 일반화 극단값 분포여야 한다는 것이다. 공간 극단값 이론에서 최대안정과정을 고려하는 이유는 다음과 같다. \\(n\\)개의 독립 반복에서 극한과정(limiting process) \\(\\{Z(x): x\\in\\mathcal{X}\\}\\)이 \\(n\\)이 충분히 클 때 부분 최대 과정(partial maxima process)을 모델링 할 좋은 후보라고 여겨지기 때문이다. Definition 56.1 (부분 최대 과정) (margin이 unit Fréchet \\((F(z)=\\exp(-1/z))\\)이라고 가정하자.) 이러한 경우에 \\[ \\begin{equation} \\max_{i=1,\\ldots , n}n^{-1}Z_{i}(\\cdot) \\stackrel{d}{=} Z(\\cdot), n\\geq 1 \\end{equation} \\] 일 경우 과정(process) \\(\\{Z(x)\\}\\)를 최대안정과정(max-stable process)이라고 부른다. 이 때 놀랍게도 최대안정과정에서 spectral characterization (뜻 찾아보기)를 얻는 것이 가능하다고 한다. Theorem 56.3 (최대안정과정의 spectral characterization) ((De Haan 1984)의 characterization) \\(\\{ (\\xi_{i}, U_{i})\\}_{i \\geq 1}\\)을 \\((0,\\infty ] \\times \\mathbb{R}^{d}\\)에서 (intensity \\(d\\Lambda (\\xi, u)=\\xi^{-2}d\\xi\\nu(du), \\nu\\)는 \\(\\mathbb{R}^{d}\\)에서 \\(\\sigma\\)-finite measure)의 Poisson point process의 점들이라고 하자. 그리고 \\(\\{Z(x) \\}_{x\\in\\mathbb{R}^{d}}\\)는 unit Fréchet margin을 가지는 최대안정과정이라고 가정하고 continuous sample path에서 \\[ \\begin{equation} \\{Z(x)\\}_{x\\in\\mathbb{R}^{d}}\\stackrel{d}{=}\\{\\max_{i\\geq 1}\\xi_{i}f_{x}(U_{i})\\}_{x\\in\\mathbb{R}^{d}} \\end{equation} \\] 를 만족한다. 그러면 다음과 같은은 음이 아닌 연속함수 \\[\\{ f_{x}(y):x,y\\in\\mathbb{R}^{d}\\}\\] 가 존재해 \\[ \\begin{equation} \\int_{\\mathbb{R}^{d}}f_{x}(y)\\nu(dy)=1, \\forall x \\in \\mathbb{R}^{d} \\end{equation} \\] 를 만족한다. FIGURE 56.1: de Haans characterization. 이 그림은 de Haan’s characterization을 묘사한 것인데 \\(\\{\\xi_{i}\\}_{i\\geq 1}\\)이 storm ferocities (아마도 발생 유무를 표시하는 Poisson point process인 듯 하다), \\(\\{\\xi_{i}\\}_{i\\geq 1}\\)는 storm centers, 그리고 \\(\\xi_{i}f_{x}(U_{i})\\)은 \\(i\\)번째 storm의 \\(x\\)지점에서 강수량을 나타낸다고 볼 수 있다. 각각의 함수가 storm event를 묘사한 것일 때, 최대값들을 이은 검은 곡선이 최대안정과정이 되는 것이다. Theorem 56.4 (unit Fréchet margin을 가지는 최대안정과정) ((Schlather 2002)의 characterization) \\(\\{ (\\xi_{i}, U_{i})\\}_{i \\geq 1}\\)이 \\((0,\\infty ]\\)에서 intensity \\(d \\Lambda (\\xi)=\\xi^{-2}d\\xi\\)를 갖는 Poisson point process의 점들이고 \\(Y_{1},Y_{2},\\ldots\\)를 \\(E[Y(x)]=1, \\forall x \\in \\mathbb{R}^{d}\\) 이고 non-negative continous sample path stochastic process \\(\\{ Y(x)\\}\\)의 independent copy들이라고 하자. 이때 \\(Y_{i}\\)들은 \\(\\{ \\xi_{i}\\}_{i \\geq 1}\\)와 독립이다. 그러면 \\[ \\{ Z(x)\\}_{x\\in\\mathbb{R}^{d}}:=\\{\\max_{i\\geq 1} \\xi_{i}Y_{i}(x) \\}_{x\\in \\mathbb{R}^{d}}\\] 는 unit Fréchet margin을 가지는 최대안정과정이다. FIGURE 56.2: Schlathers characterization 이 그림은 Schlather’s characterization을 묘사하고 있는데 앞서 de Haan’s characterization과는 달리 storm center \\(U_{i}\\)가 존재하지 않는다. 그렇지만 이 방법은 \\(f_{x}\\)라는 함수가 stochastic process로 대채되었으므로 좀 더 다양한 형태의 storm을 모델링 할 수 있다. 56.2.2 Smith 모형(Smith model) 첫 번째 제안된 공간 극단값 모형은 (Smith 1990)의 모형이다. 이를 Smith 과정(Smith process)이라고 부르기도 한다. (Schlather 2002)에서는 가우스 극단값 과정(Gaussian extreme value process)로 언급되었다. 이 모형은 \\[ \\begin{equation} Z(x)=\\max_{i\\geq 1}\\xi_{i}\\phi(x-U_{i};\\mathbf{0},\\Sigma), x\\in\\mathcal{X}, \\end{equation} \\] 이때 \\(\\phi(\\cdot, \\mathbf{0},\\Sigma)\\)는 평균이 0이고 공분산이 \\(\\Sigma\\)인 다변량 정규 확률밀도함수(multivariate Normal density)이다. 이 모형은 역사적으로는 중요하나 다변량 정규분포의 모양이 너무 제한적, 즉 모형의 유연성(felxibility)이 떨어져 잘 쓰이지는 않는다. 56.2.3 Schlather 모형(Schlather model) Smith 모형이 제안되고 10여년 후, (Schlather 2002)는 Schlather 과정(Schlather process)이라는 것을 제안했다. 이 모형은 극단 가우스 과정(extremal Gaussian process)으로 불리기도 한다. 이 모형은 \\[ \\begin{equation} Z(x)=\\sqrt{2\\pi}\\max_{i\\geq 1}\\zeta_{i}\\max\\{0,W_{i}(x)\\} \\end{equation} \\] 로 이때 \\(\\{W_{i}(x): x\\in\\mathcal{X}\\}\\)는 상관함수(correlation function) \\(\\rho\\)를 갖는 정상 가우스과정(staionary Gaussian process)의 독립된 copy들이다. 또한 척도요인(scaling factor) \\(\\sqrt{2\\pi}\\)는 모든 \\(x\\in\\mathcal{X}\\)에 대해 \\(\\sqrt{2\\pi}E[\\max\\{ 0,W(x)\\}]=1\\)를 만족해야 한다. 이 모형은 후술할 모형들에 비해 큰 값이 나오는 지역이 더 많은데 그 이유는 공간 독립(spatial independence)이 요구되지 않는 모형이기 때문이라고 한다. 56.2.4 Brown-Resnick 모형(Brown-Resnick model) 이 모형은 (Brown and Resnick 1977)이 처음 제안하였고 (Kabluchko, Schlather, and Haan 2009)가 일반화하였다. Brown-Resnick 과정(Brown-Resnick process)는 \\[ \\begin{equation} Z(x)=\\max_{i\\geq 1}\\xi_{i}\\exp\\{W_{i}(x)-\\gamma(x)\\},x\\in\\mathcal{X} \\end{equation} \\] 으로 정의된다. 이때 \\(\\{W_{i}(x): x\\in\\mathcal{X}\\}\\)는 평균이 0이며 정상증분(stationary increments)을 갖고 준변동도(semi-variogram)이 \\(\\gamma(h)=\\text{Var}\\{W(x+h)-W(x)\\}/2\\)인 가우스 과정(Gaussian process)의 독립된 cpoy들이다. 한편 Smith 모형은 위 식의 특별한 케이스로, \\[W(x)=x^{T}\\Sigma^{-1}X, X\\sim\\mathcal{N}(0,\\Sigma)\\] 이며 \\(2\\gamma(x)=x^{T}\\Sigma^{-1}\\text{Var}(X)\\Sigma^{-1}x=x^{T}\\Sigma^{-1}x\\)인 경우라고 볼 수 있다. 56.2.5 극단-t 모형(extremal-t model) 극단-t 과정(extremal-t process)는 이것의 스펠트럴 특성화(spectral representation)이 최종적으로 (Opitz 2013)에 의해 유도되었다. \\[ \\begin{equation} Z(x)=c_{\\nu}\\max_{i \\geq 1}\\zeta_{i}\\max\\{0,W_{i}(x)\\}^{\\nu}, x\\in\\mathcal{X} \\end{equation} \\] 이며 \\(\\nu \\geq 1\\), \\(\\{W_{i}(x):x\\in\\mathcal{X}\\}\\)는 상관함수가 \\(\\rho\\)이며 \\[c\\nu =\\sqrt{\\pi}2^{-(\\nu-2)/2}\\Gamma(\\frac{\\nu+1}{2})^{-1}\\] 인 정상 가우스 과정의 독립된 copy들이다. References "],
["56-3-spatial-dependence-of-extremes.html", "56.3 극단값의 공간 종속성(spatial dependence of extremes)", " 56.3 극단값의 공간 종속성(spatial dependence of extremes) 공간통계학에서 쓰이는 변동도(variogram)을 다시 정의해보면 \\[ \\begin{equation} \\frac{1}{2}E[\\{Z(x_{1})-Z(x_{2}) \\}^{2}], x_{1}, x_{2} \\in \\mathcal{X} \\end{equation} \\] 이다. 그러나 공간 극단값 이론에서는 분산 또는 평균조차도 존재하지 않을 수 있다. 다행히도 (Cooley, Naveau, and Poncet 2006)이 F-매도그램(F-madogram)이라는 적절한 툴을 제공하였다. 이것의 정의는 다음과 같다. \\[ \\begin{equation} \\nu_{F}(h)=\\frac{1}{2}E[|F\\{Z(x+h)\\}-F\\{Z(x)\\}], x,h\\in \\mathcal{X}. \\end{equation} \\] 여기서 \\(F\\)는 \\(Z(x), x\\in\\mathcal{X}\\)의 cdf를 의미한다. (준)변동도와는 달리, F-매도그램은 \\(F\\{Z(x)\\} \\sim U(0,1)\\)이므로 잘 정의가 되며 기댓값은 \\(1/2\\)을 갖는다. 또한 F-매도그램은 극단계수함수(extremal coefficient function)와 강한 연관성을 갖기 때문에 공간 극단값 분석시 유용하다. 극단계수함수는 \\[\\theta : h \\rightarrow E[\\max \\{ Y(x),Y(x+h) \\}]\\] \\[ \\begin{align*} P\\{Z(x+h)\\leq z | Z(x)\\leq z\\}&amp;=P\\{Z(x+h)\\leq z\\}^{\\theta(h)-1}\\nonumber\\\\ &amp;= \\begin{cases} 1 &amp; \\text{perfect dependence}\\\\ P\\{Z(x+h)\\leq z\\} &amp; \\text{independence} \\end{cases} \\end{align*} \\] References "],
["57-maxstableRF.html", "Chapter 57 최대안정 임의장", " Chapter 57 최대안정 임의장 우리는 때때로 어떤과정의 극단적으로 높거나 낮은 수준을 모델링하는 데 관심을 갖을 수도 있다. 공간 또는 시공간 극단값의 무작위 행동을 분석하는 한 가지 방법이 최대안정 임의장(max-stable random fields)이다. 우선 간단하게 spatial case만 살펴보자. \\(\\{Y(\\mathbf{s})\\}_{\\mathbf{s}\\in\\mathcal{S}}\\)가 continuous sample path를 갖는 정상 임의장이라고 하고 \\(Y_{1},\\ldots, Y_{n}\\)을 그것의 \\(n\\)개의 복사본이라고 하자. 다음과 같은 pointwise maximum process \\[M_{n}(\\mathbf{s}):=\\max_{i=1,\\ldots,n}Y_{i}(\\mathbf{s}), \\mathbf{s}\\in\\mathcal{S}\\] 를 생각해보자. 만약 모든 \\(\\mathbf{s}\\in\\mathcal{S}\\)에 대해 연속함수 \\(a_{n}(\\mathbf{s})&gt;0\\), \\(b_{n}(\\mathbf{s})\\in\\mathbb{R}\\)이 존재해 \\[\\frac{M_{n}(\\mathbf{s})-b_{n}(\\mathbf{s})}{a_{n}(\\mathbf{s})} \\stackrel{\\text{converge weakly}}{\\rightarrow}Z(\\mathbf{s})\\] 하고 이때 \\(Z(\\mathbf{s})\\)가 모든 임의의 \\(\\mathbf{s}\\in\\mathcal{S}\\)에 대해 non-degenerate marginal distribution을 갖는다면 이 때 \\(Z\\)는 최대안정 임의장(max-stable random fields)이 된다. 어떤 \\(\\mathbf{s}\\in\\mathcal{S}\\)에 대해 최대안정 임의장은 일변량 주변 일반화 극단값 분포(univariate marginal generalized extreme value distribution)을 갖으며 유한한 장소의 집합에 대한 결합분포는 \\[P\\{Z(\\mathbf{s}_{j})\\leq z_{j}, j \\in J\\}=e^{-V(\\mathbf{z})},\\] \\[V(\\mathbf{z})=k\\int_{\\Delta_{k-1}}\\max_{j\\in J}(\\frac{\\omega_{j}}{y_{j}})\\nu(d\\mathbf{w}), \\mathbf{z}\\in\\mathbb{R}_{+}^{k}\\] 로 정의된다. 여기서 \\(\\nu\\)는 \\((k-1)\\) 차원 unit simplex \\(\\Delta_{k-1}\\)에서 정의된 확률분포이며 \\(V\\)는 지수종속함수(exponent dependece function)이라고 불린다. 다음은 최대안정 임의장들의 예이다. 이들의 차이는 지수종속함수의 차이로부터 발생한다. Brown-Resnick ((Kabluchko, Schlather, and Haan 2009), (Kabluchko 2011)) extremal-Gaussian ((Schlather 2002)) extremal-t ((Davison, Padoan, and Ribatet 2012)) References "],
["57-1-brown-resnick-brown-resnick-random-fields.html", "57.1 Brown-Resnick 임의장(Brown-Resnick random fields)", " 57.1 Brown-Resnick 임의장(Brown-Resnick random fields) Brown-Resnick 임의장(Brown-Resnick random fields)의 이변량분포(bivariate distribution)의 지수종속함수는 \\[ V_{1}(z_{1},z_{2};\\mathbf{h})=\\frac{1}{z_{1}}\\Phi (\\frac{\\lambda(\\mathbf{h})}{2}+\\frac{\\log z_{2}/z_{1}}{\\lambda(\\mathbf{h})}) + \\frac{1}{z_{2}}\\Phi (\\frac{\\lambda(\\mathbf{h})}{2}+\\frac{\\log z_{1}/z_{2}}{\\lambda(\\mathbf{h})}) \\] 이다. 여기서 \\(\\lambda(\\mathbf{h})=\\sqrt{2\\gamma(\\mathbf{h})}\\)이며 \\(\\gamma\\)는 가우스 임의장 하의 준변동도(semivariogram)이다. 위 식의 유도는 (Hüsler and Reiss 1989)와 (Smith 1990)에 있다. 지수종속함수의 시공간 버전은 (Kabluchko 2009) 및 (Davis, Klüppelberg, and Steinkohl 2013)을 참조하길 바란다. References "],
["57-2-extremal-gaussian-extremal-gaussian-random-fields.html", "57.2 Extremal-Gaussian 임의장(extremal-Gaussian random fields)", " 57.2 Extremal-Gaussian 임의장(extremal-Gaussian random fields) Extremal-Gaussian 임의장(extremal-Gaussian random fields)의 이변량분포(bivariate distribution)의 지수종속함수는 \\[ V_{2}(z_{1},z_{2};\\mathbf{h})=\\frac{1}{2}(\\frac{1}{z_{1}}+\\frac{1}{z_{2}})(1+[1-\\frac{2z_{1}z_{2}\\{\\rho(\\mathbf{h})+1\\}}{(z_{1}+z_{2})^{2}}]^{1/2}) \\] 이며 \\(\\rho(\\mathbf{h})\\)는 가우스 임의장(Gaussian random fields)에 있던 상관관계함수이다. "],
["57-3-extremal-t-extremal-t-random-fields.html", "57.3 Extremal-t 임의장(extremal-t random fields)", " 57.3 Extremal-t 임의장(extremal-t random fields) Extremal-t 임의장(extremal-t random fields)의 이변량분포(bivariate distribution)의 지수종속함수는 \\[ V_{3}(z_{1},z_{2};\\mathbf{h})=\\frac{1}{z_{1}}T_{\\nu+1}\\{\\frac{(z_{2}/z_{1})^{1/\\nu}-\\rho(\\mathbf{h})}{\\sqrt{\\{ 1-\\rho(\\mathbf{h})^{2} \\}/(\\nu+1) }}\\} + \\frac{1}{z_{2}}T_{\\nu+1}\\{\\frac{(z_{1}/z_{2})^{1/\\nu}-\\rho(\\mathbf{h})}{\\sqrt{\\{ 1-\\rho(\\mathbf{h})^{2} \\}/(\\nu+1) }}\\} \\] 으로 여기서 \\(T_{\\nu+1}\\)는 자유도 \\(\\nu+1\\)을 같는 스튜던트-t 분포이며 \\(\\rho(\\mathbf{h})\\)는 압축함수(scaling function)이고 \\(\\nu\\)는 Student-t random field의 자유도이다. "],
["58-references.html", "Chapter 58 References", " Chapter 58 References "]
]
