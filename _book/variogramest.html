<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>통계공부와 관련된 글들</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="통계공부를 하면서 몇 가지 내용들을 gitbook 형식으로 정리하였다.">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="통계공부와 관련된 글들" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="통계공부를 하면서 몇 가지 내용들을 gitbook 형식으로 정리하였다." />
  <meta name="github-repo" content="SeoncheolPark/book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="통계공부와 관련된 글들" />
  
  <meta name="twitter:description" content="통계공부를 하면서 몇 가지 내용들을 gitbook 형식으로 정리하였다." />
  

<meta name="author" content="Seoncheol Park">

<meta name="date" content="2016-09-05">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="covmodel.html">
<link rel="next" href="pointpattern.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">통계공부와 관련된 글들</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 일러두기</a></li>
<li class="part"><span><b>Basic Concepts</b></span></li>
<li class="chapter" data-level="2" data-path="math.html"><a href="math.html"><i class="fa fa-check"></i><b>2</b> 기본적인 수학 개념들</a><ul>
<li class="chapter" data-level="2.1" data-path="math.html"><a href="math.html#sequence--limit"><i class="fa fa-check"></i><b>2.1</b> 수열(sequence)과 수열의 극한(limit)</a><ul>
<li class="chapter" data-level="2.1.1" data-path="math.html"><a href="math.html#supremum-infimum"><i class="fa fa-check"></i><b>2.1.1</b> 상한(supremum)과 하한(infimum)</a></li>
<li class="chapter" data-level="2.1.2" data-path="math.html"><a href="math.html#limit-superior-limit-infimum"><i class="fa fa-check"></i><b>2.1.2</b> 상극한(limit superior)과 하극한(limit infimum)</a></li>
<li class="chapter" data-level="2.1.3" data-path="math.html"><a href="math.html#-sequences-of-real-functions"><i class="fa fa-check"></i><b>2.1.3</b> 실함수의 수열들(sequences of real functions)</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="math.html"><a href="math.html#-operators-and-norms"><i class="fa fa-check"></i><b>2.2</b> 연산자들과 노름(operators and norms)</a><ul>
<li class="chapter" data-level="2.2.1" data-path="math.html"><a href="math.html#direct-sum"><i class="fa fa-check"></i><b>2.2.1</b> 직합(direct sum)</a></li>
<li class="chapter" data-level="2.2.2" data-path="math.html"><a href="math.html#-kronecker-product"><i class="fa fa-check"></i><b>2.2.2</b> 크로네커 곱(Kronecker product)</a></li>
<li class="chapter" data-level="2.2.3" data-path="math.html"><a href="math.html#tensor-product"><i class="fa fa-check"></i><b>2.2.3</b> 텐서곱(tensor product)</a></li>
<li class="chapter" data-level="2.2.4" data-path="math.html"><a href="math.html#norm"><i class="fa fa-check"></i><b>2.2.4</b> 노름(norm)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="math.html"><a href="math.html#space"><i class="fa fa-check"></i><b>2.3</b> 공간(space)</a><ul>
<li class="chapter" data-level="2.3.1" data-path="math.html"><a href="math.html#vector-space"><i class="fa fa-check"></i><b>2.3.1</b> 벡터공간(vector space)</a></li>
<li class="chapter" data-level="2.3.2" data-path="math.html"><a href="math.html#sobolev-sobolev-space"><i class="fa fa-check"></i><b>2.3.2</b> Sobolev 공간(Sobolev space)</a></li>
<li class="chapter" data-level="2.3.3" data-path="math.html"><a href="math.html#besov-besov-space"><i class="fa fa-check"></i><b>2.3.3</b> Besov 공간(Besov space)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basicprob.html"><a href="basicprob.html"><i class="fa fa-check"></i><b>3</b> 기본적인 확률론 개념들</a><ul>
<li class="chapter" data-level="3.1" data-path="basicprob.html"><a href="basicprob.html#-convergence-of-random-variables"><i class="fa fa-check"></i><b>3.1</b> 확률변수의 수렴(convergence of random variables)</a><ul>
<li class="chapter" data-level="3.1.1" data-path="basicprob.html"><a href="basicprob.html#---almost-sure-convergence"><i class="fa fa-check"></i><b>3.1.1</b> 거의 확실한 확률 수렴(Almost sure convergence)</a></li>
<li class="chapter" data-level="3.1.2" data-path="basicprob.html"><a href="basicprob.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.1.2</b> 확률수렴(Convergence in probability)</a></li>
<li class="chapter" data-level="3.1.3" data-path="basicprob.html"><a href="basicprob.html#lp-convergence-in-lp"><i class="fa fa-check"></i><b>3.1.3</b> Lp 수렴(Convergence in Lp)</a></li>
<li class="chapter" data-level="3.1.4" data-path="basicprob.html"><a href="basicprob.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.1.4</b> 분포수렴(Convergence in distribution)</a></li>
<li class="chapter" data-level="3.1.5" data-path="basicprob.html"><a href="basicprob.html#--connections-between-modes-of-convergence"><i class="fa fa-check"></i><b>3.1.5</b> 수렴 사이들의 관계(Connections between modes of convergence)</a></li>
<li class="chapter" data-level="3.1.6" data-path="basicprob.html"><a href="basicprob.html#convergence-of-moments-uniform-integrability"><i class="fa fa-check"></i><b>3.1.6</b> Convergence of moments: 일양적분가능성(uniform integrability)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="basicprob.html"><a href="basicprob.html#big-o-small-o-big-o-and-small-o"><i class="fa fa-check"></i><b>3.2</b> Big O와 small o (big O and small o)</a></li>
<li class="chapter" data-level="3.3" data-path="basicprob.html"><a href="basicprob.html#big-op-small-op-big-op-and-small-op"><i class="fa fa-check"></i><b>3.3</b> Big Op와 small op (big Op and small op)</a></li>
</ul></li>
<li class="part"><span><b>Multiscale Methods in Statistics</b></span></li>
<li class="chapter" data-level="4" data-path="multiscale.html"><a href="multiscale.html"><i class="fa fa-check"></i><b>4</b> 다중척도 방법론</a><ul>
<li class="chapter" data-level="4.1" data-path="multiscale.html"><a href="multiscale.html#-multiscale-transform"><i class="fa fa-check"></i><b>4.1</b> 다중척도 변환(multiscale transform)</a></li>
<li class="chapter" data-level="4.2" data-path="multiscale.html"><a href="multiscale.html#inverse"><i class="fa fa-check"></i><b>4.2</b> 역(inverse)</a></li>
<li class="chapter" data-level="4.3" data-path="multiscale.html"><a href="multiscale.html#sparsity"><i class="fa fa-check"></i><b>4.3</b> 희소성(sparsity)</a></li>
<li class="chapter" data-level="4.4" data-path="multiscale.html"><a href="multiscale.html#-filter-in-signal-processing"><i class="fa fa-check"></i><b>4.4</b> 신호처리에서의 필터(filter in signal processing)</a></li>
<li class="chapter" data-level="4.5" data-path="multiscale.html"><a href="multiscale.html#r-r-multiscale"><i class="fa fa-check"></i><b>4.5</b> R 예제(R-multiscale)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="wavelettransform.html"><a href="wavelettransform.html"><i class="fa fa-check"></i><b>5</b> 웨이블릿 변환</a><ul>
<li class="chapter" data-level="5.1" data-path="wavelettransform.html"><a href="wavelettransform.html#-haar--discrete-haar-wavelet-transform"><i class="fa fa-check"></i><b>5.1</b> 이산 Haar 웨이블릿 변환(discrete Haar wavelet transform)</a></li>
<li class="chapter" data-level="5.2" data-path="wavelettransform.html"><a href="wavelettransform.html#scaling-coefficient-translation-coefficient-"><i class="fa fa-check"></i><b>5.2</b> 압축계수(scaling coefficient)와 전이계수(translation coefficient) 개념</a></li>
<li class="chapter" data-level="5.3" data-path="wavelettransform.html"><a href="wavelettransform.html#--fine-scale-approximation"><i class="fa fa-check"></i><b>5.3</b> 섬세한 척도 근사(fine-scale approximation)</a></li>
<li class="chapter" data-level="5.4" data-path="wavelettransform.html"><a href="wavelettransform.html#-----computing-coarser-scale-coefficients-from-fine-scale"><i class="fa fa-check"></i><b>5.4</b> 섬세한 척도로부터 성긴 척도 계수의 계산(computing coarser scale coefficients from fine scale)</a></li>
<li class="chapter" data-level="5.5" data-path="wavelettransform.html"><a href="wavelettransform.html#---defference-between-scale-approximations--"><i class="fa fa-check"></i><b>5.5</b> 척도 근사들 사이의 차이(defference between scale approximations)(이를 웨이블릿이라 부름)</a></li>
<li class="chapter" data-level="5.6" data-path="wavelettransform.html"><a href="wavelettransform.html#-types-of-wavelets"><i class="fa fa-check"></i><b>5.6</b> 웨이블릿의 종류들(types of wavelets)</a><ul>
<li class="chapter" data-level="5.6.1" data-path="wavelettransform.html"><a href="wavelettransform.html#haar-haar-wavelet"><i class="fa fa-check"></i><b>5.6.1</b> Haar 웨이블릿(Haar wavelet)</a></li>
<li class="chapter" data-level="5.6.2" data-path="wavelettransform.html"><a href="wavelettransform.html#shannon-shannon-wavelet"><i class="fa fa-check"></i><b>5.6.2</b> Shannon 웨이블릿(Shannon wavelet)</a></li>
<li class="chapter" data-level="5.6.3" data-path="wavelettransform.html"><a href="wavelettransform.html#meyer-meyer-wavelet"><i class="fa fa-check"></i><b>5.6.3</b> Meyer 웨이블릿(Meyer wavelet)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="waveletshrinkage.html"><a href="waveletshrinkage.html"><i class="fa fa-check"></i><b>6</b> 웨이블릿 수축</a><ul>
<li class="chapter" data-level="6.1" data-path="waveletshrinkage.html"><a href="waveletshrinkage.html#---main-concept-of-wavelet-shrinkage"><i class="fa fa-check"></i><b>6.1</b> 웨이블릿 수축의 주된 개념(main concept of wavelet shrinkage)</a></li>
<li class="chapter" data-level="6.2" data-path="waveletshrinkage.html"><a href="waveletshrinkage.html#oracle"><i class="fa fa-check"></i><b>6.2</b> 오라클(oracle)</a></li>
<li class="chapter" data-level="6.3" data-path="waveletshrinkage.html"><a href="waveletshrinkage.html#-universal-thresholding"><i class="fa fa-check"></i><b>6.3</b> 만능 임계화(universal thresholding)</a></li>
<li class="chapter" data-level="6.4" data-path="waveletshrinkage.html"><a href="waveletshrinkage.html#stein---steins-unbiased-risk-estimator-sure"><i class="fa fa-check"></i><b>6.4</b> Stein의 불편 위험 추정량(Steins Unbiased Risk Estimator (SURE))</a></li>
<li class="chapter" data-level="6.5" data-path="waveletshrinkage.html"><a href="waveletshrinkage.html#r-r-waveletshrinkage"><i class="fa fa-check"></i><b>6.5</b> R 예제(R-waveletshrinkage)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html"><i class="fa fa-check"></i><b>7</b> 웨이블릿 수축의 고등 논제들</a><ul>
<li class="chapter" data-level="7.1" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#cross-validation"><i class="fa fa-check"></i><b>7.1</b> 교차타당성(cross-validation)</a></li>
<li class="chapter" data-level="7.2" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#-multiple-testing"><i class="fa fa-check"></i><b>7.2</b> 다중 비교(multiple testing)</a></li>
<li class="chapter" data-level="7.3" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#--bayesian-wavelet-shrinkage"><i class="fa fa-check"></i><b>7.3</b> 베이지안 웨이블릿 축소(Bayesian wavelet shrinkage)</a><ul>
<li class="chapter" data-level="7.3.1" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#prior-mixture-of-gaussian"><i class="fa fa-check"></i><b>7.3.1</b> Prior mixture of Gaussian</a></li>
<li class="chapter" data-level="7.3.2" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#prior-mixture-of-point-mass-and-gaussian"><i class="fa fa-check"></i><b>7.3.2</b> Prior mixture of point mass and Gaussian</a></li>
<li class="chapter" data-level="7.3.3" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#mixture-of-point-mass-and-heavy-tail-distribution"><i class="fa fa-check"></i><b>7.3.3</b> Mixture of point mass and heavy-tail distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#--linear-wavelet-smoothing"><i class="fa fa-check"></i><b>7.4</b> 선형 웨이블릿 평활화(linear wavelet smoothing)</a></li>
<li class="chapter" data-level="7.5" data-path="advwaveletshrinkage.html"><a href="advwaveletshrinkage.html#-block-thresholding"><i class="fa fa-check"></i><b>7.5</b> 블록 임계화(block thresholding)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multiscalets.html"><a href="multiscalets.html"><i class="fa fa-check"></i><b>8</b> 다중척도 시계열분석</a><ul>
<li class="chapter" data-level="8.1" data-path="multiscalets.html"><a href="multiscalets.html#--stationary-time-series"><i class="fa fa-check"></i><b>8.1</b> 시계열 자료의 정상성(stationary time series)</a></li>
<li class="chapter" data-level="8.2" data-path="multiscalets.html"><a href="multiscalets.html#-whitening-of-stationary-process"><i class="fa fa-check"></i><b>8.2</b> 정상과정의 백색화(whitening of stationary process)</a></li>
<li class="chapter" data-level="8.3" data-path="multiscalets.html"><a href="multiscalets.html#--spectral-representation-of-stationary-process"><i class="fa fa-check"></i><b>8.3</b> 정상과정의 스펙트럼 표현(spectral representation of stationary process)</a></li>
<li class="chapter" data-level="8.4" data-path="multiscalets.html"><a href="multiscalets.html#----non-decimated-discrete-wavelets"><i class="fa fa-check"></i><b>8.4</b> 압축 표본화되지 않은 이산 웨이블릿(non-decimated discrete wavelets)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="admultiscale.html"><a href="admultiscale.html"><i class="fa fa-check"></i><b>9</b> 고급 다중척도 방법론</a><ul>
<li class="chapter" data-level="9.1" data-path="admultiscale.html"><a href="admultiscale.html#--second-generation-wavelet-transform"><i class="fa fa-check"></i><b>9.1</b> 2세대 웨이블릿 변환(second-generation wavelet transform)</a></li>
<li class="chapter" data-level="9.2" data-path="admultiscale.html"><a href="admultiscale.html#-lifting-scheme"><i class="fa fa-check"></i><b>9.2</b> 리프팅 스킴(lifting scheme)</a></li>
<li class="chapter" data-level="9.3" data-path="admultiscale.html"><a href="admultiscale.html#---lifting-in-two-dimensions"><i class="fa fa-check"></i><b>9.3</b> 2차원 자료의 리프팅 스킴(lifting in two dimensions)</a></li>
</ul></li>
<li class="part"><span><b>Spatial Statistics</b></span></li>
<li class="chapter" data-level="10" data-path="spatial.html"><a href="spatial.html"><i class="fa fa-check"></i><b>10</b> 공간통계학</a><ul>
<li class="chapter" data-level="10.1" data-path="spatial.html"><a href="spatial.html#-classes-of-spatial-data"><i class="fa fa-check"></i><b>10.1</b> 공간자료의 종류(classes of spatial data)</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="spatialprocess.html"><a href="spatialprocess.html"><i class="fa fa-check"></i><b>11</b> 공간과정</a><ul>
<li class="chapter" data-level="11.1" data-path="spatialprocess.html"><a href="spatialprocess.html#-stationary-in-spatial-data"><i class="fa fa-check"></i><b>11.1</b> 공간자료의 정상성(stationary in spatial data)</a></li>
<li class="chapter" data-level="11.2" data-path="spatialprocess.html"><a href="spatialprocess.html#strictly-stationary"><i class="fa fa-check"></i><b>11.2</b> 순정상성(strictly stationary)</a></li>
<li class="chapter" data-level="11.3" data-path="spatialprocess.html"><a href="spatialprocess.html#second-order-stationary-weakly-stationary"><i class="fa fa-check"></i><b>11.3</b> 약정상성(second order stationary, weakly stationary)</a></li>
<li class="chapter" data-level="11.4" data-path="spatialprocess.html"><a href="spatialprocess.html#intrinsic-stationary"><i class="fa fa-check"></i><b>11.4</b> 내재정상성(intrinsic stationary)</a></li>
<li class="chapter" data-level="11.5" data-path="spatialprocess.html"><a href="spatialprocess.html#--relationship-between-stationarity"><i class="fa fa-check"></i><b>11.5</b> 정상성들 사이의 관계(relationship between stationarity)</a><ul>
<li class="chapter" data-level="11.5.1" data-path="spatialprocess.html"><a href="spatialprocess.html#--relationship-between-strong-and-weak-stationary"><i class="fa fa-check"></i><b>11.5.1</b> 순정상성과 약정상성간의 관계(relationship between strong and weak stationary)</a></li>
<li class="chapter" data-level="11.5.2" data-path="spatialprocess.html"><a href="spatialprocess.html#--relationship-between-weak-and-intrinsic-stationary"><i class="fa fa-check"></i><b>11.5.2</b> 약정상성와 내재정상성간의 관계(relationship between weak and intrinsic stationary)</a></li>
<li class="chapter" data-level="11.5.3" data-path="spatialprocess.html"><a href="spatialprocess.html#----counterexample-of-intrinsic-stationary-but-not-weak-stationary"><i class="fa fa-check"></i><b>11.5.3</b> 내재정상성이나 약정상성이 안 되는 예(counterexample of intrinsic stationary but not weak stationary)</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="spatialprocess.html"><a href="spatialprocess.html#-ergodic-process"><i class="fa fa-check"></i><b>11.6</b> 에르고딕 과정(ergodic process)</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="covfct.html"><a href="covfct.html"><i class="fa fa-check"></i><b>12</b> 공분산함수</a><ul>
<li class="chapter" data-level="12.1" data-path="covfct.html"><a href="covfct.html#--spectral-representation-theorem"><i class="fa fa-check"></i><b>12.1</b> 스펙트럴 표현 정리(spectral representation theorem)</a></li>
<li class="chapter" data-level="12.2" data-path="covfct.html"><a href="covfct.html#--kolmogorovs-existence-theorem"><i class="fa fa-check"></i><b>12.2</b> 콜모고로프 존재 정리(Kolmogorov’s existence theorem)</a></li>
<li class="chapter" data-level="12.3" data-path="covfct.html"><a href="covfct.html#-properties-of-covariance-functions"><i class="fa fa-check"></i><b>12.3</b> 공분산함수의 성질(properties of covariance functions)</a></li>
<li class="chapter" data-level="12.4" data-path="covfct.html"><a href="covfct.html#isotropy"><i class="fa fa-check"></i><b>12.4</b> 등방성(isotropy)</a></li>
<li class="chapter" data-level="12.5" data-path="covfct.html"><a href="covfct.html#homogeneous"><i class="fa fa-check"></i><b>12.5</b> 동질성(homogeneous)</a></li>
<li class="chapter" data-level="12.6" data-path="covfct.html"><a href="covfct.html#anisotropy"><i class="fa fa-check"></i><b>12.6</b> 이등방성(anisotropy)</a><ul>
<li class="chapter" data-level="12.6.1" data-path="covfct.html"><a href="covfct.html#-geometric-anisotropy"><i class="fa fa-check"></i><b>12.6.1</b> 기하학적 이등방성(Geometric anisotropy)</a></li>
<li class="chapter" data-level="12.6.2" data-path="covfct.html"><a href="covfct.html#-zonal-anisotropy"><i class="fa fa-check"></i><b>12.6.2</b> 띠모양 이등방성(zonal anisotropy)</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="covfct.html"><a href="covfct.html#---continuity-and-differentiabiliy-of-spatial-stochastic-process"><i class="fa fa-check"></i><b>12.7</b> 공간 확률과정의 연속성과 미분가능성(continuity and differentiabiliy of spatial stochastic process</a><ul>
<li class="chapter" data-level="12.7.1" data-path="covfct.html"><a href="covfct.html#path-continuity---path-differentiability"><i class="fa fa-check"></i><b>12.7.1</b> 경로연속(path-continuity) 또는 경로 미분가능성(path-differentiability)</a></li>
<li class="chapter" data-level="12.7.2" data-path="covfct.html"><a href="covfct.html#mean-square-continuity---mean-square-differentiability"><i class="fa fa-check"></i><b>12.7.2</b> 평균제곱연속(mean-square continuity) 또는 평균제곱 미분가능성(mean-square differentiability)</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="covfct.html"><a href="covfct.html#bartlett-bartletts-theorem"><i class="fa fa-check"></i><b>12.8</b> Bartlett의 정리(Bartlett’s theorem)</a></li>
<li class="chapter" data-level="12.9" data-path="covfct.html"><a href="covfct.html#kent---kents-sufficient-condition-for-path-continuity-2-d-ver"><i class="fa fa-check"></i><b>12.9</b> Kent의 경로연속을 위한 충분조건(Kent’s sufficient condition for path-continuity) (2-d ver)</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="covmodel.html"><a href="covmodel.html"><i class="fa fa-check"></i><b>13</b> 공분산모형</a><ul>
<li class="chapter" data-level="13.1" data-path="covmodel.html"><a href="covmodel.html#-nugget-effect"><i class="fa fa-check"></i><b>13.1</b> 덩어리 효과(nugget effect)</a></li>
<li class="chapter" data-level="13.2" data-path="covmodel.html"><a href="covmodel.html#--idealized-shape-of-variogram-isotropic-case"><i class="fa fa-check"></i><b>13.2</b> 이상적인 변동도의 모양(idealized Shape of Variogram (isotropic case))</a></li>
<li class="chapter" data-level="13.3" data-path="covmodel.html"><a href="covmodel.html#-effective-range"><i class="fa fa-check"></i><b>13.3</b> 유효 범위(effective range)</a></li>
<li class="chapter" data-level="13.4" data-path="covmodel.html"><a href="covmodel.html#----classical-parametric-isotropic-variogram-models"><i class="fa fa-check"></i><b>13.4</b> 대표적인 모수 등방성 변동도 모형들(classical parametric isotropic variogram models)</a><ul>
<li class="chapter" data-level="13.4.1" data-path="covmodel.html"><a href="covmodel.html#-----addtional-explanation-for-k_alpha"><i class="fa fa-check"></i><b>13.4.1</b> 변형된 이형 베셀에 대한 보충 설명(addtional explanation for K_alpha)</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="covmodel.html"><a href="covmodel.html#---variograms-in-other-situation"><i class="fa fa-check"></i><b>13.5</b> 기타 다른 상황에서의 변동도들(variograms in other situation)</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="variogramest.html"><a href="variogramest.html"><i class="fa fa-check"></i><b>14</b> 변동도의 추정</a><ul>
<li class="chapter" data-level="14.1" data-path="variogramest.html"><a href="variogramest.html#empirical-variogram"><i class="fa fa-check"></i><b>14.1</b> 경험변동도(empirical variogram)</a></li>
<li class="chapter" data-level="14.2" data-path="variogramest.html"><a href="variogramest.html#----fitting-parametric-models-to-empirical-variogram"><i class="fa fa-check"></i><b>14.2</b> 경험변동도를 이용한 모수적 모형 추정(fitting parametric models to empirical variogram)</a><ul>
<li class="chapter" data-level="14.2.1" data-path="variogramest.html"><a href="variogramest.html#ls-method"><i class="fa fa-check"></i><b>14.2.1</b> LS method</a></li>
<li class="chapter" data-level="14.2.2" data-path="variogramest.html"><a href="variogramest.html#gls-method"><i class="fa fa-check"></i><b>14.2.2</b> GLS method</a></li>
<li class="chapter" data-level="14.2.3" data-path="variogramest.html"><a href="variogramest.html#wls-method"><i class="fa fa-check"></i><b>14.2.3</b> WLS method</a></li>
<li class="chapter" data-level="14.2.4" data-path="variogramest.html"><a href="variogramest.html#-wls-approximated-wls"><i class="fa fa-check"></i><b>14.2.4</b> 근사 WLS (approximated WLS)</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="variogramest.html"><a href="variogramest.html#r-r-variogramest"><i class="fa fa-check"></i><b>14.3</b> R 예제(R-variogramest)</a></li>
</ul></li>
<li class="part"><span><b>Spatial Point Processes</b></span></li>
<li class="chapter" data-level="15" data-path="pointpattern.html"><a href="pointpattern.html"><i class="fa fa-check"></i><b>15</b> 공간점과정</a><ul>
<li class="chapter" data-level="15.1" data-path="pointpattern.html"><a href="pointpattern.html#--examples-of-spatial-point-patterns"><i class="fa fa-check"></i><b>15.1</b> 공간점패턴 자료의 예(examples of spatial point patterns)</a></li>
<li class="chapter" data-level="15.2" data-path="pointpattern.html"><a href="pointpattern.html#-complete-spatial-randomness"><i class="fa fa-check"></i><b>15.2</b> 완전공간임의성 (complete spatial randomness)</a></li>
<li class="chapter" data-level="15.3" data-path="pointpattern.html"><a href="pointpattern.html#---general-monte-carlo-test"><i class="fa fa-check"></i><b>15.3</b> 일반적인 몬테카를로 검정 (general Monte Carlo test)</a></li>
</ul></li>
<li class="part"><span><b>Quantile Regression</b></span></li>
<li class="chapter" data-level="16" data-path="qr.html"><a href="qr.html"><i class="fa fa-check"></i><b>16</b> 분위수 회귀분석</a><ul>
<li class="chapter" data-level="16.1" data-path="qr.html"><a href="qr.html#-quantile"><i class="fa fa-check"></i><b>16.1</b> 분위수 (quantile)</a></li>
<li class="chapter" data-level="16.2" data-path="qr.html"><a href="qr.html#--linear-quantile-regression"><i class="fa fa-check"></i><b>16.2</b> 선형 분위수 회귀분석(linear quantile regression)</a></li>
</ul></li>
<li class="part"><span><b>Extreme Value Statistics</b></span></li>
<li class="chapter" data-level="17" data-path="extremevaluestat.html"><a href="extremevaluestat.html"><i class="fa fa-check"></i><b>17</b> 극단값 통계학</a></li>
<li class="chapter" data-level="18" data-path="uGEVtheory.html"><a href="uGEVtheory.html"><i class="fa fa-check"></i><b>18</b> 일변량 극단값 이론</a><ul>
<li class="chapter" data-level="18.1" data-path="uGEVtheory.html"><a href="uGEVtheory.html#--generalized-extreme-value-distribution"><i class="fa fa-check"></i><b>18.1</b> 일반화 극단값 분포(generalized extreme value distribution)</a></li>
<li class="chapter" data-level="18.2" data-path="uGEVtheory.html"><a href="uGEVtheory.html#max-stablity"><i class="fa fa-check"></i><b>18.2</b> 최대안정성(max-stablity)</a></li>
<li class="chapter" data-level="18.3" data-path="uGEVtheory.html"><a href="uGEVtheory.html#-return-level"><i class="fa fa-check"></i><b>18.3</b> 복귀 수준(return level)</a></li>
<li class="chapter" data-level="18.4" data-path="uGEVtheory.html"><a href="uGEVtheory.html#--inference-in-extreme-value-statistics"><i class="fa fa-check"></i><b>18.4</b> 극단값 분포에서의 추론(inference in extreme value statistics)</a></li>
<li class="chapter" data-level="18.5" data-path="uGEVtheory.html"><a href="uGEVtheory.html#--mle-in-extreme-value-statistics"><i class="fa fa-check"></i><b>18.5</b> 극단값 분포에서의 최대가능도추정(mle in extreme value statistics)</a></li>
<li class="chapter" data-level="18.6" data-path="uGEVtheory.html"><a href="uGEVtheory.html#---profile-likelihood-in-extreme-value-statistics"><i class="fa fa-check"></i><b>18.6</b> 극단값 분포에서의 프로파일 가능도(profile likelihood in extreme value statistics)</a></li>
<li class="chapter" data-level="18.7" data-path="uGEVtheory.html"><a href="uGEVtheory.html#gev----maximum-likelihood-estimation-application-to-gev-distribution"><i class="fa fa-check"></i><b>18.7</b> GEV 분포애서의 가능도 추정 (maximum likelihood estimation: application to GEV distribution)</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="spatextremes.html"><a href="spatextremes.html"><i class="fa fa-check"></i><b>19</b> 공간 극단값 이론과 최대안정과정</a><ul>
<li class="chapter" data-level="19.1" data-path="spatextremes.html"><a href="spatextremes.html#max-stable-process"><i class="fa fa-check"></i><b>19.1</b> 최대안정과정(max-stable process)</a><ul>
<li class="chapter" data-level="19.1.1" data-path="spatextremes.html"><a href="spatextremes.html#smith-smith-model"><i class="fa fa-check"></i><b>19.1.1</b> Smith 모형(Smith model)</a></li>
<li class="chapter" data-level="19.1.2" data-path="spatextremes.html"><a href="spatextremes.html#schlather-schlather-model"><i class="fa fa-check"></i><b>19.1.2</b> Schlather 모형(Schlather model)</a></li>
<li class="chapter" data-level="19.1.3" data-path="spatextremes.html"><a href="spatextremes.html#brown-resnick-brown-resnick-model"><i class="fa fa-check"></i><b>19.1.3</b> Brown-Resnick 모형(Brown-Resnick model)</a></li>
<li class="chapter" data-level="19.1.4" data-path="spatextremes.html"><a href="spatextremes.html#-t-extremal-t-model"><i class="fa fa-check"></i><b>19.1.4</b> 극단-t 모형(extremal-t model)</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="spatextremes.html"><a href="spatextremes.html#--spatial-dependence-of-extremes"><i class="fa fa-check"></i><b>19.2</b> 극단값의 공간 종속성(spatial dependence of extremes)</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>20</b> References</a></li>
<li class="divider"></li>
<li><a href="https://seoncheolpark.github.io/" target="blank">Return to Park's Github Page</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">통계공부와 관련된 글들</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variogramest" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> 변동도의 추정</h1>
<p>이 문서에서는 variogram을 어떻게 추정할 것인지에 대해 다룰 것이다. 크게 두 가지가 있다.</p>
<ul>
<li><p>Empirical model (nonparametric)</p></li>
<li><p>Parametric fit</p></li>
</ul>
<p>그리고 <span class="citation">(Gelfand et al. <a href="#ref-Gelfand2010">2010</a>)</span>의 33쪽부터, <span class="citation">(N. A. C. Cressie <a href="#ref-Cressie1993">1993</a>)</span>의 69쪽부터 참고했다.</p>
<div id="empirical-variogram" class="section level2">
<h2><span class="header-section-number">14.1</span> 경험변동도(empirical variogram)</h2>
<p>이것은 변동도를 비모수 추정하는 것이다. 다시 한 번 변동도의 정의를 살펴보면 <span class="math display">\[2\gamma(\mathbf{h})=\text{Var}(Z(\mathbf{s}+\mathbf{h})-Z(\mathbf{s}))\]</span> 으로 lag <span class="math inline">\(\mathbf(h)\)</span>에만 의존하는 함수이다. 그런데 내재정상성(instinsic stationary)에서는 평균이 0이므로 <span class="math display">\[2\gamma(\mathbf{h})=E[Z(\mathbf{s}+\mathbf{h})-Z(\mathbf{s}))^{2}]\]</span> 이 된다.</p>
<p>다음은 추정량을 구하기 위한 방법들이다.</p>
<ol style="list-style-type: decimal">
<li>적률 추정(Metohd of moment (MoM) estimation (Matheron, 1962))</li>
</ol>
<p><span class="math inline">\(E(Z(\mathbf{s}))=\mu\)</span>라는 상수 평균(constant mean) 가정하에 적률추정량(MoM estimator)은 <span class="math display">\[2\hat{\gamma}(\mathbf{h})=\frac{1}{|N(\mathbf{h})|}\sum_{(s_{i},s_{j})\in N(\mathbf{h})}(Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j}))^{2}, \mathbf{h}\in \mathbb{R}^{d}\]</span> 이다. 여기서 <span class="math inline">\(N(\mathbf{h})\)</span>는 거리가 <span class="math inline">\(\mathbf{h}\)</span>가 되는 <span class="math inline">\((\mathbf{s}_{i},\mathbf{s}_{j})\)</span>들의 집합이다. 즉 <span class="math display">\[N(\mathbf{h})=\{ (\mathbf{s}_{i},\mathbf{s}_{j}), \mathbf{s}_{i}-\mathbf{s}_{j}=\mathbf{h} \}\]</span> 이다. <span class="math inline">\(N(\mathbf{h}) \neq N(\mathbf{-h})\)</span>임에 주의하자. 이 추정량의 문제는 <strong>정규 격자(regular grid)</strong> 자료에만 잘 적용된다는 점이다. Irregular한 자료에서는 <span class="math inline">\(\mathbf{h}\)</span>에 대응되는 <span class="math inline">\(N(\mathbf{h})\)</span>가 공집합(empty set)일 수도 있다. 그런 상황을 해결하기 위해 <span class="math inline">\(\mathbf{h}\)</span>의 적당한 근방(neighborhood) <span class="math inline">\(T(\mathbf{h})\)</span>을 생각하여 <span class="math inline">\(N(\mathbf{h})\)</span>를 정의하기도 한다. <span class="math display">\[N(\mathbf{h})=\{ (\mathbf{s}_{i},\mathbf{s}_{j}), \mathbf{s}_{i}-\mathbf{s}_{j}=T(\mathbf{h}) \} .\]</span></p>
<p>그렇다면 이 근방의 size는 어떻게 정해야 할 것인가라는 질문이 생길 수도 있다. 이것은 <strong>띠너비 선택(bandwidth selection)</strong> 문제와 유사하다. Practically하게 <span class="citation">(Journel and Huijbregts <a href="#ref-Journel2003">2003</a>)</span>는 <span class="math inline">\(| \cup \{N(\mathbf{h}): \mathbf{h} \in T(\mathbf{h}) \} |\)</span>에 들어가는 distinct pair들이 적어도 30개 이상이 되도록 잡는 것이 좋다고 하였다.</p>
<p>그러나 이 경우도 역시 데이터의 사이즈가 적을 경우 문제가 된다. 또한 <span class="math inline">\(\mathbf{h}\)</span>의 방향도 고려할 경우 자료가 더 부족해지고, <span class="math inline">\(\mathbf{h}\)</span>에 따라 pair 갯수 또한 차이가 난다. 그리고 자료로 인해 관측할 수 있는 <span class="math inline">\(\mathbf{h}\)</span>의 minimum과 maximum length가 존재한다. 역시 practically하게 <span class="math inline">\(\mathbf{h}\)</span>는 observation location들의 maximum length의 절반 정도를 고르도록 권장하고 있다.</p>
<p>마지막으로 이 추정량의 성질에 대해 알아보자. 우선 unbiased하다(특히 grid 자료인 경우). 그러나 outlier에 로버스트하지는 않다. <span class="math inline">\(Z(\mathbf{s})\)</span>가 Gaussian distribution이면 <span class="math display">\[(Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j}))^{2} \sim 2 \gamma(\mathbf{h})\chi_{1}^{2}\]</span> 이다. 그런데 카이제곱 분포는 매우 skewed된 분포인데 이 분포를 sample mean을 이용해 추정했으므로 finite sample 이용시 variation이 클 수 있다.</p>
<ol start="2" style="list-style-type: decimal">
<li>로버스트 추정량(robust estimator (Cressie and Howkins, 1980))</li>
</ol>
<p>이 문제를 해결하기 위해 Cressie와 Howkins는 robust한 통계량을 제시하였다. <span class="math display">\[2 \bar{\gamma}(\mathbf{h})=\frac{1}{0.457+\frac{0.494}{|N(\mathbf{h})|}}\{\frac{1}{|N(\mathbf{h})|}\sum_{(\mathbf{s}_{i},\mathbf{s}_{j} \in N(\mathbf{h}))} |Z(\mathbf{s}_{i}-Z(\mathbf{s}_{j})|^{\frac{1}{2}}\}^{4}.\]</span> 앞의 <span class="math inline">\(\frac{1}{0.457+\frac{0.494}{|N(\mathbf{h})|}}\)</span>는 bias correction term이다.</p>
<p>이 추정량의 아이디어는 다음과 같다. 어떤 확률변수 <span class="math inline">\(X \sim \chi_{1}^{2}\)</span>때 <span class="math inline">\(X^{\frac{1}{4}}\)</span>는 거의 symmetric임을 보일 수 있다고 한다. 즉 <span class="math inline">\(|Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j})|^{2}\)</span>보다는 <span class="math inline">\(|Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j})|^{\frac{1}{2}}\)</span>이 더 symmetric하게 행동할 수 있을 것이다. 따라서 이것을 이용하고자 하는 것이다. <span class="math inline">\(\mathbf{X}_{n}\)</span>을 <span class="math inline">\(X_{n}\equiv\frac{1}{|N(\mathbf{h})|}\sum_{(\mathbf{s}_{i},\mathbf{s}_{j} \in N(\mathbf{h}))} |Z(\mathbf{s}_{i}-Z(\mathbf{s}_{j})|^{\frac{1}{2}}\)</span> 이라고 하자.</p>
<p>다음은 <span class="math inline">\(X \sim \chi_{1}^{2}\)</span>시 몇 가지 계산 결과이다. <span class="math display">\[E(X^{\frac{1}{4}})=0.82216, \text{Var}(X^{\frac{1}{4}})=0.12192, E(X_{n})=0.82216 \equiv \nu\]</span> <span class="math display">\[\text{Var}(X_{n})=\frac{0.12192}{|N(\mathbf{h}|)} \text{(cross-covariance 무시할 경우)} .\]</span> 그 다음 <span class="math inline">\(f(x)=x^{4}\)</span>에 대해 <span class="math inline">\(\nu\)</span> 근방에서 테일러 전개를 해보자. 그러면 <span class="math display">\[f(X_{n})\circeq f(\nu) +f&#39;(\nu)(X_{n}-\nu)+\frac{1}{2}f&#39;&#39;(\nu)(X_{n}-\nu)^{2} .\]</span> 여기서 <span class="math inline">\(X_{n}\)</span>만 random이다. 기댓값을 취하면 <span class="math display">\[
\begin{aligned}
E(X_{n})^{4}&amp;\circeq f(\nu) + f&#39;(\nu)E(X_{n}-\nu) +\frac{1}{2}f&#39;&#39;(\nu)E(X_{n}-\nu)^{2}\\
&amp;\circeq 0.457 + 0 +\frac{0.494}{|N(\mathbf{h})|} \text{(second order까지 bias correction)}\\
\end{aligned}
\]</span> 따라서 robust estimator 앞에 bias correction을 위한 숫자항이 붙는 것이다.</p>
<ol start="3" style="list-style-type: decimal">
<li>또 다른 로버스트 추정량(another robust estimator)</li>
</ol>
<p>특별한 이름은 없으며 앞 estimator에서 약간 변형한 형태이다. <span class="math display">\[
\begin{aligned}
2\tilde{\gamma}(\mathbf{h})&amp;=\frac{1}{0.457}\text{Median}\{ |Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j})|^{2} , (\mathbf{s}_{i},\mathbf{s}_{j})\in N(\mathbf{h}) \}\\
&amp;=\frac{1}{0.457}\{\text{Median} \{ |Z(\mathbf{s}_{i})-Z(\mathbf{s}_{j})|^{\frac{1}{2}} \}^{4} \}
\end{aligned}
\]</span> Median을 쓸 경우 제곱근을 한 다음 네제곱을 하거나 그냥 제곱을 하거나 차이가 없다고 한다.</p>
</div>
<div id="----fitting-parametric-models-to-empirical-variogram" class="section level2">
<h2><span class="header-section-number">14.2</span> 경험변동도를 이용한 모수적 모형 추정(fitting parametric models to empirical variogram)</h2>
<p>경험변동도(empirical variogram) 자료들을 가지고 왜 또 모수적(parametric)인 적합(fitting)을 하려고 할까? 지구통계학(geostatistics)에서는 종속구조(dependence structure) <span class="math inline">\(\boldsymbol{\sigma}\)</span>를 이용한 <strong>예측(prediction)</strong>에 관심이 있다. 그런데 예측을 하려면 <span class="math inline">\(\boldsymbol{\sigma}^{-1}\)</span>이 필요하다. 그런데 경험변동도로 하면 <span class="math inline">\(\boldsymbol{\sigma}\)</span>가 비음정치(non-negative definite)가 아니거나 수치적 특이성(numerical singularity)이 생긴다. 일반적으로 다음과 같은 모수 모델 <span class="math display">\[\hat{\boldsymbol{\gamma}}(h;\hat{\boldsymbol{\theta}})\]</span> 는 양정치함수(positive definite function)임을 보장한다(물론 numerical singular한 경우도 있을 수는 있다). 이러한 이유로 공간통계학에서는 모수를 이용한 모델링을 선호하는 것이다.</p>
<p>다음과 같이 <span class="math inline">\(\hat{\gamma}(\mathbf{h}_{1}), \cdots , \hat{\gamma}(h_{m})\)</span>이 available하다고 하자(이들을 새로운 자료로 생각해도 좋다). 여기서 <span class="math inline">\(m\)</span>은 고정시킨다. 우리의 목표는 <span class="math inline">\(\boldsymbol{\gamma}(h;\boldsymbol{\theta})\)</span>가 true model일 때 <span class="math inline">\(\hat{\boldsymbol{\gamma}}(h;\hat{\boldsymbol{\theta}})\)</span>를 만들고자 한다. 추정 방법은 크게 세 가지가 있다.</p>
<div id="ls-method" class="section level3">
<h3><span class="header-section-number">14.2.1</span> LS method</h3>
<p><span class="math display">\[
\begin{aligned}
\hat{\boldsymbol{\theta}}_{LS}&amp;=\text{argmin}_{\boldsymbol{\theta}}\sum_{j=1}^{m}\{ \hat{\gamma}(h_{j})-\gamma(h_{j};\boldsymbol{\theta})\}^{2}\\
&amp;=\text{argmin}_{\boldsymbol{\theta}}(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))^{T}(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))\\
\end{aligned}
\]</span> 이 방법은 <span class="math inline">\(\hat{\gamma}(\mathbf{h}_{i})\)</span>들의 종속성(dependency)을 무시한다.</p>
</div>
<div id="gls-method" class="section level3">
<h3><span class="header-section-number">14.2.2</span> GLS method</h3>
<p>최소자승법의 약점을 보완하기 위한 방법이다. <span class="math display">\[\hat{\boldsymbol{\theta}}_{GLS}=\text{argmin}_{\boldsymbol{\theta}}(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))^{T}V^{-1}(\boldsymbol{\theta})(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))\]</span> 여기서 <span class="math inline">\(V^{-1}(\boldsymbol{\theta})=\text{Var}(\hat{\boldsymbol{\gamma}})\)</span>이다. 일반적인 GLS는 <span class="math inline">\((\hat{y}-X\beta)^{T}V^{-1}(\theta)(\hat{y}-X\beta)\)</span>꼴처럼 <span class="math inline">\(\beta\)</span>와 <span class="math inline">\(\theta\)</span>가 다르지만, 이 경우는 두 개가 <span class="math inline">\(\theta\)</span>로 같다.</p>
</div>
<div id="wls-method" class="section level3">
<h3><span class="header-section-number">14.2.3</span> WLS method</h3>
<p><span class="math display">\[\hat{\boldsymbol{\theta}}_{GLS}=\text{argmin}_{\boldsymbol{\theta}}(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))^{T}W(\boldsymbol{\theta})(\boldsymbol{\theta})(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))\]</span> 여기서 <span class="math inline">\(W(\boldsymbol{\theta})=\text{diag}(V(\boldsymbol{\theta}))\)</span>이다. 이것은 highly nonlinear한 object function이라 <span class="math inline">\(\boldsymbol{\theta}\)</span>가 많을수록 적합이 어려워진다.</p>
<p>GLS처럼 <span class="math inline">\(\beta\)</span>와 <span class="math inline">\(\theta\)</span>가 같으므로 two-stage iteration을 통해 적합한다. Iteration procedure는 다음과 같다. <span class="math display">\[\hat{\boldsymbol{\theta}}^{(k+1)}=\text{argmin}_{\boldsymbol{\theta}}(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))^{T}V^{-1}(\hat{\boldsymbol{\theta}}^{(k)})(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))\]</span> OLS로 <span class="math inline">\(\boldsymbol{\gamma}(\boldsymbol{\theta})\)</span> 부분을 먼저 고정시키고 iteration을 돌린다는 것 같다.</p>
</div>
<div id="-wls-approximated-wls" class="section level3">
<h3><span class="header-section-number">14.2.4</span> 근사 WLS (approximated WLS)</h3>
<p><span class="citation">(N. Cressie <a href="#ref-Cressie1985">1985</a>)</span>는 WLS의 계산의 어려움을 피하기 위해 다음과 같은 근사 WLS 방법을 쓰기도 한다. <span class="math display">\[\hat{\boldsymbol{\theta}}=\text{argmin}_{\boldsymbol{\theta}}\sum_{j}\frac{|N(\mathbf{h}_{j})}{\gamma^{2}(\mathbf{h}_{j};\boldsymbol{\theta})}\{ \hat{\gamma}(\mathbf{h}_{j})-\gamma(\mathbf{h}_{j};\boldsymbol{\theta}) \}^{2}\]</span> 이 근사가 가능한 이유는 <span class="math inline">\(\text{Var}(\hat{\gamma(\mathbf{h}_{j})}) \cong \frac{8 \gamma^{2}(\mathbf{h}_{j}l\boldsymbol{\theta})}{|N(\mathbf{h}_{j})|}\)</span>이기 때문이다(8은 상수라 무시해도 수렴함). 그러나 여전히 두 군데에 <span class="math inline">\(\boldsymbol{\theta}\)</span>가 있어 two-stage iteration을 해야 한다.</p>
<p>이렇게 계산한 AWLS 추정량이 (어떤 조건 하에) asymptotic normal이 됨을 보일 수 있다고 한다. 그런데 이런 경우에도 <span class="math inline">\(\hat{\gamma}(\mathbf{h}_{j}) \stackrel{n \rightarrow}{\rightarrow} \gamma(\mathbf{h};\boldsymbol{\theta})\)</span>를 따로 보여야 한다고 한다.</p>
<p>몇 가지 기본 가정들은 다음과 같다.</p>
<p>-<span class="math inline">\(\mathbf{\gamma}(\mathbf{h}_{1}), \cdots , \mathbf{\gamma}(\mathbf{h}_{m})\)</span> 이 <span class="math inline">\(\mathbf{h}_{1}, \cdots , \mathbf{h}_{m}\)</span>에서 계산되어있다. 여기서 <span class="math inline">\(m\)</span>은 고정되어 있다고 가정한다.</p>
<p>-<span class="math inline">\(|N(\mathbf{h}_{j})|=O(n)\)</span>. 좀 더 자세하게는 <span class="math inline">\(N(\mathbf{h}_{j})=n\cdot \phi_{j,n}\)</span>이고 <span class="math inline">\(\lim_{n \rightarrow \infty}\phi_{j,n}=\phi_{j} &lt; \infty\)</span>이다(그렇지 않으면 <span class="math inline">\(O(n)\)</span>의 order가 올라갈 것이다). 말로 설명하자면 데이터가 커질 때마다 밀도가 일정해야 하므로 region도 커져야 한다는 것이다.</p>
<p>참고로 <span class="citation">(N. Cressie <a href="#ref-Cressie1985">1985</a>)</span>에서는 다음과 같이 적혀 있다. “<span class="math inline">\(|N(\mathbf{h}_{j})| \rightarrow \infty\)</span> for each <span class="math inline">\(j=1, \cdots, k\)</span> as <span class="math inline">\(N \rightarrow \infty\)</span> as <span class="math inline">\(|D| \rightarrow \infty\)</span> such that <span class="math inline">\(N/|D|\)</span>, the sampling rate per unit area is constant.” 그리고 data가 evenly spaced 되어야 이 방법이 잘 맞는다고 한다.</p>
<ul>
<li><span class="math inline">\(\text{Cov}(\hat{\gamma}(\mathbf{h}_{j}), \hat{\gamma}(\mathbf{h}_{k}))=O(\frac{1}{n})\)</span>. 여기서 <span class="math inline">\(\text{Cov}(\hat{\gamma}(\mathbf{h}_{j}), \hat{\gamma}(\mathbf{h}_{k})) \sim \frac{U_{jk}(\boldsymbol{\theta})}{n}\)</span>을 만족하는 <span class="math inline">\(m \times m\)</span> 행렬 <span class="math inline">\(U(\boldsymbol{\theta})\)</span>가 존재한다. Decay 속도가 충분히 빠른 variogram model들 (ex. exponential)이 이 조건을 만족한다고 한다.</li>
</ul>
<p>이 세 가지 조건을 만족할 경우 <span class="math display">\[\sqrt{n}(\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))  \stackrel{\mathcal{D}}{\rightarrow} \mathcal{N}(\mathbf{0}, U(\boldsymbol{\theta}))\]</span> <span class="math inline">\(m\)</span>이 커지면 <span class="math inline">\((\hat{\boldsymbol{\gamma}}-\boldsymbol{\gamma}(\boldsymbol{\theta}))\)</span>의 dimension 또한 커져 복잡한 문제가 되므로 <span class="math inline">\(m\)</span>을 고정하는 것이다. <span class="math display">\[\sqrt{n}(\hat{\boldsymbol{\theta}}-\boldsymbol{\theta})  \stackrel{\mathcal{D}}{\rightarrow} \mathcal{N}(\mathbf{0}, H^{-1}R^{T}URH^{-1})\]</span> 여기서 <span class="math inline">\(R\)</span>은 <span class="math inline">\(m \times p\)</span> (p: number of parameter) 행렬인데 <span class="math display">\[R_{ij}=\frac{2\phi_{i}}{\gamma^{2}(\mathbf{h}_{i};\boldsymbol{\theta})}\cdot \frac{2\gamma}{2\boldsymbol{\theta}_{j}}(\mathbf{h}_{j};\boldsymbol{\theta})\]</span> 가 성립한다.</p>
<p>한편 <span class="math inline">\(H\)</span>는 목적함수 <span class="math inline">\(S_{n}(\boldsymbol{\theta}*)\)</span>의 헤시안의 확률수렴 값이다. <span class="math display">\[H:\frac{\nabla^{2}S_{n}(\boldsymbol{\theta}*)}{n} \stackrel{P}{\rightarrow} H(\boldsymbol{\theta})\]</span> 이다.</p>
<p>참고로 목적함수의 asymptotic은 보통 다음과 같이 한다. Consistency는 따로 보이고 이것을 만족하면 그 다음 테일러 전개로 <span class="math display">\[S_{n}&#39;(\boldsymbol{\theta})=S_{n}&#39;(\hat{\boldsymbol{\theta}})+S_{n}&#39;&#39;(\boldsymbol{\theta}*)(\hat{\boldsymbol{\theta}}-\boldsymbol{\theta})\]</span> 를 만든다 (mean value theorem에 의해 등호 성립). 이때 <span class="math inline">\(S_{n}&#39;(\hat{\boldsymbol{\theta}})\)</span>은 minimization 문제이므로 0이 된다. <span class="math inline">\(S_{n}&#39;&#39;(\boldsymbol{\theta}*)\)</span>는 <span class="math inline">\(H\)</span>에 해당된다. 따라서 <span class="math inline">\(S_{n}&#39;(\boldsymbol{\theta})\)</span>의 분포만 알아내면 되는 것이다. 이러한 방법을 “Sandwich method”라고 한다. 자세한 내용은 <a href="http://www.stat.ncsu.edu/people/fuentes/courses/st790m/">(Fuentes, 2007)</a> 강좌의 4장을 보면 된다.</p>
</div>
</div>
<div id="r-r-variogramest" class="section level2">
<h2><span class="header-section-number">14.3</span> R 예제(R-variogramest)</h2>
<p>이제 실제 R 예제에 대해 살펴보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(s100)
s100.v1 &lt;-<span class="st"> </span><span class="kw">variog</span>(s100, <span class="dt">option=</span><span class="st">&quot;cloud&quot;</span>)</code></pre></div>
<pre><code>&gt; variog: computing omnidirectional variogram</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">s100.v2 &lt;-<span class="st"> </span><span class="kw">variog</span>(s100, <span class="dt">max.dist=</span><span class="dv">1</span>, <span class="dt">estimator.type=</span><span class="st">&quot;classical&quot;</span>)</code></pre></div>
<pre><code>&gt; variog: computing omnidirectional variogram</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">s100.v3 &lt;-<span class="st"> </span><span class="kw">variog</span>(s100, <span class="dt">max.dist=</span><span class="dv">1</span>, <span class="dt">estimator.type=</span><span class="st">&quot;modulus&quot;</span>)</code></pre></div>
<pre><code>&gt; variog: computing omnidirectional variogram</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(s100$coords[,<span class="dv">1</span>], s100$coords[,<span class="dv">2</span>],
     <span class="dt">pch=</span><span class="st">&quot;x&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>, <span class="dt">main=</span><span class="st">&quot;locations&quot;</span>)
<span class="kw">plot</span>(s100.v1, <span class="dt">main=</span><span class="st">&quot;Variogram cloud&quot;</span>)
<span class="kw">plot</span>(s100.v2, <span class="dt">main=</span><span class="st">&quot;MoM estimator&quot;</span>)
<span class="kw">plot</span>(s100.v3, <span class="dt">main=</span><span class="st">&quot;Robust estimator&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-45"></span>
<img src="SeoncheolPark-book_files/figure-html/unnamed-chunk-45-1.png" alt="Various variogram estimation methods." width="672" />
<p class="caption">
Figure 14.1: Various variogram estimation methods.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">true &lt;-<span class="st"> </span><span class="dv">1</span>-<span class="kw">matern</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>),<span class="fl">0.3</span>,<span class="fl">0.5</span>)
ols &lt;-<span class="st"> </span><span class="kw">variofit</span>(s100.v2, <span class="dt">ini=</span><span class="kw">c</span>(<span class="fl">0.9</span>,<span class="fl">0.2</span>), <span class="dt">cov.model=</span><span class="st">&quot;mat&quot;</span>,
                <span class="dt">fix.kappa=</span>F, <span class="dt">kap=</span><span class="fl">1.5</span>, <span class="dt">nug=</span><span class="fl">0.2</span>, <span class="dt">weights=</span><span class="st">&quot;equal&quot;</span>)</code></pre></div>
<pre><code>&gt; variofit: covariance model used is matern 
&gt; variofit: weights used: equal 
&gt; variofit: minimisation function used: optim</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wls &lt;-<span class="st"> </span><span class="kw">variofit</span>(s100.v2, <span class="dt">ini=</span><span class="kw">c</span>(<span class="fl">0.9</span>,<span class="fl">0.2</span>), <span class="dt">cov.model=</span><span class="st">&quot;mat&quot;</span>,
                <span class="dt">fix.kappa=</span>F, <span class="dt">kap=</span><span class="fl">1.5</span>, <span class="dt">nug=</span><span class="fl">0.2</span>, <span class="dt">weights=</span><span class="st">&quot;cressie&quot;</span>)</code></pre></div>
<pre><code>&gt; variofit: covariance model used is matern 
&gt; variofit: weights used: cressie 
&gt; variofit: minimisation function used: optim</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">plot</span>(s100.v2, <span class="dt">main=</span><span class="st">&quot;&quot;</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>), true, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">lines</span>(ols, <span class="dt">lwd=</span><span class="fl">1.5</span>)
<span class="kw">lines</span>(wls, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="fl">1.5</span>)
<span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;true&quot;</span>, <span class="st">&quot;ols&quot;</span>, <span class="st">&quot;wls&quot;</span>),
       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-46"></span>
<img src="SeoncheolPark-book_files/figure-html/unnamed-chunk-46-1.png" alt="Comparison of variogram estimation methods." width="672" />
<p class="caption">
Figure 14.2: Comparison of variogram estimation methods.
</p>
</div>

</div>
</div>



<h3> References</h3>
<div id="refs" class="references">
<div id="ref-Gelfand2010">
<p>Gelfand, Alan E., Peter Diggle, Peter Guttorp, and Montserrat Fuentes. 2010. <em>Handbook of Spatial Statistics</em>. CRC Press.</p>
</div>
<div id="ref-Cressie1993">
<p>Cressie, Noel A. C. 1993. <em>Statistics for Spatial Data</em>. J. Wiley.</p>
</div>
<div id="ref-Journel2003">
<p>Journel, A. G., and Ch. J. Huijbregts. 2003. <em>Mining Geostatistics</em>. Blackburn Press.</p>
</div>
<div id="ref-Cressie1985">
<p>Cressie, Noel. 1985. “Fitting Variogram Models by Weighted Least Squares.” <em>Journal of the International Association for Mathematical Geology</em> 17 (5): 563–86. doi:<a href="https://doi.org/10.1007/BF01032109">10.1007/BF01032109</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="covmodel.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pointpattern.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://seoncheolpark.github.io/book/_book/35-variogramest.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
