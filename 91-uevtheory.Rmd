# (PART) Extreme Value Statistics {-}

통계학자 존 튜키(John Tukey)는 이렇게 말했다. "나는 모든 지구물리학자들이 실제 오차나 변동성의 분포들이 가우스(Gauss)나 라플라스(Laplace)가 만든 매끄러운 종 모양의 분포보다 훨씬 더 극단값 분포에 가까운 모양을 갖고 있음을 알고 있다고 확신한다."

# 일변량 극단값 이론 {#uGEVtheory}

이 장은 일변량 극단값 분포 이론과 모델링에 관한 내용을 담고 있다. 특히
$$M_{n}=\max\{X_{1},\ldots,X_{n}\}$$
의 통계적 움직임에 초점을 맞출 것이다. 여기서 $X_{1},\ldots,X_{n}$은 $F$라는 분포함수를 갖는 독립 확률변수의 수열이다. 일반적으로 $X_{i}$는 일정한 시간 스케일(예: 시간별, 일별, 월별 등)을 갖고 측정된 어떤 (확률)과정의 값들을 나타낸다. 정리하면 $M_{n}$은 $n$ 시간 단위의 관측값 중 최대값을 나타낸다.

<div class="example">

$n$이 일년동한 관찰한 관측값 수라고 할 경우, $M_{n}$은 월 최대값에 대응된다.

</div>

$X_{i}$들이 독립이라고 가정하였으므로 $M_{n}$의 분포는
\begin{eqnarray*}
P\{M_{n} \leq z \} &=& P\{X_{1}\leq z, \ldots, X_{n} \leq z\} \nonumber\\
&=&P\{X_{1}\leq z\}\times \cdots \times P\{X_{n}z\} \nonumber\\
&=&\{F(z)\}^{n}.
\end{eqnarray*}
가 된다.

그러나 이 식은 실제 도움이 되지 않는다. 왜냐하면 $F$의 진짜 분포가 어떤지를 모르기 때문이다. 여기서 우리는 관찰 데이터를 통해 $F$를 어떤 통계적 방법을 이용해 추정하고 그것으로 $F$를 대체할 가능성이 있는지 고민해볼 수 있다. 그렇지만 $F$의 변화가 아주 작더라도 $F^{n}$은 매우 많이 변하게 된다.

또 다른 접근방법으로는 $F$가 알려져 있지 않다는 것에 동의하고 극단값 자료만 가지고 $F^{n}$에 적합한 근사 모형이 있는지 찾아보는 방법이 있다. 이것은 표본 평균을 **중심극한정리(central limit theorem)**를 가지고 정규분포로 근사하는 것과 같은 방법이다. 즉 우리는 극단값 자료 분석에서도 중심극한정리와 같은 것이 있는지 살펴볼 필요가 있다.

$n \rightarrow \infty$일 때 $F^{n}$의 움직임에 대해 살펴보자. 논리 전개를 위해 다음과 같은 논리가 추가로 더 필요하다. $z_{+}$를 $F(z)=1$로 만드는 가장 작은 값이라고 생각하자. 그러면 모든 $z < z_{+}$에 대해 $n \rightarrow \infty$일 때 $F^{n}(z) \rightarrow 0$이다. 결국 $M_{n}$은 $z_{+}$에서 **점질량(point mass)**을 갖는 **퇴화분포(degenearte distribution)**를 따르게 된다. 퇴화분포는 다루기 어렵기 때문에 다음과 같이 $M_{n}$에 대해 **재정규화(re-normalization)**를 한다.
$$M_{n}^{*}=\frac{M_{n}-b_{n}}{a_{n}}.$$
여기서 $\{a_{n} >0\}$과 $\{b_{n}\}$은 적당한 상수열이다. $\{a_{n}\}$과 $\{b_{n}\}$은 $n$이 커짐에 따라 $M_{n}^{*}$의 위치(location)와 척도(scale)을 안정화시킬 수 있도록 잘 잡아준다.

<div class="theorem">

만약 앞서 말한 상수열 $\{a_{n} >0\}$과 $\{b_{n}\}$이 존재해
$$P\{(M_{n}-b_{n})/a_{n}\leq z\} \rightarrow G(z), \qquad{n \rightarrow \infty}$$
가 성립한다고 가정하자. 여기서 $G$는 퇴화분포가 아닌 어떤 분포함수이다. 이 때, $G$다음 세 개의 족(family) 중 하나를 따른다.

$$\textbf{굼벨(Gumbel): }G(z)=\exp\{\exp[-(\frac{z-b}{a})\}, \qquad{-\infty < z < \infty}.$$
$$\textbf{프레셰(Frechet): }G(z)=
\begin{cases}
0, & \text{z $\leq$ b}\\
\exp\{-(\frac{z-b}{a})^{-\alpha}\}, & \text{z > b}
\end{cases}$$
$$\textbf{와이블(Weibull): }G(z)=
\begin{cases}
\exp\{-[-(\frac{z-b}{a})^{-\alpha}]\}, & \text{z < b}\\
1, & \text{z $\geq$ b}
\end{cases}$$
이 때 $a>0$, $b$는 모수들이고 $\alpha >0$이다.

</div>

```{r, message=FALSE, echo=F}
library(evd) #rgev를 위해 필요
```

```{r , fig.align='center', comment=">", echo=F, fig.cap="Plot of three GEV distributions."}
x <- seq(from=-10, to =10, by=0.05)
par(mfrow=c(1,3))
plot(x, dgumbel(x, scale=2), type='l', col="green", lwd=2, ylab='Density', xlab='x', main="Gumbel")
plot(x, dgev(x, scale=2, shape=1), type='l', col="blue", lwd=2, ylab='Density', xlab='x', main="Frechet")
plot(x, dgev(x, scale=2, shape=-1), type='l', col="red", lwd=2, ylab='Density', xlab='x', main="Weibull")
```

위 정리는 재정규화 시킨 표본 최대값들 $M_{n}^{*}=\frac{M_{n}-b_{n}}{a_{n}}.$이 세 가지 분포족 중 하나로 분포수렴할 것임을 알려주고 있다. $M_{n}^{*}$의 극한 분포는 놀랍게도 $F$에 상관없이 항상 저 세가지 분포족 중 하나로 수렴한다. 세 가지 분포의 이름은 앞으로 자주 등장할 것이므로 기억해두자. 참고로 이 적당한 $a_{n}$, $b_{n}$은 존재하지 않을 수도 있다. (예: 포아송 분포)

<div class="example">

$X_{1}, X_{2}, \ldots$가 정규지수분포$(=\text{Exp}(1))$에서 추출된 확률변수의 수열이라고 하자. 참고로 $F(x)=1-\exp^{x}$ ($x>0$)이다. 이때 $a_{n}=1$, $b_{n}=\log n$이라고 하면 $n\rightarrow \infty$일 때 고정된 $z\in\mathbb{R}$에 대해

\begin{eqnarray}
P\{(M_{n}-b_{n})/a_{n} \leq z \} &=& F^{n}(z+\log n) \nonumber\\
&=&[1-e^{-(z+\log n)}]^{n} \nonumber\\
&=&[1-n^{-1}e^{-z}]^{n} \nonumber\\
&\rightarrow& \exp(-e^{-z})
\end{eqnarray}

이다. 즉 $a_{n}$과 $b_{n}$을 위와 같이 선택하였을 때 $M_{n}$의 극한분포는 굼벨분포가 된다.

</div>

<div class="example">

$X_{1}, X_{2}, \ldots$가 표준정규분포에서 추출된 확률변수의 수열이라고 하자. 이때 
$$a_{n}=(2\log n)^{-0.5}, b_{n}=(2\log n)^{0.5}-0.5(2\log n)^{-0.5}(\log\log n +log 4\pi)$$
로 놓을 경우 재정규화된 $M_{n}$ 또한 굼벨분포로 수렴함이 알려져 있다. 그러나 앞 예제와 비교하였을 때 수렴 속도는 현저히 느리다.

</div>

$M_{n}$의 수렴속도를 체크하는 것은 중요한 일이다. 왜냐면 우리는 일반화 극단값 분포를 유한개의 표본 최대값들의 점근 분포로 생각하고 사용할 것이기 때문이다. 결국 일반화 극단값 분포를 사용하기 위해 얼마나 많은 데이터가 필요할 것인가라는 문제는 $M_{n}$의 수렴속도와 관계된다.

## 일반화 극단값 분포(generalized extreme value distribution)

앞서 말한 $G$의 극한값에서의 행동은 분포에 따라 달라진다. 예를 들면, 굼벨분포와 프레셰분포는 $z_{+}=\infty$이나 와이블분포는 $z_{+}<\infty$이다. 그리고 굼벨분포에서는 $G$의 분포가 지수적으로 감소(exponentially decay)하나 프레셰분포에서는 다항식 차수로 감소(polynomially decay)한다. 즉 족이 달라지면 극단값의 움직임 또한 다르게 표현될 것임을 알려준다.

그런데 이렇게 족 별로 따로 나누어 분석하는 것은 두 가지 문제점을 지닌다. 첫째, 데이터를 보고 어떤 족으로 분석하는 것이 적절한지 미리 정해야 한다. 둘째, 이러한 결정 후에는 이 결정이 맞다는 전제 하에 추론이 진행되고 이 선택이 가지는 불확실성을 배제하게 된다. 따라서 일반적으로는 앞 정리에 나왔던 식을 재구성하여 다음과 같이 하나의 함수로 표현하여 분석하게 된다.
$$G(z)=\exp\{-[1+\xi(\frac{z-\mu}{\sigma})]^{-1/\xi}\}.$$
이 때 $\{z: 1+\xi(z-\mu)/sigma >0\}$이며 $-\infty < \mu < \infty$, $\sigma >0$ 그리고 $-\infty <\xi <\infty$를 만족한다. 이 분포를 **일반화 극단값 분포(generalized extreme value distribution)**이라고 부른다. 여기서 $\mu$는 **위치모수(location parameter)**, $\sigma$는 **척도모수(scale parameter)**, 그리고 $\xi$는 **형태모수(shape parameter)**라고 한다. 특히 $\xi$는 이 분포가 굼벨족($\xi=0$), 프레셰족($\xi>0$) 또는 와이블족($\xi<0$)이 될지 결정하는 역할을 한다.

## 최대안정성(max-stablity)

<div class="definition"> 

모든 $n=2,3,\ldots,$에서 상수들 $\alpha_{n}>0$, $\beta_{n}$이 존재해 
$$G^{n}(\alpha_{n}z+\beta_{n})=G(z)$$
일 경우 분포 G를 **최대안정(max-stable)**하다고 부른다. 즉 $G$에 거듭제곱을 하는 것은 단지 위치모수와 척도모수의 변화만 야기한다는 것이다.

</div>

최대안정성과 일반화 극단값 분포 사이에는 다음과 같은 정리가 있다.

<div class="remark"> 

어떤 분포가 최대안정한 것은 분포가 일반화 극단값 분포임과 동치이다. [@Coles2001]

</div>

## 복귀 수준(return level)

앞서 극단값 분석은 극단적인 사건들을 모델링하고 적합한 위험 평가를 해 줄 수 있는 통계적 방법을 제공한다고 설명하였다. 그렇다면 우리는 어떤 방법을 통해 이 **위험(risk)**를 측정할 수 있을까?

한 가지 방법으로 **복귀 수준(return level)**이라는 것이 있다. **n-복귀 수준**은 우리가 매 $n$년마다 한 번꼴로 초과될 것으로 기대되는 값이다. 다시 말하면 어떤 특정한 해에 그런 강도의 사건을 마주칠 확률이 $\frac{1}{n}$ 정도 될 때 $n$-복귀 수준이 된다. 분위수(quantile)로 봤을 때에는 $1-\frac{1}{n}$분위수에 대응되는 사건이다.

<div class="example">

20년 복귀 수준은 매 20년마다 최대 수준이 한 번꼴로 초과할 것으로 기대되는 수준에 대응된다. 이것은 매 년 $\frac{1}{20}=0.05$의 확률로 그러한 사건이 마주칠 것으로 기대되며 $1-\frac{1}{20}=0.95$의 분위수에 대응된다.

</div>

일반적으로 많이 쓰이는 복귀 수준은 $20, 50, 100$년 정도이다.

이 복귀 수준이라는 개념은 통계학에서 말하는 분위수와 일맥상통한다. $0<p<1$이라 할 때, 일반화 극단값 분포의 분위수 $x_{p}$는
$$x_{p}=\mu-\frac{\sigma}{\xi}[1-\{-\log(1-p)\}^{-\xi}]$$
가 된다. 이것은 $G(x_{p})=1-p$라 놓고 $x_{p}$에 대해 풀어 얻을 수 있다. 이 때 $x_{p}$를 $1/p$ **복귀 주기(return period)**에 대응되는 복귀 수준이라 부른다.

## 극단값 분포에서의 추론(inference in extreme value statistics)

$k$개의 연 최대값 $X_{1}, \ldots , X_{k}$들이 주어져 있을 때, 일반화 극단값 분포의 모수들 $(\mu, \sigma, \xi)$을 추론하는 문제를 생각해보자. 가능한 추론 방법들은 다음과 같다.

- **그래프 기반 방법**: 전통적으로 중요했고, 지금도 기본적인 모형 파악에 유용하다.

- **적률 기반(moment-based) 추정량**: 적률이 존재하지 않을 가능성이 있어 극단값 분석에 유용하지 않은 경우가 많다.

- **확률 가중 적률**: 수문학(hydrology)에서 많이 쓰이나 복잡한 자료로 확장하기 어렵다.

- **가능도(likelihood) 기반 방법**: 통계학에서 가장 많이 이용하는 방법이다. 복잡한 자료에 적용할 수 있고 일반적인 점근적 추정과 검정이론을 적용할 수 있다. 또한 베이지안 방법을 적용할 수도 있다.

일반화 극단값 분포를 가능도 기반 방법으로 분석할 때 정칙 조건(regularity condition)을 만족하는지 항상 확인해야 한다. 일반화 극단값 분포의 모수들로 표현된 값 $\mu-\sigma/\xi$이 $\xi\neq 0$일때 분포의 끝점(end point)이 되기 때문에 정칙 조건을 만족하지 않을 수도 있다.[@Smith1985]

한편 형태모수 값과 최대가능도추정량의 존재 사이의 관계에 대해 다음과 같은 사실이 알려져 있다.

- $\xi > -0.5$인 경우 최대가능도추정량은 정칙조건을 만족하며 일반적인 점근적 성질을 갖는다.

- $-1 < \xi < -0.5$인 경우 최대가능도추정량을 얻을 수는 있으나 일반적인 점근적 성질을 갖지는 않는다.

- $\xi < -1$인 경우 최대가능도추정량을 얻지 못할 가능성이 높다.

## 극단값 분포에서의 최대가능도추정(mle in extreme value statistics)

일반화 극단값 분포에 최대가능도추정을 적용하기 전에 일반적인 가능도 관련 이론에 대해 정리해보자.

<div class="definition">

$y$가 자료이고 이 자료가 다음과 같은 모수 $\theta$로 정의되는 확률변수 $Y \sim f(y;\theta)$의 실현(realization)이라고 하자. 이때 **가능도(likelihood, 우도)**와 로그 가능도는
$$L(\theta)=L(\theta;y)=f_{Y}(y;\theta), l(\theta)=\log L(\theta), \theta \in \Omega_{\theta}$$
로 정의된다.

**최대가능도추정량(maximum likelihood estimate, MLE)**은
$$l(\hat{\theta})\geq l(\theta), \forall \theta \in \Omega_{\theta}$$
을 만족시키는 $\hat{\theta}$이다. 많은 경우 $\hat{\theta}$는 유일하며 다음과 같은 **점수방정식(score equation, 또는 가능도방정식)**
$$\frac{\partial l(\theta)}{\partial \theta}=0$$
을 만족한다. 만약 $\theta$가 $p \times 1$ 벡터라면 점수방정식 또한 $p \times 1$ 벡터가 된다.

**관측정보행렬(observed information matrix)**는 점수방정식을 한 번 더 미분한 것이다.
$$J(\theta)=-\frac{\partial^{2}l(\theta)}{\partial \theta \partial \theta^{T}}.$$
만약 $\theta$가 $p \times 1$ 벡터라면 $J(\theta)$는 $p \times p$ 행렬이 된다.

**가능도 통계량(likelihood ratio statistic, 윌크스의 통계량)**은
$$W(\theta)=2\{l(\hat{\theta})-l(\theta)\}\geq 0$$
이다.

</div>

가능도 근사(likelihood approximation)은 $n$이 클때, 데이터가 $f(y,\theta^{0})$에서 생성되었다고 가정하면
$$\hat{\theta} \stackrel{\cdot}{\sim} \mathcal{N}_{p}(\theta^{0}, J(\hat{\theta})^{-1})$$
로 근사하는 것이다. 이때 $\hat{\theta}$, $J(\hat{\theta})$는 보통 수치적으로 계산하게 된다. 그리고 검정통계량은 $n$이 작을지라도
$$W(\theta^{0}) \stackrel{\cdot}{\sim} \xi_{p}^{2}$$
근사를 이용한다.

실제로는 $\theta$를 **흥미있는 모수들(interest parameters)** $\psi_{q\times 1}$와 **장애모수들(nuisance parameters)** $\lambda_{p-q\times 1}$로 나누어 분석하게 된다. $\hat{\lambda}_{\psi}$를 $\psi$가 고정되어 있을 때 $\lambda$의 최대가능도추정량이라고 하자. 그러면 **일반화가능도통계량(generalized likelihood ratio statistic)**을
$$W_{p}(\psi)=2\{l(\hat{\psi},\hat{\lambda})-l(\psi,\hat{\lambda}_{\psi})\}=2\{l(\hat{\theta})-l(\hat{\theta}_{\psi})\}$$
로 정의한다. 이 때 다음과 같은 통계량을 정의할 수 있다.

<div class="definition">

**일반화가능도통계량(generalized likelihood ratio statistic)**은
$$W_{p}(\psi)=2\{l(\hat{\psi},\hat{\lambda})-l(\psi,\hat{\lambda}_{\psi})\}=2\{l(\hat{\theta})-l(\hat{\theta}_{\psi})\}$$
이다.

</div>

만약 $\psi^{0}$이 정칙모형(regular model)의 자료로부터 얻은 $\psi$값이라고 하면 앞선 정의에 의해
$$W_{p}(\psi) \stackrel{\cdot}{\sim} \xi_{q}^{2}, \qquad{for large n}$$
이 된다. $\psi^{0}$에 대한 신뢰구간(confidence interval)과 검정은 이것에 기초해서 만들게 된다.

## 극단값 분포에서의 프로파일 가능도(profile likelihood in extreme value statistics)

앞선 상황처럼 알려지지 않은 모수를 흥미있는 모수들과 장애모수들로 나눌 수 있고 이 둘을 모두 추정해야 하나 흥미있는 모수들에만 관심이 있을 경우 사용할 수 있는 것 중의 하나가 **프로파일 가능도(profile likelihood)**이다.

<div class="definition">

$\theta$를 모수 벡터라 하고 $\theta_{i}$를 제외한 모든 $\theta$의 원소들의 모임을 $\theta_{-i}$라고 했을 때 $\theta_{i}$에 대한 **프로파일 로그 가능도(profile log-likelihood)**는
$$l_{p}(\theta_{i})=\max_{\theta_{-i}}l(\theta_{i},\theta_{-i})$$
이다.

</div>

<div class="definition">

$\theta$를 모수 벡터라 하고 이것을 $(\theta^{(1)}, \theta^{(2)})$로 분할할 수 있다고 하자. 여기서 $\theta^{(1)}$은 $k$차원 흥미있는 모수들의 벡터이며 $\theta^{(2)}$는 나머지들의 $(d-k)$차원 벡터이다. 이때 $\theta^{(1)}$에 대한 **프로파일 로그 가능도(profile log-likelihood)**는
$$l_{p}(\theta^{1})=\max_{\theta^{(2)}}l(\theta^{(1)},\theta^{(2)})$$
이다.

</div>

정칙 조건 하에서 프로파일 로그 가능도를 이용한 통계량은 다음과 같은 점근분포를 갖음이 알려져 있다.[@Coles2001]

<div class="theorem">

$x_{1}, \ldots , x_{n}$을 모수분포 $\mathcal{F}$ 안에 있는 어떤 분포의 독립적인 실현이라고 하자. $\hat{\theta}_{0}$을 $d$차원 모수벡터 $\theta_{0}=(\theta^{(1)},\theta^{(2)})$의 최대가능도추정량이라고 하자. 이때 $\theta^{(1)}$의 길이를 $k$라고 하자. 그러면 정칙 조건 하에서 $n$이 클 때
$$D_{p}(\theta^{(1)})=2\{l(\hat{\theta}_{0})-l_{p}(\theta^{(1)}) \} \stackrel{\cdot}{\sim} \chi_{k}^{2}$$
이다.

</div>

위 정리는 크게 두 가지 상황에서 쓰인다. 첫째, 길이 1의 모수 $\theta_{i}$에 대해 $(1-\alpha)$ 신뢰구간 $C_{\alpha}=\{\theta_{i}: D_{p}(\theta_{i})\leq c_{\alpha}\}$를 계산할 때 쓴다. 여기서 $c_{\alpha}$는 $\xi_{1}^{2}$ 분포의 $(1-\alpha)$ 분위수를 뜻한다. 두 번째 응용은 모형 선택이다.
