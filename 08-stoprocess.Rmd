# 확률과정론 {#stoprocess}

참고할만한 책으로 [@Lindgren2012]가 있다.

## 확률과정이란?(stochastic process)

[@Lindgren2012]에 있는 그림이다.

```{r, echo=F, fig.cap='Overview of the threee types of worlds in which our processes live.', fig.align='center'}
knitr::include_graphics("images/basic_stprocess.png")
```

**확률과정(stochastic process)**란 확률공간에서 정의되는 확률변수들의 모임 $\{ Z, t \in T\}$라고 할 수 있다. 이 때 $T=(-\infty, \infty)$ 등과 같이 연속된 구간의 형태를 갖는 경우를 **연속형 확률과정(continuous stochastic process)**, $T=\{ 0, \pm 1, \pm 2 , \ldots\}$ 등과 같이 이산 구간일 경우는 **이산형 확률과정(discrete stochastic process)**라고 한다.

## 확률과정에서의 연속성(continuity of stochastic process)

```{definition, name="연속표본경로"}
과정 $X$가 $t_{0}$에서 연속이라 함은
$$\text{For almost all }\omega, t \rightarrow t_{0} \text{ implies } X(t,\omega) \rightarrow X(t_{0},\omega)$$
를 의미한다. 과정 $X$가 연속이라 함은
$$\text{For almost all }\omega, X(\cdot, \omega) \text{ is a continuous function}$$
임을 의미한다.

```

```{definition, name="CADLAG (CAGLAD)"}
Well-ordered set $T$에 있는 sample function $x$가 모든점에서 continuous from the right (left)하고 limited from the left (right)일 때 **CADLAG (CAGLAD)**이라고 한다. 즉, 모든 $t_{0}\in T$에서 $t\downarrow t_{0}$이 $x(t) \rightarrow x(t_{0})$를 의미하고 $t\uparrow t_{0}$일 때 $\lim_{t\uparrow t_{0}} x(t)$가 존재하나 꼭 $x(t_{0})$일 필요는 없는 상황임을 의미한다. 어떤 확률과정 $X$가 CADLAG임은 그것의 almost all sample path가 CADLAG임을 의미한다.

```

```{definition, name="확률과정의 version"}
Common index set $T$를 갖는 두 개의 확률과정 $X$와 $Y$이 서로의 **version**이라 함은
$$\forall t \in T, \mathbb{P}(\omega: X(t,\omega)=Y(t,\omega))=1$$
임을 의미한다. 이러한 과정들을 **stochastically equivalent**라고도 부른다. 이는 임의의 시간대에서 $X$와 $Y$는 almost surely equal이라는 것이다.

```

```{definition, name="확률과정의 구분불가능성"}
두 개의 확률과정 $X$와 $Y$가 **구분불가능(indistinguishable)** 또는 **euqivalent up to evanescense**하다는 것은
$$\mathbb{P}(\omega: \forall t, X(t,\omega)=Y(t,\omega))=1$$
임을 의미한다. 쉽게 얘기하면 $X$와 $Y$의 표본 경로가 equal almost surely라는 것이다.

```

구분불가능성을 갖는 확률과정은 서로의 version이 되나, 그 반대는 성립하지 않는다. 

그렇다면 확률과정에서 왜 연속성이 이슈가 되는가? 우리는 sample path를 보통 연속인 함수로 제한하고 싶어한다. 더 나아가 미분가능할 정도로 부드러운 함수를 다루고자 하는 경우가 많다. 물론 이는 수학적인 편리함을 위해서이다.

```{proposition}
$X(t,\omega)$를 실변수이며 연속 표본 경로를 갖는 연속 모수 과정이라고 하자. 그러면 모든 유한한 구간 $I$에 대해 $M(\omega)=\equiv \sup_{t\in I}X(t,\omega)$이고 $m(\omega)\equiv \inf_{t\in I}X(t,\omega)$는 가측 확률변수이다.

```

우리는 특정 시간에 관찰된 확률과정을 다룰 때 product $\sigma$-field를 보통 쓴다. Product $\sigma$-field는 countable question에 대해 답을 해 준다. 즉 어떤 measurable set $A$가 있으면 이 때 $x(\cdot, \omega)\in A$는 countably many indices $t$의 $x(t,\omega)$ value들에 depend해야한다는 것이다. 이것은 모든 continuous sample path들의 class가 not product $\sigma$-field measurable이 될 수도 있다는 것을 의미하는데, 그 이유는 $x(\cdot, \omega)$가 $t$에서 연속이라는 것은 모든 수열 $t_{n}\rightarrow t$에 대해 $x(t_{n},\omega)\rightarrow x(t,\omega)$라는 것을 의미하면 이것은 uncountably many coordinates들의 함숫값들을 포함하는 것이기 때문이다. 더 나아가 differentiable function들의 class 또한 $\sigma$-field measurable이 아니다.

## 분리가능한 무작위 함수들(separable random functions)

**분리가능(separable)**한 무작위 함수들의 기본 아이디어는 contable, dense subset만 다룬다는 것이다.

```{definition, name="분리가능 함수들(separable functions"}
$\Xi$와 $T$가 metric space라고 하고, $D$를 $T$의 countable, dense subset이라고 하자. 그러면 함수 $x: T\rightarrow \Xi$가 $\forall t\in T$에 대해 수열 $t_{i}\in D$가 존재해 $t_{i}\rightarrow t$ 그리고 $x(t_{i})\rightarrow x(t)$를 만족할 경우 함수 $x$를 **D-분리가능(D-separable)** 또는 D에 대해 분리가능하다고 한다.

```

```{lemma}
다음 조건들은 분리가능성의 충분조건이다.

1. $T$ is countable

2. $T$ is continuous

3. $T$ is well-ordered and $x$ is right-continuous.

```

```{proof}
1. $T$ 자체를 separating set으로 잡으면 된다.

2. 어떤 countable dense set $D$를 잡는다. Dense 성질에 의해 모든 $t$에 대해 다음과 같은 수열 $t_{i}\in D$가 존재해 $t_{i}\rightarrow t$이다. 연속성에 의해 $x(t_{i})\rightarrow t$가 된다.

3. 2와 마찬가지로 모든 coundtable dense $D$에 대해 $t_{i}>t$가 되도록인 채로 2와 같은 논리를 따라가면 된다.

```

```{definition, name="분리가능 과정"}
$\Xi$-valued process $X$ on $T$가 **D에 대해 분리가능(separable with respect to D)**하다는 것은 $D$가 $T$의 countable, dense subset이고 다음과 같은 measure-zero set $N\in\Omega$가 존재해 모든 $\omega \in N$에 대해 $X(\cdot, \omega)$가 $D$-분리가능이라는 것이다. 즉 $X(\cdot, \omega)$가 almost surely $D$-separable이라는 것이다.

```

## 경험과정(empirical process)

이 부분은 [@Jiang2010] 7장을 참고했다. 확률변수들은 관찰값(observation)들의 형태로 얻어지는데, 관찰된 확률변수들로 구성된 함수를 우리는 특별히 **통계적 함수(statistical function)**이라고 부른다. 통계적 함수는 실제로 얻을 수 있다는 점에서 많은 사람들이 그 성질에 대해 관심을 갖는다. 보통은 통계적 함수들 중 **경험과정(empriical process)**이라고 부르는 것에 집중을 하게 된다. $X_{1},X_{2},\ldots $가 분포함수 $F$를 갖는 i.i.d. 확률변수들의 수열이라고 하자. 그러면 **경험적 분포함수(empirical distribution function)**은 다음과 같이 정의된다.

```{definition, name="경험적 분포함수"}
경험적 분포함수 $F_{n}(x)$는 다음과 같이 정의된다.

\begin{equation}
F_{n}(x)=\frac{1}{n}\sum_{i=1}^{n}1_{(X_{i}\leq x)}, -\infty < x < \infty.
(\#eq:empiricalDF)
\end{equation}


```

식 \@ref(eq:empiricalDF)은 쉬워보이지만 이 식의 뜻을 쉽게 이해하기는 어렵다. 여기서 $X_{i}$들은 관찰값들이고 $x$는 함수값이다. $X_{i}$들의 실현(realization)에 대해 식 \@ref(eq:empiricalDF)은 계단함수를 정의한다. 그리고 $X_{i}$들이 무작위이므로 식 \@ref(eq:empiricalDF) 또한 무작위이다. 즉 $X_{1},\ldots ,X_{n}$들이 매 번 실현될 때마다 다른 함수를 얻게 된다.

대수의 약법칙에 의해 각 $x$에 대해 경험적 분포함수는 $n\rightarrow\infty$일 때 $E\{1_{(X_{1}\leq X)}\}=P(X_{1}\leq x)=F(x)$에 거의 확실한 수렴(converge a.s)을 한다. 실제로는 더 강한 결과가 성립한다. 이 거의 확실한 수렴은 $n\rightarrow\infty$일 때
$$\sup_{x}|F_{n}(x)-F(x)|\stackrel{\text{a.s.}}{\rightarrow}0$$
이므로 uniform하게 수렴한다. 그러면 우리는 경험적 분포함수에 대해서도 다음과 같은 centeralized되어있고 normalized version의 경험적 분포함수를 정의할 수 있다. 이를 **경험적 과정(empirical process)**라고 부른다.

```{definition, name="경험적 과정"}
경험적 과정은 무작위 함수로 다음과 같이 정의된다.
$$\sqrt{n}\{ F_{n}(x) - F(x) \},\qquad{-\infty < x \infty.}$$

```


## 포아송과정(Poisson process)

우리의 휴대전화로 오는 문제메시지는 하루종일 불규칙한 간격으로 온다. 고속도로에서의 사고들은 시간과 공간에 독립적으로 일어난다. 이러한 현상들은 연속 구간(보통 시간)에서의 발생 또는 도착 사건들을 모델링하는 데 사용되는 확률과정인 **포아송과정(Poisson process)**으로 잘 모델링할 수 있다. 

### 셈과정(counting process)

포아송 과정은 **셈과정(counting process)**의 특별한 타입이다. 어떤 사건들의 흐름이 $t=0$에서 시작하는 시간대에서 무작위로 도착한다고 가정해보자. 이 때 $t$시간까지 도착한 사건의 숫자를 $N_{t}$라고 하자. 모든 $t\geq 0$에서 $N_{t}$는 확률변수다. 이런 확률변수들의 모임(collection) $(N_{t})_{t\geq 0}$은 연속이며 정수값을 갖는 확률과정이고 이를 셈과정이라고 부른다. $N_{t}$는 $[0,t]$ 사이의 사건을 세기 때문에 $t$가 증가함에 따라 $N_{t}$ 또한 증가한다.

```{definition, name="셈과정"}
셈과정 $(N_{t})_{t\geq 0}$은 음이 아니고 정수값을 갖는 확률변수들의 모임으로 $0\leq s \leq t$일 때 $N_{s} \leq N_{t}$이다.

```

확률변수들의 수열인 마르코프 체인과 다르게 셈과정은 연속인 시간 간격에서 indexed 되어 있으므로 셀 수 없는 모임이다.

### 포아송과정의 정의(definition of Poisson process)

**포아송과정(Poisson process)을 정의하는 방법은 몇 가지가 있다.

1. 고정된 간격에서의 사건 숫자의 초점을 맞추는 방법

2. 이떤 사건이 일어났을 때 사건들 사이의 시간에 초점을 맞추는 방법

3. 무한소(infinitesimal, 모든 양수보다는 작지만 0보다 큰 상태) 간격에서의 개별 사건들의 확률적 행동에 초점을 맞추는 방법

이에 따라 포아송과정의 정의도 세 가지가 있다.

```{definition, name="포아송과정 (정의1)"}
모수 $\lambda$를 갖는 포아송 과정$(N_{t})_{t\geq 0}$은 다음 조건들을 만족하는 셈과정이다.

1. $N_{0}=0$.

2. 모든 $t>0$에 대해 $N_{t}$는 모수 $\lambda t$를 갖는 포아송 분포를 따른다.

3. (정상 증분) 모든 $s,t>0$에 대해 $N_{t+s}-N_{s}$는 $N_{t}$와 같은 분포를 갖는다. 즉 다음을 만족한다.

$$P(N_{t+s}-N_{s} = k) = P(N_{t} = k) = \frac{e^{-\lambda t}(\lambda t)^{k}}{k!},\qquad{k=0,1,\ldots}$$
  
4. (독립 증분) $0\leq q < r \leq s < t$인 $q,r,s,t$에 대해 $N_{t}-N_{s}$와 $N_{r}-N_{q}$는 독립인 확률변수들이다.

```

**정상 증분(stationary increment)** 성질은 어떤 구간에서의 도착 숫자의 분포는 오직 구간의 길이에만 관련이 있다는 것이다. **독립 증분(independent increment)**성질은 disjoint intervals에서의 도착들의 숫자는 독립 확률 변수들이 된다는 것이다.

### 포아송 무작위 측도들(Poisson random measures)

다음 [사이트](http://www.math.wisc.edu/~kurtz/735/main735.pdf)의 9장을 참고하였다. [@Mikhail2014] 또한 참고할만하다. $(E,\mathcal{E})$를 가측공간이라고 하고, $\nu$를 $\mathcal{E}$에서의 $\sigma$-finite 측도라고 하자. $\mathcal{N}(E)$는 $E$에서의 counting measure의 collection이라고 하자, 즉 음이 아닌 정수값들의 측도이다. $\xi$는 만약 각각의 $\omega \in \Omega$에서 $\xi(\omega, \cdot)\in\mathcal{N}(E)$이고 각각의 $A\in\mathcal{E}$에서 $\xi(A)$가 $\mathbb{N}\cup\{\infty\}$의 값을 갖는 확률변수일 때 확률공간 $(\Omega, \mathcal{F}, P)$에서의 $\mathcal{N}(E)$-확률변수다. 편의를 위해 $\xi(\omega, A)$대신 $\xi(A)$라고 쓰자.

```{definition, name="포아송 무작위 측도"}
어떤 $\mathcal{N}(E)$-확률변수가

1. 각각의 $A\in\mathcal{E}$에 대해 $\xi(A)\sim \text{Poisson}(\nu(A))$이다.

2. 만약 $A_{1},A_{},\ldots \in \mathcal{E}$가 disjoint이면 $\xi(A_{1}), \xi(A_{2}),\ldots $는 독립인 확률변수이다.

를 만족하면 **평균측도(mean measure)** $\nu$를 갖는 **포아송 무작위 측도(Poisson random measure)**이다. 

```

$\nu$는 $\xi$가 존재할 경우 $\xi$의 분포를 결정한다. 먼저 $\nu$가 유한하게 존재한다면 $\nu$가 $\sigma$-finite한 것으로 고려한다.

```{proposition}
$\nu$가 $(E,\mathcal{E})$에서의 측도이고 $\nu(E)<\infty$라고 하자. 그러면 평균측도 $\nu$를 갖는 포아송 무작위 측도가 존재한다.

```

평균측도를 다른 말로 intensity measure라고 부르기도 한다. 

### 공간 포아송 과정(spatial Poisson process)

[@Dobrow2016]의 6.6절을 참고하였다. **공간 포아송 과정(spatial Poisson process)**란 사건 또는 점의 분포에 관한 모형으로, 2차원 이상 공간에서 다뤄지는 것이 특징이다. 이러한 과정의 예로 숲에서의 나무들의 장소에 대한 모형이나, 밤하늘 은하의 위치에 대한 모형 그리고 미국의 암 군집에 대한 모형 등을 들 수 있다.

$d\geq 1$이고 $A\subset \mathbb{R}^{d}$라고 할 때 $N_{A}$를 집합 $A$에 속하는 점들의 갯수로 정의하자. 그리고 $|A|$를 $A$의 size (즉 $\mathbb{R}^{2}$일 때에는 넓이, $\mathbb{R}^{3}$일 때에는 부피가 된다.)로 정의하자. 

```{definition, name="공간 포아송 과정"}
확률변수들 $(N_{A})_{A\subseteq \mathbb{R}^{d}}$가 다음의 두 조건

1. 각각의 유계집합 $A\subseteq \mathbb{R}^{d}$에 대해 $N_{A}$가 모수 $\lambda |A|$인 포아송 분포를 갖는다.

2. $A$와 $B$가 disjoint set일 때 $N_{A}$, $N_{B}$는 독립인 확률변수들이 된다.

을 만족하는 모수 $\lambda$를 갖는 공간 포아송 과정이라고 부른다.

```


```{example, name="공간 포아송 과정에서의 확률계산"}
모수 $\lambda=0.5$인 공간 포아송 과정이 있다고 하자. $(3,4)$를 중심으로 하고 반지름이 2인 디스크가 정확하게 5개의 점을 포함할 확률은 $|C|=\pi r^{2}=4\pi$를 이용하면
$$P(N_{C}=5)=\frac{e^{-\lambda |C|}(\lambda |C|)^{5}}{5!}=\frac{e^{-2\pi}(2\pi)^{5}}{5!}=0.152.$$
가 된다.

```

공간 과정에서 발생하는 균등분포는 1차원 포아송 과정에서 하는 일과 유사하다. 유계집합 $A\subseteq \mathbb{R}^{d}$이 주어졌을 때 $A$에 $n$개의 점이 있다고 조건을 달면 이 점들의 위치는 $A$에서 균등하게 분포되어 있어야 한다. 이러한 이유로 공간 포아송 과정을 때때로 **complete spatial randomness (CSR)** 모형이라고 부르기도 한다.

공간 포아송 과정은 공간상에서의 점의 분포를 모델링하는 일반적인 방법인 **점과정(point process)**의 특별한 경우이다. 때로는 주어진 포인트 패턴이 CSR과 얼마나 가까운지 측정하고 싶을 때도 있다. 그럴 때 사용할 수 있는 흔한 측도로 과정의 어떤 점과 그 점에서 가장 가까운 이웃과의 거리를 계산한 **최근접 거리(nearest neighbor distance)**가 있다.

모수가 $\lambda$인 $\mathbb{R}^{2}$에서의 공간 포아송 과정을 생각해보자. $x$를 plane에서의 고정된 점으로 둔다. $D$는 $x$의 최근접 거리라고 하자. 그러면 사건 $\{ D > t\}$는 $x$를 중심으로 하고 반지름이 $t$인 원 안에 다른 점이 하나도 없는 사건과 동치이다. 따라서 확률을
$$P(D>t)=P(N_{C_{x}}=0)=e^{-\lambda |C_{x}|} = e^{-\lambda \pi t^{2}}, \qquad{\text{for } t > 0}$$
과 같이 계산할 수 있다. 이것을 미분하면 최근접 거리에 대한 밀도함수를 얻을 수 있다.
$$f_{D}(t)=e^{-\lambda \pi t^{2}}2\lambda \pi t, \qquad{\text{for } t > 0.}$$
그리고 이것의 평균과 분산은 다음과 같다.
$$E(D) = \frac{1}{2\sqrt{\lambda}}, \text{Var}(D)=\frac{4-\pi}{4\pi\lambda}.$$

### 공간 포아송 과정 생성 예제(example of simulating a spatial Poisson process)

다음 R 예제는 $\lambda=100$인 포아송 과정을 영역 $[0,1]\times [0,1]$ 내에서 $(0.7,0.7)$을 중심으로 하고 반지름이 $r=0.2$인 원 안에 들어가 있는 점의 갯수를 100,000번 반복 생성하여 계산해보고 기댓값과 비교해 보는 예제이다. 실제 기댓값은 $\lambda |C|=100\pi (0.2)^{2}=12.567$이다.

```{r, fig.align='center', comment=">", fig.cap = 'Samples of a spatial Poisson process.'}
library(plotrix)
# spatialPoisson.R
lambda <- 100
squarearea <- 1
trials <- 100000
simlist <- numeric(trials)
par(mfrow=c(2,2))
par(mar=c(5.1,4.1,4.1,2.1)/4)
for (i in 1:trials) {
  N <- rpois(1,lambda*squarearea)
  xpoints <- runif(N,0,1)
  ypoints <- runif(N,0,1)
  ct <- sum(((xpoints-0.7)^2+(ypoints-0.7)^2)<=0.2^2)
  simlist[i] <- ct 
  if(i <=4){
    plot(xpoints,ypoints, xlim=c(0,1), ylim=c(0,1), xlab="", ylab="", main="",xaxt="n",yaxt="n")
    draw.circle(x=0.7,y=0.7,radius=0.2,nv=100,border="black",col=NA,lty=1,density=NULL,
                angle=45,lwd=1)
  }
} # number of points in circle
mean(simlist)
var(simlist)
# Compare with theoretical mean and variance
lambda*pi*(0.2)^2
```

### 비동질적 포아송 과정(nonhomogeneous Poisson process)

포아송 과정에서, 도착은 시간과 독립이다. 그러나 많은 응용에서 이는 비현실적인 가정이다. 대학 식당의 점심시간을 생각해보자. 문을 오전 11시에 연다고 했을 때 학생들의 도착을 정오까지 점점 증가하다가 상수를 이루다 문을 닫는 시간인 낮 3시까지 감소하게 될 것이다. 이러한 행동들은 율(rate)가 $\lambda=\lambda(t)$인 **비동질적 포아송 과정(nonhomogeneous Poisson process)**으로 모델링할 수 있다. 이러한 율 함수를 **강도함수(intensity function)**라고 부른다.

```{definition, name="비동질적 포아송 과정"}
셈과정(counting process) $(N_{t})_{t\geq 0}$은 다음 조건들을 만족할 때

1. $N_{0}=0$.

2. 모든 $t>0$에 대해 $N_{t}$는 평균이 $E(N_{t})=\int_{0}^{t}\lambda(x)dx$인 포아송 분포를 갖는다.

3. $0\leq q < r \leq s < t$인 $q,r,s,t$에 대해 $N_{r}-N_{q}$ $N_{t}-N_{s}$가 독립인 확률변수다.

강도함수가 $\lambda(t)$인 비동질적 포아송과정이다.

```

비동질적 포아송 과정인 독립 증분을 갖으나 정상 증분(stationary increment)을 가질 필요는 없다. 이는 $0<s<t$일때 $N_{t}-N_{s}$는 모수 $\int_{s}^{t}\lambda(x)dx$를 갖는 포아송 분포를 갖음으로부터 알 수 있다.

### 공간 포아송 과정 이론(theory of spatial Poisson process)

이 절은 Rasmussen의 2011년 강의노트를 따른다.

## 브라운운동(Brownian motion)

```{definition, name="저차원에서의 브라운운동"}
실수값을 갖는 확률과정 $\{ B(t) : t\geq 0\}$이 다음 조건들을 만족할 때

1. $B(0)=x$

2. 그 과정이 독립 증분(independent increment)을 갖는다. 즉 모든 시간 $0 \leq t_{1} \leq t_{2} \leq \cdots \leq t_{n}$에 대해 증분 $B(t_{n})-B_(t_{n-1}),\ldots, B(t_{2})-B_(t_{1})$이 독립 확률변수다.

3. 모든 $t \geq 0$과 $h > 0$에 대해 증분 이 정규분포를 따른다.
$$B(t+h)-B(t) \sim \mathcal{N}(0,h).$$

4. 함수 $t \rightarrow B(t)$가 연속이다.

$x\in\mathbb{R}$에서 시작하는 (선형) **브라운운동(Brownian motion)**이라고 한다. 특별히 $x=0$일 때 $\{ B(t): t\geq 0\}$을 정규 브라운운동(standard Brownian motion)이라고 부른다.

```

브라운운동의 정의는 나중에 공간과정에도 잠시 나올 것이다.

### 분수 브라운운동(fractional Brownian motion)

**분수 브라운운동(fractional Brownian motion)**이란 fractional derivative (또는 fractional integral) of Brownian motion을 일컫는 말이다.

## 마팅게일(martingale)

**마팅게일(martingale)**은 평균 0을 갖는 독립인 확률변수들의 합의 일반화이다. 마팅게일은 확률과 통계에서 중요한 역할을 하며, 과거의 모든 정보를 알고 있다면 미래의 기댓값이 현재 값과 동일한 과정이다. 마팅게일이라는 말은 원래 도박에서 유래하였다고 한다. 마팅게일을 정의할 때는 조건부 기댓값이 중요한 역할을 한다.

```{definition, name="마팅게일"}
확률과정 $\{X_{n}\}$가 

1. $E |X_{n}| < \infty$

2. $X_{n}$ is adpated to $\mathcal{F}_{n}$. (즉 모든 $n$에 대해 $X_{n}\in\mathcal{F}_{n}$)

3. $E(X_{n+1}|\mathcal{F}_{n})=X_{n}, \text{ for all } n$

을 만족할 때, 이 확률과정을 filtration $\mathcal{F}_{n}$에 대한 **마팅게일(martingale)**이라 부른다.

```
